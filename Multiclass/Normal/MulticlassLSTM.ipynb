{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "traindata['attack_cat'] = lb_make.fit_transform(traindata['attack_cat'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "testdata['attack_cat'] = lb_make.fit_transform(testdata['attack_cat'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-2]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-2]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "Y = to_categorical(Y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],1,X.shape[1]))\n",
    "x = np.reshape(x, (x.shape[0],1,x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, input_shape=(None, 41))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4,input_dim=41)) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "a=[]\n",
    "folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 1.5309 - accuracy: 0.4908 - val_loss: 1.3923 - val_accuracy: 0.5320\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.4076 - accuracy: 0.5181 - val_loss: 1.3762 - val_accuracy: 0.5340\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.3951 - accuracy: 0.5229 - val_loss: 1.3684 - val_accuracy: 0.5349\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.3871 - accuracy: 0.5258 - val_loss: 1.3625 - val_accuracy: 0.5354\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 1.3796 - accuracy: 0.5283 - val_loss: 1.3571 - val_accuracy: 0.5359\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.3732 - accuracy: 0.5295 - val_loss: 1.3494 - val_accuracy: 0.5360\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 1.3654 - accuracy: 0.5303 - val_loss: 1.3432 - val_accuracy: 0.5361\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.3575 - accuracy: 0.5307 - val_loss: 1.3332 - val_accuracy: 0.5361\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.3461 - accuracy: 0.5317 - val_loss: 1.3230 - val_accuracy: 0.5363\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.3339 - accuracy: 0.5317 - val_loss: 1.3076 - val_accuracy: 0.5365\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.3192 - accuracy: 0.5326 - val_loss: 1.2932 - val_accuracy: 0.5367\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 1.3046 - accuracy: 0.5337 - val_loss: 1.2784 - val_accuracy: 0.5378\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 1.2891 - accuracy: 0.5359 - val_loss: 1.2623 - val_accuracy: 0.5378\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.2752 - accuracy: 0.5394 - val_loss: 1.2504 - val_accuracy: 0.5379\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 18s 128us/step - loss: 1.2655 - accuracy: 0.5431 - val_loss: 1.2384 - val_accuracy: 0.5378\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 1.2550 - accuracy: 0.5522 - val_loss: 1.2287 - val_accuracy: 0.5377\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.2461 - accuracy: 0.5640 - val_loss: 1.2190 - val_accuracy: 0.5942\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.2383 - accuracy: 0.5746 - val_loss: 1.2143 - val_accuracy: 0.5969\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.2325 - accuracy: 0.5804 - val_loss: 1.2027 - val_accuracy: 0.5941\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 1.2249 - accuracy: 0.5831 - val_loss: 1.1963 - val_accuracy: 0.5942\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.2198 - accuracy: 0.5851 - val_loss: 1.1898 - val_accuracy: 0.5969\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.2153 - accuracy: 0.5865 - val_loss: 1.1875 - val_accuracy: 0.5942\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.2122 - accuracy: 0.5875 - val_loss: 1.1806 - val_accuracy: 0.5969\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 1.2080 - accuracy: 0.5885 - val_loss: 1.1794 - val_accuracy: 0.5982\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 18s 128us/step - loss: 1.2039 - accuracy: 0.5900 - val_loss: 1.1728 - val_accuracy: 0.5968\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 17s 125us/step - loss: 1.2020 - accuracy: 0.5912 - val_loss: 1.1710 - val_accuracy: 0.5971\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.1989 - accuracy: 0.5912 - val_loss: 1.1687 - val_accuracy: 0.5985\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 18s 125us/step - loss: 1.1970 - accuracy: 0.5917 - val_loss: 1.1632 - val_accuracy: 0.5969\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.1937 - accuracy: 0.5925 - val_loss: 1.1618 - val_accuracy: 0.5985\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 18s 125us/step - loss: 1.1932 - accuracy: 0.5917 - val_loss: 1.1582 - val_accuracy: 0.5971\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 1.1902 - accuracy: 0.5927 - val_loss: 1.1568 - val_accuracy: 0.5969\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 1.1884 - accuracy: 0.5931 - val_loss: 1.1552 - val_accuracy: 0.5990\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 1.1863 - accuracy: 0.5933 - val_loss: 1.1522 - val_accuracy: 0.5972\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1859 - accuracy: 0.5932 - val_loss: 1.1518 - val_accuracy: 0.5975\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.1840 - accuracy: 0.5929 - val_loss: 1.1480 - val_accuracy: 0.5970\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1827 - accuracy: 0.5935 - val_loss: 1.1474 - val_accuracy: 0.5970\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1814 - accuracy: 0.5936 - val_loss: 1.1485 - val_accuracy: 0.5988\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1788 - accuracy: 0.5947 - val_loss: 1.1442 - val_accuracy: 0.5975\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 1.1796 - accuracy: 0.5941 - val_loss: 1.1449 - val_accuracy: 0.5982\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1795 - accuracy: 0.5937 - val_loss: 1.1430 - val_accuracy: 0.5987\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1766 - accuracy: 0.5940 - val_loss: 1.1433 - val_accuracy: 0.5972\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1751 - accuracy: 0.5948 - val_loss: 1.1409 - val_accuracy: 0.5970\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1756 - accuracy: 0.5944 - val_loss: 1.1423 - val_accuracy: 0.5977\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.1750 - accuracy: 0.5949 - val_loss: 1.1397 - val_accuracy: 0.5986\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1745 - accuracy: 0.5944 - val_loss: 1.1390 - val_accuracy: 0.5976\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 1.1740 - accuracy: 0.5935 - val_loss: 1.1395 - val_accuracy: 0.5971\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.1727 - accuracy: 0.5940 - val_loss: 1.1375 - val_accuracy: 0.5975\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.1705 - accuracy: 0.5947 - val_loss: 1.1365 - val_accuracy: 0.5969\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1687 - accuracy: 0.5935 - val_loss: 1.1339 - val_accuracy: 0.5982\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.1660 - accuracy: 0.5936 - val_loss: 1.1319 - val_accuracy: 0.5990\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 1.1640 - accuracy: 0.5927 - val_loss: 1.1296 - val_accuracy: 0.5970\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.1599 - accuracy: 0.5947 - val_loss: 1.1289 - val_accuracy: 0.5984\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 1.1614 - accuracy: 0.5950 - val_loss: 1.1290 - val_accuracy: 0.5998\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1580 - accuracy: 0.5947 - val_loss: 1.1297 - val_accuracy: 0.5989\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1571 - accuracy: 0.5961 - val_loss: 1.1250 - val_accuracy: 0.5986\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1577 - accuracy: 0.5957 - val_loss: 1.1249 - val_accuracy: 0.5982\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1561 - accuracy: 0.5957 - val_loss: 1.1261 - val_accuracy: 0.5964\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1548 - accuracy: 0.5951 - val_loss: 1.1249 - val_accuracy: 0.5981\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1565 - accuracy: 0.5958 - val_loss: 1.1262 - val_accuracy: 0.5990\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1557 - accuracy: 0.5955 - val_loss: 1.1232 - val_accuracy: 0.5984\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1553 - accuracy: 0.5959 - val_loss: 1.1235 - val_accuracy: 0.5999\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1551 - accuracy: 0.5953 - val_loss: 1.1348 - val_accuracy: 0.5984\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1545 - accuracy: 0.5954 - val_loss: 1.1232 - val_accuracy: 0.5999\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1546 - accuracy: 0.5959 - val_loss: 1.1240 - val_accuracy: 0.5972\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1541 - accuracy: 0.5955 - val_loss: 1.1260 - val_accuracy: 0.5987\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1529 - accuracy: 0.5956 - val_loss: 1.1211 - val_accuracy: 0.6000\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1524 - accuracy: 0.5959 - val_loss: 1.1203 - val_accuracy: 0.5987\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1528 - accuracy: 0.5957 - val_loss: 1.1222 - val_accuracy: 0.5989\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1513 - accuracy: 0.5957 - val_loss: 1.1223 - val_accuracy: 0.5981\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1509 - accuracy: 0.5960 - val_loss: 1.1202 - val_accuracy: 0.5980\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1516 - accuracy: 0.5962 - val_loss: 1.1211 - val_accuracy: 0.5995\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1518 - accuracy: 0.5948 - val_loss: 1.1215 - val_accuracy: 0.5975\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1515 - accuracy: 0.5962 - val_loss: 1.1205 - val_accuracy: 0.5984\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1517 - accuracy: 0.5953 - val_loss: 1.1194 - val_accuracy: 0.6003\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1504 - accuracy: 0.5964 - val_loss: 1.1180 - val_accuracy: 0.5990\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1500 - accuracy: 0.5958 - val_loss: 1.1182 - val_accuracy: 0.5999\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1495 - accuracy: 0.5963 - val_loss: 1.1193 - val_accuracy: 0.5980\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1488 - accuracy: 0.5959 - val_loss: 1.1190 - val_accuracy: 0.5985\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1490 - accuracy: 0.5957 - val_loss: 1.1184 - val_accuracy: 0.5993\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 1.1487 - accuracy: 0.5964 - val_loss: 1.1179 - val_accuracy: 0.6000\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1487 - accuracy: 0.5961 - val_loss: 1.1273 - val_accuracy: 0.5944\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 1.1485 - accuracy: 0.5960 - val_loss: 1.1175 - val_accuracy: 0.5994\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1484 - accuracy: 0.5967 - val_loss: 1.1172 - val_accuracy: 0.5986\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 118us/step - loss: 1.1490 - accuracy: 0.5960 - val_loss: 1.1170 - val_accuracy: 0.6000\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1476 - accuracy: 0.5966 - val_loss: 1.1174 - val_accuracy: 0.6002\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1478 - accuracy: 0.5956 - val_loss: 1.1156 - val_accuracy: 0.5981\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1482 - accuracy: 0.5958 - val_loss: 1.1171 - val_accuracy: 0.5987\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1479 - accuracy: 0.5967 - val_loss: 1.1171 - val_accuracy: 0.5987\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1464 - accuracy: 0.5958 - val_loss: 1.1180 - val_accuracy: 0.5984\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1467 - accuracy: 0.5964 - val_loss: 1.1168 - val_accuracy: 0.6005\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1482 - accuracy: 0.5962 - val_loss: 1.1184 - val_accuracy: 0.5977\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1456 - accuracy: 0.5965 - val_loss: 1.1154 - val_accuracy: 0.5985\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1465 - accuracy: 0.5962 - val_loss: 1.1183 - val_accuracy: 0.5977\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1467 - accuracy: 0.5966 - val_loss: 1.1163 - val_accuracy: 0.5997\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 118us/step - loss: 1.1472 - accuracy: 0.5967 - val_loss: 1.1187 - val_accuracy: 0.5979\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1470 - accuracy: 0.5952 - val_loss: 1.1238 - val_accuracy: 0.5969\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1456 - accuracy: 0.5964 - val_loss: 1.1164 - val_accuracy: 0.5984\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1455 - accuracy: 0.5961 - val_loss: 1.1142 - val_accuracy: 0.5996\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1472 - accuracy: 0.5962 - val_loss: 1.1171 - val_accuracy: 0.5980\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1458 - accuracy: 0.5969 - val_loss: 1.1130 - val_accuracy: 0.5996\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1452 - accuracy: 0.5964 - val_loss: 1.1133 - val_accuracy: 0.6003\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 1.1458 - accuracy: 0.5966 - val_loss: 1.1135 - val_accuracy: 0.5987\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1451 - accuracy: 0.5958 - val_loss: 1.1138 - val_accuracy: 0.5992\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 1.1447 - accuracy: 0.5969 - val_loss: 1.1166 - val_accuracy: 0.6001\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.1450 - accuracy: 0.5961 - val_loss: 1.1116 - val_accuracy: 0.5985\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 1.1443 - accuracy: 0.5954 - val_loss: 1.1151 - val_accuracy: 0.5987\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1436 - accuracy: 0.5973 - val_loss: 1.1131 - val_accuracy: 0.5980\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1443 - accuracy: 0.5958 - val_loss: 1.1122 - val_accuracy: 0.6000\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1442 - accuracy: 0.5961 - val_loss: 1.1134 - val_accuracy: 0.6000\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 1.1436 - accuracy: 0.5966 - val_loss: 1.1145 - val_accuracy: 0.5997\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1435 - accuracy: 0.5957 - val_loss: 1.1149 - val_accuracy: 0.5992\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1438 - accuracy: 0.5963 - val_loss: 1.1104 - val_accuracy: 0.5989\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1437 - accuracy: 0.5961 - val_loss: 1.1104 - val_accuracy: 0.5998\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1430 - accuracy: 0.5965 - val_loss: 1.1152 - val_accuracy: 0.5980\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1431 - accuracy: 0.5958 - val_loss: 1.1109 - val_accuracy: 0.5998\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1422 - accuracy: 0.5960 - val_loss: 1.1124 - val_accuracy: 0.6000\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1420 - accuracy: 0.5963 - val_loss: 1.1109 - val_accuracy: 0.5999\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1430 - accuracy: 0.5963 - val_loss: 1.1086 - val_accuracy: 0.5985\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1428 - accuracy: 0.5970 - val_loss: 1.1156 - val_accuracy: 0.5966\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1416 - accuracy: 0.5962 - val_loss: 1.1080 - val_accuracy: 0.6006\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1432 - accuracy: 0.5963 - val_loss: 1.1106 - val_accuracy: 0.5985\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1422 - accuracy: 0.5970 - val_loss: 1.1094 - val_accuracy: 0.6001\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1402 - accuracy: 0.5972 - val_loss: 1.1156 - val_accuracy: 0.5978\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1422 - accuracy: 0.5973 - val_loss: 1.1092 - val_accuracy: 0.5991\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1414 - accuracy: 0.5952 - val_loss: 1.1097 - val_accuracy: 0.5985\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1417 - accuracy: 0.5965 - val_loss: 1.1142 - val_accuracy: 0.6006\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1411 - accuracy: 0.5966 - val_loss: 1.1065 - val_accuracy: 0.6001\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 1.1414 - accuracy: 0.5968 - val_loss: 1.1163 - val_accuracy: 0.5978\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1416 - accuracy: 0.5969 - val_loss: 1.1069 - val_accuracy: 0.6008\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1414 - accuracy: 0.5967 - val_loss: 1.1099 - val_accuracy: 0.5975\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1415 - accuracy: 0.5970 - val_loss: 1.1073 - val_accuracy: 0.5982\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1402 - accuracy: 0.5967 - val_loss: 1.1072 - val_accuracy: 0.5996\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1414 - accuracy: 0.5974 - val_loss: 1.1088 - val_accuracy: 0.5975\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1407 - accuracy: 0.5967 - val_loss: 1.1060 - val_accuracy: 0.5994\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1400 - accuracy: 0.5966 - val_loss: 1.1089 - val_accuracy: 0.5943\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1406 - accuracy: 0.5954 - val_loss: 1.1055 - val_accuracy: 0.5986\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1396 - accuracy: 0.5971 - val_loss: 1.1070 - val_accuracy: 0.6006\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1394 - accuracy: 0.5968 - val_loss: 1.1075 - val_accuracy: 0.6008\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1393 - accuracy: 0.5961 - val_loss: 1.1116 - val_accuracy: 0.5981\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1391 - accuracy: 0.5956 - val_loss: 1.1061 - val_accuracy: 0.6018\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.1394 - accuracy: 0.5969 - val_loss: 1.1074 - val_accuracy: 0.5978\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1396 - accuracy: 0.5969 - val_loss: 1.1045 - val_accuracy: 0.5991\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1395 - accuracy: 0.5962 - val_loss: 1.1105 - val_accuracy: 0.5978\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1402 - accuracy: 0.5965 - val_loss: 1.1058 - val_accuracy: 0.6005\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1396 - accuracy: 0.5955 - val_loss: 1.1050 - val_accuracy: 0.6003\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1394 - accuracy: 0.5964 - val_loss: 1.1118 - val_accuracy: 0.5995\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1399 - accuracy: 0.5964 - val_loss: 1.1042 - val_accuracy: 0.6004\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1390 - accuracy: 0.5970 - val_loss: 1.1055 - val_accuracy: 0.5990\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1382 - accuracy: 0.5965 - val_loss: 1.1064 - val_accuracy: 0.5989\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1371 - accuracy: 0.5978 - val_loss: 1.1147 - val_accuracy: 0.5982\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1381 - accuracy: 0.5973 - val_loss: 1.1051 - val_accuracy: 0.5975\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1385 - accuracy: 0.5964 - val_loss: 1.1041 - val_accuracy: 0.6006\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1380 - accuracy: 0.5968 - val_loss: 1.1038 - val_accuracy: 0.6003\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1382 - accuracy: 0.5969 - val_loss: 1.1038 - val_accuracy: 0.6005\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1386 - accuracy: 0.5954 - val_loss: 1.1081 - val_accuracy: 0.5995\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1384 - accuracy: 0.5957 - val_loss: 1.1031 - val_accuracy: 0.5989\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1377 - accuracy: 0.5961 - val_loss: 1.1087 - val_accuracy: 0.5977\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1387 - accuracy: 0.5958 - val_loss: 1.1057 - val_accuracy: 0.5995\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1382 - accuracy: 0.5964 - val_loss: 1.1119 - val_accuracy: 0.5992\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1370 - accuracy: 0.5959 - val_loss: 1.1062 - val_accuracy: 0.5986\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1378 - accuracy: 0.5962 - val_loss: 1.1070 - val_accuracy: 0.5978\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1379 - accuracy: 0.5958 - val_loss: 1.1041 - val_accuracy: 0.5986\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1361 - accuracy: 0.5964 - val_loss: 1.1071 - val_accuracy: 0.5987\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1371 - accuracy: 0.5962 - val_loss: 1.1053 - val_accuracy: 0.6007\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1369 - accuracy: 0.5965 - val_loss: 1.1052 - val_accuracy: 0.5990\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1375 - accuracy: 0.5957 - val_loss: 1.1050 - val_accuracy: 0.6003\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1371 - accuracy: 0.5964 - val_loss: 1.1087 - val_accuracy: 0.6003\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1367 - accuracy: 0.5965 - val_loss: 1.1068 - val_accuracy: 0.5992\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1368 - accuracy: 0.5966 - val_loss: 1.1050 - val_accuracy: 0.5990\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1358 - accuracy: 0.5962 - val_loss: 1.1030 - val_accuracy: 0.5981\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1366 - accuracy: 0.5968 - val_loss: 1.1095 - val_accuracy: 0.6033\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1364 - accuracy: 0.5975 - val_loss: 1.1027 - val_accuracy: 0.5991\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1353 - accuracy: 0.5968 - val_loss: 1.1018 - val_accuracy: 0.6000\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1349 - accuracy: 0.5965 - val_loss: 1.1018 - val_accuracy: 0.5997\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1362 - accuracy: 0.5963 - val_loss: 1.1044 - val_accuracy: 0.5995\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1356 - accuracy: 0.5965 - val_loss: 1.1030 - val_accuracy: 0.6003\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1359 - accuracy: 0.5962 - val_loss: 1.1022 - val_accuracy: 0.6002\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1367 - accuracy: 0.5953 - val_loss: 1.1023 - val_accuracy: 0.5994\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1367 - accuracy: 0.5960 - val_loss: 1.1052 - val_accuracy: 0.5990\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1354 - accuracy: 0.5959 - val_loss: 1.1026 - val_accuracy: 0.5984\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1345 - accuracy: 0.5952 - val_loss: 1.1003 - val_accuracy: 0.6007\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1356 - accuracy: 0.5963 - val_loss: 1.1059 - val_accuracy: 0.6002\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1359 - accuracy: 0.5960 - val_loss: 1.1009 - val_accuracy: 0.5999\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1352 - accuracy: 0.5964 - val_loss: 1.1017 - val_accuracy: 0.6003\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1349 - accuracy: 0.5967 - val_loss: 1.1094 - val_accuracy: 0.5938\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1349 - accuracy: 0.5973 - val_loss: 1.1089 - val_accuracy: 0.6004\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1349 - accuracy: 0.5959 - val_loss: 1.1097 - val_accuracy: 0.6012\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1356 - accuracy: 0.5962 - val_loss: 1.1043 - val_accuracy: 0.5994\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1353 - accuracy: 0.5955 - val_loss: 1.1040 - val_accuracy: 0.5996\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1341 - accuracy: 0.5951 - val_loss: 1.1030 - val_accuracy: 0.5991\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1340 - accuracy: 0.5956 - val_loss: 1.0995 - val_accuracy: 0.6005\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1338 - accuracy: 0.5963 - val_loss: 1.1008 - val_accuracy: 0.5998\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1341 - accuracy: 0.5967 - val_loss: 1.1009 - val_accuracy: 0.5997\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1351 - accuracy: 0.5958 - val_loss: 1.1028 - val_accuracy: 0.5991\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1335 - accuracy: 0.5961 - val_loss: 1.1003 - val_accuracy: 0.6004\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1343 - accuracy: 0.5957 - val_loss: 1.0996 - val_accuracy: 0.6009\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1337 - accuracy: 0.5971 - val_loss: 1.1020 - val_accuracy: 0.6001\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1344 - accuracy: 0.5960 - val_loss: 1.1072 - val_accuracy: 0.5992\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1342 - accuracy: 0.5956 - val_loss: 1.1014 - val_accuracy: 0.5980\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1336 - accuracy: 0.5965 - val_loss: 1.0998 - val_accuracy: 0.6003\n",
      "accuracy: 60.03%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1327 - accuracy: 0.5957 - val_loss: 1.1071 - val_accuracy: 0.5996\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1327 - accuracy: 0.5959 - val_loss: 1.1001 - val_accuracy: 0.6018\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1323 - accuracy: 0.5956 - val_loss: 1.1013 - val_accuracy: 0.6015\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1331 - accuracy: 0.5963 - val_loss: 1.1027 - val_accuracy: 0.6014\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1339 - accuracy: 0.5955 - val_loss: 1.1012 - val_accuracy: 0.6035\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1327 - accuracy: 0.5955 - val_loss: 1.1056 - val_accuracy: 0.6005\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1323 - accuracy: 0.5945 - val_loss: 1.0996 - val_accuracy: 0.6012\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1311 - accuracy: 0.5970 - val_loss: 1.1021 - val_accuracy: 0.5997\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1324 - accuracy: 0.5960 - val_loss: 1.1013 - val_accuracy: 0.6004\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1314 - accuracy: 0.5966 - val_loss: 1.1030 - val_accuracy: 0.6023\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1323 - accuracy: 0.5960 - val_loss: 1.1001 - val_accuracy: 0.6019\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1320 - accuracy: 0.5950 - val_loss: 1.1057 - val_accuracy: 0.6011\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1314 - accuracy: 0.5960 - val_loss: 1.1044 - val_accuracy: 0.6003\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1313 - accuracy: 0.5963 - val_loss: 1.0990 - val_accuracy: 0.6015\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1321 - accuracy: 0.5957 - val_loss: 1.1003 - val_accuracy: 0.6018\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1327 - accuracy: 0.5963 - val_loss: 1.0987 - val_accuracy: 0.6020\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1313 - accuracy: 0.5959 - val_loss: 1.0999 - val_accuracy: 0.6031\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1322 - accuracy: 0.5962 - val_loss: 1.1005 - val_accuracy: 0.6012\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1303 - accuracy: 0.5961 - val_loss: 1.1015 - val_accuracy: 0.6012\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1311 - accuracy: 0.5965 - val_loss: 1.0996 - val_accuracy: 0.6008\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1308 - accuracy: 0.5955 - val_loss: 1.1002 - val_accuracy: 0.6021\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1318 - accuracy: 0.5956 - val_loss: 1.1063 - val_accuracy: 0.6006\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1315 - accuracy: 0.5962 - val_loss: 1.1008 - val_accuracy: 0.6022\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1312 - accuracy: 0.5962 - val_loss: 1.0978 - val_accuracy: 0.6007\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1300 - accuracy: 0.5966 - val_loss: 1.0981 - val_accuracy: 0.6014\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1299 - accuracy: 0.5964 - val_loss: 1.0996 - val_accuracy: 0.6007\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1291 - accuracy: 0.5969 - val_loss: 1.0998 - val_accuracy: 0.6024\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1300 - accuracy: 0.5963 - val_loss: 1.1011 - val_accuracy: 0.6012\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1289 - accuracy: 0.5969 - val_loss: 1.0989 - val_accuracy: 0.6039\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1295 - accuracy: 0.5969 - val_loss: 1.1060 - val_accuracy: 0.6008\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1298 - accuracy: 0.5964 - val_loss: 1.0988 - val_accuracy: 0.6004\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1296 - accuracy: 0.5966 - val_loss: 1.0989 - val_accuracy: 0.6017\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1291 - accuracy: 0.5965 - val_loss: 1.0981 - val_accuracy: 0.6023\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1292 - accuracy: 0.5957 - val_loss: 1.1047 - val_accuracy: 0.6040\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1289 - accuracy: 0.5965 - val_loss: 1.1072 - val_accuracy: 0.5997\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1280 - accuracy: 0.5967 - val_loss: 1.0977 - val_accuracy: 0.6016\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1274 - accuracy: 0.5971 - val_loss: 1.0989 - val_accuracy: 0.6019\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1287 - accuracy: 0.5971 - val_loss: 1.0957 - val_accuracy: 0.6016\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1286 - accuracy: 0.5963 - val_loss: 1.0988 - val_accuracy: 0.6021\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1288 - accuracy: 0.5963 - val_loss: 1.0982 - val_accuracy: 0.6015\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1284 - accuracy: 0.5971 - val_loss: 1.1024 - val_accuracy: 0.6017\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1298 - accuracy: 0.5960 - val_loss: 1.0977 - val_accuracy: 0.6028\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1282 - accuracy: 0.5963 - val_loss: 1.0955 - val_accuracy: 0.6026\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1276 - accuracy: 0.5971 - val_loss: 1.1071 - val_accuracy: 0.6040\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1280 - accuracy: 0.5973 - val_loss: 1.1046 - val_accuracy: 0.6003\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1270 - accuracy: 0.5979 - val_loss: 1.0974 - val_accuracy: 0.6018\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1282 - accuracy: 0.5968 - val_loss: 1.0950 - val_accuracy: 0.6012\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1274 - accuracy: 0.5966 - val_loss: 1.0963 - val_accuracy: 0.6042\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1268 - accuracy: 0.5974 - val_loss: 1.0963 - val_accuracy: 0.6043\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1277 - accuracy: 0.5970 - val_loss: 1.0946 - val_accuracy: 0.6017\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1268 - accuracy: 0.5978 - val_loss: 1.0958 - val_accuracy: 0.6015\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1268 - accuracy: 0.5961 - val_loss: 1.0951 - val_accuracy: 0.6028\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1272 - accuracy: 0.5969 - val_loss: 1.0955 - val_accuracy: 0.6028\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1276 - accuracy: 0.5966 - val_loss: 1.0990 - val_accuracy: 0.5998\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1274 - accuracy: 0.5973 - val_loss: 1.0940 - val_accuracy: 0.6009\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1281 - accuracy: 0.5971 - val_loss: 1.0939 - val_accuracy: 0.6014\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1273 - accuracy: 0.5969 - val_loss: 1.0990 - val_accuracy: 0.6015\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1259 - accuracy: 0.5978 - val_loss: 1.0941 - val_accuracy: 0.6021\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1253 - accuracy: 0.5969 - val_loss: 1.0952 - val_accuracy: 0.6030\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1265 - accuracy: 0.5971 - val_loss: 1.0994 - val_accuracy: 0.6022\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1261 - accuracy: 0.5979 - val_loss: 1.1070 - val_accuracy: 0.6008\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1252 - accuracy: 0.5981 - val_loss: 1.1009 - val_accuracy: 0.6019\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1251 - accuracy: 0.5965 - val_loss: 1.0949 - val_accuracy: 0.6046\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1257 - accuracy: 0.5975 - val_loss: 1.0948 - val_accuracy: 0.6022\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1257 - accuracy: 0.5972 - val_loss: 1.0956 - val_accuracy: 0.6022\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1255 - accuracy: 0.5967 - val_loss: 1.0963 - val_accuracy: 0.6008\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1253 - accuracy: 0.5979 - val_loss: 1.0925 - val_accuracy: 0.6019\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1249 - accuracy: 0.5979 - val_loss: 1.1003 - val_accuracy: 0.6017\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1234 - accuracy: 0.5982 - val_loss: 1.0985 - val_accuracy: 0.6000\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1247 - accuracy: 0.5975 - val_loss: 1.0961 - val_accuracy: 0.6025\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1234 - accuracy: 0.5969 - val_loss: 1.0922 - val_accuracy: 0.6024\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1241 - accuracy: 0.5972 - val_loss: 1.0935 - val_accuracy: 0.6004\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1244 - accuracy: 0.5969 - val_loss: 1.0924 - val_accuracy: 0.6028\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1246 - accuracy: 0.5978 - val_loss: 1.0935 - val_accuracy: 0.6048\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1251 - accuracy: 0.5976 - val_loss: 1.0943 - val_accuracy: 0.6014\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1235 - accuracy: 0.5969 - val_loss: 1.0943 - val_accuracy: 0.6019\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1238 - accuracy: 0.5983 - val_loss: 1.0911 - val_accuracy: 0.6026\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1233 - accuracy: 0.5972 - val_loss: 1.0959 - val_accuracy: 0.6059\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1240 - accuracy: 0.5969 - val_loss: 1.0918 - val_accuracy: 0.6021\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1237 - accuracy: 0.5974 - val_loss: 1.0907 - val_accuracy: 0.6016\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1246 - accuracy: 0.5968 - val_loss: 1.0902 - val_accuracy: 0.6034\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1239 - accuracy: 0.5976 - val_loss: 1.0941 - val_accuracy: 0.6016\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1235 - accuracy: 0.5969 - val_loss: 1.1014 - val_accuracy: 0.6011\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1230 - accuracy: 0.5975 - val_loss: 1.0928 - val_accuracy: 0.6026\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1221 - accuracy: 0.5971 - val_loss: 1.0902 - val_accuracy: 0.6024\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1231 - accuracy: 0.5972 - val_loss: 1.0919 - val_accuracy: 0.6017\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1226 - accuracy: 0.5983 - val_loss: 1.0913 - val_accuracy: 0.6022\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1234 - accuracy: 0.5972 - val_loss: 1.0938 - val_accuracy: 0.6019\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1222 - accuracy: 0.5978 - val_loss: 1.0912 - val_accuracy: 0.6035\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1224 - accuracy: 0.5982 - val_loss: 1.0940 - val_accuracy: 0.6029\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1212 - accuracy: 0.5978 - val_loss: 1.0893 - val_accuracy: 0.6025\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1233 - accuracy: 0.5966 - val_loss: 1.0924 - val_accuracy: 0.6006\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1242 - accuracy: 0.5972 - val_loss: 1.0966 - val_accuracy: 0.6013\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1228 - accuracy: 0.5975 - val_loss: 1.0900 - val_accuracy: 0.5990\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1220 - accuracy: 0.5967 - val_loss: 1.0910 - val_accuracy: 0.6024\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1226 - accuracy: 0.5971 - val_loss: 1.0887 - val_accuracy: 0.6025\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1207 - accuracy: 0.5979 - val_loss: 1.0887 - val_accuracy: 0.6026\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1217 - accuracy: 0.5977 - val_loss: 1.0928 - val_accuracy: 0.6032\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1223 - accuracy: 0.5972 - val_loss: 1.0914 - val_accuracy: 0.6022\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1220 - accuracy: 0.5974 - val_loss: 1.0880 - val_accuracy: 0.6020\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1226 - accuracy: 0.5974 - val_loss: 1.0922 - val_accuracy: 0.6084\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1210 - accuracy: 0.5985 - val_loss: 1.0893 - val_accuracy: 0.6034\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1207 - accuracy: 0.5976 - val_loss: 1.0919 - val_accuracy: 0.6038\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1191 - accuracy: 0.5972 - val_loss: 1.0902 - val_accuracy: 0.6064\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1200 - accuracy: 0.5978 - val_loss: 1.0882 - val_accuracy: 0.6025\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1215 - accuracy: 0.5980 - val_loss: 1.0890 - val_accuracy: 0.6027\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1204 - accuracy: 0.5970 - val_loss: 1.0951 - val_accuracy: 0.6018\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1214 - accuracy: 0.5978 - val_loss: 1.0886 - val_accuracy: 0.6031\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1200 - accuracy: 0.5972 - val_loss: 1.0883 - val_accuracy: 0.6027\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1205 - accuracy: 0.5972 - val_loss: 1.0885 - val_accuracy: 0.6025\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1210 - accuracy: 0.5978 - val_loss: 1.0868 - val_accuracy: 0.6023\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1213 - accuracy: 0.5969 - val_loss: 1.1008 - val_accuracy: 0.6003\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1204 - accuracy: 0.5970 - val_loss: 1.0913 - val_accuracy: 0.6062\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1194 - accuracy: 0.5985 - val_loss: 1.0887 - val_accuracy: 0.6031\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1198 - accuracy: 0.5983 - val_loss: 1.0919 - val_accuracy: 0.6067\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1192 - accuracy: 0.5972 - val_loss: 1.0919 - val_accuracy: 0.6008\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1190 - accuracy: 0.5983 - val_loss: 1.0891 - val_accuracy: 0.6022\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1202 - accuracy: 0.5971 - val_loss: 1.0865 - val_accuracy: 0.6020\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1205 - accuracy: 0.5985 - val_loss: 1.0881 - val_accuracy: 0.6044\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1197 - accuracy: 0.5970 - val_loss: 1.0859 - val_accuracy: 0.6043\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1191 - accuracy: 0.5973 - val_loss: 1.0877 - val_accuracy: 0.6031\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1189 - accuracy: 0.5978 - val_loss: 1.0880 - val_accuracy: 0.6033\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1184 - accuracy: 0.5982 - val_loss: 1.0950 - val_accuracy: 0.6020\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1180 - accuracy: 0.5966 - val_loss: 1.0859 - val_accuracy: 0.6032\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1181 - accuracy: 0.5984 - val_loss: 1.0894 - val_accuracy: 0.6100\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1182 - accuracy: 0.5980 - val_loss: 1.0856 - val_accuracy: 0.6028\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1200 - accuracy: 0.5975 - val_loss: 1.0873 - val_accuracy: 0.6044\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1178 - accuracy: 0.5984 - val_loss: 1.0865 - val_accuracy: 0.6075\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1180 - accuracy: 0.5987 - val_loss: 1.0890 - val_accuracy: 0.6001\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1166 - accuracy: 0.5974 - val_loss: 1.0875 - val_accuracy: 0.6061\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1186 - accuracy: 0.5975 - val_loss: 1.0905 - val_accuracy: 0.6033\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1188 - accuracy: 0.5985 - val_loss: 1.0841 - val_accuracy: 0.6028\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1179 - accuracy: 0.5978 - val_loss: 1.0891 - val_accuracy: 0.6029\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1171 - accuracy: 0.5968 - val_loss: 1.0865 - val_accuracy: 0.6043\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1172 - accuracy: 0.5974 - val_loss: 1.0844 - val_accuracy: 0.6024\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1182 - accuracy: 0.5973 - val_loss: 1.0842 - val_accuracy: 0.6049\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1173 - accuracy: 0.5977 - val_loss: 1.1069 - val_accuracy: 0.6024\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1167 - accuracy: 0.5976 - val_loss: 1.0840 - val_accuracy: 0.6033\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1169 - accuracy: 0.5984 - val_loss: 1.0856 - val_accuracy: 0.6026\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1171 - accuracy: 0.5983 - val_loss: 1.0867 - val_accuracy: 0.6115\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1156 - accuracy: 0.5977 - val_loss: 1.0844 - val_accuracy: 0.6024\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1159 - accuracy: 0.5988 - val_loss: 1.0854 - val_accuracy: 0.6021\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1167 - accuracy: 0.5976 - val_loss: 1.0832 - val_accuracy: 0.6028\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1177 - accuracy: 0.5975 - val_loss: 1.0828 - val_accuracy: 0.6031\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1161 - accuracy: 0.5982 - val_loss: 1.0912 - val_accuracy: 0.6031\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1176 - accuracy: 0.5970 - val_loss: 1.0927 - val_accuracy: 0.6096\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1153 - accuracy: 0.5977 - val_loss: 1.0841 - val_accuracy: 0.6032\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1162 - accuracy: 0.5987 - val_loss: 1.0855 - val_accuracy: 0.6039\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1163 - accuracy: 0.5983 - val_loss: 1.0821 - val_accuracy: 0.6021\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.1154 - accuracy: 0.5981 - val_loss: 1.0837 - val_accuracy: 0.6033\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1163 - accuracy: 0.5976 - val_loss: 1.0838 - val_accuracy: 0.6019\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1142 - accuracy: 0.5984 - val_loss: 1.0816 - val_accuracy: 0.6028\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1155 - accuracy: 0.5980 - val_loss: 1.0812 - val_accuracy: 0.6021\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1149 - accuracy: 0.5982 - val_loss: 1.0811 - val_accuracy: 0.6032\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1149 - accuracy: 0.5969 - val_loss: 1.0991 - val_accuracy: 0.6024\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1138 - accuracy: 0.5983 - val_loss: 1.0846 - val_accuracy: 0.6026\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1161 - accuracy: 0.5979 - val_loss: 1.0821 - val_accuracy: 0.6028\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1158 - accuracy: 0.5974 - val_loss: 1.0842 - val_accuracy: 0.6027\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1154 - accuracy: 0.5977 - val_loss: 1.0819 - val_accuracy: 0.6055\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1142 - accuracy: 0.5986 - val_loss: 1.0824 - val_accuracy: 0.6019\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1147 - accuracy: 0.5977 - val_loss: 1.0832 - val_accuracy: 0.6036\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1130 - accuracy: 0.5983 - val_loss: 1.0798 - val_accuracy: 0.6025\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1135 - accuracy: 0.5979 - val_loss: 1.0893 - val_accuracy: 0.6011\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1143 - accuracy: 0.5989 - val_loss: 1.0820 - val_accuracy: 0.6028\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1142 - accuracy: 0.5978 - val_loss: 1.0831 - val_accuracy: 0.6085\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1132 - accuracy: 0.5986 - val_loss: 1.0801 - val_accuracy: 0.6029\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1134 - accuracy: 0.5978 - val_loss: 1.0810 - val_accuracy: 0.6036\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1136 - accuracy: 0.5986 - val_loss: 1.0789 - val_accuracy: 0.6043\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1121 - accuracy: 0.5990 - val_loss: 1.0800 - val_accuracy: 0.6034\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1123 - accuracy: 0.5993 - val_loss: 1.0784 - val_accuracy: 0.6040\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1125 - accuracy: 0.5979 - val_loss: 1.0781 - val_accuracy: 0.6043\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1123 - accuracy: 0.5981 - val_loss: 1.0817 - val_accuracy: 0.6009\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1115 - accuracy: 0.5990 - val_loss: 1.0789 - val_accuracy: 0.6025\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1120 - accuracy: 0.5991 - val_loss: 1.0784 - val_accuracy: 0.6040\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1116 - accuracy: 0.5983 - val_loss: 1.0776 - val_accuracy: 0.6020\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1113 - accuracy: 0.5984 - val_loss: 1.0843 - val_accuracy: 0.6032\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1112 - accuracy: 0.5982 - val_loss: 1.0778 - val_accuracy: 0.6021\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1126 - accuracy: 0.5979 - val_loss: 1.0779 - val_accuracy: 0.6041\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1116 - accuracy: 0.5978 - val_loss: 1.0779 - val_accuracy: 0.6032\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1113 - accuracy: 0.5992 - val_loss: 1.0766 - val_accuracy: 0.6022\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1113 - accuracy: 0.5983 - val_loss: 1.0803 - val_accuracy: 0.6042\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1115 - accuracy: 0.5973 - val_loss: 1.0761 - val_accuracy: 0.6017\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1121 - accuracy: 0.5988 - val_loss: 1.0771 - val_accuracy: 0.6059\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1109 - accuracy: 0.5992 - val_loss: 1.0774 - val_accuracy: 0.6027\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1099 - accuracy: 0.5990 - val_loss: 1.0794 - val_accuracy: 0.6022\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1122 - accuracy: 0.5984 - val_loss: 1.0915 - val_accuracy: 0.6009\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1108 - accuracy: 0.5985 - val_loss: 1.0750 - val_accuracy: 0.6027\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1107 - accuracy: 0.5984 - val_loss: 1.0781 - val_accuracy: 0.6036\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1099 - accuracy: 0.5984 - val_loss: 1.0767 - val_accuracy: 0.6068\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1103 - accuracy: 0.5986 - val_loss: 1.0754 - val_accuracy: 0.6040\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1098 - accuracy: 0.5987 - val_loss: 1.0780 - val_accuracy: 0.6080\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1095 - accuracy: 0.5982 - val_loss: 1.0788 - val_accuracy: 0.6075\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1104 - accuracy: 0.5982 - val_loss: 1.0766 - val_accuracy: 0.6050\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1109 - accuracy: 0.5979 - val_loss: 1.0786 - val_accuracy: 0.6019\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1092 - accuracy: 0.5994 - val_loss: 1.0786 - val_accuracy: 0.6017\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1091 - accuracy: 0.5987 - val_loss: 1.0738 - val_accuracy: 0.6026\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1095 - accuracy: 0.5979 - val_loss: 1.1008 - val_accuracy: 0.5946\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1096 - accuracy: 0.5992 - val_loss: 1.0834 - val_accuracy: 0.6053\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1087 - accuracy: 0.5989 - val_loss: 1.0754 - val_accuracy: 0.6039\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1093 - accuracy: 0.5985 - val_loss: 1.0916 - val_accuracy: 0.6019\n",
      "accuracy: 60.19%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1091 - accuracy: 0.5986 - val_loss: 1.0729 - val_accuracy: 0.6039\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1092 - accuracy: 0.5981 - val_loss: 1.0709 - val_accuracy: 0.6081\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1087 - accuracy: 0.5990 - val_loss: 1.0704 - val_accuracy: 0.6049\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1093 - accuracy: 0.5985 - val_loss: 1.0707 - val_accuracy: 0.6027\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1092 - accuracy: 0.5986 - val_loss: 1.0725 - val_accuracy: 0.6089\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1087 - accuracy: 0.5976 - val_loss: 1.0808 - val_accuracy: 0.6052\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1089 - accuracy: 0.5991 - val_loss: 1.0794 - val_accuracy: 0.6042\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1084 - accuracy: 0.5984 - val_loss: 1.0705 - val_accuracy: 0.6030\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1079 - accuracy: 0.5990 - val_loss: 1.0826 - val_accuracy: 0.6018\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1083 - accuracy: 0.5980 - val_loss: 1.0701 - val_accuracy: 0.6053\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1088 - accuracy: 0.5986 - val_loss: 1.0715 - val_accuracy: 0.6048\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1077 - accuracy: 0.5986 - val_loss: 1.0711 - val_accuracy: 0.6028\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1075 - accuracy: 0.5988 - val_loss: 1.0705 - val_accuracy: 0.6035\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1071 - accuracy: 0.5985 - val_loss: 1.0686 - val_accuracy: 0.6034\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1076 - accuracy: 0.5984 - val_loss: 1.0770 - val_accuracy: 0.6034\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1072 - accuracy: 0.5990 - val_loss: 1.0692 - val_accuracy: 0.6032\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1073 - accuracy: 0.5983 - val_loss: 1.0752 - val_accuracy: 0.6023\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1068 - accuracy: 0.5986 - val_loss: 1.0714 - val_accuracy: 0.6026\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1062 - accuracy: 0.5981 - val_loss: 1.0738 - val_accuracy: 0.6028\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.1067 - accuracy: 0.5986 - val_loss: 1.0680 - val_accuracy: 0.6055\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1051 - accuracy: 0.5988 - val_loss: 1.0723 - val_accuracy: 0.6068\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.1055 - accuracy: 0.5993 - val_loss: 1.0718 - val_accuracy: 0.6078\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 15s 109us/step - loss: 1.1064 - accuracy: 0.5986 - val_loss: 1.0683 - val_accuracy: 0.6033\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1062 - accuracy: 0.5973 - val_loss: 1.0673 - val_accuracy: 0.6073\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1053 - accuracy: 0.5991 - val_loss: 1.0865 - val_accuracy: 0.5984\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1056 - accuracy: 0.5993 - val_loss: 1.0686 - val_accuracy: 0.6042\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1057 - accuracy: 0.5988 - val_loss: 1.0680 - val_accuracy: 0.6098\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1055 - accuracy: 0.5979 - val_loss: 1.0659 - val_accuracy: 0.6009\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1051 - accuracy: 0.5996 - val_loss: 1.0747 - val_accuracy: 0.6043\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1032 - accuracy: 0.5995 - val_loss: 1.0726 - val_accuracy: 0.6060\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1039 - accuracy: 0.6001 - val_loss: 1.0752 - val_accuracy: 0.6038\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1044 - accuracy: 0.5999 - val_loss: 1.0657 - val_accuracy: 0.6035\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1032 - accuracy: 0.5996 - val_loss: 1.0668 - val_accuracy: 0.6070\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1041 - accuracy: 0.6000 - val_loss: 1.0703 - val_accuracy: 0.6081\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1032 - accuracy: 0.6006 - val_loss: 1.0651 - val_accuracy: 0.6036\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1018 - accuracy: 0.5999 - val_loss: 1.0656 - val_accuracy: 0.6069\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1030 - accuracy: 0.6002 - val_loss: 1.0651 - val_accuracy: 0.6122\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1019 - accuracy: 0.6011 - val_loss: 1.0658 - val_accuracy: 0.6070\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1032 - accuracy: 0.5992 - val_loss: 1.0657 - val_accuracy: 0.6125\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1030 - accuracy: 0.6007 - val_loss: 1.0718 - val_accuracy: 0.6082\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.1004 - accuracy: 0.6007 - val_loss: 1.0661 - val_accuracy: 0.6148\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1029 - accuracy: 0.5997 - val_loss: 1.0652 - val_accuracy: 0.6076\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1023 - accuracy: 0.6006 - val_loss: 1.0641 - val_accuracy: 0.6141\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1011 - accuracy: 0.5997 - val_loss: 1.0661 - val_accuracy: 0.6080\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1001 - accuracy: 0.6013 - val_loss: 1.0634 - val_accuracy: 0.6066\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1013 - accuracy: 0.6017 - val_loss: 1.0666 - val_accuracy: 0.6048\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.1011 - accuracy: 0.6010 - val_loss: 1.0668 - val_accuracy: 0.6125\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.1009 - accuracy: 0.6022 - val_loss: 1.0665 - val_accuracy: 0.6055\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1003 - accuracy: 0.6023 - val_loss: 1.0802 - val_accuracy: 0.6095\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0996 - accuracy: 0.6009 - val_loss: 1.0614 - val_accuracy: 0.6080\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0983 - accuracy: 0.6028 - val_loss: 1.0675 - val_accuracy: 0.6075\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1006 - accuracy: 0.6024 - val_loss: 1.0631 - val_accuracy: 0.6064\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0998 - accuracy: 0.6026 - val_loss: 1.0656 - val_accuracy: 0.6067\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0989 - accuracy: 0.6026 - val_loss: 1.0604 - val_accuracy: 0.6118\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.1001 - accuracy: 0.6030 - val_loss: 1.0611 - val_accuracy: 0.6127\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0988 - accuracy: 0.6029 - val_loss: 1.0622 - val_accuracy: 0.6132\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0987 - accuracy: 0.6033 - val_loss: 1.0585 - val_accuracy: 0.6078\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0973 - accuracy: 0.6030 - val_loss: 1.0601 - val_accuracy: 0.6103\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.0991 - accuracy: 0.6037 - val_loss: 1.0593 - val_accuracy: 0.6107\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0980 - accuracy: 0.6030 - val_loss: 1.0590 - val_accuracy: 0.6085\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0969 - accuracy: 0.6032 - val_loss: 1.0586 - val_accuracy: 0.6060\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0966 - accuracy: 0.6041 - val_loss: 1.0626 - val_accuracy: 0.6073\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0979 - accuracy: 0.6033 - val_loss: 1.0587 - val_accuracy: 0.6097\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.0978 - accuracy: 0.6046 - val_loss: 1.0591 - val_accuracy: 0.6051\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0964 - accuracy: 0.6029 - val_loss: 1.0628 - val_accuracy: 0.6067\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0961 - accuracy: 0.6043 - val_loss: 1.0588 - val_accuracy: 0.6117\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.0949 - accuracy: 0.6051 - val_loss: 1.0567 - val_accuracy: 0.6093\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0965 - accuracy: 0.6039 - val_loss: 1.0611 - val_accuracy: 0.6113\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0961 - accuracy: 0.6048 - val_loss: 1.0574 - val_accuracy: 0.6069\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0957 - accuracy: 0.6049 - val_loss: 1.0573 - val_accuracy: 0.6105\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.0964 - accuracy: 0.6039 - val_loss: 1.0634 - val_accuracy: 0.6086\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0949 - accuracy: 0.6050 - val_loss: 1.0556 - val_accuracy: 0.6125\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0953 - accuracy: 0.6043 - val_loss: 1.0579 - val_accuracy: 0.6087\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0939 - accuracy: 0.6045 - val_loss: 1.0551 - val_accuracy: 0.6113\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0943 - accuracy: 0.6054 - val_loss: 1.0578 - val_accuracy: 0.6078\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0940 - accuracy: 0.6056 - val_loss: 1.0615 - val_accuracy: 0.6109\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0951 - accuracy: 0.6047 - val_loss: 1.0559 - val_accuracy: 0.6122\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0937 - accuracy: 0.6042 - val_loss: 1.0576 - val_accuracy: 0.6067\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0934 - accuracy: 0.6044 - val_loss: 1.0576 - val_accuracy: 0.6114\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0925 - accuracy: 0.6046 - val_loss: 1.0546 - val_accuracy: 0.6084\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0931 - accuracy: 0.6052 - val_loss: 1.0571 - val_accuracy: 0.6114\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0927 - accuracy: 0.6059 - val_loss: 1.0545 - val_accuracy: 0.6073\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0929 - accuracy: 0.6042 - val_loss: 1.0539 - val_accuracy: 0.6113\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0922 - accuracy: 0.6054 - val_loss: 1.0521 - val_accuracy: 0.6138\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0916 - accuracy: 0.6049 - val_loss: 1.0551 - val_accuracy: 0.6087\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0925 - accuracy: 0.6052 - val_loss: 1.0553 - val_accuracy: 0.6104\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0914 - accuracy: 0.6050 - val_loss: 1.0560 - val_accuracy: 0.6115\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0918 - accuracy: 0.6054 - val_loss: 1.0608 - val_accuracy: 0.6107\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0908 - accuracy: 0.6047 - val_loss: 1.0522 - val_accuracy: 0.6114\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0925 - accuracy: 0.6039 - val_loss: 1.0552 - val_accuracy: 0.6104\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0912 - accuracy: 0.6055 - val_loss: 1.0505 - val_accuracy: 0.6090\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0891 - accuracy: 0.6058 - val_loss: 1.0623 - val_accuracy: 0.6068\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0894 - accuracy: 0.6056 - val_loss: 1.0532 - val_accuracy: 0.6124\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0905 - accuracy: 0.6062 - val_loss: 1.0616 - val_accuracy: 0.6079\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0894 - accuracy: 0.6053 - val_loss: 1.0511 - val_accuracy: 0.6121\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0911 - accuracy: 0.6056 - val_loss: 1.0819 - val_accuracy: 0.6126\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0895 - accuracy: 0.6068 - val_loss: 1.0525 - val_accuracy: 0.6079\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0908 - accuracy: 0.6045 - val_loss: 1.0491 - val_accuracy: 0.6080\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0894 - accuracy: 0.6054 - val_loss: 1.0490 - val_accuracy: 0.6095\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0879 - accuracy: 0.6057 - val_loss: 1.0502 - val_accuracy: 0.6082\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0905 - accuracy: 0.6057 - val_loss: 1.0498 - val_accuracy: 0.6180\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0904 - accuracy: 0.6052 - val_loss: 1.0499 - val_accuracy: 0.6163\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0864 - accuracy: 0.6057 - val_loss: 1.0524 - val_accuracy: 0.6123\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0876 - accuracy: 0.6054 - val_loss: 1.0483 - val_accuracy: 0.6130\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0884 - accuracy: 0.6060 - val_loss: 1.0482 - val_accuracy: 0.6079\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0877 - accuracy: 0.6048 - val_loss: 1.0468 - val_accuracy: 0.6075\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0874 - accuracy: 0.6057 - val_loss: 1.0472 - val_accuracy: 0.6088\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0879 - accuracy: 0.6057 - val_loss: 1.0468 - val_accuracy: 0.6130\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0872 - accuracy: 0.6066 - val_loss: 1.0558 - val_accuracy: 0.6082\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0874 - accuracy: 0.6060 - val_loss: 1.0514 - val_accuracy: 0.6115\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0865 - accuracy: 0.6064 - val_loss: 1.0458 - val_accuracy: 0.6101\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0865 - accuracy: 0.6065 - val_loss: 1.0459 - val_accuracy: 0.6135\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0869 - accuracy: 0.6066 - val_loss: 1.0555 - val_accuracy: 0.6095\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0864 - accuracy: 0.6072 - val_loss: 1.0491 - val_accuracy: 0.6128\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0871 - accuracy: 0.6064 - val_loss: 1.0455 - val_accuracy: 0.6118\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0857 - accuracy: 0.6057 - val_loss: 1.0457 - val_accuracy: 0.6094\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0861 - accuracy: 0.6066 - val_loss: 1.0464 - val_accuracy: 0.6139\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0858 - accuracy: 0.6052 - val_loss: 1.0452 - val_accuracy: 0.6140\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0855 - accuracy: 0.6061 - val_loss: 1.0450 - val_accuracy: 0.6096\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0851 - accuracy: 0.6058 - val_loss: 1.0519 - val_accuracy: 0.6092\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0846 - accuracy: 0.6058 - val_loss: 1.0428 - val_accuracy: 0.6087\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0845 - accuracy: 0.6065 - val_loss: 1.0430 - val_accuracy: 0.6096\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0843 - accuracy: 0.6057 - val_loss: 1.0441 - val_accuracy: 0.6102\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0838 - accuracy: 0.6061 - val_loss: 1.0409 - val_accuracy: 0.6097\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0853 - accuracy: 0.6054 - val_loss: 1.0468 - val_accuracy: 0.6153\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0829 - accuracy: 0.6061 - val_loss: 1.0413 - val_accuracy: 0.6120\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0853 - accuracy: 0.6060 - val_loss: 1.0420 - val_accuracy: 0.6140\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0842 - accuracy: 0.6059 - val_loss: 1.0514 - val_accuracy: 0.6094\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0813 - accuracy: 0.6062 - val_loss: 1.0426 - val_accuracy: 0.6163\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0829 - accuracy: 0.6057 - val_loss: 1.0411 - val_accuracy: 0.6121\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0820 - accuracy: 0.6053 - val_loss: 1.0398 - val_accuracy: 0.6105\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0834 - accuracy: 0.6059 - val_loss: 1.0417 - val_accuracy: 0.6114\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0820 - accuracy: 0.6065 - val_loss: 1.0400 - val_accuracy: 0.6133\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0813 - accuracy: 0.6065 - val_loss: 1.0393 - val_accuracy: 0.6134\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0817 - accuracy: 0.6068 - val_loss: 1.0437 - val_accuracy: 0.6081\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0801 - accuracy: 0.6062 - val_loss: 1.0401 - val_accuracy: 0.6101\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0795 - accuracy: 0.6068 - val_loss: 1.0422 - val_accuracy: 0.6116\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0824 - accuracy: 0.6066 - val_loss: 1.0377 - val_accuracy: 0.6098\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0808 - accuracy: 0.6062 - val_loss: 1.0382 - val_accuracy: 0.6119\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0797 - accuracy: 0.6082 - val_loss: 1.0406 - val_accuracy: 0.6117\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0798 - accuracy: 0.6078 - val_loss: 1.0398 - val_accuracy: 0.6101\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0799 - accuracy: 0.6072 - val_loss: 1.0390 - val_accuracy: 0.6168\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0797 - accuracy: 0.6072 - val_loss: 1.0397 - val_accuracy: 0.6188\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0776 - accuracy: 0.6079 - val_loss: 1.0369 - val_accuracy: 0.6102\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0779 - accuracy: 0.6083 - val_loss: 1.0403 - val_accuracy: 0.6119\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0766 - accuracy: 0.6084 - val_loss: 1.0366 - val_accuracy: 0.6128\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0785 - accuracy: 0.6082 - val_loss: 1.0502 - val_accuracy: 0.6116\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0782 - accuracy: 0.6087 - val_loss: 1.0353 - val_accuracy: 0.6124\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0779 - accuracy: 0.6066 - val_loss: 1.0364 - val_accuracy: 0.6113\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0783 - accuracy: 0.6081 - val_loss: 1.0370 - val_accuracy: 0.6161\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0761 - accuracy: 0.6072 - val_loss: 1.0361 - val_accuracy: 0.6128\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0764 - accuracy: 0.6088 - val_loss: 1.0356 - val_accuracy: 0.6138\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0769 - accuracy: 0.6093 - val_loss: 1.0406 - val_accuracy: 0.6105\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0754 - accuracy: 0.6079 - val_loss: 1.0352 - val_accuracy: 0.6126\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0756 - accuracy: 0.6083 - val_loss: 1.0375 - val_accuracy: 0.6146\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0758 - accuracy: 0.6091 - val_loss: 1.0409 - val_accuracy: 0.6158\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0756 - accuracy: 0.6081 - val_loss: 1.0309 - val_accuracy: 0.6133\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0757 - accuracy: 0.6087 - val_loss: 1.0338 - val_accuracy: 0.6145\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0743 - accuracy: 0.6095 - val_loss: 1.0332 - val_accuracy: 0.6163\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0753 - accuracy: 0.6105 - val_loss: 1.0323 - val_accuracy: 0.6111\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0753 - accuracy: 0.6096 - val_loss: 1.0313 - val_accuracy: 0.6147\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0743 - accuracy: 0.6099 - val_loss: 1.0311 - val_accuracy: 0.6168\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0754 - accuracy: 0.6094 - val_loss: 1.0314 - val_accuracy: 0.6140\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0749 - accuracy: 0.6089 - val_loss: 1.0315 - val_accuracy: 0.6159\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0729 - accuracy: 0.6103 - val_loss: 1.0286 - val_accuracy: 0.6166\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0719 - accuracy: 0.6094 - val_loss: 1.0302 - val_accuracy: 0.6182\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0726 - accuracy: 0.6092 - val_loss: 1.0317 - val_accuracy: 0.6158\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0725 - accuracy: 0.6100 - val_loss: 1.0284 - val_accuracy: 0.6206\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0704 - accuracy: 0.6105 - val_loss: 1.0325 - val_accuracy: 0.6152\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0714 - accuracy: 0.6104 - val_loss: 1.0308 - val_accuracy: 0.6162\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0717 - accuracy: 0.6109 - val_loss: 1.0262 - val_accuracy: 0.6201\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0718 - accuracy: 0.6109 - val_loss: 1.0269 - val_accuracy: 0.6184\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0695 - accuracy: 0.6115 - val_loss: 1.0263 - val_accuracy: 0.6152\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0717 - accuracy: 0.6119 - val_loss: 1.0262 - val_accuracy: 0.6156\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0699 - accuracy: 0.6098 - val_loss: 1.0276 - val_accuracy: 0.6201\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0693 - accuracy: 0.6103 - val_loss: 1.0241 - val_accuracy: 0.6164\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0692 - accuracy: 0.6101 - val_loss: 1.0290 - val_accuracy: 0.6149\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 1.0705 - accuracy: 0.6109 - val_loss: 1.0241 - val_accuracy: 0.6143\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0680 - accuracy: 0.6106 - val_loss: 1.0414 - val_accuracy: 0.6150\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0672 - accuracy: 0.6104 - val_loss: 1.0235 - val_accuracy: 0.6160\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0693 - accuracy: 0.6100 - val_loss: 1.0332 - val_accuracy: 0.6114\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0690 - accuracy: 0.6100 - val_loss: 1.0226 - val_accuracy: 0.6181\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0680 - accuracy: 0.6117 - val_loss: 1.0244 - val_accuracy: 0.6189\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0680 - accuracy: 0.6095 - val_loss: 1.0219 - val_accuracy: 0.6130\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0684 - accuracy: 0.6106 - val_loss: 1.0216 - val_accuracy: 0.6161\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0668 - accuracy: 0.6106 - val_loss: 1.0216 - val_accuracy: 0.6193\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0663 - accuracy: 0.6100 - val_loss: 1.0217 - val_accuracy: 0.6221\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0659 - accuracy: 0.6112 - val_loss: 1.0311 - val_accuracy: 0.6123\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0672 - accuracy: 0.6113 - val_loss: 1.0253 - val_accuracy: 0.6200\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0653 - accuracy: 0.6105 - val_loss: 1.0497 - val_accuracy: 0.6172\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0638 - accuracy: 0.6097 - val_loss: 1.0202 - val_accuracy: 0.6163\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0653 - accuracy: 0.6110 - val_loss: 1.0250 - val_accuracy: 0.6222\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0660 - accuracy: 0.6107 - val_loss: 1.0213 - val_accuracy: 0.6223\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0645 - accuracy: 0.6117 - val_loss: 1.0192 - val_accuracy: 0.6208\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0656 - accuracy: 0.6120 - val_loss: 1.0180 - val_accuracy: 0.6157\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0645 - accuracy: 0.6125 - val_loss: 1.0395 - val_accuracy: 0.6158\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0635 - accuracy: 0.6117 - val_loss: 1.0197 - val_accuracy: 0.6216\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0636 - accuracy: 0.6112 - val_loss: 1.0169 - val_accuracy: 0.6237\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0626 - accuracy: 0.6118 - val_loss: 1.0176 - val_accuracy: 0.6163\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0635 - accuracy: 0.6105 - val_loss: 1.0186 - val_accuracy: 0.6148\n",
      "accuracy: 61.48%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0626 - accuracy: 0.6113 - val_loss: 1.0138 - val_accuracy: 0.6238\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0626 - accuracy: 0.6124 - val_loss: 1.0117 - val_accuracy: 0.6196\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0627 - accuracy: 0.6117 - val_loss: 1.0133 - val_accuracy: 0.6229\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0625 - accuracy: 0.6125 - val_loss: 1.0098 - val_accuracy: 0.6177\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0606 - accuracy: 0.6131 - val_loss: 1.0236 - val_accuracy: 0.6157\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0616 - accuracy: 0.6130 - val_loss: 1.0151 - val_accuracy: 0.6116\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0621 - accuracy: 0.6132 - val_loss: 1.0089 - val_accuracy: 0.6137\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0611 - accuracy: 0.6130 - val_loss: 1.0086 - val_accuracy: 0.6168\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0609 - accuracy: 0.6121 - val_loss: 1.0082 - val_accuracy: 0.6183\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0613 - accuracy: 0.6120 - val_loss: 1.0086 - val_accuracy: 0.6276\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0606 - accuracy: 0.6122 - val_loss: 1.0103 - val_accuracy: 0.6271\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0598 - accuracy: 0.6123 - val_loss: 1.0128 - val_accuracy: 0.6201\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0599 - accuracy: 0.6139 - val_loss: 1.0081 - val_accuracy: 0.6135\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0583 - accuracy: 0.6135 - val_loss: 1.0062 - val_accuracy: 0.6135\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0598 - accuracy: 0.6135 - val_loss: 1.0087 - val_accuracy: 0.6221\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0590 - accuracy: 0.6126 - val_loss: 1.0060 - val_accuracy: 0.6118\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0574 - accuracy: 0.6132 - val_loss: 1.0097 - val_accuracy: 0.6233\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0584 - accuracy: 0.6127 - val_loss: 1.0025 - val_accuracy: 0.6253\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0594 - accuracy: 0.6134 - val_loss: 1.0078 - val_accuracy: 0.6144\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0572 - accuracy: 0.6139 - val_loss: 1.0072 - val_accuracy: 0.6243\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0571 - accuracy: 0.6133 - val_loss: 1.0103 - val_accuracy: 0.6190\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0551 - accuracy: 0.6133 - val_loss: 1.0052 - val_accuracy: 0.6192\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0565 - accuracy: 0.6133 - val_loss: 1.0094 - val_accuracy: 0.6215\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0565 - accuracy: 0.6135 - val_loss: 1.0216 - val_accuracy: 0.6158\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0564 - accuracy: 0.6134 - val_loss: 1.0044 - val_accuracy: 0.6222\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0549 - accuracy: 0.6136 - val_loss: 1.0028 - val_accuracy: 0.6263\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0569 - accuracy: 0.6124 - val_loss: 1.0055 - val_accuracy: 0.6194\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0550 - accuracy: 0.6135 - val_loss: 0.9991 - val_accuracy: 0.6204\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0557 - accuracy: 0.6134 - val_loss: 1.0021 - val_accuracy: 0.6184\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0551 - accuracy: 0.6144 - val_loss: 1.0034 - val_accuracy: 0.6239\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0565 - accuracy: 0.6133 - val_loss: 1.0013 - val_accuracy: 0.6205\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0541 - accuracy: 0.6129 - val_loss: 0.9982 - val_accuracy: 0.6194\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.0534 - accuracy: 0.6136 - val_loss: 0.9985 - val_accuracy: 0.6208\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0527 - accuracy: 0.6136 - val_loss: 1.0002 - val_accuracy: 0.6202\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0533 - accuracy: 0.6139 - val_loss: 1.0027 - val_accuracy: 0.6188\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0516 - accuracy: 0.6144 - val_loss: 0.9960 - val_accuracy: 0.6176\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0552 - accuracy: 0.6131 - val_loss: 1.0017 - val_accuracy: 0.6223\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0520 - accuracy: 0.6128 - val_loss: 0.9975 - val_accuracy: 0.6251\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0529 - accuracy: 0.6135 - val_loss: 0.9970 - val_accuracy: 0.6234\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0534 - accuracy: 0.6122 - val_loss: 0.9979 - val_accuracy: 0.6262\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0512 - accuracy: 0.6137 - val_loss: 1.0133 - val_accuracy: 0.6142\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0515 - accuracy: 0.6136 - val_loss: 1.0047 - val_accuracy: 0.6187\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0522 - accuracy: 0.6129 - val_loss: 0.9979 - val_accuracy: 0.6136\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0505 - accuracy: 0.6123 - val_loss: 0.9960 - val_accuracy: 0.6194\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0509 - accuracy: 0.6123 - val_loss: 0.9985 - val_accuracy: 0.6176\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0486 - accuracy: 0.6130 - val_loss: 0.9954 - val_accuracy: 0.6299\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0497 - accuracy: 0.6135 - val_loss: 0.9992 - val_accuracy: 0.6188\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0489 - accuracy: 0.6123 - val_loss: 1.0094 - val_accuracy: 0.6191\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0484 - accuracy: 0.6134 - val_loss: 0.9938 - val_accuracy: 0.6183\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0497 - accuracy: 0.6126 - val_loss: 0.9942 - val_accuracy: 0.6253\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0469 - accuracy: 0.6125 - val_loss: 1.0028 - val_accuracy: 0.6197\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0491 - accuracy: 0.6121 - val_loss: 0.9949 - val_accuracy: 0.6198\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0470 - accuracy: 0.6139 - val_loss: 0.9905 - val_accuracy: 0.6169\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0486 - accuracy: 0.6119 - val_loss: 0.9913 - val_accuracy: 0.6295\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0490 - accuracy: 0.6124 - val_loss: 0.9890 - val_accuracy: 0.6241\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0470 - accuracy: 0.6132 - val_loss: 1.0068 - val_accuracy: 0.6171\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0478 - accuracy: 0.6139 - val_loss: 0.9885 - val_accuracy: 0.6196\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0470 - accuracy: 0.6135 - val_loss: 0.9888 - val_accuracy: 0.6192\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0462 - accuracy: 0.6129 - val_loss: 0.9913 - val_accuracy: 0.6264\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0459 - accuracy: 0.6129 - val_loss: 0.9898 - val_accuracy: 0.6193\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0447 - accuracy: 0.6134 - val_loss: 0.9900 - val_accuracy: 0.6212\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0461 - accuracy: 0.6129 - val_loss: 0.9882 - val_accuracy: 0.6237\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0444 - accuracy: 0.6128 - val_loss: 0.9916 - val_accuracy: 0.6216\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0454 - accuracy: 0.6128 - val_loss: 0.9856 - val_accuracy: 0.6195\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0459 - accuracy: 0.6124 - val_loss: 0.9865 - val_accuracy: 0.6193\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0442 - accuracy: 0.6135 - val_loss: 0.9893 - val_accuracy: 0.6166\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0446 - accuracy: 0.6115 - val_loss: 0.9929 - val_accuracy: 0.6173\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0446 - accuracy: 0.6123 - val_loss: 0.9860 - val_accuracy: 0.6240\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0454 - accuracy: 0.6129 - val_loss: 0.9923 - val_accuracy: 0.6198\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0450 - accuracy: 0.6125 - val_loss: 0.9861 - val_accuracy: 0.6298\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0439 - accuracy: 0.6126 - val_loss: 0.9852 - val_accuracy: 0.6257\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0434 - accuracy: 0.6119 - val_loss: 0.9841 - val_accuracy: 0.6299\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0443 - accuracy: 0.6131 - val_loss: 0.9880 - val_accuracy: 0.6251\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0433 - accuracy: 0.6120 - val_loss: 0.9909 - val_accuracy: 0.6200\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0434 - accuracy: 0.6128 - val_loss: 0.9835 - val_accuracy: 0.6308\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0404 - accuracy: 0.6125 - val_loss: 0.9862 - val_accuracy: 0.6310\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0420 - accuracy: 0.6130 - val_loss: 0.9826 - val_accuracy: 0.6231\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0423 - accuracy: 0.6121 - val_loss: 0.9837 - val_accuracy: 0.6213\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0423 - accuracy: 0.6120 - val_loss: 0.9869 - val_accuracy: 0.6239\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0413 - accuracy: 0.6119 - val_loss: 0.9830 - val_accuracy: 0.6200\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0423 - accuracy: 0.6125 - val_loss: 0.9807 - val_accuracy: 0.6192\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0427 - accuracy: 0.6131 - val_loss: 0.9905 - val_accuracy: 0.6195\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0394 - accuracy: 0.6135 - val_loss: 0.9812 - val_accuracy: 0.6308\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0412 - accuracy: 0.6121 - val_loss: 0.9802 - val_accuracy: 0.6314\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0404 - accuracy: 0.6120 - val_loss: 0.9794 - val_accuracy: 0.6243\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.0410 - accuracy: 0.6121 - val_loss: 0.9816 - val_accuracy: 0.6266\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0401 - accuracy: 0.6137 - val_loss: 0.9868 - val_accuracy: 0.6198\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0400 - accuracy: 0.6136 - val_loss: 0.9819 - val_accuracy: 0.6249\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0381 - accuracy: 0.6126 - val_loss: 0.9807 - val_accuracy: 0.6198\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0408 - accuracy: 0.6128 - val_loss: 0.9776 - val_accuracy: 0.6241\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0381 - accuracy: 0.6129 - val_loss: 0.9785 - val_accuracy: 0.6215\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0364 - accuracy: 0.6138 - val_loss: 0.9789 - val_accuracy: 0.6186\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0368 - accuracy: 0.6133 - val_loss: 0.9780 - val_accuracy: 0.6232\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0390 - accuracy: 0.6128 - val_loss: 0.9761 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0393 - accuracy: 0.6116 - val_loss: 0.9798 - val_accuracy: 0.6208\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0387 - accuracy: 0.6121 - val_loss: 0.9789 - val_accuracy: 0.6295\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0377 - accuracy: 0.6123 - val_loss: 0.9856 - val_accuracy: 0.6232\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0387 - accuracy: 0.6125 - val_loss: 0.9750 - val_accuracy: 0.6224\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0374 - accuracy: 0.6120 - val_loss: 0.9756 - val_accuracy: 0.6213\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0376 - accuracy: 0.6124 - val_loss: 0.9835 - val_accuracy: 0.6251\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0362 - accuracy: 0.6126 - val_loss: 0.9762 - val_accuracy: 0.6205\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0378 - accuracy: 0.6120 - val_loss: 0.9771 - val_accuracy: 0.6208\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0368 - accuracy: 0.6130 - val_loss: 0.9784 - val_accuracy: 0.6211\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0374 - accuracy: 0.6129 - val_loss: 0.9751 - val_accuracy: 0.6223\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0362 - accuracy: 0.6130 - val_loss: 0.9751 - val_accuracy: 0.6194\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0356 - accuracy: 0.6137 - val_loss: 0.9789 - val_accuracy: 0.6198\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0372 - accuracy: 0.6127 - val_loss: 0.9751 - val_accuracy: 0.6265\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0356 - accuracy: 0.6128 - val_loss: 0.9734 - val_accuracy: 0.6205\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0342 - accuracy: 0.6137 - val_loss: 0.9724 - val_accuracy: 0.6243\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0348 - accuracy: 0.6143 - val_loss: 0.9731 - val_accuracy: 0.6317\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0352 - accuracy: 0.6142 - val_loss: 0.9760 - val_accuracy: 0.6192\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0342 - accuracy: 0.6136 - val_loss: 0.9729 - val_accuracy: 0.6180\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0347 - accuracy: 0.6129 - val_loss: 0.9762 - val_accuracy: 0.6187\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0351 - accuracy: 0.6123 - val_loss: 0.9729 - val_accuracy: 0.6320\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0328 - accuracy: 0.6126 - val_loss: 0.9755 - val_accuracy: 0.6268\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0353 - accuracy: 0.6121 - val_loss: 0.9818 - val_accuracy: 0.6208\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0344 - accuracy: 0.6122 - val_loss: 0.9733 - val_accuracy: 0.6187\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0348 - accuracy: 0.6137 - val_loss: 0.9696 - val_accuracy: 0.6247\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0330 - accuracy: 0.6125 - val_loss: 0.9844 - val_accuracy: 0.6211\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0344 - accuracy: 0.6124 - val_loss: 0.9718 - val_accuracy: 0.6199\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0330 - accuracy: 0.6139 - val_loss: 0.9712 - val_accuracy: 0.6267\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0345 - accuracy: 0.6126 - val_loss: 0.9698 - val_accuracy: 0.6193\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0346 - accuracy: 0.6125 - val_loss: 0.9788 - val_accuracy: 0.6197\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0338 - accuracy: 0.6125 - val_loss: 0.9746 - val_accuracy: 0.6267\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0334 - accuracy: 0.6121 - val_loss: 0.9739 - val_accuracy: 0.6172\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0342 - accuracy: 0.6141 - val_loss: 0.9783 - val_accuracy: 0.6283\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0313 - accuracy: 0.6128 - val_loss: 0.9770 - val_accuracy: 0.6211\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0330 - accuracy: 0.6132 - val_loss: 0.9763 - val_accuracy: 0.6221\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0333 - accuracy: 0.6139 - val_loss: 0.9864 - val_accuracy: 0.6160\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0325 - accuracy: 0.6134 - val_loss: 0.9694 - val_accuracy: 0.6237\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0318 - accuracy: 0.6138 - val_loss: 0.9694 - val_accuracy: 0.6324\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0327 - accuracy: 0.6119 - val_loss: 0.9701 - val_accuracy: 0.6211\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0316 - accuracy: 0.6135 - val_loss: 0.9766 - val_accuracy: 0.6199\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0329 - accuracy: 0.6139 - val_loss: 0.9705 - val_accuracy: 0.6181\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0316 - accuracy: 0.6136 - val_loss: 0.9704 - val_accuracy: 0.6261\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0311 - accuracy: 0.6138 - val_loss: 0.9690 - val_accuracy: 0.6314\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0324 - accuracy: 0.6141 - val_loss: 0.9722 - val_accuracy: 0.6291\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0299 - accuracy: 0.6132 - val_loss: 0.9706 - val_accuracy: 0.6196\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0300 - accuracy: 0.6134 - val_loss: 0.9682 - val_accuracy: 0.6257\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0326 - accuracy: 0.6122 - val_loss: 0.9759 - val_accuracy: 0.6283\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0306 - accuracy: 0.6131 - val_loss: 0.9699 - val_accuracy: 0.6302\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0304 - accuracy: 0.6126 - val_loss: 0.9694 - val_accuracy: 0.6300\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0324 - accuracy: 0.6125 - val_loss: 0.9713 - val_accuracy: 0.6212\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0316 - accuracy: 0.6117 - val_loss: 0.9739 - val_accuracy: 0.6218\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0291 - accuracy: 0.6125 - val_loss: 0.9678 - val_accuracy: 0.6208\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0318 - accuracy: 0.6129 - val_loss: 0.9734 - val_accuracy: 0.6276\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0290 - accuracy: 0.6129 - val_loss: 0.9663 - val_accuracy: 0.6198\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0296 - accuracy: 0.6129 - val_loss: 0.9658 - val_accuracy: 0.6246\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0299 - accuracy: 0.6128 - val_loss: 0.9762 - val_accuracy: 0.6217\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0284 - accuracy: 0.6131 - val_loss: 0.9742 - val_accuracy: 0.6232\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0304 - accuracy: 0.6138 - val_loss: 0.9684 - val_accuracy: 0.6210\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0285 - accuracy: 0.6146 - val_loss: 0.9736 - val_accuracy: 0.6199\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0311 - accuracy: 0.6129 - val_loss: 0.9756 - val_accuracy: 0.6180\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0312 - accuracy: 0.6135 - val_loss: 0.9673 - val_accuracy: 0.6217\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0296 - accuracy: 0.6137 - val_loss: 0.9683 - val_accuracy: 0.6286\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0301 - accuracy: 0.6117 - val_loss: 0.9661 - val_accuracy: 0.6265\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0288 - accuracy: 0.6124 - val_loss: 0.9722 - val_accuracy: 0.6208\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0281 - accuracy: 0.6139 - val_loss: 0.9744 - val_accuracy: 0.6219\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0294 - accuracy: 0.6145 - val_loss: 0.9791 - val_accuracy: 0.6217\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0299 - accuracy: 0.6119 - val_loss: 0.9712 - val_accuracy: 0.6288\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0292 - accuracy: 0.6136 - val_loss: 0.9676 - val_accuracy: 0.6312\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0280 - accuracy: 0.6144 - val_loss: 0.9684 - val_accuracy: 0.6218\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0288 - accuracy: 0.6147 - val_loss: 0.9709 - val_accuracy: 0.6255\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0291 - accuracy: 0.6144 - val_loss: 0.9666 - val_accuracy: 0.6208\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0287 - accuracy: 0.6127 - val_loss: 0.9675 - val_accuracy: 0.6223\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0275 - accuracy: 0.6124 - val_loss: 0.9704 - val_accuracy: 0.6288\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0289 - accuracy: 0.6122 - val_loss: 0.9656 - val_accuracy: 0.6198\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0278 - accuracy: 0.6148 - val_loss: 0.9702 - val_accuracy: 0.6233\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0298 - accuracy: 0.6130 - val_loss: 0.9642 - val_accuracy: 0.6211\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0296 - accuracy: 0.6124 - val_loss: 0.9722 - val_accuracy: 0.6218\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0291 - accuracy: 0.6123 - val_loss: 0.9653 - val_accuracy: 0.6298\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0275 - accuracy: 0.6145 - val_loss: 0.9663 - val_accuracy: 0.6196\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0276 - accuracy: 0.6128 - val_loss: 0.9702 - val_accuracy: 0.6228\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0280 - accuracy: 0.6143 - val_loss: 0.9641 - val_accuracy: 0.6202\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0273 - accuracy: 0.6138 - val_loss: 0.9821 - val_accuracy: 0.6197\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0274 - accuracy: 0.6135 - val_loss: 0.9683 - val_accuracy: 0.6297\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0285 - accuracy: 0.6137 - val_loss: 0.9632 - val_accuracy: 0.6229\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0275 - accuracy: 0.6151 - val_loss: 0.9767 - val_accuracy: 0.6203\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0269 - accuracy: 0.6139 - val_loss: 0.9699 - val_accuracy: 0.6264\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0272 - accuracy: 0.6140 - val_loss: 0.9634 - val_accuracy: 0.6213\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0274 - accuracy: 0.6143 - val_loss: 0.9647 - val_accuracy: 0.6205\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0267 - accuracy: 0.6136 - val_loss: 0.9629 - val_accuracy: 0.6249\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0273 - accuracy: 0.6150 - val_loss: 0.9852 - val_accuracy: 0.6141\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0268 - accuracy: 0.6137 - val_loss: 0.9625 - val_accuracy: 0.6234\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0264 - accuracy: 0.6138 - val_loss: 0.9640 - val_accuracy: 0.6263\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0245 - accuracy: 0.6150 - val_loss: 0.9623 - val_accuracy: 0.6268\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0246 - accuracy: 0.6141 - val_loss: 0.9628 - val_accuracy: 0.6214\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0249 - accuracy: 0.6145 - val_loss: 0.9656 - val_accuracy: 0.6205\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0250 - accuracy: 0.6143 - val_loss: 0.9624 - val_accuracy: 0.6234\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0262 - accuracy: 0.6141 - val_loss: 0.9616 - val_accuracy: 0.6280\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0232 - accuracy: 0.6144 - val_loss: 0.9648 - val_accuracy: 0.6209\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.0243 - accuracy: 0.6144 - val_loss: 0.9665 - val_accuracy: 0.6206\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0245 - accuracy: 0.6158 - val_loss: 0.9658 - val_accuracy: 0.6195\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0221 - accuracy: 0.6152 - val_loss: 0.9678 - val_accuracy: 0.6221\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0236 - accuracy: 0.6160 - val_loss: 0.9601 - val_accuracy: 0.6242\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0270 - accuracy: 0.6139 - val_loss: 0.9701 - val_accuracy: 0.6232\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0252 - accuracy: 0.6153 - val_loss: 0.9663 - val_accuracy: 0.6205\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0249 - accuracy: 0.6154 - val_loss: 0.9628 - val_accuracy: 0.6286\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0243 - accuracy: 0.6154 - val_loss: 0.9640 - val_accuracy: 0.6182\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0249 - accuracy: 0.6147 - val_loss: 0.9646 - val_accuracy: 0.6180\n",
      "accuracy: 61.80%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0258 - accuracy: 0.6128 - val_loss: 0.9580 - val_accuracy: 0.6304\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0241 - accuracy: 0.6152 - val_loss: 0.9584 - val_accuracy: 0.6337\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0256 - accuracy: 0.6138 - val_loss: 0.9590 - val_accuracy: 0.6349\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0255 - accuracy: 0.6144 - val_loss: 0.9599 - val_accuracy: 0.6260\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0241 - accuracy: 0.6140 - val_loss: 0.9597 - val_accuracy: 0.6299\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0264 - accuracy: 0.6138 - val_loss: 0.9570 - val_accuracy: 0.6306\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0259 - accuracy: 0.6148 - val_loss: 0.9627 - val_accuracy: 0.6238\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0249 - accuracy: 0.6147 - val_loss: 0.9589 - val_accuracy: 0.6269\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0235 - accuracy: 0.6146 - val_loss: 0.9626 - val_accuracy: 0.6280\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0259 - accuracy: 0.6127 - val_loss: 0.9665 - val_accuracy: 0.6237\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0250 - accuracy: 0.6151 - val_loss: 0.9627 - val_accuracy: 0.6329\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0224 - accuracy: 0.6152 - val_loss: 0.9574 - val_accuracy: 0.6298\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0250 - accuracy: 0.6150 - val_loss: 0.9614 - val_accuracy: 0.6318\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0239 - accuracy: 0.6154 - val_loss: 0.9567 - val_accuracy: 0.6285\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0240 - accuracy: 0.6154 - val_loss: 0.9671 - val_accuracy: 0.6249\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0235 - accuracy: 0.6139 - val_loss: 0.9566 - val_accuracy: 0.6282\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0239 - accuracy: 0.6145 - val_loss: 0.9607 - val_accuracy: 0.6274\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0262 - accuracy: 0.6150 - val_loss: 0.9569 - val_accuracy: 0.6268\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0235 - accuracy: 0.6158 - val_loss: 0.9593 - val_accuracy: 0.6275\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0226 - accuracy: 0.6156 - val_loss: 0.9571 - val_accuracy: 0.6307\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0240 - accuracy: 0.6150 - val_loss: 0.9580 - val_accuracy: 0.6359\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0228 - accuracy: 0.6147 - val_loss: 0.9560 - val_accuracy: 0.6303\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0237 - accuracy: 0.6141 - val_loss: 0.9566 - val_accuracy: 0.6304\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0220 - accuracy: 0.6145 - val_loss: 0.9585 - val_accuracy: 0.6341\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0251 - accuracy: 0.6151 - val_loss: 0.9656 - val_accuracy: 0.6294\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0235 - accuracy: 0.6150 - val_loss: 0.9618 - val_accuracy: 0.6318\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0244 - accuracy: 0.6152 - val_loss: 0.9655 - val_accuracy: 0.6303\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0221 - accuracy: 0.6160 - val_loss: 0.9568 - val_accuracy: 0.6279\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0249 - accuracy: 0.6155 - val_loss: 0.9566 - val_accuracy: 0.6330\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0246 - accuracy: 0.6150 - val_loss: 0.9612 - val_accuracy: 0.6273\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0224 - accuracy: 0.6155 - val_loss: 0.9623 - val_accuracy: 0.6271\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0203 - accuracy: 0.6156 - val_loss: 0.9599 - val_accuracy: 0.6335\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0235 - accuracy: 0.6146 - val_loss: 0.9569 - val_accuracy: 0.6290\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0235 - accuracy: 0.6154 - val_loss: 0.9597 - val_accuracy: 0.6266\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0239 - accuracy: 0.6149 - val_loss: 0.9662 - val_accuracy: 0.6273\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0242 - accuracy: 0.6165 - val_loss: 0.9558 - val_accuracy: 0.6284\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0221 - accuracy: 0.6147 - val_loss: 0.9562 - val_accuracy: 0.6276\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0238 - accuracy: 0.6143 - val_loss: 0.9563 - val_accuracy: 0.6289\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0210 - accuracy: 0.6146 - val_loss: 0.9658 - val_accuracy: 0.6281\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0228 - accuracy: 0.6147 - val_loss: 0.9554 - val_accuracy: 0.6290\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0200 - accuracy: 0.6144 - val_loss: 0.9574 - val_accuracy: 0.6287\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0216 - accuracy: 0.6145 - val_loss: 0.9552 - val_accuracy: 0.6322\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0216 - accuracy: 0.6151 - val_loss: 0.9602 - val_accuracy: 0.6301\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 1.0224 - accuracy: 0.6151 - val_loss: 0.9637 - val_accuracy: 0.6270\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0199 - accuracy: 0.6155 - val_loss: 0.9571 - val_accuracy: 0.6274\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0220 - accuracy: 0.6151 - val_loss: 0.9614 - val_accuracy: 0.6292\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0204 - accuracy: 0.6160 - val_loss: 0.9646 - val_accuracy: 0.6265\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0236 - accuracy: 0.6147 - val_loss: 0.9570 - val_accuracy: 0.6277\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0228 - accuracy: 0.6156 - val_loss: 0.9573 - val_accuracy: 0.6265\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0210 - accuracy: 0.6150 - val_loss: 0.9840 - val_accuracy: 0.6266\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0210 - accuracy: 0.6151 - val_loss: 0.9541 - val_accuracy: 0.6293\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0221 - accuracy: 0.6143 - val_loss: 0.9594 - val_accuracy: 0.6265\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0205 - accuracy: 0.6162 - val_loss: 0.9677 - val_accuracy: 0.6290\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0228 - accuracy: 0.6158 - val_loss: 0.9591 - val_accuracy: 0.6267\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0231 - accuracy: 0.6162 - val_loss: 0.9585 - val_accuracy: 0.6300\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0202 - accuracy: 0.6164 - val_loss: 0.9552 - val_accuracy: 0.6290\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0210 - accuracy: 0.6153 - val_loss: 0.9556 - val_accuracy: 0.6326\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0223 - accuracy: 0.6160 - val_loss: 0.9544 - val_accuracy: 0.6278\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0208 - accuracy: 0.6159 - val_loss: 0.9591 - val_accuracy: 0.6365\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0211 - accuracy: 0.6157 - val_loss: 0.9571 - val_accuracy: 0.6308\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0198 - accuracy: 0.6171 - val_loss: 0.9582 - val_accuracy: 0.6288\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0224 - accuracy: 0.6166 - val_loss: 0.9593 - val_accuracy: 0.6285\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0219 - accuracy: 0.6156 - val_loss: 0.9557 - val_accuracy: 0.6307\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0220 - accuracy: 0.6166 - val_loss: 0.9565 - val_accuracy: 0.6298\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0202 - accuracy: 0.6153 - val_loss: 0.9576 - val_accuracy: 0.6292\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0197 - accuracy: 0.6165 - val_loss: 0.9554 - val_accuracy: 0.6331\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0206 - accuracy: 0.6152 - val_loss: 0.9595 - val_accuracy: 0.6267\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0196 - accuracy: 0.6162 - val_loss: 0.9589 - val_accuracy: 0.6321\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0200 - accuracy: 0.6163 - val_loss: 0.9562 - val_accuracy: 0.6351\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0216 - accuracy: 0.6159 - val_loss: 0.9542 - val_accuracy: 0.6288\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0181 - accuracy: 0.6166 - val_loss: 0.9586 - val_accuracy: 0.6280\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0229 - accuracy: 0.6156 - val_loss: 0.9549 - val_accuracy: 0.6325\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0212 - accuracy: 0.6162 - val_loss: 0.9545 - val_accuracy: 0.6299\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0190 - accuracy: 0.6160 - val_loss: 0.9614 - val_accuracy: 0.6298\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0211 - accuracy: 0.6158 - val_loss: 0.9564 - val_accuracy: 0.6337\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0194 - accuracy: 0.6162 - val_loss: 0.9578 - val_accuracy: 0.6274\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0212 - accuracy: 0.6163 - val_loss: 0.9555 - val_accuracy: 0.6301\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0202 - accuracy: 0.6168 - val_loss: 0.9548 - val_accuracy: 0.6351\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0205 - accuracy: 0.6159 - val_loss: 0.9568 - val_accuracy: 0.6338\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0210 - accuracy: 0.6169 - val_loss: 0.9538 - val_accuracy: 0.6297\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0191 - accuracy: 0.6162 - val_loss: 0.9543 - val_accuracy: 0.6301\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0189 - accuracy: 0.6162 - val_loss: 0.9530 - val_accuracy: 0.6368\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0215 - accuracy: 0.6159 - val_loss: 0.9550 - val_accuracy: 0.6270\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0181 - accuracy: 0.6170 - val_loss: 0.9536 - val_accuracy: 0.6293\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0202 - accuracy: 0.6159 - val_loss: 0.9552 - val_accuracy: 0.6322\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0197 - accuracy: 0.6160 - val_loss: 0.9613 - val_accuracy: 0.6284\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0201 - accuracy: 0.6153 - val_loss: 0.9548 - val_accuracy: 0.6298\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0214 - accuracy: 0.6161 - val_loss: 0.9562 - val_accuracy: 0.6277\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0197 - accuracy: 0.6158 - val_loss: 0.9544 - val_accuracy: 0.6351\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0202 - accuracy: 0.6166 - val_loss: 0.9558 - val_accuracy: 0.6268\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0173 - accuracy: 0.6165 - val_loss: 0.9590 - val_accuracy: 0.6288\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0196 - accuracy: 0.6168 - val_loss: 0.9650 - val_accuracy: 0.6290\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0216 - accuracy: 0.6171 - val_loss: 0.9562 - val_accuracy: 0.6379\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0195 - accuracy: 0.6157 - val_loss: 0.9549 - val_accuracy: 0.6274\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0190 - accuracy: 0.6174 - val_loss: 0.9557 - val_accuracy: 0.6290\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0201 - accuracy: 0.6176 - val_loss: 0.9531 - val_accuracy: 0.6322\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 1.0202 - accuracy: 0.6172 - val_loss: 0.9564 - val_accuracy: 0.6328\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0189 - accuracy: 0.6169 - val_loss: 0.9653 - val_accuracy: 0.6308\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0196 - accuracy: 0.6152 - val_loss: 0.9574 - val_accuracy: 0.6310\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0196 - accuracy: 0.6161 - val_loss: 0.9567 - val_accuracy: 0.6326\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0205 - accuracy: 0.6162 - val_loss: 0.9545 - val_accuracy: 0.6305\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0182 - accuracy: 0.6182 - val_loss: 0.9563 - val_accuracy: 0.6322\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0193 - accuracy: 0.6166 - val_loss: 0.9545 - val_accuracy: 0.6278\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0200 - accuracy: 0.6172 - val_loss: 0.9525 - val_accuracy: 0.6385\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0186 - accuracy: 0.6175 - val_loss: 0.9587 - val_accuracy: 0.6284\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0179 - accuracy: 0.6171 - val_loss: 0.9533 - val_accuracy: 0.6359\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0193 - accuracy: 0.6184 - val_loss: 0.9564 - val_accuracy: 0.6336\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 1.0189 - accuracy: 0.6167 - val_loss: 0.9586 - val_accuracy: 0.6271\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0181 - accuracy: 0.6182 - val_loss: 0.9573 - val_accuracy: 0.6286\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0171 - accuracy: 0.6163 - val_loss: 0.9526 - val_accuracy: 0.6295\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0171 - accuracy: 0.6173 - val_loss: 0.9601 - val_accuracy: 0.6314\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0195 - accuracy: 0.6168 - val_loss: 0.9513 - val_accuracy: 0.6288\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0188 - accuracy: 0.6163 - val_loss: 0.9550 - val_accuracy: 0.6313\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0174 - accuracy: 0.6167 - val_loss: 0.9531 - val_accuracy: 0.6308\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0176 - accuracy: 0.6173 - val_loss: 0.9563 - val_accuracy: 0.6312\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0186 - accuracy: 0.6167 - val_loss: 0.9552 - val_accuracy: 0.6328\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0196 - accuracy: 0.6168 - val_loss: 0.9579 - val_accuracy: 0.6273\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0177 - accuracy: 0.6167 - val_loss: 0.9659 - val_accuracy: 0.6263\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0174 - accuracy: 0.6171 - val_loss: 0.9609 - val_accuracy: 0.6278\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0183 - accuracy: 0.6170 - val_loss: 0.9541 - val_accuracy: 0.6347\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0186 - accuracy: 0.6171 - val_loss: 0.9540 - val_accuracy: 0.6325\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0188 - accuracy: 0.6165 - val_loss: 0.9582 - val_accuracy: 0.6327\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0170 - accuracy: 0.6175 - val_loss: 0.9569 - val_accuracy: 0.6332\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0167 - accuracy: 0.6171 - val_loss: 0.9551 - val_accuracy: 0.6279\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0176 - accuracy: 0.6177 - val_loss: 0.9523 - val_accuracy: 0.6309\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0205 - accuracy: 0.6185 - val_loss: 0.9513 - val_accuracy: 0.6275\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0191 - accuracy: 0.6162 - val_loss: 0.9559 - val_accuracy: 0.6275\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0185 - accuracy: 0.6160 - val_loss: 0.9555 - val_accuracy: 0.6355\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0182 - accuracy: 0.6176 - val_loss: 0.9579 - val_accuracy: 0.6295\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0170 - accuracy: 0.6173 - val_loss: 0.9560 - val_accuracy: 0.6292\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0154 - accuracy: 0.6165 - val_loss: 0.9536 - val_accuracy: 0.6273\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0189 - accuracy: 0.6170 - val_loss: 0.9525 - val_accuracy: 0.6305\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0158 - accuracy: 0.6178 - val_loss: 0.9566 - val_accuracy: 0.6308\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0176 - accuracy: 0.6173 - val_loss: 0.9564 - val_accuracy: 0.6307\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0158 - accuracy: 0.6176 - val_loss: 0.9530 - val_accuracy: 0.6356\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0170 - accuracy: 0.6171 - val_loss: 0.9546 - val_accuracy: 0.6288\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0161 - accuracy: 0.6188 - val_loss: 0.9510 - val_accuracy: 0.6301\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0182 - accuracy: 0.6185 - val_loss: 0.9527 - val_accuracy: 0.6310\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0155 - accuracy: 0.6184 - val_loss: 0.9526 - val_accuracy: 0.6277\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0158 - accuracy: 0.6183 - val_loss: 0.9570 - val_accuracy: 0.6297\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0170 - accuracy: 0.6178 - val_loss: 0.9517 - val_accuracy: 0.6302\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0176 - accuracy: 0.6169 - val_loss: 0.9547 - val_accuracy: 0.6282\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0159 - accuracy: 0.6177 - val_loss: 0.9548 - val_accuracy: 0.6288\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0175 - accuracy: 0.6165 - val_loss: 0.9508 - val_accuracy: 0.6326\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0164 - accuracy: 0.6181 - val_loss: 0.9547 - val_accuracy: 0.6276\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0176 - accuracy: 0.6179 - val_loss: 0.9598 - val_accuracy: 0.6250\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0164 - accuracy: 0.6173 - val_loss: 0.9536 - val_accuracy: 0.6314\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0157 - accuracy: 0.6179 - val_loss: 0.9696 - val_accuracy: 0.6235\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0165 - accuracy: 0.6167 - val_loss: 0.9539 - val_accuracy: 0.6309\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 1.0173 - accuracy: 0.6179 - val_loss: 0.9538 - val_accuracy: 0.6262\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0169 - accuracy: 0.6155 - val_loss: 0.9513 - val_accuracy: 0.6348\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0157 - accuracy: 0.6170 - val_loss: 0.9572 - val_accuracy: 0.6301\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0170 - accuracy: 0.6167 - val_loss: 0.9518 - val_accuracy: 0.6355\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0186 - accuracy: 0.6172 - val_loss: 0.9525 - val_accuracy: 0.6274\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0179 - accuracy: 0.6169 - val_loss: 0.9547 - val_accuracy: 0.6276\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0166 - accuracy: 0.6176 - val_loss: 0.9514 - val_accuracy: 0.6308\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0174 - accuracy: 0.6170 - val_loss: 0.9515 - val_accuracy: 0.6335\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0173 - accuracy: 0.6174 - val_loss: 0.9535 - val_accuracy: 0.6303\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0168 - accuracy: 0.6173 - val_loss: 0.9618 - val_accuracy: 0.6297\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0175 - accuracy: 0.6174 - val_loss: 0.9511 - val_accuracy: 0.6379\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0177 - accuracy: 0.6173 - val_loss: 0.9513 - val_accuracy: 0.6347\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0164 - accuracy: 0.6172 - val_loss: 0.9501 - val_accuracy: 0.6332\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0155 - accuracy: 0.6178 - val_loss: 0.9604 - val_accuracy: 0.6282\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0162 - accuracy: 0.6184 - val_loss: 0.9527 - val_accuracy: 0.6286\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0166 - accuracy: 0.6167 - val_loss: 0.9500 - val_accuracy: 0.6280\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0157 - accuracy: 0.6187 - val_loss: 0.9570 - val_accuracy: 0.6268\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0166 - accuracy: 0.6176 - val_loss: 0.9513 - val_accuracy: 0.6306\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0159 - accuracy: 0.6183 - val_loss: 0.9621 - val_accuracy: 0.6276\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0170 - accuracy: 0.6167 - val_loss: 0.9542 - val_accuracy: 0.6292\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0173 - accuracy: 0.6185 - val_loss: 0.9545 - val_accuracy: 0.6304\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0167 - accuracy: 0.6177 - val_loss: 0.9603 - val_accuracy: 0.6296\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0177 - accuracy: 0.6176 - val_loss: 0.9504 - val_accuracy: 0.6287\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0157 - accuracy: 0.6174 - val_loss: 0.9501 - val_accuracy: 0.6340\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0170 - accuracy: 0.6174 - val_loss: 0.9578 - val_accuracy: 0.6292\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0159 - accuracy: 0.6175 - val_loss: 0.9511 - val_accuracy: 0.6300\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0154 - accuracy: 0.6169 - val_loss: 0.9542 - val_accuracy: 0.6312\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0155 - accuracy: 0.6178 - val_loss: 0.9526 - val_accuracy: 0.6361\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0157 - accuracy: 0.6180 - val_loss: 0.9518 - val_accuracy: 0.6306\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0164 - accuracy: 0.6180 - val_loss: 0.9597 - val_accuracy: 0.6264\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0170 - accuracy: 0.6176 - val_loss: 0.9518 - val_accuracy: 0.6343\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0153 - accuracy: 0.6172 - val_loss: 0.9531 - val_accuracy: 0.6276\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0162 - accuracy: 0.6173 - val_loss: 0.9547 - val_accuracy: 0.6293\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0165 - accuracy: 0.6184 - val_loss: 0.9550 - val_accuracy: 0.6267\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0186 - accuracy: 0.6186 - val_loss: 0.9509 - val_accuracy: 0.6347\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0159 - accuracy: 0.6175 - val_loss: 0.9519 - val_accuracy: 0.6361\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0162 - accuracy: 0.6184 - val_loss: 0.9522 - val_accuracy: 0.6382\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0156 - accuracy: 0.6175 - val_loss: 0.9581 - val_accuracy: 0.6269\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0148 - accuracy: 0.6181 - val_loss: 0.9526 - val_accuracy: 0.6326\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0166 - accuracy: 0.6188 - val_loss: 0.9569 - val_accuracy: 0.6297\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 1.0161 - accuracy: 0.6165 - val_loss: 0.9522 - val_accuracy: 0.6325\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0162 - accuracy: 0.6187 - val_loss: 0.9539 - val_accuracy: 0.6352\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0147 - accuracy: 0.6190 - val_loss: 0.9508 - val_accuracy: 0.6287\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0167 - accuracy: 0.6182 - val_loss: 0.9603 - val_accuracy: 0.6266\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0154 - accuracy: 0.6179 - val_loss: 0.9515 - val_accuracy: 0.6271\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0174 - accuracy: 0.6179 - val_loss: 0.9545 - val_accuracy: 0.6268\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 1.0152 - accuracy: 0.6169 - val_loss: 0.9510 - val_accuracy: 0.6308\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0155 - accuracy: 0.6187 - val_loss: 0.9553 - val_accuracy: 0.6312\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0166 - accuracy: 0.6173 - val_loss: 0.9520 - val_accuracy: 0.6320\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 1.0148 - accuracy: 0.6180 - val_loss: 0.9548 - val_accuracy: 0.6334\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 1.0152 - accuracy: 0.6192 - val_loss: 0.9524 - val_accuracy: 0.6352\n",
      "accuracy: 63.52%\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    XTrain, XVal, yTrain, yVal = train_test_split(X, Y, test_size=0.2, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    model.fit(XTrain, yTrain, nb_epoch=200, validation_data=(XVal, yVal))\n",
    "    scores = model.evaluate(XVal, yVal, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    a.append(scores[1] * 100)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.033077001571655, 60.192763805389404, 61.47879958152771, 61.79531812667847, 63.51763606071472]\n"
     ]
    }
   ],
   "source": [
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
