{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "traindata['attack_cat'] = lb_make.fit_transform(traindata['attack_cat'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "testdata['attack_cat'] = lb_make.fit_transform(testdata['attack_cat'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-2]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-2]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "Y = to_categorical(Y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],X.shape[1],1))\n",
    "x = np.reshape(x, (x.shape[0],x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\", input_shape=(41, 1))`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(10, activation=\"softmax\"))\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "a=[]\n",
    "folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 45s 317us/step - loss: 1.3947 - accuracy: 0.5301 - val_loss: 1.3491 - val_accuracy: 0.5348\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 42s 299us/step - loss: 1.3508 - accuracy: 0.5338 - val_loss: 1.3245 - val_accuracy: 0.5357\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 42s 300us/step - loss: 1.3372 - accuracy: 0.5358 - val_loss: 1.3201 - val_accuracy: 0.5369\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 43s 304us/step - loss: 1.3296 - accuracy: 0.5394 - val_loss: 1.3141 - val_accuracy: 0.5428\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 43s 304us/step - loss: 1.3246 - accuracy: 0.5429 - val_loss: 1.3110 - val_accuracy: 0.5543\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 43s 304us/step - loss: 1.3203 - accuracy: 0.5436 - val_loss: 1.3072 - val_accuracy: 0.5484\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 42s 301us/step - loss: 1.3183 - accuracy: 0.5446 - val_loss: 1.3044 - val_accuracy: 0.5506\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 43s 309us/step - loss: 1.3135 - accuracy: 0.5464 - val_loss: 1.3041 - val_accuracy: 0.5540\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 1.3048 - accuracy: 0.5469 - val_loss: 1.2746 - val_accuracy: 0.5544\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 1.2584 - accuracy: 0.5478 - val_loss: 1.1892 - val_accuracy: 0.5549\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 1.1819 - accuracy: 0.5730 - val_loss: 1.1110 - val_accuracy: 0.6153\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 1.1225 - accuracy: 0.6067 - val_loss: 1.0596 - val_accuracy: 0.6189\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 43s 309us/step - loss: 1.0778 - accuracy: 0.6099 - val_loss: 1.0273 - val_accuracy: 0.6214\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 1.0581 - accuracy: 0.6105 - val_loss: 1.0060 - val_accuracy: 0.6216\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 1.0446 - accuracy: 0.6144 - val_loss: 1.0079 - val_accuracy: 0.6238\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 43s 309us/step - loss: 1.0368 - accuracy: 0.6162 - val_loss: 0.9974 - val_accuracy: 0.6226\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 44s 310us/step - loss: 1.0289 - accuracy: 0.6174 - val_loss: 0.9932 - val_accuracy: 0.6260\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 1.0253 - accuracy: 0.6193 - val_loss: 0.9824 - val_accuracy: 0.6294\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 43s 306us/step - loss: 1.0187 - accuracy: 0.6211 - val_loss: 0.9886 - val_accuracy: 0.6293\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 1.0167 - accuracy: 0.6214 - val_loss: 0.9812 - val_accuracy: 0.6318\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 1.0145 - accuracy: 0.6230 - val_loss: 0.9918 - val_accuracy: 0.6177\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 44s 312us/step - loss: 1.0129 - accuracy: 0.6237 - val_loss: 0.9702 - val_accuracy: 0.6270\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 44s 313us/step - loss: 1.0095 - accuracy: 0.6248 - val_loss: 0.9648 - val_accuracy: 0.6308\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 44s 311us/step - loss: 1.0081 - accuracy: 0.6252 - val_loss: 0.9667 - val_accuracy: 0.6510\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 1.0063 - accuracy: 0.6271 - val_loss: 0.9641 - val_accuracy: 0.6490\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 44s 312us/step - loss: 1.0037 - accuracy: 0.6272 - val_loss: 0.9588 - val_accuracy: 0.6295\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 44s 316us/step - loss: 0.9999 - accuracy: 0.6276 - val_loss: 0.9555 - val_accuracy: 0.6319\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.9960 - accuracy: 0.6294 - val_loss: 0.9594 - val_accuracy: 0.6481\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 44s 312us/step - loss: 0.9909 - accuracy: 0.6316 - val_loss: 0.9448 - val_accuracy: 0.6520\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 0.9840 - accuracy: 0.6323 - val_loss: 0.9451 - val_accuracy: 0.6310\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.9781 - accuracy: 0.6333 - val_loss: 0.9328 - val_accuracy: 0.6519\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 0.9747 - accuracy: 0.6334 - val_loss: 0.9228 - val_accuracy: 0.6533\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.9685 - accuracy: 0.6344 - val_loss: 0.9248 - val_accuracy: 0.6542\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 0.9637 - accuracy: 0.6363 - val_loss: 0.9185 - val_accuracy: 0.6546\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 43s 305us/step - loss: 0.9586 - accuracy: 0.6379 - val_loss: 0.9101 - val_accuracy: 0.6558\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 43s 305us/step - loss: 0.9573 - accuracy: 0.6370 - val_loss: 0.9101 - val_accuracy: 0.6540\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 43s 304us/step - loss: 0.9509 - accuracy: 0.6386 - val_loss: 0.9083 - val_accuracy: 0.6521\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 43s 305us/step - loss: 0.9473 - accuracy: 0.6389 - val_loss: 0.9055 - val_accuracy: 0.6571\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 43s 303us/step - loss: 0.9453 - accuracy: 0.6381 - val_loss: 0.8983 - val_accuracy: 0.6558\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 43s 307us/step - loss: 0.9414 - accuracy: 0.6406 - val_loss: 0.9220 - val_accuracy: 0.6533\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 43s 305us/step - loss: 0.9384 - accuracy: 0.6413 - val_loss: 0.9009 - val_accuracy: 0.6568\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 43s 307us/step - loss: 0.9361 - accuracy: 0.6421 - val_loss: 0.8904 - val_accuracy: 0.6541\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 43s 309us/step - loss: 0.9310 - accuracy: 0.6437 - val_loss: 0.8873 - val_accuracy: 0.6539\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 42s 300us/step - loss: 0.9292 - accuracy: 0.6426 - val_loss: 0.8878 - val_accuracy: 0.6544\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.9264 - accuracy: 0.6435 - val_loss: 0.8912 - val_accuracy: 0.6567\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.9244 - accuracy: 0.6443 - val_loss: 0.8871 - val_accuracy: 0.6541\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.9226 - accuracy: 0.6437 - val_loss: 0.8745 - val_accuracy: 0.6553\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.9206 - accuracy: 0.6436 - val_loss: 0.8872 - val_accuracy: 0.6581\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.9184 - accuracy: 0.6450 - val_loss: 0.8819 - val_accuracy: 0.6529\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.9175 - accuracy: 0.6446 - val_loss: 0.8787 - val_accuracy: 0.6566\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.9160 - accuracy: 0.6449 - val_loss: 0.8752 - val_accuracy: 0.6576\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.9121 - accuracy: 0.6454 - val_loss: 0.8760 - val_accuracy: 0.6649\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.9140 - accuracy: 0.6462 - val_loss: 0.8657 - val_accuracy: 0.6586\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.9126 - accuracy: 0.6471 - val_loss: 0.8793 - val_accuracy: 0.6637\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.9115 - accuracy: 0.6471 - val_loss: 0.8705 - val_accuracy: 0.6551\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.9109 - accuracy: 0.6466 - val_loss: 0.8632 - val_accuracy: 0.6545\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.9093 - accuracy: 0.6472 - val_loss: 0.8676 - val_accuracy: 0.6607\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.9070 - accuracy: 0.6476 - val_loss: 0.8586 - val_accuracy: 0.6639\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.9062 - accuracy: 0.6473 - val_loss: 0.8685 - val_accuracy: 0.6623\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.9035 - accuracy: 0.6490 - val_loss: 0.8622 - val_accuracy: 0.6528\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.9011 - accuracy: 0.6493 - val_loss: 0.8647 - val_accuracy: 0.6587\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.9009 - accuracy: 0.6500 - val_loss: 0.8732 - val_accuracy: 0.6606\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.9011 - accuracy: 0.6504 - val_loss: 0.8569 - val_accuracy: 0.6673\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8989 - accuracy: 0.6495 - val_loss: 0.8518 - val_accuracy: 0.6604\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8977 - accuracy: 0.6503 - val_loss: 0.8516 - val_accuracy: 0.6619\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8965 - accuracy: 0.6518 - val_loss: 0.8530 - val_accuracy: 0.6627\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8956 - accuracy: 0.6501 - val_loss: 0.8474 - val_accuracy: 0.6614\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8946 - accuracy: 0.6507 - val_loss: 0.8515 - val_accuracy: 0.6620\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8933 - accuracy: 0.6514 - val_loss: 0.8458 - val_accuracy: 0.6623\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8942 - accuracy: 0.6524 - val_loss: 0.8587 - val_accuracy: 0.6633\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8918 - accuracy: 0.6516 - val_loss: 0.8468 - val_accuracy: 0.6651\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8917 - accuracy: 0.6518 - val_loss: 0.8505 - val_accuracy: 0.6640\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8901 - accuracy: 0.6521 - val_loss: 0.8494 - val_accuracy: 0.6673\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8893 - accuracy: 0.6518 - val_loss: 0.8458 - val_accuracy: 0.6616\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8880 - accuracy: 0.6524 - val_loss: 0.8465 - val_accuracy: 0.6649\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8906 - accuracy: 0.6493 - val_loss: 0.8461 - val_accuracy: 0.6658\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8930 - accuracy: 0.6510 - val_loss: 0.8505 - val_accuracy: 0.6659\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8889 - accuracy: 0.6529 - val_loss: 0.8463 - val_accuracy: 0.6657\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8909 - accuracy: 0.6528 - val_loss: 0.8434 - val_accuracy: 0.6655\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8899 - accuracy: 0.6512 - val_loss: 0.8587 - val_accuracy: 0.6635\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8887 - accuracy: 0.6516 - val_loss: 0.8491 - val_accuracy: 0.6662\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8880 - accuracy: 0.6505 - val_loss: 0.8598 - val_accuracy: 0.6456\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8881 - accuracy: 0.6504 - val_loss: 0.8456 - val_accuracy: 0.6614\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8880 - accuracy: 0.6517 - val_loss: 0.8430 - val_accuracy: 0.6616\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8871 - accuracy: 0.6522 - val_loss: 0.8435 - val_accuracy: 0.6643\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8877 - accuracy: 0.6498 - val_loss: 0.8469 - val_accuracy: 0.6585\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8878 - accuracy: 0.6509 - val_loss: 0.8445 - val_accuracy: 0.6667\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8874 - accuracy: 0.6513 - val_loss: 0.8749 - val_accuracy: 0.6556\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8842 - accuracy: 0.6519 - val_loss: 0.8667 - val_accuracy: 0.6566\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8846 - accuracy: 0.6509 - val_loss: 0.8393 - val_accuracy: 0.6671\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8841 - accuracy: 0.6522 - val_loss: 0.8415 - val_accuracy: 0.6653\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8827 - accuracy: 0.6528 - val_loss: 0.8402 - val_accuracy: 0.6657\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8860 - accuracy: 0.6522 - val_loss: 0.8506 - val_accuracy: 0.6648\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8854 - accuracy: 0.6523 - val_loss: 0.8460 - val_accuracy: 0.6647\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8865 - accuracy: 0.6520 - val_loss: 0.8423 - val_accuracy: 0.6674\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8887 - accuracy: 0.6507 - val_loss: 0.8485 - val_accuracy: 0.6667\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8876 - accuracy: 0.6517 - val_loss: 0.8625 - val_accuracy: 0.6582\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8898 - accuracy: 0.6508 - val_loss: 0.8402 - val_accuracy: 0.6663\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8894 - accuracy: 0.6508 - val_loss: 0.8472 - val_accuracy: 0.6669\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8878 - accuracy: 0.6517 - val_loss: 0.8514 - val_accuracy: 0.6637\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8898 - accuracy: 0.6513 - val_loss: 0.8479 - val_accuracy: 0.6603\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8874 - accuracy: 0.6512 - val_loss: 0.8629 - val_accuracy: 0.6631\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8879 - accuracy: 0.6515 - val_loss: 0.8453 - val_accuracy: 0.6664\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8874 - accuracy: 0.6529 - val_loss: 0.8410 - val_accuracy: 0.6652\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8872 - accuracy: 0.6513 - val_loss: 0.8399 - val_accuracy: 0.6660\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8871 - accuracy: 0.6520 - val_loss: 0.8403 - val_accuracy: 0.6654\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8885 - accuracy: 0.6512 - val_loss: 0.8409 - val_accuracy: 0.6626\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8867 - accuracy: 0.6518 - val_loss: 0.8452 - val_accuracy: 0.6674\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8883 - accuracy: 0.6509 - val_loss: 0.8535 - val_accuracy: 0.6588\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8903 - accuracy: 0.6500 - val_loss: 0.8401 - val_accuracy: 0.6665\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8887 - accuracy: 0.6515 - val_loss: 0.8342 - val_accuracy: 0.6666\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8883 - accuracy: 0.6520 - val_loss: 0.8546 - val_accuracy: 0.6664\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8878 - accuracy: 0.6511 - val_loss: 0.8435 - val_accuracy: 0.6639\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8904 - accuracy: 0.6514 - val_loss: 0.8477 - val_accuracy: 0.6630\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8874 - accuracy: 0.6521 - val_loss: 0.8370 - val_accuracy: 0.6687\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8901 - accuracy: 0.6504 - val_loss: 0.8420 - val_accuracy: 0.6638\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8849 - accuracy: 0.6520 - val_loss: 0.8321 - val_accuracy: 0.6676\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8873 - accuracy: 0.6515 - val_loss: 0.8555 - val_accuracy: 0.6700\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8876 - accuracy: 0.6517 - val_loss: 0.8433 - val_accuracy: 0.6654\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8882 - accuracy: 0.6519 - val_loss: 0.8437 - val_accuracy: 0.6621\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8894 - accuracy: 0.6515 - val_loss: 0.8379 - val_accuracy: 0.6659\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8890 - accuracy: 0.6518 - val_loss: 0.8330 - val_accuracy: 0.6688\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8880 - accuracy: 0.6526 - val_loss: 0.8535 - val_accuracy: 0.6655\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8875 - accuracy: 0.6523 - val_loss: 0.8413 - val_accuracy: 0.6683\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8881 - accuracy: 0.6528 - val_loss: 0.8406 - val_accuracy: 0.6663\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8867 - accuracy: 0.6517 - val_loss: 0.8484 - val_accuracy: 0.6670\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8856 - accuracy: 0.6522 - val_loss: 0.8523 - val_accuracy: 0.6647\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8873 - accuracy: 0.6529 - val_loss: 0.8379 - val_accuracy: 0.6628\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8861 - accuracy: 0.6526 - val_loss: 0.8585 - val_accuracy: 0.6652\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8850 - accuracy: 0.6524 - val_loss: 0.8479 - val_accuracy: 0.6653\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8851 - accuracy: 0.6539 - val_loss: 0.8362 - val_accuracy: 0.6687\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8879 - accuracy: 0.6526 - val_loss: 0.8447 - val_accuracy: 0.6650\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8875 - accuracy: 0.6522 - val_loss: 0.8375 - val_accuracy: 0.6711\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8881 - accuracy: 0.6520 - val_loss: 0.8623 - val_accuracy: 0.6590\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8873 - accuracy: 0.6521 - val_loss: 0.8461 - val_accuracy: 0.6653\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8859 - accuracy: 0.6527 - val_loss: 0.8427 - val_accuracy: 0.6682\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8859 - accuracy: 0.6534 - val_loss: 0.8436 - val_accuracy: 0.6622\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8846 - accuracy: 0.6535 - val_loss: 0.8398 - val_accuracy: 0.6659\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8845 - accuracy: 0.6527 - val_loss: 0.8381 - val_accuracy: 0.6674\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8857 - accuracy: 0.6533 - val_loss: 0.8372 - val_accuracy: 0.6652\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8859 - accuracy: 0.6539 - val_loss: 0.8437 - val_accuracy: 0.6660\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8839 - accuracy: 0.6535 - val_loss: 0.8389 - val_accuracy: 0.6627\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8859 - accuracy: 0.6521 - val_loss: 0.8410 - val_accuracy: 0.6675\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8851 - accuracy: 0.6539 - val_loss: 0.8381 - val_accuracy: 0.6676\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8845 - accuracy: 0.6544 - val_loss: 0.8395 - val_accuracy: 0.6673\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8831 - accuracy: 0.6529 - val_loss: 0.8325 - val_accuracy: 0.6660\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8823 - accuracy: 0.6538 - val_loss: 0.8398 - val_accuracy: 0.6669\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8813 - accuracy: 0.6543 - val_loss: 0.8411 - val_accuracy: 0.6653\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8833 - accuracy: 0.6556 - val_loss: 0.8522 - val_accuracy: 0.6509\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8851 - accuracy: 0.6540 - val_loss: 0.8658 - val_accuracy: 0.6524\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8857 - accuracy: 0.6524 - val_loss: 0.8481 - val_accuracy: 0.6689\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8871 - accuracy: 0.6532 - val_loss: 0.8346 - val_accuracy: 0.6679\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8860 - accuracy: 0.6529 - val_loss: 0.8369 - val_accuracy: 0.6670\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8864 - accuracy: 0.6523 - val_loss: 0.8327 - val_accuracy: 0.6694\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8852 - accuracy: 0.6543 - val_loss: 0.8338 - val_accuracy: 0.6673\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8845 - accuracy: 0.6532 - val_loss: 0.8393 - val_accuracy: 0.6691\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8843 - accuracy: 0.6543 - val_loss: 0.8388 - val_accuracy: 0.6687\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8839 - accuracy: 0.6533 - val_loss: 0.8338 - val_accuracy: 0.6685\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8876 - accuracy: 0.6535 - val_loss: 0.8328 - val_accuracy: 0.6698\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8845 - accuracy: 0.6541 - val_loss: 0.8364 - val_accuracy: 0.6675\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8829 - accuracy: 0.6531 - val_loss: 0.8787 - val_accuracy: 0.6592\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8839 - accuracy: 0.6529 - val_loss: 0.8503 - val_accuracy: 0.6597\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8833 - accuracy: 0.6541 - val_loss: 0.8320 - val_accuracy: 0.6683\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8842 - accuracy: 0.6537 - val_loss: 0.8354 - val_accuracy: 0.6667\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8828 - accuracy: 0.6546 - val_loss: 0.8376 - val_accuracy: 0.6671\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8843 - accuracy: 0.6543 - val_loss: 0.8320 - val_accuracy: 0.6703\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8835 - accuracy: 0.6551 - val_loss: 0.8493 - val_accuracy: 0.6647\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8829 - accuracy: 0.6529 - val_loss: 0.8529 - val_accuracy: 0.6468\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8815 - accuracy: 0.6540 - val_loss: 0.8350 - val_accuracy: 0.6677\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8820 - accuracy: 0.6543 - val_loss: 0.8322 - val_accuracy: 0.6665\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8843 - accuracy: 0.6531 - val_loss: 0.8389 - val_accuracy: 0.6666\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8819 - accuracy: 0.6540 - val_loss: 0.8879 - val_accuracy: 0.6634\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8823 - accuracy: 0.6527 - val_loss: 0.8350 - val_accuracy: 0.6673\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8838 - accuracy: 0.6534 - val_loss: 0.8379 - val_accuracy: 0.6652\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 49s 346us/step - loss: 0.8825 - accuracy: 0.6545 - val_loss: 0.8277 - val_accuracy: 0.6695\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.8809 - accuracy: 0.6535 - val_loss: 0.8320 - val_accuracy: 0.6661\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8795 - accuracy: 0.6556 - val_loss: 0.8298 - val_accuracy: 0.6637\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8808 - accuracy: 0.6540 - val_loss: 0.8302 - val_accuracy: 0.6656\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8809 - accuracy: 0.6548 - val_loss: 0.8299 - val_accuracy: 0.6697\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8816 - accuracy: 0.6542 - val_loss: 0.8336 - val_accuracy: 0.6672\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8812 - accuracy: 0.6539 - val_loss: 0.8380 - val_accuracy: 0.6691\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8850 - accuracy: 0.6526 - val_loss: 0.8400 - val_accuracy: 0.6645\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8822 - accuracy: 0.6535 - val_loss: 0.8311 - val_accuracy: 0.6678\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8820 - accuracy: 0.6538 - val_loss: 0.8379 - val_accuracy: 0.6636\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8824 - accuracy: 0.6551 - val_loss: 0.8543 - val_accuracy: 0.6645\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8849 - accuracy: 0.6527 - val_loss: 0.8413 - val_accuracy: 0.6619\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8812 - accuracy: 0.6542 - val_loss: 0.8426 - val_accuracy: 0.6635\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8817 - accuracy: 0.6533 - val_loss: 0.8292 - val_accuracy: 0.6660\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8827 - accuracy: 0.6528 - val_loss: 0.8406 - val_accuracy: 0.6597\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8814 - accuracy: 0.6542 - val_loss: 0.8294 - val_accuracy: 0.6681\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8846 - accuracy: 0.6523 - val_loss: 0.8572 - val_accuracy: 0.6670\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8828 - accuracy: 0.6520 - val_loss: 0.8423 - val_accuracy: 0.6665\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8818 - accuracy: 0.6534 - val_loss: 0.8304 - val_accuracy: 0.6697\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8815 - accuracy: 0.6541 - val_loss: 0.8574 - val_accuracy: 0.6676\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8819 - accuracy: 0.6537 - val_loss: 0.8476 - val_accuracy: 0.6485\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8823 - accuracy: 0.6522 - val_loss: 0.8350 - val_accuracy: 0.6654\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8816 - accuracy: 0.6521 - val_loss: 0.8417 - val_accuracy: 0.6656\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8816 - accuracy: 0.6539 - val_loss: 0.8433 - val_accuracy: 0.6545\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8816 - accuracy: 0.6524 - val_loss: 0.8399 - val_accuracy: 0.6566\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8821 - accuracy: 0.6520 - val_loss: 0.8501 - val_accuracy: 0.6425\n",
      "accuracy: 64.25%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8825 - accuracy: 0.6530 - val_loss: 0.8310 - val_accuracy: 0.6636\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8814 - accuracy: 0.6543 - val_loss: 0.8272 - val_accuracy: 0.6681\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8812 - accuracy: 0.6547 - val_loss: 0.8321 - val_accuracy: 0.6684\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8820 - accuracy: 0.6536 - val_loss: 0.8510 - val_accuracy: 0.6476\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8818 - accuracy: 0.6535 - val_loss: 0.8400 - val_accuracy: 0.6553\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8822 - accuracy: 0.6531 - val_loss: 0.8352 - val_accuracy: 0.6634\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8816 - accuracy: 0.6547 - val_loss: 0.8300 - val_accuracy: 0.6659\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8845 - accuracy: 0.6513 - val_loss: 0.8472 - val_accuracy: 0.6635\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8811 - accuracy: 0.6553 - val_loss: 0.8348 - val_accuracy: 0.6602\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8806 - accuracy: 0.6546 - val_loss: 0.8291 - val_accuracy: 0.6689\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8812 - accuracy: 0.6538 - val_loss: 0.8281 - val_accuracy: 0.6647\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8795 - accuracy: 0.6536 - val_loss: 0.8361 - val_accuracy: 0.6681\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8821 - accuracy: 0.6541 - val_loss: 0.8297 - val_accuracy: 0.6687\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8791 - accuracy: 0.6546 - val_loss: 0.8314 - val_accuracy: 0.6668\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8808 - accuracy: 0.6545 - val_loss: 0.8462 - val_accuracy: 0.6486\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8788 - accuracy: 0.6540 - val_loss: 0.8240 - val_accuracy: 0.6658\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8783 - accuracy: 0.6553 - val_loss: 0.8444 - val_accuracy: 0.6507\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8801 - accuracy: 0.6541 - val_loss: 0.8346 - val_accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8820 - accuracy: 0.6523 - val_loss: 0.8323 - val_accuracy: 0.6687\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8791 - accuracy: 0.6537 - val_loss: 0.8311 - val_accuracy: 0.6661\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8802 - accuracy: 0.6541 - val_loss: 0.8278 - val_accuracy: 0.6640\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8778 - accuracy: 0.6535 - val_loss: 0.8315 - val_accuracy: 0.6681\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8783 - accuracy: 0.6546 - val_loss: 0.8271 - val_accuracy: 0.6661\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8807 - accuracy: 0.6545 - val_loss: 0.8289 - val_accuracy: 0.6658\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8787 - accuracy: 0.6550 - val_loss: 0.8276 - val_accuracy: 0.6681\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8812 - accuracy: 0.6535 - val_loss: 0.8339 - val_accuracy: 0.6676\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8792 - accuracy: 0.6533 - val_loss: 0.8260 - val_accuracy: 0.6676\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8793 - accuracy: 0.6533 - val_loss: 0.8347 - val_accuracy: 0.6592\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8791 - accuracy: 0.6540 - val_loss: 0.8257 - val_accuracy: 0.6668\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8762 - accuracy: 0.6552 - val_loss: 0.8420 - val_accuracy: 0.6513\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8779 - accuracy: 0.6543 - val_loss: 0.8480 - val_accuracy: 0.6497\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8784 - accuracy: 0.6539 - val_loss: 0.8323 - val_accuracy: 0.6705\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8762 - accuracy: 0.6536 - val_loss: 0.8465 - val_accuracy: 0.6557\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8762 - accuracy: 0.6555 - val_loss: 0.8369 - val_accuracy: 0.6620\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8754 - accuracy: 0.6545 - val_loss: 0.8596 - val_accuracy: 0.6468\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8797 - accuracy: 0.6541 - val_loss: 0.8263 - val_accuracy: 0.6665\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8781 - accuracy: 0.6544 - val_loss: 0.8260 - val_accuracy: 0.6629\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8782 - accuracy: 0.6539 - val_loss: 0.8292 - val_accuracy: 0.6653\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8781 - accuracy: 0.6550 - val_loss: 0.8283 - val_accuracy: 0.6663\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8770 - accuracy: 0.6552 - val_loss: 0.8286 - val_accuracy: 0.6626\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8776 - accuracy: 0.6542 - val_loss: 0.8260 - val_accuracy: 0.6660\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8772 - accuracy: 0.6538 - val_loss: 0.8362 - val_accuracy: 0.6607\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8752 - accuracy: 0.6562 - val_loss: 0.8365 - val_accuracy: 0.6646\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8784 - accuracy: 0.6558 - val_loss: 0.8269 - val_accuracy: 0.6650\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8775 - accuracy: 0.6552 - val_loss: 0.8334 - val_accuracy: 0.6692\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8799 - accuracy: 0.6545 - val_loss: 0.8330 - val_accuracy: 0.6685\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8796 - accuracy: 0.6543 - val_loss: 0.8440 - val_accuracy: 0.6436\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8787 - accuracy: 0.6540 - val_loss: 0.8304 - val_accuracy: 0.6674\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8792 - accuracy: 0.6543 - val_loss: 0.8256 - val_accuracy: 0.6675\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8796 - accuracy: 0.6535 - val_loss: 0.8289 - val_accuracy: 0.6635\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8786 - accuracy: 0.6558 - val_loss: 0.8280 - val_accuracy: 0.6643\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8775 - accuracy: 0.6546 - val_loss: 0.8243 - val_accuracy: 0.6651\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8772 - accuracy: 0.6555 - val_loss: 0.8281 - val_accuracy: 0.6641\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8788 - accuracy: 0.6541 - val_loss: 0.8306 - val_accuracy: 0.6668\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8779 - accuracy: 0.6558 - val_loss: 0.8315 - val_accuracy: 0.6645\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8807 - accuracy: 0.6530 - val_loss: 0.8408 - val_accuracy: 0.6613\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8769 - accuracy: 0.6549 - val_loss: 0.8280 - val_accuracy: 0.6677\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8810 - accuracy: 0.6536 - val_loss: 0.8348 - val_accuracy: 0.6698\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8814 - accuracy: 0.6530 - val_loss: 0.8474 - val_accuracy: 0.6619\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8793 - accuracy: 0.6548 - val_loss: 0.8361 - val_accuracy: 0.6654\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8792 - accuracy: 0.6545 - val_loss: 0.8300 - val_accuracy: 0.6650\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8799 - accuracy: 0.6546 - val_loss: 0.8255 - val_accuracy: 0.6673\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8800 - accuracy: 0.6536 - val_loss: 0.8250 - val_accuracy: 0.6636\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8794 - accuracy: 0.6541 - val_loss: 0.8499 - val_accuracy: 0.6467\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8787 - accuracy: 0.6544 - val_loss: 0.8280 - val_accuracy: 0.6667\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8791 - accuracy: 0.6539 - val_loss: 0.8252 - val_accuracy: 0.6678\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8772 - accuracy: 0.6550 - val_loss: 0.8244 - val_accuracy: 0.6653\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8771 - accuracy: 0.6550 - val_loss: 0.8301 - val_accuracy: 0.6624\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8779 - accuracy: 0.6552 - val_loss: 0.8215 - val_accuracy: 0.6689\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8768 - accuracy: 0.6561 - val_loss: 0.8415 - val_accuracy: 0.6636\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8762 - accuracy: 0.6550 - val_loss: 0.8332 - val_accuracy: 0.6630\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8763 - accuracy: 0.6550 - val_loss: 0.8245 - val_accuracy: 0.6658\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8787 - accuracy: 0.6538 - val_loss: 0.8268 - val_accuracy: 0.6671\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8846 - accuracy: 0.6532 - val_loss: 0.8363 - val_accuracy: 0.6542\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8800 - accuracy: 0.6552 - val_loss: 0.8279 - val_accuracy: 0.6634\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8813 - accuracy: 0.6529 - val_loss: 0.8275 - val_accuracy: 0.6623\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8750 - accuracy: 0.6548 - val_loss: 0.8244 - val_accuracy: 0.6678\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8791 - accuracy: 0.6550 - val_loss: 0.8290 - val_accuracy: 0.6667\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8766 - accuracy: 0.6548 - val_loss: 0.8286 - val_accuracy: 0.6696\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8752 - accuracy: 0.6562 - val_loss: 0.8275 - val_accuracy: 0.6682\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8789 - accuracy: 0.6535 - val_loss: 0.8244 - val_accuracy: 0.6673\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8765 - accuracy: 0.6559 - val_loss: 0.8237 - val_accuracy: 0.6666\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8751 - accuracy: 0.6558 - val_loss: 0.8290 - val_accuracy: 0.6700\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8780 - accuracy: 0.6531 - val_loss: 0.8233 - val_accuracy: 0.6691\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8778 - accuracy: 0.6541 - val_loss: 0.8264 - val_accuracy: 0.6653\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8749 - accuracy: 0.6554 - val_loss: 0.8312 - val_accuracy: 0.6693\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8762 - accuracy: 0.6557 - val_loss: 0.8225 - val_accuracy: 0.6681\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8736 - accuracy: 0.6566 - val_loss: 0.8241 - val_accuracy: 0.6666\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8745 - accuracy: 0.6558 - val_loss: 0.8413 - val_accuracy: 0.6609\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8757 - accuracy: 0.6554 - val_loss: 0.8399 - val_accuracy: 0.6626\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8759 - accuracy: 0.6557 - val_loss: 0.8234 - val_accuracy: 0.6650\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8756 - accuracy: 0.6546 - val_loss: 0.8259 - val_accuracy: 0.6698\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8733 - accuracy: 0.6568 - val_loss: 0.8284 - val_accuracy: 0.6663\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8785 - accuracy: 0.6558 - val_loss: 0.8264 - val_accuracy: 0.6671\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8772 - accuracy: 0.6554 - val_loss: 0.8318 - val_accuracy: 0.6668\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8804 - accuracy: 0.6535 - val_loss: 0.8301 - val_accuracy: 0.6677\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8801 - accuracy: 0.6545 - val_loss: 0.8287 - val_accuracy: 0.6645\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8846 - accuracy: 0.6523 - val_loss: 0.8392 - val_accuracy: 0.6672\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8838 - accuracy: 0.6538 - val_loss: 0.8372 - val_accuracy: 0.6698\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8836 - accuracy: 0.6520 - val_loss: 0.8424 - val_accuracy: 0.6648\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8755 - accuracy: 0.6561 - val_loss: 0.8298 - val_accuracy: 0.6641\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8755 - accuracy: 0.6549 - val_loss: 0.8270 - val_accuracy: 0.6638\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8748 - accuracy: 0.6559 - val_loss: 0.8249 - val_accuracy: 0.6624\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8758 - accuracy: 0.6540 - val_loss: 0.8260 - val_accuracy: 0.6660\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8736 - accuracy: 0.6557 - val_loss: 0.8383 - val_accuracy: 0.6600\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8752 - accuracy: 0.6545 - val_loss: 0.8308 - val_accuracy: 0.6600\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8752 - accuracy: 0.6549 - val_loss: 0.8300 - val_accuracy: 0.6602\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8756 - accuracy: 0.6565 - val_loss: 0.8332 - val_accuracy: 0.6623\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8747 - accuracy: 0.6555 - val_loss: 0.8252 - val_accuracy: 0.6659\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8729 - accuracy: 0.6558 - val_loss: 0.8273 - val_accuracy: 0.6652\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8753 - accuracy: 0.6553 - val_loss: 0.8326 - val_accuracy: 0.6643\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8754 - accuracy: 0.6548 - val_loss: 0.8248 - val_accuracy: 0.6686\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8750 - accuracy: 0.6552 - val_loss: 0.8282 - val_accuracy: 0.6626\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8773 - accuracy: 0.6520 - val_loss: 0.8438 - val_accuracy: 0.6646\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8791 - accuracy: 0.6525 - val_loss: 0.8353 - val_accuracy: 0.6644\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8774 - accuracy: 0.6544 - val_loss: 0.8419 - val_accuracy: 0.6535\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8732 - accuracy: 0.6556 - val_loss: 0.8249 - val_accuracy: 0.6653\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8726 - accuracy: 0.6553 - val_loss: 0.8316 - val_accuracy: 0.6671\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8756 - accuracy: 0.6551 - val_loss: 0.8308 - val_accuracy: 0.6629\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8757 - accuracy: 0.6540 - val_loss: 0.8444 - val_accuracy: 0.6617\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8738 - accuracy: 0.6553 - val_loss: 0.8255 - val_accuracy: 0.6677\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8730 - accuracy: 0.6564 - val_loss: 0.8331 - val_accuracy: 0.6599\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8749 - accuracy: 0.6547 - val_loss: 0.8547 - val_accuracy: 0.6466\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8763 - accuracy: 0.6541 - val_loss: 0.8293 - val_accuracy: 0.6665\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8755 - accuracy: 0.6550 - val_loss: 0.8282 - val_accuracy: 0.6639\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8777 - accuracy: 0.6538 - val_loss: 0.8405 - val_accuracy: 0.6656\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8758 - accuracy: 0.6555 - val_loss: 0.8322 - val_accuracy: 0.6656\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8736 - accuracy: 0.6563 - val_loss: 0.8255 - val_accuracy: 0.6686\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8745 - accuracy: 0.6558 - val_loss: 0.8279 - val_accuracy: 0.6691\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8756 - accuracy: 0.6548 - val_loss: 0.8280 - val_accuracy: 0.6630\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8744 - accuracy: 0.6548 - val_loss: 0.8258 - val_accuracy: 0.6649\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8743 - accuracy: 0.6543 - val_loss: 0.8261 - val_accuracy: 0.6694\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8738 - accuracy: 0.6550 - val_loss: 0.8320 - val_accuracy: 0.6650\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8744 - accuracy: 0.6553 - val_loss: 0.8290 - val_accuracy: 0.6643\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8746 - accuracy: 0.6550 - val_loss: 0.8294 - val_accuracy: 0.6594\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8774 - accuracy: 0.6549 - val_loss: 0.8243 - val_accuracy: 0.6647\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8757 - accuracy: 0.6553 - val_loss: 0.8285 - val_accuracy: 0.6596\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8775 - accuracy: 0.6558 - val_loss: 0.8223 - val_accuracy: 0.6699\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8751 - accuracy: 0.6551 - val_loss: 0.8333 - val_accuracy: 0.6610\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8764 - accuracy: 0.6562 - val_loss: 0.8266 - val_accuracy: 0.6685\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8748 - accuracy: 0.6561 - val_loss: 0.8265 - val_accuracy: 0.6634\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8763 - accuracy: 0.6554 - val_loss: 0.8364 - val_accuracy: 0.6628\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8737 - accuracy: 0.6563 - val_loss: 0.8228 - val_accuracy: 0.6677\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8742 - accuracy: 0.6546 - val_loss: 0.8246 - val_accuracy: 0.6628\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8718 - accuracy: 0.6567 - val_loss: 0.8221 - val_accuracy: 0.6691\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8736 - accuracy: 0.6547 - val_loss: 0.8255 - val_accuracy: 0.6638\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8718 - accuracy: 0.6558 - val_loss: 0.8293 - val_accuracy: 0.6684\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8728 - accuracy: 0.6558 - val_loss: 0.8250 - val_accuracy: 0.6627\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8714 - accuracy: 0.6554 - val_loss: 0.8304 - val_accuracy: 0.6657\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8725 - accuracy: 0.6572 - val_loss: 0.8304 - val_accuracy: 0.6696\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8713 - accuracy: 0.6566 - val_loss: 0.8303 - val_accuracy: 0.6645\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8842 - accuracy: 0.6540 - val_loss: 0.8232 - val_accuracy: 0.6691\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8763 - accuracy: 0.6547 - val_loss: 0.8306 - val_accuracy: 0.6688\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8790 - accuracy: 0.6547 - val_loss: 0.8317 - val_accuracy: 0.6632\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8764 - accuracy: 0.6566 - val_loss: 0.8693 - val_accuracy: 0.6485\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8764 - accuracy: 0.6555 - val_loss: 0.8253 - val_accuracy: 0.6654\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8725 - accuracy: 0.6564 - val_loss: 0.8258 - val_accuracy: 0.6670\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8719 - accuracy: 0.6564 - val_loss: 0.8304 - val_accuracy: 0.6663\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8731 - accuracy: 0.6550 - val_loss: 0.8253 - val_accuracy: 0.6680\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8727 - accuracy: 0.6568 - val_loss: 0.8330 - val_accuracy: 0.6614\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8745 - accuracy: 0.6553 - val_loss: 0.8251 - val_accuracy: 0.6683\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8727 - accuracy: 0.6571 - val_loss: 0.8289 - val_accuracy: 0.6641\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8701 - accuracy: 0.6572 - val_loss: 0.8268 - val_accuracy: 0.6668\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8753 - accuracy: 0.6550 - val_loss: 0.8230 - val_accuracy: 0.6686\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8733 - accuracy: 0.6556 - val_loss: 0.8528 - val_accuracy: 0.6657\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8819 - accuracy: 0.6531 - val_loss: 0.8381 - val_accuracy: 0.6639\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8747 - accuracy: 0.6548 - val_loss: 0.8328 - val_accuracy: 0.6629\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8740 - accuracy: 0.6557 - val_loss: 0.8401 - val_accuracy: 0.6483\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8741 - accuracy: 0.6562 - val_loss: 0.8226 - val_accuracy: 0.6635\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8729 - accuracy: 0.6569 - val_loss: 0.8318 - val_accuracy: 0.6620\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8757 - accuracy: 0.6553 - val_loss: 0.8356 - val_accuracy: 0.6503\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8746 - accuracy: 0.6561 - val_loss: 0.8461 - val_accuracy: 0.6640\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8739 - accuracy: 0.6551 - val_loss: 0.8359 - val_accuracy: 0.6453\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8745 - accuracy: 0.6560 - val_loss: 0.8271 - val_accuracy: 0.6669\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8753 - accuracy: 0.6549 - val_loss: 0.8221 - val_accuracy: 0.6668\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8730 - accuracy: 0.6561 - val_loss: 0.8283 - val_accuracy: 0.6686\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8750 - accuracy: 0.6554 - val_loss: 0.8214 - val_accuracy: 0.6689\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8732 - accuracy: 0.6570 - val_loss: 0.8232 - val_accuracy: 0.6624\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8754 - accuracy: 0.6561 - val_loss: 0.8260 - val_accuracy: 0.6689\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8722 - accuracy: 0.6564 - val_loss: 0.8353 - val_accuracy: 0.6600\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8734 - accuracy: 0.6564 - val_loss: 0.8227 - val_accuracy: 0.6675\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8748 - accuracy: 0.6565 - val_loss: 0.8307 - val_accuracy: 0.6649\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8770 - accuracy: 0.6533 - val_loss: 0.8290 - val_accuracy: 0.6666\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8719 - accuracy: 0.6563 - val_loss: 0.8244 - val_accuracy: 0.6666\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8728 - accuracy: 0.6552 - val_loss: 0.8293 - val_accuracy: 0.6636\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8750 - accuracy: 0.6552 - val_loss: 0.8269 - val_accuracy: 0.6616\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 39s 281us/step - loss: 0.8705 - accuracy: 0.6575 - val_loss: 0.8244 - val_accuracy: 0.6683\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8744 - accuracy: 0.6544 - val_loss: 0.8290 - val_accuracy: 0.6679\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8732 - accuracy: 0.6553 - val_loss: 0.8209 - val_accuracy: 0.6666\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8720 - accuracy: 0.6554 - val_loss: 0.8246 - val_accuracy: 0.6675\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8741 - accuracy: 0.6551 - val_loss: 0.8245 - val_accuracy: 0.6657\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8726 - accuracy: 0.6572 - val_loss: 0.8346 - val_accuracy: 0.6600\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8721 - accuracy: 0.6570 - val_loss: 0.8334 - val_accuracy: 0.6630\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8701 - accuracy: 0.6569 - val_loss: 0.8274 - val_accuracy: 0.6647\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8725 - accuracy: 0.6562 - val_loss: 0.8273 - val_accuracy: 0.6628\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8723 - accuracy: 0.6570 - val_loss: 0.8357 - val_accuracy: 0.6577\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8718 - accuracy: 0.6565 - val_loss: 0.8246 - val_accuracy: 0.6689\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8724 - accuracy: 0.6557 - val_loss: 0.8269 - val_accuracy: 0.6628\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8737 - accuracy: 0.6553 - val_loss: 0.8224 - val_accuracy: 0.6625\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8717 - accuracy: 0.6554 - val_loss: 0.8458 - val_accuracy: 0.6645\n",
      "accuracy: 66.45%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8713 - accuracy: 0.6556 - val_loss: 0.8318 - val_accuracy: 0.6607\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8739 - accuracy: 0.6554 - val_loss: 0.8265 - val_accuracy: 0.6624\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8744 - accuracy: 0.6549 - val_loss: 0.8234 - val_accuracy: 0.6643\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8729 - accuracy: 0.6550 - val_loss: 0.8266 - val_accuracy: 0.6622\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8728 - accuracy: 0.6554 - val_loss: 0.8347 - val_accuracy: 0.6655\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8725 - accuracy: 0.6548 - val_loss: 0.8283 - val_accuracy: 0.6651\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8707 - accuracy: 0.6543 - val_loss: 0.8253 - val_accuracy: 0.6641\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8715 - accuracy: 0.6548 - val_loss: 0.8279 - val_accuracy: 0.6667\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8712 - accuracy: 0.6555 - val_loss: 0.8307 - val_accuracy: 0.6697\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8703 - accuracy: 0.6556 - val_loss: 0.8365 - val_accuracy: 0.6548\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8691 - accuracy: 0.6562 - val_loss: 0.8535 - val_accuracy: 0.6408\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8747 - accuracy: 0.6541 - val_loss: 0.8447 - val_accuracy: 0.6616\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.8740 - accuracy: 0.6542 - val_loss: 0.8392 - val_accuracy: 0.6566\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8723 - accuracy: 0.6555 - val_loss: 0.8245 - val_accuracy: 0.6718\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8727 - accuracy: 0.6551 - val_loss: 0.8281 - val_accuracy: 0.6688\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8709 - accuracy: 0.6554 - val_loss: 0.8502 - val_accuracy: 0.6576\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8733 - accuracy: 0.6534 - val_loss: 0.8226 - val_accuracy: 0.6683\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8722 - accuracy: 0.6543 - val_loss: 0.8651 - val_accuracy: 0.6422\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8704 - accuracy: 0.6555 - val_loss: 0.8260 - val_accuracy: 0.6683\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8734 - accuracy: 0.6548 - val_loss: 0.8332 - val_accuracy: 0.6612\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8726 - accuracy: 0.6546 - val_loss: 0.8220 - val_accuracy: 0.6656\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8715 - accuracy: 0.6565 - val_loss: 0.8260 - val_accuracy: 0.6646\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8757 - accuracy: 0.6533 - val_loss: 0.8331 - val_accuracy: 0.6622\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8760 - accuracy: 0.6542 - val_loss: 0.8304 - val_accuracy: 0.6620\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8774 - accuracy: 0.6540 - val_loss: 0.8302 - val_accuracy: 0.6712\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8823 - accuracy: 0.6521 - val_loss: 0.8266 - val_accuracy: 0.6617\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8815 - accuracy: 0.6523 - val_loss: 0.8347 - val_accuracy: 0.6640\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8831 - accuracy: 0.6528 - val_loss: 0.8277 - val_accuracy: 0.6706\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8811 - accuracy: 0.6514 - val_loss: 0.8388 - val_accuracy: 0.6540\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8765 - accuracy: 0.6540 - val_loss: 0.8266 - val_accuracy: 0.6635\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8759 - accuracy: 0.6545 - val_loss: 0.8249 - val_accuracy: 0.6690\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8755 - accuracy: 0.6546 - val_loss: 0.8247 - val_accuracy: 0.6638\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8724 - accuracy: 0.6551 - val_loss: 0.8354 - val_accuracy: 0.6616\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8766 - accuracy: 0.6553 - val_loss: 0.8400 - val_accuracy: 0.6511\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8755 - accuracy: 0.6542 - val_loss: 0.8329 - val_accuracy: 0.6683\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8750 - accuracy: 0.6538 - val_loss: 0.8307 - val_accuracy: 0.6603\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8730 - accuracy: 0.6551 - val_loss: 0.8292 - val_accuracy: 0.6649\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8744 - accuracy: 0.6548 - val_loss: 0.8299 - val_accuracy: 0.6676\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8746 - accuracy: 0.6541 - val_loss: 0.8396 - val_accuracy: 0.6551\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8750 - accuracy: 0.6541 - val_loss: 0.8262 - val_accuracy: 0.6646\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8779 - accuracy: 0.6541 - val_loss: 0.8259 - val_accuracy: 0.6610\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8774 - accuracy: 0.6546 - val_loss: 0.8391 - val_accuracy: 0.6665\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8735 - accuracy: 0.6551 - val_loss: 0.8425 - val_accuracy: 0.6616\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8756 - accuracy: 0.6529 - val_loss: 0.8248 - val_accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8734 - accuracy: 0.6551 - val_loss: 0.8240 - val_accuracy: 0.6654\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8726 - accuracy: 0.6536 - val_loss: 0.8605 - val_accuracy: 0.6493\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8718 - accuracy: 0.6545 - val_loss: 0.8376 - val_accuracy: 0.6675\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8735 - accuracy: 0.6541 - val_loss: 0.8329 - val_accuracy: 0.6644\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8743 - accuracy: 0.6540 - val_loss: 0.8357 - val_accuracy: 0.6512\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8765 - accuracy: 0.6540 - val_loss: 0.8317 - val_accuracy: 0.6699\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8753 - accuracy: 0.6546 - val_loss: 0.8322 - val_accuracy: 0.6621\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8746 - accuracy: 0.6552 - val_loss: 0.8307 - val_accuracy: 0.6687\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8812 - accuracy: 0.6536 - val_loss: 0.8354 - val_accuracy: 0.6580\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8779 - accuracy: 0.6545 - val_loss: 0.8274 - val_accuracy: 0.6637\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8755 - accuracy: 0.6545 - val_loss: 0.8329 - val_accuracy: 0.6634\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8763 - accuracy: 0.6550 - val_loss: 0.8265 - val_accuracy: 0.6639\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 43s 307us/step - loss: 0.8785 - accuracy: 0.6545 - val_loss: 0.8293 - val_accuracy: 0.6639\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8821 - accuracy: 0.6542 - val_loss: 0.8425 - val_accuracy: 0.6642\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8904 - accuracy: 0.6510 - val_loss: 0.8335 - val_accuracy: 0.6683\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8854 - accuracy: 0.6524 - val_loss: 0.8456 - val_accuracy: 0.6621\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8831 - accuracy: 0.6527 - val_loss: 0.8485 - val_accuracy: 0.6632\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8856 - accuracy: 0.6512 - val_loss: 0.8362 - val_accuracy: 0.6647\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8834 - accuracy: 0.6524 - val_loss: 0.8443 - val_accuracy: 0.6660\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8822 - accuracy: 0.6516 - val_loss: 0.8293 - val_accuracy: 0.6641\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8810 - accuracy: 0.6533 - val_loss: 0.8307 - val_accuracy: 0.6639\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8795 - accuracy: 0.6533 - val_loss: 0.8280 - val_accuracy: 0.6681\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8803 - accuracy: 0.6526 - val_loss: 0.8319 - val_accuracy: 0.6703\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8828 - accuracy: 0.6509 - val_loss: 0.8348 - val_accuracy: 0.6595\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8807 - accuracy: 0.6535 - val_loss: 0.8310 - val_accuracy: 0.6642\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8867 - accuracy: 0.6491 - val_loss: 0.8403 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8882 - accuracy: 0.6421 - val_loss: 0.8427 - val_accuracy: 0.6488\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8896 - accuracy: 0.6415 - val_loss: 0.8797 - val_accuracy: 0.6459\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.8880 - accuracy: 0.6414 - val_loss: 0.8381 - val_accuracy: 0.6505\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8896 - accuracy: 0.6434 - val_loss: 0.8400 - val_accuracy: 0.6534\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8888 - accuracy: 0.6420 - val_loss: 0.8365 - val_accuracy: 0.6560\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8877 - accuracy: 0.6433 - val_loss: 0.8388 - val_accuracy: 0.6532\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8891 - accuracy: 0.6429 - val_loss: 0.8399 - val_accuracy: 0.6528\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8881 - accuracy: 0.6409 - val_loss: 0.8430 - val_accuracy: 0.6525\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8856 - accuracy: 0.6416 - val_loss: 0.8389 - val_accuracy: 0.6585\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8912 - accuracy: 0.6425 - val_loss: 0.8399 - val_accuracy: 0.6551\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8884 - accuracy: 0.6418 - val_loss: 0.8363 - val_accuracy: 0.6562\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8878 - accuracy: 0.6427 - val_loss: 0.8380 - val_accuracy: 0.6463\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8883 - accuracy: 0.6433 - val_loss: 0.8655 - val_accuracy: 0.6358\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8898 - accuracy: 0.6441 - val_loss: 0.8452 - val_accuracy: 0.6523\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8882 - accuracy: 0.6428 - val_loss: 0.8428 - val_accuracy: 0.6560\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8883 - accuracy: 0.6421 - val_loss: 0.8393 - val_accuracy: 0.6447\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8874 - accuracy: 0.6436 - val_loss: 0.8456 - val_accuracy: 0.6464\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8887 - accuracy: 0.6429 - val_loss: 0.9524 - val_accuracy: 0.6215\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8861 - accuracy: 0.6437 - val_loss: 0.8376 - val_accuracy: 0.6535\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8873 - accuracy: 0.6421 - val_loss: 0.8370 - val_accuracy: 0.6481\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8870 - accuracy: 0.6414 - val_loss: 0.8468 - val_accuracy: 0.6523\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8882 - accuracy: 0.6417 - val_loss: 0.8405 - val_accuracy: 0.6539\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8912 - accuracy: 0.6420 - val_loss: 0.8401 - val_accuracy: 0.6456\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8904 - accuracy: 0.6426 - val_loss: 0.8436 - val_accuracy: 0.6432\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8912 - accuracy: 0.6411 - val_loss: 0.8564 - val_accuracy: 0.6527\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8906 - accuracy: 0.6406 - val_loss: 0.8407 - val_accuracy: 0.6560\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8944 - accuracy: 0.6416 - val_loss: 0.8538 - val_accuracy: 0.6521\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8880 - accuracy: 0.6424 - val_loss: 0.8353 - val_accuracy: 0.6552\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8863 - accuracy: 0.6421 - val_loss: 0.8368 - val_accuracy: 0.6485\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8869 - accuracy: 0.6425 - val_loss: 0.8676 - val_accuracy: 0.6351\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8867 - accuracy: 0.6431 - val_loss: 0.8377 - val_accuracy: 0.6548\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8865 - accuracy: 0.6417 - val_loss: 0.8471 - val_accuracy: 0.6522\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8884 - accuracy: 0.6423 - val_loss: 0.8506 - val_accuracy: 0.6431\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8884 - accuracy: 0.6421 - val_loss: 0.8360 - val_accuracy: 0.6527\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8897 - accuracy: 0.6431 - val_loss: 0.8437 - val_accuracy: 0.6448\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8959 - accuracy: 0.6384 - val_loss: 0.8419 - val_accuracy: 0.6522\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8906 - accuracy: 0.6427 - val_loss: 0.8399 - val_accuracy: 0.6549\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8908 - accuracy: 0.6430 - val_loss: 0.8398 - val_accuracy: 0.6554\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8894 - accuracy: 0.6424 - val_loss: 0.8413 - val_accuracy: 0.6418\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8879 - accuracy: 0.6422 - val_loss: 0.8427 - val_accuracy: 0.6535\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8870 - accuracy: 0.6430 - val_loss: 0.8445 - val_accuracy: 0.6561\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8883 - accuracy: 0.6421 - val_loss: 0.8539 - val_accuracy: 0.6551\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8871 - accuracy: 0.6422 - val_loss: 0.8475 - val_accuracy: 0.6524\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8882 - accuracy: 0.6429 - val_loss: 0.8448 - val_accuracy: 0.6522\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8869 - accuracy: 0.6421 - val_loss: 0.8397 - val_accuracy: 0.6429\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8872 - accuracy: 0.6417 - val_loss: 0.8386 - val_accuracy: 0.6554\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8897 - accuracy: 0.6423 - val_loss: 0.8378 - val_accuracy: 0.6475\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8898 - accuracy: 0.6410 - val_loss: 0.8396 - val_accuracy: 0.6593\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8915 - accuracy: 0.6400 - val_loss: 0.8385 - val_accuracy: 0.6586\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8899 - accuracy: 0.6405 - val_loss: 0.8383 - val_accuracy: 0.6524\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8911 - accuracy: 0.6409 - val_loss: 0.8379 - val_accuracy: 0.6549\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8901 - accuracy: 0.6414 - val_loss: 0.8379 - val_accuracy: 0.6459\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8899 - accuracy: 0.6406 - val_loss: 0.8396 - val_accuracy: 0.6514\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8923 - accuracy: 0.6406 - val_loss: 0.8427 - val_accuracy: 0.6505\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8886 - accuracy: 0.6413 - val_loss: 0.8517 - val_accuracy: 0.6527\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8908 - accuracy: 0.6418 - val_loss: 0.8418 - val_accuracy: 0.6518\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8910 - accuracy: 0.6410 - val_loss: 0.8661 - val_accuracy: 0.6248\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8934 - accuracy: 0.6406 - val_loss: 0.8416 - val_accuracy: 0.6484\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8912 - accuracy: 0.6409 - val_loss: 0.8456 - val_accuracy: 0.6437\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8915 - accuracy: 0.6409 - val_loss: 0.8530 - val_accuracy: 0.6569\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8916 - accuracy: 0.6416 - val_loss: 0.8441 - val_accuracy: 0.6539\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8927 - accuracy: 0.6397 - val_loss: 0.8364 - val_accuracy: 0.6526\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8908 - accuracy: 0.6404 - val_loss: 0.8385 - val_accuracy: 0.6545\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8918 - accuracy: 0.6404 - val_loss: 0.8402 - val_accuracy: 0.6563\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8893 - accuracy: 0.6413 - val_loss: 0.8412 - val_accuracy: 0.6416\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8908 - accuracy: 0.6406 - val_loss: 0.8411 - val_accuracy: 0.6590\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8901 - accuracy: 0.6411 - val_loss: 0.8472 - val_accuracy: 0.6511\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8906 - accuracy: 0.6413 - val_loss: 0.8402 - val_accuracy: 0.6546\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8907 - accuracy: 0.6402 - val_loss: 0.8431 - val_accuracy: 0.6528\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8882 - accuracy: 0.6422 - val_loss: 0.8393 - val_accuracy: 0.6550\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8921 - accuracy: 0.6400 - val_loss: 0.8389 - val_accuracy: 0.6610\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8912 - accuracy: 0.6406 - val_loss: 0.8632 - val_accuracy: 0.6344\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8906 - accuracy: 0.6399 - val_loss: 0.8446 - val_accuracy: 0.6505\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8914 - accuracy: 0.6415 - val_loss: 0.8419 - val_accuracy: 0.6533\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8891 - accuracy: 0.6410 - val_loss: 0.8406 - val_accuracy: 0.6598\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8904 - accuracy: 0.6403 - val_loss: 0.8449 - val_accuracy: 0.6456\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8908 - accuracy: 0.6413 - val_loss: 0.8413 - val_accuracy: 0.6535\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8939 - accuracy: 0.6405 - val_loss: 0.8520 - val_accuracy: 0.6457\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8890 - accuracy: 0.6410 - val_loss: 0.8413 - val_accuracy: 0.6473\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8910 - accuracy: 0.6405 - val_loss: 0.8400 - val_accuracy: 0.6556\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8899 - accuracy: 0.6405 - val_loss: 0.8375 - val_accuracy: 0.6560\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8862 - accuracy: 0.6419 - val_loss: 0.8370 - val_accuracy: 0.6500\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8851 - accuracy: 0.6428 - val_loss: 0.8366 - val_accuracy: 0.6443\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8865 - accuracy: 0.6428 - val_loss: 0.8364 - val_accuracy: 0.6528\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8856 - accuracy: 0.6426 - val_loss: 0.8377 - val_accuracy: 0.6568\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8873 - accuracy: 0.6424 - val_loss: 0.8365 - val_accuracy: 0.6471\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 46s 328us/step - loss: 0.8875 - accuracy: 0.6410 - val_loss: 0.8510 - val_accuracy: 0.6523\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8871 - accuracy: 0.6419 - val_loss: 0.8399 - val_accuracy: 0.6526\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8847 - accuracy: 0.6432 - val_loss: 0.8395 - val_accuracy: 0.6577\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8885 - accuracy: 0.6420 - val_loss: 0.9585 - val_accuracy: 0.6158\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8893 - accuracy: 0.6416 - val_loss: 0.8374 - val_accuracy: 0.6547\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8878 - accuracy: 0.6419 - val_loss: 0.8343 - val_accuracy: 0.6597\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8850 - accuracy: 0.6438 - val_loss: 0.8365 - val_accuracy: 0.6525\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8859 - accuracy: 0.6432 - val_loss: 0.8362 - val_accuracy: 0.6564\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8864 - accuracy: 0.6432 - val_loss: 0.8378 - val_accuracy: 0.6525\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8880 - accuracy: 0.6417 - val_loss: 0.8406 - val_accuracy: 0.6540\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8900 - accuracy: 0.6412 - val_loss: 0.8663 - val_accuracy: 0.6468\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8897 - accuracy: 0.6407 - val_loss: 0.8366 - val_accuracy: 0.6443\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8902 - accuracy: 0.6417 - val_loss: 0.8411 - val_accuracy: 0.6540\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8896 - accuracy: 0.6416 - val_loss: 0.8372 - val_accuracy: 0.6417\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8883 - accuracy: 0.6416 - val_loss: 0.8432 - val_accuracy: 0.6541\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8876 - accuracy: 0.6419 - val_loss: 0.8363 - val_accuracy: 0.6525\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8857 - accuracy: 0.6426 - val_loss: 0.8366 - val_accuracy: 0.6518\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8880 - accuracy: 0.6418 - val_loss: 0.8386 - val_accuracy: 0.6555\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8867 - accuracy: 0.6423 - val_loss: 0.8395 - val_accuracy: 0.6554\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8866 - accuracy: 0.6420 - val_loss: 0.8381 - val_accuracy: 0.6535\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8845 - accuracy: 0.6437 - val_loss: 0.8433 - val_accuracy: 0.6591\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.8891 - accuracy: 0.6414 - val_loss: 0.8355 - val_accuracy: 0.6538\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 50s 356us/step - loss: 0.8901 - accuracy: 0.6408 - val_loss: 0.8394 - val_accuracy: 0.6446\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 0.8872 - accuracy: 0.6420 - val_loss: 0.8696 - val_accuracy: 0.6260\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8889 - accuracy: 0.6412 - val_loss: 0.8594 - val_accuracy: 0.6504\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8856 - accuracy: 0.6425 - val_loss: 0.8430 - val_accuracy: 0.6516\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8824 - accuracy: 0.6430 - val_loss: 0.8508 - val_accuracy: 0.6515\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8858 - accuracy: 0.6433 - val_loss: 0.8395 - val_accuracy: 0.6449\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8869 - accuracy: 0.6417 - val_loss: 0.8379 - val_accuracy: 0.6525\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8940 - accuracy: 0.6417 - val_loss: 0.8373 - val_accuracy: 0.6533\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8884 - accuracy: 0.6410 - val_loss: 0.8368 - val_accuracy: 0.6477\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8907 - accuracy: 0.6413 - val_loss: 0.8367 - val_accuracy: 0.6579\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8849 - accuracy: 0.6437 - val_loss: 0.8356 - val_accuracy: 0.6554\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8857 - accuracy: 0.6432 - val_loss: 0.8385 - val_accuracy: 0.6535\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8839 - accuracy: 0.6437 - val_loss: 0.8397 - val_accuracy: 0.6537\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8859 - accuracy: 0.6424 - val_loss: 0.8376 - val_accuracy: 0.6508\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8870 - accuracy: 0.6439 - val_loss: 0.8377 - val_accuracy: 0.6525\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8867 - accuracy: 0.6434 - val_loss: 0.8366 - val_accuracy: 0.6533\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8843 - accuracy: 0.6424 - val_loss: 0.8375 - val_accuracy: 0.6505\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8884 - accuracy: 0.6425 - val_loss: 0.8377 - val_accuracy: 0.6456\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8853 - accuracy: 0.6430 - val_loss: 0.8367 - val_accuracy: 0.6528\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8854 - accuracy: 0.6436 - val_loss: 0.8525 - val_accuracy: 0.6572\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8858 - accuracy: 0.6436 - val_loss: 0.8369 - val_accuracy: 0.6529\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8878 - accuracy: 0.6433 - val_loss: 0.8366 - val_accuracy: 0.6602\n",
      "accuracy: 66.02%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8893 - accuracy: 0.6433 - val_loss: 0.8340 - val_accuracy: 0.6526\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8910 - accuracy: 0.6428 - val_loss: 0.8312 - val_accuracy: 0.6523\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8883 - accuracy: 0.6419 - val_loss: 0.8290 - val_accuracy: 0.6522\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8909 - accuracy: 0.6426 - val_loss: 0.8448 - val_accuracy: 0.6440\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8891 - accuracy: 0.6435 - val_loss: 0.8344 - val_accuracy: 0.6415\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8902 - accuracy: 0.6439 - val_loss: 0.8305 - val_accuracy: 0.6527\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8889 - accuracy: 0.6429 - val_loss: 0.8421 - val_accuracy: 0.6502\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8878 - accuracy: 0.6432 - val_loss: 0.8318 - val_accuracy: 0.6474\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8892 - accuracy: 0.6423 - val_loss: 0.8414 - val_accuracy: 0.6492\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8907 - accuracy: 0.6429 - val_loss: 0.8361 - val_accuracy: 0.6499\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8867 - accuracy: 0.6441 - val_loss: 0.8845 - val_accuracy: 0.6409\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8876 - accuracy: 0.6434 - val_loss: 0.8358 - val_accuracy: 0.6499\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8856 - accuracy: 0.6441 - val_loss: 0.8306 - val_accuracy: 0.6544\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8826 - accuracy: 0.6434 - val_loss: 0.8332 - val_accuracy: 0.6482\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8859 - accuracy: 0.6448 - val_loss: 0.8352 - val_accuracy: 0.6535\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8845 - accuracy: 0.6443 - val_loss: 0.8317 - val_accuracy: 0.6513\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8859 - accuracy: 0.6437 - val_loss: 0.8575 - val_accuracy: 0.6407\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8906 - accuracy: 0.6421 - val_loss: 0.8443 - val_accuracy: 0.6504\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8880 - accuracy: 0.6433 - val_loss: 0.8364 - val_accuracy: 0.6494\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8851 - accuracy: 0.6437 - val_loss: 0.8346 - val_accuracy: 0.6507\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8969 - accuracy: 0.6396 - val_loss: 0.8349 - val_accuracy: 0.6506\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8962 - accuracy: 0.6415 - val_loss: 0.8363 - val_accuracy: 0.6503\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8972 - accuracy: 0.6403 - val_loss: 0.8741 - val_accuracy: 0.6326\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8947 - accuracy: 0.6413 - val_loss: 0.8363 - val_accuracy: 0.6478\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8920 - accuracy: 0.6419 - val_loss: 0.8393 - val_accuracy: 0.6504\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8902 - accuracy: 0.6428 - val_loss: 0.8461 - val_accuracy: 0.6457\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8907 - accuracy: 0.6427 - val_loss: 0.8350 - val_accuracy: 0.6503\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8886 - accuracy: 0.6430 - val_loss: 0.8387 - val_accuracy: 0.6502\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8919 - accuracy: 0.6419 - val_loss: 0.8607 - val_accuracy: 0.6422\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8910 - accuracy: 0.6421 - val_loss: 0.8477 - val_accuracy: 0.6530\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8907 - accuracy: 0.6429 - val_loss: 0.8339 - val_accuracy: 0.6564\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8915 - accuracy: 0.6419 - val_loss: 0.8394 - val_accuracy: 0.6464\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8910 - accuracy: 0.6426 - val_loss: 0.8467 - val_accuracy: 0.6414\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8920 - accuracy: 0.6417 - val_loss: 0.8342 - val_accuracy: 0.6547\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8933 - accuracy: 0.6429 - val_loss: 0.8368 - val_accuracy: 0.6523\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8914 - accuracy: 0.6429 - val_loss: 0.8335 - val_accuracy: 0.6604\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8950 - accuracy: 0.6409 - val_loss: 0.8429 - val_accuracy: 0.6499\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8953 - accuracy: 0.6405 - val_loss: 0.8342 - val_accuracy: 0.6529\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8958 - accuracy: 0.6411 - val_loss: 0.8349 - val_accuracy: 0.6501\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8905 - accuracy: 0.6415 - val_loss: 0.8505 - val_accuracy: 0.6478\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8953 - accuracy: 0.6413 - val_loss: 0.8357 - val_accuracy: 0.6534\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8926 - accuracy: 0.6428 - val_loss: 0.8323 - val_accuracy: 0.6523\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8903 - accuracy: 0.6419 - val_loss: 0.8397 - val_accuracy: 0.6507\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8920 - accuracy: 0.6428 - val_loss: 0.8543 - val_accuracy: 0.6489\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8892 - accuracy: 0.6421 - val_loss: 0.8386 - val_accuracy: 0.6481\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8902 - accuracy: 0.6430 - val_loss: 0.8391 - val_accuracy: 0.6490\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8903 - accuracy: 0.6414 - val_loss: 0.8362 - val_accuracy: 0.6499\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8932 - accuracy: 0.6418 - val_loss: 0.8370 - val_accuracy: 0.6543\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8905 - accuracy: 0.6432 - val_loss: 0.8364 - val_accuracy: 0.6508\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8914 - accuracy: 0.6433 - val_loss: 0.8339 - val_accuracy: 0.6616\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8894 - accuracy: 0.6438 - val_loss: 0.8370 - val_accuracy: 0.6513\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8890 - accuracy: 0.6422 - val_loss: 0.8345 - val_accuracy: 0.6499\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8905 - accuracy: 0.6410 - val_loss: 0.8386 - val_accuracy: 0.6464\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8913 - accuracy: 0.6429 - val_loss: 0.8480 - val_accuracy: 0.6476\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8902 - accuracy: 0.6435 - val_loss: 0.8314 - val_accuracy: 0.6547\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8887 - accuracy: 0.6431 - val_loss: 0.8354 - val_accuracy: 0.6553\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8926 - accuracy: 0.6424 - val_loss: 0.8335 - val_accuracy: 0.6474\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8984 - accuracy: 0.6389 - val_loss: 0.8371 - val_accuracy: 0.6503\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8923 - accuracy: 0.6408 - val_loss: 0.8382 - val_accuracy: 0.6509\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8914 - accuracy: 0.6418 - val_loss: 0.8357 - val_accuracy: 0.6528\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8901 - accuracy: 0.6428 - val_loss: 0.8365 - val_accuracy: 0.6527\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8879 - accuracy: 0.6433 - val_loss: 0.8349 - val_accuracy: 0.6504\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8908 - accuracy: 0.6434 - val_loss: 0.8421 - val_accuracy: 0.6486\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8898 - accuracy: 0.6427 - val_loss: 0.8323 - val_accuracy: 0.6560\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8894 - accuracy: 0.6430 - val_loss: 0.8391 - val_accuracy: 0.6493\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8916 - accuracy: 0.6423 - val_loss: 0.8434 - val_accuracy: 0.6515\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8899 - accuracy: 0.6422 - val_loss: 0.8363 - val_accuracy: 0.6500\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8864 - accuracy: 0.6433 - val_loss: 0.8343 - val_accuracy: 0.6555\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8890 - accuracy: 0.6427 - val_loss: 0.8388 - val_accuracy: 0.6539\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8900 - accuracy: 0.6436 - val_loss: 0.8355 - val_accuracy: 0.6512\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8907 - accuracy: 0.6436 - val_loss: 0.8368 - val_accuracy: 0.6551\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8905 - accuracy: 0.6441 - val_loss: 0.8314 - val_accuracy: 0.6492\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8881 - accuracy: 0.6435 - val_loss: 0.8354 - val_accuracy: 0.6545\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8994 - accuracy: 0.6421 - val_loss: 0.8570 - val_accuracy: 0.6515\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8900 - accuracy: 0.6430 - val_loss: 0.8350 - val_accuracy: 0.6474\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8880 - accuracy: 0.6426 - val_loss: 0.8392 - val_accuracy: 0.6468\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8928 - accuracy: 0.6410 - val_loss: 0.8377 - val_accuracy: 0.6510\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8897 - accuracy: 0.6433 - val_loss: 0.8328 - val_accuracy: 0.6532\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8945 - accuracy: 0.6416 - val_loss: 0.8321 - val_accuracy: 0.6507\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8890 - accuracy: 0.6429 - val_loss: 0.8418 - val_accuracy: 0.6478\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.8886 - accuracy: 0.6433 - val_loss: 0.8347 - val_accuracy: 0.6544\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8904 - accuracy: 0.6430 - val_loss: 0.8399 - val_accuracy: 0.6524\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8904 - accuracy: 0.6431 - val_loss: 0.8513 - val_accuracy: 0.6539\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8902 - accuracy: 0.6450 - val_loss: 0.8343 - val_accuracy: 0.6450\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8889 - accuracy: 0.6431 - val_loss: 0.8353 - val_accuracy: 0.6513\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8895 - accuracy: 0.6433 - val_loss: 0.8340 - val_accuracy: 0.6560\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 39s 281us/step - loss: 0.8869 - accuracy: 0.6437 - val_loss: 0.8389 - val_accuracy: 0.6496\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8884 - accuracy: 0.6437 - val_loss: 0.8717 - val_accuracy: 0.6289\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8919 - accuracy: 0.6428 - val_loss: 0.8387 - val_accuracy: 0.6496\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8913 - accuracy: 0.6429 - val_loss: 0.8322 - val_accuracy: 0.6546\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8903 - accuracy: 0.6432 - val_loss: 0.8337 - val_accuracy: 0.6446\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8905 - accuracy: 0.6422 - val_loss: 0.8327 - val_accuracy: 0.6521\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8942 - accuracy: 0.6413 - val_loss: 0.8436 - val_accuracy: 0.6563\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8969 - accuracy: 0.6433 - val_loss: 0.8392 - val_accuracy: 0.6512\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8926 - accuracy: 0.6411 - val_loss: 0.8373 - val_accuracy: 0.6574\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8928 - accuracy: 0.6427 - val_loss: 0.8326 - val_accuracy: 0.6543\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8905 - accuracy: 0.6436 - val_loss: 0.8363 - val_accuracy: 0.6535\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8883 - accuracy: 0.6441 - val_loss: 0.8351 - val_accuracy: 0.6536\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8880 - accuracy: 0.6431 - val_loss: 0.8399 - val_accuracy: 0.6500\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8880 - accuracy: 0.6435 - val_loss: 0.8349 - val_accuracy: 0.6513\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8930 - accuracy: 0.6443 - val_loss: 0.8348 - val_accuracy: 0.6503\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8900 - accuracy: 0.6436 - val_loss: 0.8369 - val_accuracy: 0.6503\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8868 - accuracy: 0.6442 - val_loss: 0.9146 - val_accuracy: 0.6397\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8929 - accuracy: 0.6426 - val_loss: 0.8365 - val_accuracy: 0.6496\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8886 - accuracy: 0.6419 - val_loss: 0.8340 - val_accuracy: 0.6510\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8886 - accuracy: 0.6452 - val_loss: 0.8376 - val_accuracy: 0.6530\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8886 - accuracy: 0.6441 - val_loss: 0.8450 - val_accuracy: 0.6557\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8890 - accuracy: 0.6437 - val_loss: 0.8369 - val_accuracy: 0.6492\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8881 - accuracy: 0.6436 - val_loss: 0.8327 - val_accuracy: 0.6519\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8872 - accuracy: 0.6452 - val_loss: 0.8320 - val_accuracy: 0.6492\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8910 - accuracy: 0.6438 - val_loss: 0.8334 - val_accuracy: 0.6524\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8879 - accuracy: 0.6440 - val_loss: 0.8310 - val_accuracy: 0.6493\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8870 - accuracy: 0.6449 - val_loss: 0.8329 - val_accuracy: 0.6491\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.9046 - accuracy: 0.6397 - val_loss: 0.8349 - val_accuracy: 0.6517\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8897 - accuracy: 0.6430 - val_loss: 0.8342 - val_accuracy: 0.6513\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8898 - accuracy: 0.6442 - val_loss: 0.8357 - val_accuracy: 0.6535\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8880 - accuracy: 0.6450 - val_loss: 0.8412 - val_accuracy: 0.6532\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8895 - accuracy: 0.6443 - val_loss: 0.8354 - val_accuracy: 0.6562\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8900 - accuracy: 0.6436 - val_loss: 0.8432 - val_accuracy: 0.6485\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8934 - accuracy: 0.6438 - val_loss: 0.8318 - val_accuracy: 0.6594\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8896 - accuracy: 0.6430 - val_loss: 0.8357 - val_accuracy: 0.6525\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8923 - accuracy: 0.6430 - val_loss: 0.8334 - val_accuracy: 0.6487\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8906 - accuracy: 0.6426 - val_loss: 0.8358 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8888 - accuracy: 0.6423 - val_loss: 0.8338 - val_accuracy: 0.6558\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8926 - accuracy: 0.6428 - val_loss: 0.8367 - val_accuracy: 0.6537\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8874 - accuracy: 0.6437 - val_loss: 0.8357 - val_accuracy: 0.6529\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8895 - accuracy: 0.6430 - val_loss: 0.8597 - val_accuracy: 0.6350\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8885 - accuracy: 0.6435 - val_loss: 0.8429 - val_accuracy: 0.6460\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8917 - accuracy: 0.6441 - val_loss: 0.8356 - val_accuracy: 0.6557\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8892 - accuracy: 0.6429 - val_loss: 0.8315 - val_accuracy: 0.6480\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8891 - accuracy: 0.6444 - val_loss: 0.8321 - val_accuracy: 0.6496\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8872 - accuracy: 0.6447 - val_loss: 0.8369 - val_accuracy: 0.6531\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8884 - accuracy: 0.6449 - val_loss: 0.8360 - val_accuracy: 0.6498\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8905 - accuracy: 0.6431 - val_loss: 0.8424 - val_accuracy: 0.6491\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8890 - accuracy: 0.6435 - val_loss: 0.8322 - val_accuracy: 0.6489\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8899 - accuracy: 0.6448 - val_loss: 0.8348 - val_accuracy: 0.6537\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8898 - accuracy: 0.6431 - val_loss: 0.8394 - val_accuracy: 0.6522\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8883 - accuracy: 0.6438 - val_loss: 0.8563 - val_accuracy: 0.6402\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8891 - accuracy: 0.6430 - val_loss: 0.8356 - val_accuracy: 0.6523\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8879 - accuracy: 0.6445 - val_loss: 0.8344 - val_accuracy: 0.6585\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8908 - accuracy: 0.6419 - val_loss: 0.8308 - val_accuracy: 0.6516\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8876 - accuracy: 0.6435 - val_loss: 0.8324 - val_accuracy: 0.6497\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8859 - accuracy: 0.6451 - val_loss: 0.8364 - val_accuracy: 0.6513\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8893 - accuracy: 0.6438 - val_loss: 0.8563 - val_accuracy: 0.6529\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8873 - accuracy: 0.6444 - val_loss: 0.8295 - val_accuracy: 0.6496\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8969 - accuracy: 0.6419 - val_loss: 0.8352 - val_accuracy: 0.6556\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8886 - accuracy: 0.6446 - val_loss: 0.8593 - val_accuracy: 0.6317\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8878 - accuracy: 0.6439 - val_loss: 0.8344 - val_accuracy: 0.6521\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8890 - accuracy: 0.6445 - val_loss: 0.8599 - val_accuracy: 0.6312\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8856 - accuracy: 0.6450 - val_loss: 0.8363 - val_accuracy: 0.6524\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8895 - accuracy: 0.6449 - val_loss: 0.8306 - val_accuracy: 0.6517\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8896 - accuracy: 0.6454 - val_loss: 0.8302 - val_accuracy: 0.6558\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8922 - accuracy: 0.6430 - val_loss: 0.8373 - val_accuracy: 0.6495\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8858 - accuracy: 0.6450 - val_loss: 0.8506 - val_accuracy: 0.6548\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8871 - accuracy: 0.6438 - val_loss: 0.8304 - val_accuracy: 0.6536\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8891 - accuracy: 0.6427 - val_loss: 0.8347 - val_accuracy: 0.6516\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8858 - accuracy: 0.6442 - val_loss: 0.8414 - val_accuracy: 0.6486\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8902 - accuracy: 0.6441 - val_loss: 0.8370 - val_accuracy: 0.6543\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8917 - accuracy: 0.6434 - val_loss: 0.8392 - val_accuracy: 0.6490\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8892 - accuracy: 0.6445 - val_loss: 0.8392 - val_accuracy: 0.6519\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8881 - accuracy: 0.6451 - val_loss: 0.8330 - val_accuracy: 0.6542\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8924 - accuracy: 0.6437 - val_loss: 0.8337 - val_accuracy: 0.6519\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8906 - accuracy: 0.6440 - val_loss: 0.8346 - val_accuracy: 0.6504\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8912 - accuracy: 0.6446 - val_loss: 0.8443 - val_accuracy: 0.6522\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8932 - accuracy: 0.6433 - val_loss: 0.8500 - val_accuracy: 0.6479\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8907 - accuracy: 0.6444 - val_loss: 0.8392 - val_accuracy: 0.6564\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8972 - accuracy: 0.6437 - val_loss: 0.8427 - val_accuracy: 0.6515\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8947 - accuracy: 0.6442 - val_loss: 0.8549 - val_accuracy: 0.6553\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8940 - accuracy: 0.6439 - val_loss: 0.8428 - val_accuracy: 0.6472\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8898 - accuracy: 0.6445 - val_loss: 0.8718 - val_accuracy: 0.6326\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8931 - accuracy: 0.6427 - val_loss: 0.8373 - val_accuracy: 0.6541\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8957 - accuracy: 0.6436 - val_loss: 0.8419 - val_accuracy: 0.6541\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8907 - accuracy: 0.6453 - val_loss: 0.8469 - val_accuracy: 0.6521\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8924 - accuracy: 0.6439 - val_loss: 0.8498 - val_accuracy: 0.6540\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8936 - accuracy: 0.6434 - val_loss: 0.8465 - val_accuracy: 0.6522\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8910 - accuracy: 0.6423 - val_loss: 0.8515 - val_accuracy: 0.6508\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8930 - accuracy: 0.6430 - val_loss: 0.8372 - val_accuracy: 0.6565\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8930 - accuracy: 0.6439 - val_loss: 0.8420 - val_accuracy: 0.6470\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8897 - accuracy: 0.6458 - val_loss: 0.8372 - val_accuracy: 0.6528\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8950 - accuracy: 0.6426 - val_loss: 0.8433 - val_accuracy: 0.6519\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8935 - accuracy: 0.6433 - val_loss: 0.8419 - val_accuracy: 0.6499\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8962 - accuracy: 0.6425 - val_loss: 0.8393 - val_accuracy: 0.6512\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8924 - accuracy: 0.6428 - val_loss: 0.8702 - val_accuracy: 0.6374\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8891 - accuracy: 0.6439 - val_loss: 0.8462 - val_accuracy: 0.6522\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.8922 - accuracy: 0.6433 - val_loss: 0.8397 - val_accuracy: 0.6490\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.8926 - accuracy: 0.6452 - val_loss: 0.8371 - val_accuracy: 0.6557\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8933 - accuracy: 0.6433 - val_loss: 0.8375 - val_accuracy: 0.6534\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8922 - accuracy: 0.6435 - val_loss: 0.8494 - val_accuracy: 0.6478\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8927 - accuracy: 0.6451 - val_loss: 0.8420 - val_accuracy: 0.6531\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8936 - accuracy: 0.6436 - val_loss: 0.8391 - val_accuracy: 0.6559\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8899 - accuracy: 0.6435 - val_loss: 0.8424 - val_accuracy: 0.6496\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8972 - accuracy: 0.6434 - val_loss: 0.8405 - val_accuracy: 0.6588\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8915 - accuracy: 0.6442 - val_loss: 0.8452 - val_accuracy: 0.6561\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 39s 280us/step - loss: 0.8921 - accuracy: 0.6438 - val_loss: 0.9144 - val_accuracy: 0.6192\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8972 - accuracy: 0.6418 - val_loss: 0.8389 - val_accuracy: 0.6561\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8942 - accuracy: 0.6440 - val_loss: 0.8586 - val_accuracy: 0.6483\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8947 - accuracy: 0.6430 - val_loss: 0.8398 - val_accuracy: 0.6531\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8944 - accuracy: 0.6441 - val_loss: 0.8444 - val_accuracy: 0.6544\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8889 - accuracy: 0.6452 - val_loss: 0.8696 - val_accuracy: 0.6304\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8907 - accuracy: 0.6446 - val_loss: 0.8368 - val_accuracy: 0.6562\n",
      "accuracy: 65.62%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8940 - accuracy: 0.6423 - val_loss: 0.8453 - val_accuracy: 0.6563\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8940 - accuracy: 0.6424 - val_loss: 0.8293 - val_accuracy: 0.6601\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8927 - accuracy: 0.6431 - val_loss: 0.8302 - val_accuracy: 0.6607\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8949 - accuracy: 0.6439 - val_loss: 0.8624 - val_accuracy: 0.6451\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8953 - accuracy: 0.6419 - val_loss: 0.8329 - val_accuracy: 0.6588\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8998 - accuracy: 0.6415 - val_loss: 0.8570 - val_accuracy: 0.6421\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8932 - accuracy: 0.6435 - val_loss: 0.8329 - val_accuracy: 0.6571\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8950 - accuracy: 0.6440 - val_loss: 0.8272 - val_accuracy: 0.6543\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8979 - accuracy: 0.6413 - val_loss: 0.8257 - val_accuracy: 0.6622\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8955 - accuracy: 0.6435 - val_loss: 0.8373 - val_accuracy: 0.6614\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8997 - accuracy: 0.6424 - val_loss: 0.8533 - val_accuracy: 0.6507\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.9001 - accuracy: 0.6422 - val_loss: 0.8358 - val_accuracy: 0.6607\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8980 - accuracy: 0.6414 - val_loss: 0.8390 - val_accuracy: 0.6583\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8933 - accuracy: 0.6430 - val_loss: 0.8308 - val_accuracy: 0.6531\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8940 - accuracy: 0.6430 - val_loss: 0.8340 - val_accuracy: 0.6584\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8966 - accuracy: 0.6412 - val_loss: 0.8298 - val_accuracy: 0.6610\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8951 - accuracy: 0.6434 - val_loss: 0.8317 - val_accuracy: 0.6581\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.9259 - accuracy: 0.6363 - val_loss: 0.8316 - val_accuracy: 0.6570\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8935 - accuracy: 0.6437 - val_loss: 0.8340 - val_accuracy: 0.6630\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.9056 - accuracy: 0.6413 - val_loss: 0.8330 - val_accuracy: 0.6621\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8944 - accuracy: 0.6426 - val_loss: 0.8317 - val_accuracy: 0.6495\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8961 - accuracy: 0.6424 - val_loss: 0.8287 - val_accuracy: 0.6588\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8938 - accuracy: 0.6435 - val_loss: 0.8337 - val_accuracy: 0.6568\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8932 - accuracy: 0.6431 - val_loss: 0.8315 - val_accuracy: 0.6598\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8933 - accuracy: 0.6428 - val_loss: 0.8589 - val_accuracy: 0.6462\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.9019 - accuracy: 0.6418 - val_loss: 0.8553 - val_accuracy: 0.6513\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8926 - accuracy: 0.6418 - val_loss: 0.8661 - val_accuracy: 0.6473\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8941 - accuracy: 0.6416 - val_loss: 0.8410 - val_accuracy: 0.6602\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8937 - accuracy: 0.6436 - val_loss: 0.8493 - val_accuracy: 0.6584\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.8968 - accuracy: 0.6432 - val_loss: 0.8276 - val_accuracy: 0.6498\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8985 - accuracy: 0.6412 - val_loss: 0.8318 - val_accuracy: 0.6592\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8938 - accuracy: 0.6422 - val_loss: 0.8278 - val_accuracy: 0.6636\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8934 - accuracy: 0.6440 - val_loss: 0.8291 - val_accuracy: 0.6499\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8948 - accuracy: 0.6435 - val_loss: 0.8575 - val_accuracy: 0.6416\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8933 - accuracy: 0.6430 - val_loss: 0.8296 - val_accuracy: 0.6554\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8933 - accuracy: 0.6433 - val_loss: 0.8268 - val_accuracy: 0.6610\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8968 - accuracy: 0.6426 - val_loss: 0.8307 - val_accuracy: 0.6621\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8947 - accuracy: 0.6430 - val_loss: 0.8348 - val_accuracy: 0.6636\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8923 - accuracy: 0.6451 - val_loss: 0.8333 - val_accuracy: 0.6630\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8928 - accuracy: 0.6434 - val_loss: 0.8319 - val_accuracy: 0.6621\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8923 - accuracy: 0.6440 - val_loss: 0.8293 - val_accuracy: 0.6630\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8952 - accuracy: 0.6429 - val_loss: 0.8276 - val_accuracy: 0.6608\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8948 - accuracy: 0.6429 - val_loss: 0.8290 - val_accuracy: 0.6611\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8949 - accuracy: 0.6424 - val_loss: 0.8292 - val_accuracy: 0.6583\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8977 - accuracy: 0.6422 - val_loss: 0.8335 - val_accuracy: 0.6607\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8929 - accuracy: 0.6430 - val_loss: 0.8574 - val_accuracy: 0.6391\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8969 - accuracy: 0.6420 - val_loss: 0.8311 - val_accuracy: 0.6632\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8966 - accuracy: 0.6430 - val_loss: 0.8453 - val_accuracy: 0.6577\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8955 - accuracy: 0.6427 - val_loss: 0.8280 - val_accuracy: 0.6612\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8980 - accuracy: 0.6427 - val_loss: 0.8345 - val_accuracy: 0.6565\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8945 - accuracy: 0.6423 - val_loss: 0.8390 - val_accuracy: 0.6574\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8949 - accuracy: 0.6442 - val_loss: 0.8545 - val_accuracy: 0.6385\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8960 - accuracy: 0.6428 - val_loss: 0.8374 - val_accuracy: 0.6592\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8949 - accuracy: 0.6427 - val_loss: 0.8276 - val_accuracy: 0.6610\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.9003 - accuracy: 0.6423 - val_loss: 0.8342 - val_accuracy: 0.6601\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8952 - accuracy: 0.6431 - val_loss: 0.8673 - val_accuracy: 0.6454\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8950 - accuracy: 0.6437 - val_loss: 0.8287 - val_accuracy: 0.6613\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8917 - accuracy: 0.6439 - val_loss: 0.8270 - val_accuracy: 0.6600\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8959 - accuracy: 0.6427 - val_loss: 0.8300 - val_accuracy: 0.6642\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.8989 - accuracy: 0.6425 - val_loss: 0.8285 - val_accuracy: 0.6617\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8947 - accuracy: 0.6425 - val_loss: 0.8284 - val_accuracy: 0.6575\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8976 - accuracy: 0.6430 - val_loss: 0.8300 - val_accuracy: 0.6610\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8945 - accuracy: 0.6432 - val_loss: 0.8338 - val_accuracy: 0.6670\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8949 - accuracy: 0.6435 - val_loss: 0.8263 - val_accuracy: 0.6622\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8963 - accuracy: 0.6434 - val_loss: 0.8318 - val_accuracy: 0.6548\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8916 - accuracy: 0.6434 - val_loss: 0.8290 - val_accuracy: 0.6594\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8951 - accuracy: 0.6422 - val_loss: 0.8444 - val_accuracy: 0.6661\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8956 - accuracy: 0.6441 - val_loss: 0.8319 - val_accuracy: 0.6594\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8937 - accuracy: 0.6417 - val_loss: 0.8401 - val_accuracy: 0.6550\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8961 - accuracy: 0.6424 - val_loss: 0.8351 - val_accuracy: 0.6595\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8916 - accuracy: 0.6434 - val_loss: 0.8319 - val_accuracy: 0.6611\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8955 - accuracy: 0.6412 - val_loss: 0.8306 - val_accuracy: 0.6616\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8981 - accuracy: 0.6426 - val_loss: 0.8654 - val_accuracy: 0.6504\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8943 - accuracy: 0.6444 - val_loss: 0.8443 - val_accuracy: 0.6574\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8949 - accuracy: 0.6439 - val_loss: 0.8299 - val_accuracy: 0.6626\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8965 - accuracy: 0.6403 - val_loss: 0.8297 - val_accuracy: 0.6613\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8963 - accuracy: 0.6439 - val_loss: 0.8324 - val_accuracy: 0.6645\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8979 - accuracy: 0.6424 - val_loss: 0.8346 - val_accuracy: 0.6528\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8954 - accuracy: 0.6423 - val_loss: 0.8305 - val_accuracy: 0.6628\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8941 - accuracy: 0.6426 - val_loss: 0.8284 - val_accuracy: 0.6621\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8946 - accuracy: 0.6433 - val_loss: 0.8287 - val_accuracy: 0.6584\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8945 - accuracy: 0.6427 - val_loss: 0.8605 - val_accuracy: 0.6455\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8944 - accuracy: 0.6436 - val_loss: 0.8317 - val_accuracy: 0.6642\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8942 - accuracy: 0.6444 - val_loss: 0.8460 - val_accuracy: 0.6595\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8946 - accuracy: 0.6428 - val_loss: 0.8403 - val_accuracy: 0.6631\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8914 - accuracy: 0.6426 - val_loss: 0.8593 - val_accuracy: 0.6373\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8946 - accuracy: 0.6425 - val_loss: 0.8312 - val_accuracy: 0.6612\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8928 - accuracy: 0.6417 - val_loss: 0.8599 - val_accuracy: 0.6369\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8943 - accuracy: 0.6429 - val_loss: 0.8298 - val_accuracy: 0.6570\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8940 - accuracy: 0.6437 - val_loss: 0.8295 - val_accuracy: 0.6596\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8992 - accuracy: 0.6410 - val_loss: 0.8323 - val_accuracy: 0.6643\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8942 - accuracy: 0.6434 - val_loss: 0.8316 - val_accuracy: 0.6579\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.9089 - accuracy: 0.6411 - val_loss: 0.8418 - val_accuracy: 0.6573\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8933 - accuracy: 0.6424 - val_loss: 0.8327 - val_accuracy: 0.6611\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8923 - accuracy: 0.6439 - val_loss: 0.8295 - val_accuracy: 0.6633\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8927 - accuracy: 0.6445 - val_loss: 0.8293 - val_accuracy: 0.6511\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8941 - accuracy: 0.6426 - val_loss: 0.8322 - val_accuracy: 0.6690\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8960 - accuracy: 0.6425 - val_loss: 0.8292 - val_accuracy: 0.6584\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8955 - accuracy: 0.6415 - val_loss: 0.8360 - val_accuracy: 0.6605\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8906 - accuracy: 0.6435 - val_loss: 0.8600 - val_accuracy: 0.6433\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8941 - accuracy: 0.6445 - val_loss: 0.8307 - val_accuracy: 0.6620\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8981 - accuracy: 0.6411 - val_loss: 0.8397 - val_accuracy: 0.6580\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8938 - accuracy: 0.6427 - val_loss: 0.8405 - val_accuracy: 0.6620\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8946 - accuracy: 0.6428 - val_loss: 0.8326 - val_accuracy: 0.6636\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8970 - accuracy: 0.6424 - val_loss: 0.8361 - val_accuracy: 0.6537\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8915 - accuracy: 0.6429 - val_loss: 0.8267 - val_accuracy: 0.6616\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8971 - accuracy: 0.6427 - val_loss: 0.8408 - val_accuracy: 0.6590\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8923 - accuracy: 0.6431 - val_loss: 0.8326 - val_accuracy: 0.6602\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8957 - accuracy: 0.6439 - val_loss: 0.8315 - val_accuracy: 0.6599\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 40s 282us/step - loss: 0.8970 - accuracy: 0.6419 - val_loss: 0.8308 - val_accuracy: 0.6577\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8970 - accuracy: 0.6417 - val_loss: 0.8255 - val_accuracy: 0.6609\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8935 - accuracy: 0.6426 - val_loss: 0.8248 - val_accuracy: 0.6591\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8945 - accuracy: 0.6423 - val_loss: 0.8357 - val_accuracy: 0.6602\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8957 - accuracy: 0.6426 - val_loss: 0.8278 - val_accuracy: 0.6669\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8910 - accuracy: 0.6448 - val_loss: 0.8687 - val_accuracy: 0.6584\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.9003 - accuracy: 0.6418 - val_loss: 0.8304 - val_accuracy: 0.6638\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8916 - accuracy: 0.6430 - val_loss: 0.8277 - val_accuracy: 0.6621\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8921 - accuracy: 0.6432 - val_loss: 0.8304 - val_accuracy: 0.6630\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8946 - accuracy: 0.6432 - val_loss: 0.8377 - val_accuracy: 0.6605\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8934 - accuracy: 0.6426 - val_loss: 0.8440 - val_accuracy: 0.6621\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8953 - accuracy: 0.6432 - val_loss: 0.8722 - val_accuracy: 0.6325\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8940 - accuracy: 0.6426 - val_loss: 0.8424 - val_accuracy: 0.6578\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8965 - accuracy: 0.6424 - val_loss: 0.8277 - val_accuracy: 0.6626\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8952 - accuracy: 0.6424 - val_loss: 0.8303 - val_accuracy: 0.6598\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8930 - accuracy: 0.6437 - val_loss: 0.8524 - val_accuracy: 0.6396\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8938 - accuracy: 0.6433 - val_loss: 0.8457 - val_accuracy: 0.6580\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8956 - accuracy: 0.6432 - val_loss: 0.8425 - val_accuracy: 0.6549\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8928 - accuracy: 0.6443 - val_loss: 0.8314 - val_accuracy: 0.6601\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8945 - accuracy: 0.6426 - val_loss: 0.8362 - val_accuracy: 0.6569\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8973 - accuracy: 0.6412 - val_loss: 0.8337 - val_accuracy: 0.6662\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8962 - accuracy: 0.6420 - val_loss: 0.8422 - val_accuracy: 0.6551\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.8954 - accuracy: 0.6438 - val_loss: 0.8292 - val_accuracy: 0.6569\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8946 - accuracy: 0.6435 - val_loss: 0.8292 - val_accuracy: 0.6591\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8916 - accuracy: 0.6434 - val_loss: 0.8543 - val_accuracy: 0.6448\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8925 - accuracy: 0.6439 - val_loss: 0.8312 - val_accuracy: 0.6600\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8966 - accuracy: 0.6425 - val_loss: 0.8311 - val_accuracy: 0.6589\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8928 - accuracy: 0.6443 - val_loss: 0.8315 - val_accuracy: 0.6605\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8949 - accuracy: 0.6419 - val_loss: 0.8301 - val_accuracy: 0.6588\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8922 - accuracy: 0.6436 - val_loss: 0.8287 - val_accuracy: 0.6611\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8988 - accuracy: 0.6438 - val_loss: 0.8268 - val_accuracy: 0.6629\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8925 - accuracy: 0.6414 - val_loss: 0.8313 - val_accuracy: 0.6599\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8944 - accuracy: 0.6433 - val_loss: 0.8319 - val_accuracy: 0.6561\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.8940 - accuracy: 0.6435 - val_loss: 0.8594 - val_accuracy: 0.6415\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8927 - accuracy: 0.6435 - val_loss: 0.8279 - val_accuracy: 0.6628\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8914 - accuracy: 0.6429 - val_loss: 0.8293 - val_accuracy: 0.6580\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.8971 - accuracy: 0.6424 - val_loss: 0.8289 - val_accuracy: 0.6601\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8932 - accuracy: 0.6444 - val_loss: 0.8300 - val_accuracy: 0.6645\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8947 - accuracy: 0.6430 - val_loss: 0.8269 - val_accuracy: 0.6703\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8954 - accuracy: 0.6444 - val_loss: 0.8331 - val_accuracy: 0.6613\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8937 - accuracy: 0.6425 - val_loss: 0.8344 - val_accuracy: 0.6612\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8954 - accuracy: 0.6432 - val_loss: 0.8556 - val_accuracy: 0.6483\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8952 - accuracy: 0.6435 - val_loss: 0.8322 - val_accuracy: 0.6633\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8925 - accuracy: 0.6432 - val_loss: 0.8314 - val_accuracy: 0.6610\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.9010 - accuracy: 0.6428 - val_loss: 0.8291 - val_accuracy: 0.6661\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 40s 283us/step - loss: 0.8934 - accuracy: 0.6429 - val_loss: 0.8316 - val_accuracy: 0.6610\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 40s 284us/step - loss: 0.8925 - accuracy: 0.6433 - val_loss: 0.8332 - val_accuracy: 0.6625\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8935 - accuracy: 0.6430 - val_loss: 0.8459 - val_accuracy: 0.6564\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8937 - accuracy: 0.6431 - val_loss: 0.8399 - val_accuracy: 0.6616\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8909 - accuracy: 0.6450 - val_loss: 0.8298 - val_accuracy: 0.6620\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8928 - accuracy: 0.6425 - val_loss: 0.8369 - val_accuracy: 0.6536\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8977 - accuracy: 0.6431 - val_loss: 0.8315 - val_accuracy: 0.6580\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8941 - accuracy: 0.6445 - val_loss: 0.8300 - val_accuracy: 0.6602\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8934 - accuracy: 0.6419 - val_loss: 0.8317 - val_accuracy: 0.6604\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8972 - accuracy: 0.6419 - val_loss: 0.8286 - val_accuracy: 0.6608\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8927 - accuracy: 0.6427 - val_loss: 0.8374 - val_accuracy: 0.6618\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.8935 - accuracy: 0.6434 - val_loss: 0.8342 - val_accuracy: 0.6639\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8935 - accuracy: 0.6427 - val_loss: 0.8318 - val_accuracy: 0.6588\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8927 - accuracy: 0.6434 - val_loss: 0.8366 - val_accuracy: 0.6576\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8915 - accuracy: 0.6434 - val_loss: 0.8365 - val_accuracy: 0.6586\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8923 - accuracy: 0.6435 - val_loss: 0.8327 - val_accuracy: 0.6623\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8942 - accuracy: 0.6433 - val_loss: 0.8367 - val_accuracy: 0.6564\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8940 - accuracy: 0.6420 - val_loss: 0.8352 - val_accuracy: 0.6628\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.8944 - accuracy: 0.6425 - val_loss: 0.8386 - val_accuracy: 0.6659\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8972 - accuracy: 0.6430 - val_loss: 0.8296 - val_accuracy: 0.6612\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.8937 - accuracy: 0.6431 - val_loss: 0.8380 - val_accuracy: 0.6643\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8939 - accuracy: 0.6443 - val_loss: 0.8405 - val_accuracy: 0.6519\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.8947 - accuracy: 0.6437 - val_loss: 0.8283 - val_accuracy: 0.6606\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8929 - accuracy: 0.6447 - val_loss: 0.8672 - val_accuracy: 0.6444\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8965 - accuracy: 0.6443 - val_loss: 0.8523 - val_accuracy: 0.6482\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8952 - accuracy: 0.6432 - val_loss: 0.8308 - val_accuracy: 0.6594\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8918 - accuracy: 0.6444 - val_loss: 0.8299 - val_accuracy: 0.6570\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.9009 - accuracy: 0.6410 - val_loss: 0.8527 - val_accuracy: 0.6386\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.8932 - accuracy: 0.6427 - val_loss: 0.8428 - val_accuracy: 0.6592\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.8926 - accuracy: 0.6444 - val_loss: 0.8288 - val_accuracy: 0.6603\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.8928 - accuracy: 0.6441 - val_loss: 0.8272 - val_accuracy: 0.6616\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 46s 329us/step - loss: 0.9007 - accuracy: 0.6436 - val_loss: 0.8303 - val_accuracy: 0.6578\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.8992 - accuracy: 0.6423 - val_loss: 0.8370 - val_accuracy: 0.6554\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 43s 306us/step - loss: 0.8934 - accuracy: 0.6435 - val_loss: 0.8298 - val_accuracy: 0.6586\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 43s 306us/step - loss: 0.8927 - accuracy: 0.6438 - val_loss: 0.8284 - val_accuracy: 0.6606\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 43s 305us/step - loss: 0.8963 - accuracy: 0.6420 - val_loss: 0.8275 - val_accuracy: 0.6575\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 42s 303us/step - loss: 0.8934 - accuracy: 0.6416 - val_loss: 0.8322 - val_accuracy: 0.6590\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 0.8956 - accuracy: 0.6412 - val_loss: 0.8298 - val_accuracy: 0.6571\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 43s 306us/step - loss: 0.8931 - accuracy: 0.6434 - val_loss: 0.8288 - val_accuracy: 0.6630\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.8930 - accuracy: 0.6431 - val_loss: 0.8290 - val_accuracy: 0.6589\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 43s 306us/step - loss: 0.8926 - accuracy: 0.6438 - val_loss: 0.8284 - val_accuracy: 0.6587\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 43s 306us/step - loss: 0.8926 - accuracy: 0.6440 - val_loss: 0.8263 - val_accuracy: 0.6582\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 30s 216us/step - loss: 0.8945 - accuracy: 0.6434 - val_loss: 0.8267 - val_accuracy: 0.6605\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 23s 161us/step - loss: 0.8927 - accuracy: 0.6438 - val_loss: 0.8296 - val_accuracy: 0.6580\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 23s 161us/step - loss: 0.8921 - accuracy: 0.6443 - val_loss: 0.8307 - val_accuracy: 0.6631\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 23s 162us/step - loss: 0.9000 - accuracy: 0.6427 - val_loss: 0.8364 - val_accuracy: 0.6605\n",
      "accuracy: 66.05%\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    XTrain, XVal, yTrain, yVal = train_test_split(X, Y, test_size=0.2, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    cnn.fit(XTrain, yTrain, nb_epoch=200, validation_data=(XVal, yVal))\n",
    "    scores = cnn.evaluate(XVal, yVal, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (cnn.metrics_names[1], scores[1]*100))\n",
    "    a.append(scores[1] * 100)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.25047516822815, 66.45470261573792, 66.01842045783997, 65.61635732650757, 66.04693531990051]\n"
     ]
    }
   ],
   "source": [
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
