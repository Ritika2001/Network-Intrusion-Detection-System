{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal            56000\n",
      "Generic           40000\n",
      "Exploits          33393\n",
      "Fuzzers           18184\n",
      "DoS               12264\n",
      "Reconnaissance    10491\n",
      "Analysis           2000\n",
      "Backdoor           1746\n",
      "Shellcode          1133\n",
      "Worms               130\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(traindata['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121478</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.623129</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
       "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
       "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
       "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
       "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
       "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
       "\n",
       "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "0  ...                 1               1             0           0   \n",
       "1  ...                 1               2             0           0   \n",
       "2  ...                 1               3             0           0   \n",
       "3  ...                 1               3             1           1   \n",
       "4  ...                 1              40             0           0   \n",
       "\n",
       "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
       "0                 0           1           1                0      Normal   \n",
       "1                 0           1           6                0      Normal   \n",
       "2                 0           2           6                0      Normal   \n",
       "3                 0           2           1                0      Normal   \n",
       "4                 0           2          39                0      Normal   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "traindata['attack_cat'] = lb_make.fit_transform(traindata['attack_cat'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "testdata['attack_cat'] = lb_make.fit_transform(testdata['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-2]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "Y = to_categorical(Y)\n",
    "y = to_categorical(y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175341, 41, 1)\n",
      "(175341, 10)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X, (X.shape[0],X.shape[1],1))\n",
    "x = np.reshape(x, (x.shape[0],x.shape[1],1))\n",
    "\n",
    "print (X.shape)\n",
    "print (Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\", input_shape=(41, 1))`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "lstm_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Bidirectional(LSTM(lstm_output_size)))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 183s 1ms/step - loss: 1.4010 - accuracy: 0.5247 - val_loss: 1.3717 - val_accuracy: 0.5307\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 1.3625 - accuracy: 0.5325 - val_loss: 1.3347 - val_accuracy: 0.5319\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.3328 - accuracy: 0.5437 - val_loss: 1.3176 - val_accuracy: 0.5480\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.3252 - accuracy: 0.5471 - val_loss: 1.3199 - val_accuracy: 0.5523\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.3185 - accuracy: 0.5492 - val_loss: 1.3437 - val_accuracy: 0.5433\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 1.3130 - accuracy: 0.5505 - val_loss: 1.3115 - val_accuracy: 0.5521\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 1.3108 - accuracy: 0.5510 - val_loss: 1.3041 - val_accuracy: 0.5530\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 1.3102 - accuracy: 0.5510 - val_loss: 1.3094 - val_accuracy: 0.5503\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 1.3069 - accuracy: 0.5516 - val_loss: 1.3047 - val_accuracy: 0.5491\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.3036 - accuracy: 0.5531 - val_loss: 1.3078 - val_accuracy: 0.5535\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 1.3033 - accuracy: 0.5525 - val_loss: 1.2968 - val_accuracy: 0.5540\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 1.3014 - accuracy: 0.5528 - val_loss: 1.2964 - val_accuracy: 0.5545\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 1.3008 - accuracy: 0.5533 - val_loss: 1.2956 - val_accuracy: 0.5537\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.2963 - accuracy: 0.5543 - val_loss: 1.2899 - val_accuracy: 0.5527\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.2699 - accuracy: 0.5550 - val_loss: 1.2705 - val_accuracy: 0.5569\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.1520 - accuracy: 0.5837 - val_loss: 0.9151 - val_accuracy: 0.6290\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 1.1050 - accuracy: 0.5959 - val_loss: 1.0404 - val_accuracy: 0.6144\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 1.0049 - accuracy: 0.6208 - val_loss: 0.8995 - val_accuracy: 0.6565\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.9308 - accuracy: 0.6431 - val_loss: 0.8744 - val_accuracy: 0.6613\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 1.1485 - accuracy: 0.5930 - val_loss: 1.2602 - val_accuracy: 0.5510\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.2225 - accuracy: 0.5671 - val_loss: 1.2547 - val_accuracy: 0.5562\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.2674 - accuracy: 0.5570 - val_loss: 1.2563 - val_accuracy: 0.5578\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.2259 - accuracy: 0.5637 - val_loss: 1.0453 - val_accuracy: 0.6196\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 1.1736 - accuracy: 0.5801 - val_loss: 1.2621 - val_accuracy: 0.5556\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 1.1798 - accuracy: 0.5788 - val_loss: 1.3774 - val_accuracy: 0.5566\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 1.0777 - accuracy: 0.6028 - val_loss: 0.9644 - val_accuracy: 0.6456\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 1.0968 - accuracy: 0.6035 - val_loss: 1.2639 - val_accuracy: 0.5564\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 1.0742 - accuracy: 0.6062 - val_loss: 0.9410 - val_accuracy: 0.6509\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 1.0233 - accuracy: 0.6186 - val_loss: 1.2415 - val_accuracy: 0.5486\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.9765 - accuracy: 0.6307 - val_loss: 0.8557 - val_accuracy: 0.6609\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.8811 - accuracy: 0.6562 - val_loss: 0.8628 - val_accuracy: 0.6590\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.8809 - accuracy: 0.6514 - val_loss: 0.8397 - val_accuracy: 0.6617\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.8458 - accuracy: 0.6605 - val_loss: 0.8197 - val_accuracy: 0.6679\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.8361 - accuracy: 0.6643 - val_loss: 0.8420 - val_accuracy: 0.6605\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.8299 - accuracy: 0.6649 - val_loss: 0.8231 - val_accuracy: 0.6714\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.8222 - accuracy: 0.6670 - val_loss: 0.8017 - val_accuracy: 0.6747\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.8159 - accuracy: 0.6686 - val_loss: 0.7991 - val_accuracy: 0.6744\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.8113 - accuracy: 0.6709 - val_loss: 0.8062 - val_accuracy: 0.6661\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.8068 - accuracy: 0.6714 - val_loss: 0.8066 - val_accuracy: 0.6776\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.8047 - accuracy: 0.6731 - val_loss: 0.7982 - val_accuracy: 0.6669\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7987 - accuracy: 0.6753 - val_loss: 0.7977 - val_accuracy: 0.6738\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.7999 - accuracy: 0.6758 - val_loss: 0.7869 - val_accuracy: 0.6782\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.7899 - accuracy: 0.6793 - val_loss: 0.7776 - val_accuracy: 0.6835\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.7913 - accuracy: 0.6798 - val_loss: 0.7893 - val_accuracy: 0.6756\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.7931 - accuracy: 0.6815 - val_loss: 0.7905 - val_accuracy: 0.6774\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7894 - accuracy: 0.6817 - val_loss: 0.7914 - val_accuracy: 0.6849\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.7823 - accuracy: 0.6850 - val_loss: 0.8149 - val_accuracy: 0.6768\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7955 - accuracy: 0.6808 - val_loss: 0.7671 - val_accuracy: 0.6930\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7770 - accuracy: 0.6880 - val_loss: 0.8856 - val_accuracy: 0.6726\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7719 - accuracy: 0.6901 - val_loss: 0.7662 - val_accuracy: 0.6910\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7641 - accuracy: 0.6928 - val_loss: 0.7433 - val_accuracy: 0.7037\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7638 - accuracy: 0.6949 - val_loss: 0.7472 - val_accuracy: 0.7001\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.7560 - accuracy: 0.6976 - val_loss: 0.7716 - val_accuracy: 0.6988\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.7560 - accuracy: 0.6976 - val_loss: 0.7509 - val_accuracy: 0.6949\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.7494 - accuracy: 0.7002 - val_loss: 0.8159 - val_accuracy: 0.6801\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.7447 - accuracy: 0.7023 - val_loss: 0.7431 - val_accuracy: 0.7047\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.7451 - accuracy: 0.7038 - val_loss: 0.7366 - val_accuracy: 0.7018\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.7470 - accuracy: 0.7038 - val_loss: 0.7314 - val_accuracy: 0.7083\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7418 - accuracy: 0.7050 - val_loss: 0.7286 - val_accuracy: 0.7117\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.7406 - accuracy: 0.7055 - val_loss: 0.7296 - val_accuracy: 0.7099\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7339 - accuracy: 0.7082 - val_loss: 0.8181 - val_accuracy: 0.7106\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7359 - accuracy: 0.7086 - val_loss: 0.7280 - val_accuracy: 0.7120\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7292 - accuracy: 0.7106 - val_loss: 0.7525 - val_accuracy: 0.7060\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7276 - accuracy: 0.7117 - val_loss: 0.7247 - val_accuracy: 0.7164\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7260 - accuracy: 0.7132 - val_loss: 0.8092 - val_accuracy: 0.6731\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7255 - accuracy: 0.7122 - val_loss: 0.7110 - val_accuracy: 0.7194\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7228 - accuracy: 0.7146 - val_loss: 0.7844 - val_accuracy: 0.7020\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7304 - accuracy: 0.7120 - val_loss: 0.7081 - val_accuracy: 0.7193\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7185 - accuracy: 0.7161 - val_loss: 0.7174 - val_accuracy: 0.7168\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7174 - accuracy: 0.7168 - val_loss: 0.7584 - val_accuracy: 0.7025\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7201 - accuracy: 0.7164 - val_loss: 0.7220 - val_accuracy: 0.7130\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7151 - accuracy: 0.7180 - val_loss: 0.7235 - val_accuracy: 0.7183\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7125 - accuracy: 0.7188 - val_loss: 0.7096 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7084 - accuracy: 0.7208 - val_loss: 0.7083 - val_accuracy: 0.7227\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7088 - accuracy: 0.7215 - val_loss: 0.7039 - val_accuracy: 0.7259\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.7070 - accuracy: 0.7228 - val_loss: 0.7113 - val_accuracy: 0.7207\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7072 - accuracy: 0.7226 - val_loss: 0.7024 - val_accuracy: 0.7262\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7046 - accuracy: 0.7237 - val_loss: 0.7194 - val_accuracy: 0.7240\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7013 - accuracy: 0.7248 - val_loss: 0.6949 - val_accuracy: 0.7277\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6991 - accuracy: 0.7249 - val_loss: 0.6948 - val_accuracy: 0.7260\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6981 - accuracy: 0.7257 - val_loss: 0.6911 - val_accuracy: 0.7313\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6991 - accuracy: 0.7257 - val_loss: 0.7239 - val_accuracy: 0.7146\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6966 - accuracy: 0.7266 - val_loss: 0.6957 - val_accuracy: 0.7246\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6909 - accuracy: 0.7286 - val_loss: 0.6896 - val_accuracy: 0.7284\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7584 - accuracy: 0.7094 - val_loss: 1.2760 - val_accuracy: 0.5455\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 1.0388 - accuracy: 0.6120 - val_loss: 1.0447 - val_accuracy: 0.6206\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.8321 - accuracy: 0.6729 - val_loss: 0.7028 - val_accuracy: 0.7273\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7044 - accuracy: 0.7249 - val_loss: 0.6945 - val_accuracy: 0.7269\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6910 - accuracy: 0.7290 - val_loss: 0.6922 - val_accuracy: 0.7300\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6882 - accuracy: 0.7313 - val_loss: 0.6823 - val_accuracy: 0.7347\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6853 - accuracy: 0.7310 - val_loss: 0.6799 - val_accuracy: 0.7361\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6844 - accuracy: 0.7317 - val_loss: 0.6834 - val_accuracy: 0.7326\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6854 - accuracy: 0.7322 - val_loss: 0.6881 - val_accuracy: 0.7275\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6834 - accuracy: 0.7329 - val_loss: 0.6836 - val_accuracy: 0.7365\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6950 - accuracy: 0.7290 - val_loss: 0.6755 - val_accuracy: 0.7385\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6793 - accuracy: 0.7337 - val_loss: 0.6989 - val_accuracy: 0.7249\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6797 - accuracy: 0.7341 - val_loss: 0.6749 - val_accuracy: 0.7344\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6773 - accuracy: 0.7348 - val_loss: 0.6786 - val_accuracy: 0.7353\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6727 - accuracy: 0.7360 - val_loss: 0.6736 - val_accuracy: 0.7353\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6737 - accuracy: 0.7355 - val_loss: 0.6718 - val_accuracy: 0.7338\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6764 - accuracy: 0.7353 - val_loss: 0.6721 - val_accuracy: 0.7390\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6720 - accuracy: 0.7376 - val_loss: 0.6645 - val_accuracy: 0.7400\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6687 - accuracy: 0.7382 - val_loss: 0.6598 - val_accuracy: 0.7434\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6674 - accuracy: 0.7390 - val_loss: 0.6850 - val_accuracy: 0.7308\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6689 - accuracy: 0.7378 - val_loss: 0.6724 - val_accuracy: 0.7403\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6702 - accuracy: 0.7383 - val_loss: 0.7094 - val_accuracy: 0.7174\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6633 - accuracy: 0.7400 - val_loss: 0.6630 - val_accuracy: 0.7413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6626 - accuracy: 0.7400 - val_loss: 0.6542 - val_accuracy: 0.7470\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6612 - accuracy: 0.7407 - val_loss: 0.6579 - val_accuracy: 0.7436\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6621 - accuracy: 0.7407 - val_loss: 0.6774 - val_accuracy: 0.7396\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6589 - accuracy: 0.7422 - val_loss: 0.6742 - val_accuracy: 0.7398\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6603 - accuracy: 0.7415 - val_loss: 1.4661 - val_accuracy: 0.4404\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6590 - accuracy: 0.7421 - val_loss: 0.6633 - val_accuracy: 0.7417\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6581 - accuracy: 0.7424 - val_loss: 0.6687 - val_accuracy: 0.7379\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6549 - accuracy: 0.7433 - val_loss: 0.6613 - val_accuracy: 0.7425\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6528 - accuracy: 0.7444 - val_loss: 0.6700 - val_accuracy: 0.7399\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6615 - accuracy: 0.7398 - val_loss: 0.7120 - val_accuracy: 0.7183\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6523 - accuracy: 0.7435 - val_loss: 0.6577 - val_accuracy: 0.7457\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6503 - accuracy: 0.7447 - val_loss: 0.6524 - val_accuracy: 0.7470\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6516 - accuracy: 0.7450 - val_loss: 0.6686 - val_accuracy: 0.7397\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6545 - accuracy: 0.7441 - val_loss: 0.6718 - val_accuracy: 0.7388\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6508 - accuracy: 0.7456 - val_loss: 0.6565 - val_accuracy: 0.7474\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6498 - accuracy: 0.7454 - val_loss: 0.6552 - val_accuracy: 0.7468\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.6485 - accuracy: 0.7453 - val_loss: 0.6478 - val_accuracy: 0.7501\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6499 - accuracy: 0.7449 - val_loss: 0.6628 - val_accuracy: 0.7427\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6495 - accuracy: 0.7453 - val_loss: 0.6556 - val_accuracy: 0.7458\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6485 - accuracy: 0.7454 - val_loss: 0.6681 - val_accuracy: 0.7401\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6459 - accuracy: 0.7463 - val_loss: 0.6602 - val_accuracy: 0.7445\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6452 - accuracy: 0.7471 - val_loss: 0.6522 - val_accuracy: 0.7470\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6432 - accuracy: 0.7477 - val_loss: 0.6757 - val_accuracy: 0.7320\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6495 - accuracy: 0.7464 - val_loss: 0.6575 - val_accuracy: 0.7450\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6430 - accuracy: 0.7476 - val_loss: 0.6601 - val_accuracy: 0.7447\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6462 - accuracy: 0.7458 - val_loss: 0.6511 - val_accuracy: 0.7477\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6447 - accuracy: 0.7476 - val_loss: 0.7514 - val_accuracy: 0.6755\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6458 - accuracy: 0.7474 - val_loss: 0.6718 - val_accuracy: 0.7394\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6441 - accuracy: 0.7481 - val_loss: 0.6501 - val_accuracy: 0.7463\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6413 - accuracy: 0.7480 - val_loss: 0.6478 - val_accuracy: 0.7507\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6428 - accuracy: 0.7486 - val_loss: 0.6532 - val_accuracy: 0.7462\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6429 - accuracy: 0.7489 - val_loss: 0.6499 - val_accuracy: 0.7487\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6394 - accuracy: 0.7485 - val_loss: 0.6436 - val_accuracy: 0.7513\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6398 - accuracy: 0.7489 - val_loss: 0.6474 - val_accuracy: 0.7499\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6413 - accuracy: 0.7490 - val_loss: 0.6499 - val_accuracy: 0.7499\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6370 - accuracy: 0.7500 - val_loss: 0.6470 - val_accuracy: 0.7504\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6376 - accuracy: 0.7501 - val_loss: 0.6615 - val_accuracy: 0.7440\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6377 - accuracy: 0.7501 - val_loss: 0.6709 - val_accuracy: 0.7415\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.6358 - accuracy: 0.7504 - val_loss: 0.6472 - val_accuracy: 0.7529\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6362 - accuracy: 0.7507 - val_loss: 0.6526 - val_accuracy: 0.7479\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6344 - accuracy: 0.7508 - val_loss: 0.6612 - val_accuracy: 0.7424\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6367 - accuracy: 0.7507 - val_loss: 0.6598 - val_accuracy: 0.7467\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6364 - accuracy: 0.7496 - val_loss: 0.6352 - val_accuracy: 0.7553\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6328 - accuracy: 0.7521 - val_loss: 0.6374 - val_accuracy: 0.7538\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6418 - accuracy: 0.7489 - val_loss: 0.6466 - val_accuracy: 0.7486\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.6369 - accuracy: 0.7498 - val_loss: 0.6590 - val_accuracy: 0.7458\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.6350 - accuracy: 0.7515 - val_loss: 0.6454 - val_accuracy: 0.7502\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 211s 2ms/step - loss: 0.6303 - accuracy: 0.7524 - val_loss: 0.6466 - val_accuracy: 0.7498\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.6322 - accuracy: 0.7517 - val_loss: 0.6462 - val_accuracy: 0.7501\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 213s 2ms/step - loss: 0.6329 - accuracy: 0.7517 - val_loss: 0.6457 - val_accuracy: 0.7515\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6317 - accuracy: 0.7520 - val_loss: 0.6382 - val_accuracy: 0.7537\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6329 - accuracy: 0.7520 - val_loss: 0.6515 - val_accuracy: 0.7509\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6344 - accuracy: 0.7514 - val_loss: 0.6542 - val_accuracy: 0.7468\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6331 - accuracy: 0.7527 - val_loss: 0.6555 - val_accuracy: 0.7482\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6313 - accuracy: 0.7521 - val_loss: 0.6506 - val_accuracy: 0.7494\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6303 - accuracy: 0.7530 - val_loss: 0.6419 - val_accuracy: 0.7527\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6303 - accuracy: 0.7533 - val_loss: 0.6336 - val_accuracy: 0.7541\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6285 - accuracy: 0.7541 - val_loss: 0.6376 - val_accuracy: 0.7549\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6273 - accuracy: 0.7542 - val_loss: 0.6438 - val_accuracy: 0.7520\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.6278 - accuracy: 0.7535 - val_loss: 0.6441 - val_accuracy: 0.7503\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.6281 - accuracy: 0.7539 - val_loss: 0.6509 - val_accuracy: 0.7479\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6257 - accuracy: 0.7543 - val_loss: 0.6416 - val_accuracy: 0.7546\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6288 - accuracy: 0.7537 - val_loss: 0.6407 - val_accuracy: 0.7503\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6257 - accuracy: 0.7545 - val_loss: 0.6424 - val_accuracy: 0.7528\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6248 - accuracy: 0.7539 - val_loss: 0.6415 - val_accuracy: 0.7528\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6283 - accuracy: 0.7538 - val_loss: 0.6353 - val_accuracy: 0.7537\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6294 - accuracy: 0.7535 - val_loss: 0.6384 - val_accuracy: 0.7551\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6401 - accuracy: 0.7491 - val_loss: 0.6395 - val_accuracy: 0.7544\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6268 - accuracy: 0.7549 - val_loss: 0.6381 - val_accuracy: 0.7525\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6270 - accuracy: 0.7542 - val_loss: 0.6399 - val_accuracy: 0.7539\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6281 - accuracy: 0.7551 - val_loss: 0.6728 - val_accuracy: 0.7389\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6236 - accuracy: 0.7554 - val_loss: 0.6469 - val_accuracy: 0.7499\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6250 - accuracy: 0.7548 - val_loss: 0.6417 - val_accuracy: 0.7527\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6218 - accuracy: 0.7555 - val_loss: 0.6358 - val_accuracy: 0.7555\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6246 - accuracy: 0.7550 - val_loss: 0.6413 - val_accuracy: 0.7525\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6214 - accuracy: 0.7559 - val_loss: 0.6394 - val_accuracy: 0.7540\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6315 - accuracy: 0.7546 - val_loss: 0.6481 - val_accuracy: 0.7485\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6212 - accuracy: 0.7555 - val_loss: 0.6530 - val_accuracy: 0.7478\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6215 - accuracy: 0.7552 - val_loss: 0.6381 - val_accuracy: 0.7542\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6206 - accuracy: 0.7561 - val_loss: 0.6402 - val_accuracy: 0.7514\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6274 - accuracy: 0.7547 - val_loss: 0.6388 - val_accuracy: 0.7531\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6236 - accuracy: 0.7559 - val_loss: 0.6328 - val_accuracy: 0.7566\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6189 - accuracy: 0.7569 - val_loss: 0.6470 - val_accuracy: 0.7486\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6201 - accuracy: 0.7570 - val_loss: 0.6463 - val_accuracy: 0.7537\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6196 - accuracy: 0.7571 - val_loss: 0.6454 - val_accuracy: 0.7523\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6253 - accuracy: 0.7541 - val_loss: 0.6422 - val_accuracy: 0.7546\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6227 - accuracy: 0.7561 - val_loss: 0.6675 - val_accuracy: 0.7414\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6233 - accuracy: 0.7549 - val_loss: 0.6366 - val_accuracy: 0.7549\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6185 - accuracy: 0.7564 - val_loss: 0.6387 - val_accuracy: 0.7551\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6208 - accuracy: 0.7566 - val_loss: 0.6800 - val_accuracy: 0.7349\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6214 - accuracy: 0.7554 - val_loss: 0.6860 - val_accuracy: 0.7348\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6191 - accuracy: 0.7577 - val_loss: 0.6374 - val_accuracy: 0.7550\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6316 - accuracy: 0.7524 - val_loss: 0.6550 - val_accuracy: 0.7478\n",
      "accuracy: 74.78%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6243 - accuracy: 0.7561 - val_loss: 0.6154 - val_accuracy: 0.7576\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6221 - accuracy: 0.7567 - val_loss: 0.6222 - val_accuracy: 0.7558\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6227 - accuracy: 0.7558 - val_loss: 0.6198 - val_accuracy: 0.7582\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6212 - accuracy: 0.7568 - val_loss: 0.6263 - val_accuracy: 0.7545\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6188 - accuracy: 0.7569 - val_loss: 0.6296 - val_accuracy: 0.7562\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6221 - accuracy: 0.7565 - val_loss: 0.6302 - val_accuracy: 0.7529\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6195 - accuracy: 0.7575 - val_loss: 0.6523 - val_accuracy: 0.7404\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6175 - accuracy: 0.7570 - val_loss: 0.6276 - val_accuracy: 0.7559\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6216 - accuracy: 0.7571 - val_loss: 0.6226 - val_accuracy: 0.7570\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6186 - accuracy: 0.7573 - val_loss: 0.6197 - val_accuracy: 0.7582\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6246 - accuracy: 0.7571 - val_loss: 0.6367 - val_accuracy: 0.7532\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6278 - accuracy: 0.7558 - val_loss: 0.6334 - val_accuracy: 0.7555\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6271 - accuracy: 0.7549 - val_loss: 0.6296 - val_accuracy: 0.7546\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6192 - accuracy: 0.7572 - val_loss: 0.6272 - val_accuracy: 0.7576\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6176 - accuracy: 0.7584 - val_loss: 0.6281 - val_accuracy: 0.7563\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6711 - accuracy: 0.7403 - val_loss: 0.9844 - val_accuracy: 0.6130\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.8785 - accuracy: 0.6564 - val_loss: 0.8714 - val_accuracy: 0.6605\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.8101 - accuracy: 0.6839 - val_loss: 0.7078 - val_accuracy: 0.7191\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6417 - accuracy: 0.7515 - val_loss: 0.6315 - val_accuracy: 0.7517\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6247 - accuracy: 0.7558 - val_loss: 0.6372 - val_accuracy: 0.7507\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.6234 - accuracy: 0.7555 - val_loss: 0.6278 - val_accuracy: 0.7549\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6260 - accuracy: 0.7564 - val_loss: 0.6300 - val_accuracy: 0.7552\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6182 - accuracy: 0.7574 - val_loss: 0.6302 - val_accuracy: 0.7524\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6186 - accuracy: 0.7573 - val_loss: 0.6277 - val_accuracy: 0.7551\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6162 - accuracy: 0.7583 - val_loss: 0.6392 - val_accuracy: 0.7565\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6170 - accuracy: 0.7585 - val_loss: 0.6314 - val_accuracy: 0.7548\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6142 - accuracy: 0.7592 - val_loss: 0.6286 - val_accuracy: 0.7560\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6147 - accuracy: 0.7590 - val_loss: 0.6276 - val_accuracy: 0.7547\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6175 - accuracy: 0.7587 - val_loss: 0.6282 - val_accuracy: 0.7571\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6198 - accuracy: 0.7574 - val_loss: 0.6343 - val_accuracy: 0.7541\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6151 - accuracy: 0.7586 - val_loss: 0.6348 - val_accuracy: 0.7538\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6154 - accuracy: 0.7589 - val_loss: 0.6297 - val_accuracy: 0.7556\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6187 - accuracy: 0.7587 - val_loss: 0.6279 - val_accuracy: 0.7571\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6133 - accuracy: 0.7600 - val_loss: 0.6311 - val_accuracy: 0.7550\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6124 - accuracy: 0.7602 - val_loss: 0.6385 - val_accuracy: 0.7535\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6133 - accuracy: 0.7585 - val_loss: 0.6316 - val_accuracy: 0.7547\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6108 - accuracy: 0.7601 - val_loss: 0.6295 - val_accuracy: 0.7545\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6121 - accuracy: 0.7596 - val_loss: 0.6315 - val_accuracy: 0.7540\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.6142 - accuracy: 0.7592 - val_loss: 0.6297 - val_accuracy: 0.7555\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6317 - accuracy: 0.7544 - val_loss: 0.6396 - val_accuracy: 0.7527\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.6142 - accuracy: 0.7599 - val_loss: 0.6317 - val_accuracy: 0.7565\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.6130 - accuracy: 0.7586 - val_loss: 0.6278 - val_accuracy: 0.7588\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6130 - accuracy: 0.7593 - val_loss: 0.6589 - val_accuracy: 0.7411\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6146 - accuracy: 0.7594 - val_loss: 0.6404 - val_accuracy: 0.7522\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6158 - accuracy: 0.7588 - val_loss: 0.6251 - val_accuracy: 0.7570\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6104 - accuracy: 0.7598 - val_loss: 0.6281 - val_accuracy: 0.7549\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6092 - accuracy: 0.7604 - val_loss: 0.6228 - val_accuracy: 0.7571\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6110 - accuracy: 0.7606 - val_loss: 0.6578 - val_accuracy: 0.7443\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6114 - accuracy: 0.7604 - val_loss: 0.6361 - val_accuracy: 0.7549\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6135 - accuracy: 0.7599 - val_loss: 0.6368 - val_accuracy: 0.7533\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6092 - accuracy: 0.7608 - val_loss: 0.6450 - val_accuracy: 0.7480\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6113 - accuracy: 0.7596 - val_loss: 0.6270 - val_accuracy: 0.7588\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6086 - accuracy: 0.7605 - val_loss: 0.6337 - val_accuracy: 0.7561\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6100 - accuracy: 0.7608 - val_loss: 0.6270 - val_accuracy: 0.7588\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6085 - accuracy: 0.7611 - val_loss: 0.6226 - val_accuracy: 0.7580\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6072 - accuracy: 0.7615 - val_loss: 0.6245 - val_accuracy: 0.7588\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6070 - accuracy: 0.7609 - val_loss: 0.6323 - val_accuracy: 0.7542\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6086 - accuracy: 0.7613 - val_loss: 0.6299 - val_accuracy: 0.7565\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6073 - accuracy: 0.7618 - val_loss: 0.6309 - val_accuracy: 0.7561\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6058 - accuracy: 0.7619 - val_loss: 0.6328 - val_accuracy: 0.7574\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6057 - accuracy: 0.7620 - val_loss: 0.6276 - val_accuracy: 0.7573\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6095 - accuracy: 0.7614 - val_loss: 0.6684 - val_accuracy: 0.7411\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6072 - accuracy: 0.7613 - val_loss: 0.6505 - val_accuracy: 0.7432\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6087 - accuracy: 0.7608 - val_loss: 0.6313 - val_accuracy: 0.7561\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6050 - accuracy: 0.7620 - val_loss: 0.6477 - val_accuracy: 0.7501\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6060 - accuracy: 0.7624 - val_loss: 0.6291 - val_accuracy: 0.7584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6050 - accuracy: 0.7624 - val_loss: 0.6250 - val_accuracy: 0.7576\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6066 - accuracy: 0.7627 - val_loss: 0.6402 - val_accuracy: 0.7556\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6041 - accuracy: 0.7632 - val_loss: 0.6287 - val_accuracy: 0.7569\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6045 - accuracy: 0.7624 - val_loss: 0.6378 - val_accuracy: 0.7529\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6037 - accuracy: 0.7629 - val_loss: 0.6332 - val_accuracy: 0.7583\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6046 - accuracy: 0.7622 - val_loss: 0.6564 - val_accuracy: 0.7456\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6026 - accuracy: 0.7630 - val_loss: 0.6308 - val_accuracy: 0.7566\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6049 - accuracy: 0.7619 - val_loss: 0.6362 - val_accuracy: 0.7555\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6050 - accuracy: 0.7622 - val_loss: 0.6247 - val_accuracy: 0.7574\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6018 - accuracy: 0.7630 - val_loss: 0.6292 - val_accuracy: 0.7591\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6008 - accuracy: 0.7640 - val_loss: 0.6434 - val_accuracy: 0.7512\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6096 - accuracy: 0.7624 - val_loss: 0.6273 - val_accuracy: 0.7594\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6054 - accuracy: 0.7621 - val_loss: 0.6266 - val_accuracy: 0.7573\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6051 - accuracy: 0.7630 - val_loss: 0.7006 - val_accuracy: 0.7053\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6028 - accuracy: 0.7626 - val_loss: 0.6293 - val_accuracy: 0.7550\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6030 - accuracy: 0.7633 - val_loss: 0.6270 - val_accuracy: 0.7569\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6028 - accuracy: 0.7630 - val_loss: 0.6439 - val_accuracy: 0.7517\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6033 - accuracy: 0.7634 - val_loss: 0.6253 - val_accuracy: 0.7576\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6014 - accuracy: 0.7640 - val_loss: 0.6298 - val_accuracy: 0.7569\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6014 - accuracy: 0.7634 - val_loss: 0.6319 - val_accuracy: 0.7557\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5998 - accuracy: 0.7640 - val_loss: 0.6525 - val_accuracy: 0.7494\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6016 - accuracy: 0.7635 - val_loss: 0.6312 - val_accuracy: 0.7543\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5990 - accuracy: 0.7645 - val_loss: 0.6242 - val_accuracy: 0.7596\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5994 - accuracy: 0.7639 - val_loss: 0.6239 - val_accuracy: 0.7578\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5997 - accuracy: 0.7642 - val_loss: 0.6261 - val_accuracy: 0.7590\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6013 - accuracy: 0.7637 - val_loss: 0.6277 - val_accuracy: 0.7557\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6014 - accuracy: 0.7640 - val_loss: 0.6371 - val_accuracy: 0.7538\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6010 - accuracy: 0.7640 - val_loss: 0.6435 - val_accuracy: 0.7551\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5996 - accuracy: 0.7641 - val_loss: 0.6243 - val_accuracy: 0.7602\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5997 - accuracy: 0.7636 - val_loss: 0.6286 - val_accuracy: 0.7577\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5988 - accuracy: 0.7643 - val_loss: 0.6256 - val_accuracy: 0.7591\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5990 - accuracy: 0.7651 - val_loss: 0.6382 - val_accuracy: 0.7544\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5980 - accuracy: 0.7653 - val_loss: 0.6450 - val_accuracy: 0.7501\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6002 - accuracy: 0.7643 - val_loss: 0.6302 - val_accuracy: 0.7563\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5970 - accuracy: 0.7654 - val_loss: 0.6288 - val_accuracy: 0.7563\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.6006 - accuracy: 0.7646 - val_loss: 0.6494 - val_accuracy: 0.7469\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5961 - accuracy: 0.7646 - val_loss: 0.6293 - val_accuracy: 0.7559\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5974 - accuracy: 0.7646 - val_loss: 0.6355 - val_accuracy: 0.7552\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5959 - accuracy: 0.7655 - val_loss: 0.6654 - val_accuracy: 0.7420\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5980 - accuracy: 0.7642 - val_loss: 0.6294 - val_accuracy: 0.7573\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5987 - accuracy: 0.7649 - val_loss: 0.6260 - val_accuracy: 0.7602\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5970 - accuracy: 0.7658 - val_loss: 0.6439 - val_accuracy: 0.7487\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5984 - accuracy: 0.7650 - val_loss: 0.6247 - val_accuracy: 0.7600\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5976 - accuracy: 0.7655 - val_loss: 0.6228 - val_accuracy: 0.7602\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5973 - accuracy: 0.7650 - val_loss: 0.6293 - val_accuracy: 0.7583\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5946 - accuracy: 0.7665 - val_loss: 0.6414 - val_accuracy: 0.7502\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5951 - accuracy: 0.7647 - val_loss: 0.6295 - val_accuracy: 0.7596\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.5982 - accuracy: 0.7641 - val_loss: 0.6481 - val_accuracy: 0.7520\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5957 - accuracy: 0.7653 - val_loss: 0.6254 - val_accuracy: 0.7597\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5934 - accuracy: 0.7663 - val_loss: 0.6281 - val_accuracy: 0.7595\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5951 - accuracy: 0.7657 - val_loss: 0.6297 - val_accuracy: 0.7590\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5979 - accuracy: 0.7655 - val_loss: 0.6290 - val_accuracy: 0.7576\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5978 - accuracy: 0.7647 - val_loss: 0.6357 - val_accuracy: 0.7556\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5945 - accuracy: 0.7659 - val_loss: 0.6272 - val_accuracy: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5999 - accuracy: 0.7639 - val_loss: 0.6310 - val_accuracy: 0.7573\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5931 - accuracy: 0.7664 - val_loss: 0.6377 - val_accuracy: 0.7561\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5935 - accuracy: 0.7671 - val_loss: 0.6295 - val_accuracy: 0.7585\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5952 - accuracy: 0.7653 - val_loss: 0.6289 - val_accuracy: 0.7593\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5934 - accuracy: 0.7663 - val_loss: 0.6259 - val_accuracy: 0.7577\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5956 - accuracy: 0.7656 - val_loss: 0.6289 - val_accuracy: 0.7594\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5939 - accuracy: 0.7668 - val_loss: 0.6393 - val_accuracy: 0.7533\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5964 - accuracy: 0.7656 - val_loss: 0.6329 - val_accuracy: 0.7571\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5956 - accuracy: 0.7652 - val_loss: 0.6295 - val_accuracy: 0.7578\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5922 - accuracy: 0.7672 - val_loss: 0.6498 - val_accuracy: 0.7499\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5935 - accuracy: 0.7664 - val_loss: 0.6370 - val_accuracy: 0.7545\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5934 - accuracy: 0.7654 - val_loss: 0.6269 - val_accuracy: 0.7585\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5910 - accuracy: 0.7671 - val_loss: 0.6277 - val_accuracy: 0.7578\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5925 - accuracy: 0.7662 - val_loss: 0.6324 - val_accuracy: 0.7568\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5944 - accuracy: 0.7664 - val_loss: 0.6314 - val_accuracy: 0.7584\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5918 - accuracy: 0.7664 - val_loss: 0.6326 - val_accuracy: 0.7580\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5950 - accuracy: 0.7649 - val_loss: 0.6272 - val_accuracy: 0.7596\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5918 - accuracy: 0.7670 - val_loss: 0.6267 - val_accuracy: 0.7584\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5943 - accuracy: 0.7657 - val_loss: 0.6271 - val_accuracy: 0.7598\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5919 - accuracy: 0.7667 - val_loss: 0.6305 - val_accuracy: 0.7563\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5935 - accuracy: 0.7666 - val_loss: 0.6318 - val_accuracy: 0.7571\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5925 - accuracy: 0.7667 - val_loss: 0.6250 - val_accuracy: 0.7596\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5927 - accuracy: 0.7668 - val_loss: 0.6275 - val_accuracy: 0.7590\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5934 - accuracy: 0.7663 - val_loss: 0.6313 - val_accuracy: 0.7575\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5918 - accuracy: 0.7665 - val_loss: 0.6278 - val_accuracy: 0.7583\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5943 - accuracy: 0.7664 - val_loss: 0.6303 - val_accuracy: 0.7561\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5887 - accuracy: 0.7688 - val_loss: 0.6371 - val_accuracy: 0.7562\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5907 - accuracy: 0.7673 - val_loss: 0.6326 - val_accuracy: 0.7565\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5918 - accuracy: 0.7662 - val_loss: 0.6311 - val_accuracy: 0.7581\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5903 - accuracy: 0.7673 - val_loss: 0.6244 - val_accuracy: 0.7603\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5906 - accuracy: 0.7674 - val_loss: 0.6333 - val_accuracy: 0.7542\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5913 - accuracy: 0.7666 - val_loss: 0.6467 - val_accuracy: 0.7507\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5908 - accuracy: 0.7675 - val_loss: 0.6332 - val_accuracy: 0.7574\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5907 - accuracy: 0.7680 - val_loss: 0.6346 - val_accuracy: 0.7568\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5923 - accuracy: 0.7671 - val_loss: 0.6398 - val_accuracy: 0.7557\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5932 - accuracy: 0.7670 - val_loss: 0.6244 - val_accuracy: 0.7594\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5906 - accuracy: 0.7672 - val_loss: 0.6297 - val_accuracy: 0.7576\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5907 - accuracy: 0.7673 - val_loss: 0.6345 - val_accuracy: 0.7580\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5898 - accuracy: 0.7680 - val_loss: 0.6295 - val_accuracy: 0.7581\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5920 - accuracy: 0.7666 - val_loss: 0.6420 - val_accuracy: 0.7543\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5926 - accuracy: 0.7674 - val_loss: 0.6402 - val_accuracy: 0.7525\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5910 - accuracy: 0.7667 - val_loss: 0.6515 - val_accuracy: 0.7490\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5892 - accuracy: 0.7677 - val_loss: 0.6469 - val_accuracy: 0.7493\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5881 - accuracy: 0.7685 - val_loss: 0.6343 - val_accuracy: 0.7567\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5908 - accuracy: 0.7672 - val_loss: 0.6334 - val_accuracy: 0.7562\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5899 - accuracy: 0.7684 - val_loss: 0.6359 - val_accuracy: 0.7579\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5890 - accuracy: 0.7683 - val_loss: 0.6297 - val_accuracy: 0.7582\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5902 - accuracy: 0.7675 - val_loss: 0.6282 - val_accuracy: 0.7571\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5934 - accuracy: 0.7674 - val_loss: 0.6362 - val_accuracy: 0.7566\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5966 - accuracy: 0.7659 - val_loss: 0.6397 - val_accuracy: 0.7562\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5925 - accuracy: 0.7673 - val_loss: 0.6304 - val_accuracy: 0.7566\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5949 - accuracy: 0.7670 - val_loss: 0.6325 - val_accuracy: 0.7567\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5911 - accuracy: 0.7665 - val_loss: 0.6334 - val_accuracy: 0.7566\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5891 - accuracy: 0.7681 - val_loss: 0.6331 - val_accuracy: 0.7581\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5898 - accuracy: 0.7667 - val_loss: 0.6262 - val_accuracy: 0.7598\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5885 - accuracy: 0.7676 - val_loss: 0.6285 - val_accuracy: 0.7587\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5879 - accuracy: 0.7686 - val_loss: 0.6296 - val_accuracy: 0.7563\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6011 - accuracy: 0.7644 - val_loss: 0.6281 - val_accuracy: 0.7577\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5872 - accuracy: 0.7690 - val_loss: 0.6392 - val_accuracy: 0.7550\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5883 - accuracy: 0.7679 - val_loss: 0.6407 - val_accuracy: 0.7556\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5906 - accuracy: 0.7681 - val_loss: 0.6256 - val_accuracy: 0.7606\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5878 - accuracy: 0.7690 - val_loss: 0.6339 - val_accuracy: 0.7565\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5853 - accuracy: 0.7690 - val_loss: 0.6605 - val_accuracy: 0.7491\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5923 - accuracy: 0.7674 - val_loss: 0.6432 - val_accuracy: 0.7545\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5868 - accuracy: 0.7689 - val_loss: 0.6362 - val_accuracy: 0.7563\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5868 - accuracy: 0.7684 - val_loss: 0.6236 - val_accuracy: 0.7598\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5872 - accuracy: 0.7687 - val_loss: 0.6268 - val_accuracy: 0.7593\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5862 - accuracy: 0.7689 - val_loss: 0.6278 - val_accuracy: 0.7576\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5881 - accuracy: 0.7678 - val_loss: 0.6351 - val_accuracy: 0.7571\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5891 - accuracy: 0.7686 - val_loss: 0.6298 - val_accuracy: 0.7588\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5855 - accuracy: 0.7691 - val_loss: 0.6342 - val_accuracy: 0.7612\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5871 - accuracy: 0.7688 - val_loss: 0.6435 - val_accuracy: 0.7545\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5861 - accuracy: 0.7688 - val_loss: 0.6304 - val_accuracy: 0.7592\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5843 - accuracy: 0.7687 - val_loss: 0.6433 - val_accuracy: 0.7557\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5861 - accuracy: 0.7691 - val_loss: 0.6345 - val_accuracy: 0.7593\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.7141 - accuracy: 0.7215 - val_loss: 0.9009 - val_accuracy: 0.6545\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6266 - accuracy: 0.7567 - val_loss: 0.6378 - val_accuracy: 0.7563\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6034 - accuracy: 0.7643 - val_loss: 0.6338 - val_accuracy: 0.7581\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5943 - accuracy: 0.7671 - val_loss: 0.6400 - val_accuracy: 0.7571\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5920 - accuracy: 0.7676 - val_loss: 0.6402 - val_accuracy: 0.7565\n",
      "accuracy: 75.65%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6061 - accuracy: 0.7634 - val_loss: 0.5893 - val_accuracy: 0.7689\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6036 - accuracy: 0.7650 - val_loss: 0.5904 - val_accuracy: 0.7689\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6046 - accuracy: 0.7637 - val_loss: 0.5924 - val_accuracy: 0.7695\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6013 - accuracy: 0.7653 - val_loss: 0.6008 - val_accuracy: 0.7663\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6041 - accuracy: 0.7649 - val_loss: 0.6118 - val_accuracy: 0.7629\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.6032 - accuracy: 0.7641 - val_loss: 0.6226 - val_accuracy: 0.7548\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5992 - accuracy: 0.7651 - val_loss: 0.5966 - val_accuracy: 0.7661\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5995 - accuracy: 0.7651 - val_loss: 0.6112 - val_accuracy: 0.7611\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5992 - accuracy: 0.7647 - val_loss: 0.5955 - val_accuracy: 0.7673\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6020 - accuracy: 0.7647 - val_loss: 0.6029 - val_accuracy: 0.7651\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5984 - accuracy: 0.7657 - val_loss: 0.6039 - val_accuracy: 0.7637\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5971 - accuracy: 0.7652 - val_loss: 0.6039 - val_accuracy: 0.7628\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5982 - accuracy: 0.7662 - val_loss: 0.6318 - val_accuracy: 0.7503\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6023 - accuracy: 0.7640 - val_loss: 0.6069 - val_accuracy: 0.7632\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5962 - accuracy: 0.7662 - val_loss: 0.6147 - val_accuracy: 0.7598\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5989 - accuracy: 0.7658 - val_loss: 0.6067 - val_accuracy: 0.7626\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5974 - accuracy: 0.7662 - val_loss: 0.6281 - val_accuracy: 0.7592\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5973 - accuracy: 0.7664 - val_loss: 0.5939 - val_accuracy: 0.7688\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5941 - accuracy: 0.7666 - val_loss: 0.6074 - val_accuracy: 0.7646\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5953 - accuracy: 0.7662 - val_loss: 0.6049 - val_accuracy: 0.7644\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5964 - accuracy: 0.7663 - val_loss: 0.6011 - val_accuracy: 0.7660\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5950 - accuracy: 0.7673 - val_loss: 0.5972 - val_accuracy: 0.7693\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5925 - accuracy: 0.7672 - val_loss: 0.6021 - val_accuracy: 0.7655\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5948 - accuracy: 0.7662 - val_loss: 0.5969 - val_accuracy: 0.7659\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5955 - accuracy: 0.7665 - val_loss: 0.6039 - val_accuracy: 0.7638\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5932 - accuracy: 0.7680 - val_loss: 0.6031 - val_accuracy: 0.7677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5945 - accuracy: 0.7665 - val_loss: 0.6258 - val_accuracy: 0.7586\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5978 - accuracy: 0.7658 - val_loss: 0.6001 - val_accuracy: 0.7658\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5976 - accuracy: 0.7660 - val_loss: 0.6746 - val_accuracy: 0.7425\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5937 - accuracy: 0.7663 - val_loss: 0.6118 - val_accuracy: 0.7632\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6011 - accuracy: 0.7651 - val_loss: 0.6033 - val_accuracy: 0.7661\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5924 - accuracy: 0.7674 - val_loss: 0.6154 - val_accuracy: 0.7620\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5960 - accuracy: 0.7658 - val_loss: 0.6164 - val_accuracy: 0.7595\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5932 - accuracy: 0.7669 - val_loss: 0.6176 - val_accuracy: 0.7606\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5942 - accuracy: 0.7664 - val_loss: 0.6037 - val_accuracy: 0.7649\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5914 - accuracy: 0.7684 - val_loss: 0.6110 - val_accuracy: 0.7620\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5914 - accuracy: 0.7674 - val_loss: 0.6037 - val_accuracy: 0.7650\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5919 - accuracy: 0.7675 - val_loss: 0.6086 - val_accuracy: 0.7650\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5899 - accuracy: 0.7687 - val_loss: 0.6047 - val_accuracy: 0.7636\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5892 - accuracy: 0.7688 - val_loss: 0.6128 - val_accuracy: 0.7644\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5910 - accuracy: 0.7679 - val_loss: 0.6050 - val_accuracy: 0.7654\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5897 - accuracy: 0.7682 - val_loss: 0.6144 - val_accuracy: 0.7598\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5914 - accuracy: 0.7677 - val_loss: 0.6087 - val_accuracy: 0.7632\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5927 - accuracy: 0.7670 - val_loss: 0.6272 - val_accuracy: 0.7584\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5911 - accuracy: 0.7684 - val_loss: 0.6079 - val_accuracy: 0.7653\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5927 - accuracy: 0.7675 - val_loss: 0.6228 - val_accuracy: 0.7600\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5929 - accuracy: 0.7679 - val_loss: 0.6177 - val_accuracy: 0.7633\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5904 - accuracy: 0.7686 - val_loss: 0.6123 - val_accuracy: 0.7616\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5892 - accuracy: 0.7691 - val_loss: 0.6114 - val_accuracy: 0.7634\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5921 - accuracy: 0.7674 - val_loss: 0.6308 - val_accuracy: 0.7552\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6062 - accuracy: 0.7636 - val_loss: 0.6351 - val_accuracy: 0.7539\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5969 - accuracy: 0.7656 - val_loss: 0.6154 - val_accuracy: 0.7636\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5932 - accuracy: 0.7676 - val_loss: 0.6056 - val_accuracy: 0.7637\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5899 - accuracy: 0.7682 - val_loss: 0.6041 - val_accuracy: 0.7659\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5903 - accuracy: 0.7678 - val_loss: 0.6264 - val_accuracy: 0.7578\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5938 - accuracy: 0.7672 - val_loss: 0.6211 - val_accuracy: 0.7614\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5891 - accuracy: 0.7685 - val_loss: 0.6037 - val_accuracy: 0.7650\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5904 - accuracy: 0.7686 - val_loss: 0.6347 - val_accuracy: 0.7519\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5906 - accuracy: 0.7683 - val_loss: 0.6119 - val_accuracy: 0.7646\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5903 - accuracy: 0.7678 - val_loss: 0.6061 - val_accuracy: 0.7653\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5880 - accuracy: 0.7689 - val_loss: 0.6071 - val_accuracy: 0.7656\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5878 - accuracy: 0.7690 - val_loss: 0.6099 - val_accuracy: 0.7635\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5878 - accuracy: 0.7693 - val_loss: 0.6039 - val_accuracy: 0.7651\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5886 - accuracy: 0.7691 - val_loss: 0.6052 - val_accuracy: 0.7649\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5877 - accuracy: 0.7692 - val_loss: 0.6072 - val_accuracy: 0.7644\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5875 - accuracy: 0.7692 - val_loss: 0.6065 - val_accuracy: 0.7647\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5881 - accuracy: 0.7692 - val_loss: 0.6003 - val_accuracy: 0.7662\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5880 - accuracy: 0.7690 - val_loss: 0.6095 - val_accuracy: 0.7660\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5868 - accuracy: 0.7699 - val_loss: 0.6297 - val_accuracy: 0.7579\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5873 - accuracy: 0.7689 - val_loss: 0.6128 - val_accuracy: 0.7640\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5889 - accuracy: 0.7682 - val_loss: 0.6122 - val_accuracy: 0.7643\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5946 - accuracy: 0.7675 - val_loss: 0.6140 - val_accuracy: 0.7637\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5888 - accuracy: 0.7692 - val_loss: 0.6080 - val_accuracy: 0.7642\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5897 - accuracy: 0.7683 - val_loss: 0.6140 - val_accuracy: 0.7618\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5873 - accuracy: 0.7693 - val_loss: 0.6172 - val_accuracy: 0.7594\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5873 - accuracy: 0.7690 - val_loss: 0.6126 - val_accuracy: 0.7639\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5864 - accuracy: 0.7696 - val_loss: 0.6054 - val_accuracy: 0.7660\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6119 - accuracy: 0.7605 - val_loss: 0.6032 - val_accuracy: 0.7658\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5932 - accuracy: 0.7679 - val_loss: 0.6111 - val_accuracy: 0.7633\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5873 - accuracy: 0.7688 - val_loss: 0.6244 - val_accuracy: 0.7590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5873 - accuracy: 0.7699 - val_loss: 0.6236 - val_accuracy: 0.7581\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5872 - accuracy: 0.7691 - val_loss: 0.6057 - val_accuracy: 0.7667\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5860 - accuracy: 0.7696 - val_loss: 0.6034 - val_accuracy: 0.7659\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5854 - accuracy: 0.7700 - val_loss: 0.6133 - val_accuracy: 0.7631\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5827 - accuracy: 0.7708 - val_loss: 0.6161 - val_accuracy: 0.7613\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5857 - accuracy: 0.7698 - val_loss: 0.6085 - val_accuracy: 0.7642\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.8855 - accuracy: 0.6542 - val_loss: 0.8476 - val_accuracy: 0.6669\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.8511 - accuracy: 0.6644 - val_loss: 0.8423 - val_accuracy: 0.6684\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7580 - accuracy: 0.7026 - val_loss: 0.6484 - val_accuracy: 0.7531\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6216 - accuracy: 0.7583 - val_loss: 0.6294 - val_accuracy: 0.7583\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6042 - accuracy: 0.7641 - val_loss: 0.6139 - val_accuracy: 0.7641\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5961 - accuracy: 0.7659 - val_loss: 0.6261 - val_accuracy: 0.7594\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5977 - accuracy: 0.7661 - val_loss: 0.6131 - val_accuracy: 0.7638\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5927 - accuracy: 0.7677 - val_loss: 0.6179 - val_accuracy: 0.7641\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5912 - accuracy: 0.7682 - val_loss: 0.6153 - val_accuracy: 0.7644\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5919 - accuracy: 0.7688 - val_loss: 0.6248 - val_accuracy: 0.7599\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5897 - accuracy: 0.7687 - val_loss: 0.6139 - val_accuracy: 0.7620\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5913 - accuracy: 0.7692 - val_loss: 0.6291 - val_accuracy: 0.7571\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5878 - accuracy: 0.7699 - val_loss: 0.6215 - val_accuracy: 0.7612\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5883 - accuracy: 0.7691 - val_loss: 0.6100 - val_accuracy: 0.7649\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7804 - accuracy: 0.6864 - val_loss: 0.7588 - val_accuracy: 0.6896\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6175 - accuracy: 0.7585 - val_loss: 0.6095 - val_accuracy: 0.7632\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5906 - accuracy: 0.7684 - val_loss: 0.6091 - val_accuracy: 0.7640\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5877 - accuracy: 0.7698 - val_loss: 0.6125 - val_accuracy: 0.7657\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5877 - accuracy: 0.7699 - val_loss: 0.6125 - val_accuracy: 0.7646\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5869 - accuracy: 0.7695 - val_loss: 0.6213 - val_accuracy: 0.7620\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5875 - accuracy: 0.7694 - val_loss: 0.6166 - val_accuracy: 0.7629\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5854 - accuracy: 0.7704 - val_loss: 0.6078 - val_accuracy: 0.7659\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5856 - accuracy: 0.7692 - val_loss: 0.6067 - val_accuracy: 0.7660\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5832 - accuracy: 0.7708 - val_loss: 0.6204 - val_accuracy: 0.7623\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5834 - accuracy: 0.7703 - val_loss: 0.6113 - val_accuracy: 0.7658\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5849 - accuracy: 0.7705 - val_loss: 0.6136 - val_accuracy: 0.7625\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5833 - accuracy: 0.7705 - val_loss: 0.6151 - val_accuracy: 0.7633\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5841 - accuracy: 0.7707 - val_loss: 0.6157 - val_accuracy: 0.7639\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5852 - accuracy: 0.7701 - val_loss: 0.6265 - val_accuracy: 0.7598\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5854 - accuracy: 0.7697 - val_loss: 0.6120 - val_accuracy: 0.7644\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5866 - accuracy: 0.7690 - val_loss: 0.6170 - val_accuracy: 0.7630\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5902 - accuracy: 0.7686 - val_loss: 0.6175 - val_accuracy: 0.7606\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5843 - accuracy: 0.7708 - val_loss: 0.6161 - val_accuracy: 0.7636\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5836 - accuracy: 0.7710 - val_loss: 0.6034 - val_accuracy: 0.7660\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5817 - accuracy: 0.7708 - val_loss: 0.6134 - val_accuracy: 0.7642\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5819 - accuracy: 0.7706 - val_loss: 0.6290 - val_accuracy: 0.7608\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5866 - accuracy: 0.7696 - val_loss: 0.6362 - val_accuracy: 0.7517\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5831 - accuracy: 0.7706 - val_loss: 0.6149 - val_accuracy: 0.7624\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5841 - accuracy: 0.7702 - val_loss: 0.6129 - val_accuracy: 0.7653\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5821 - accuracy: 0.7708 - val_loss: 0.6146 - val_accuracy: 0.7639\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5851 - accuracy: 0.7695 - val_loss: 0.6125 - val_accuracy: 0.7640\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5855 - accuracy: 0.7698 - val_loss: 0.6198 - val_accuracy: 0.7635\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5809 - accuracy: 0.7708 - val_loss: 0.6176 - val_accuracy: 0.7629\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5844 - accuracy: 0.7699 - val_loss: 0.6289 - val_accuracy: 0.7586\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5828 - accuracy: 0.7705 - val_loss: 0.6087 - val_accuracy: 0.7653\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5814 - accuracy: 0.7713 - val_loss: 0.6184 - val_accuracy: 0.7619\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5816 - accuracy: 0.7712 - val_loss: 0.6260 - val_accuracy: 0.7602\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5810 - accuracy: 0.7713 - val_loss: 0.6114 - val_accuracy: 0.7646\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5811 - accuracy: 0.7714 - val_loss: 0.6222 - val_accuracy: 0.7603\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5818 - accuracy: 0.7718 - val_loss: 0.6147 - val_accuracy: 0.7655\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5814 - accuracy: 0.7716 - val_loss: 0.6140 - val_accuracy: 0.7644\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5816 - accuracy: 0.7710 - val_loss: 0.6179 - val_accuracy: 0.7638\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6985 - accuracy: 0.7299 - val_loss: 0.9621 - val_accuracy: 0.6311\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.9250 - accuracy: 0.6419 - val_loss: 0.8654 - val_accuracy: 0.6656\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.8370 - accuracy: 0.6686 - val_loss: 0.7144 - val_accuracy: 0.7254\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6309 - accuracy: 0.7554 - val_loss: 0.6290 - val_accuracy: 0.7612\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6743 - accuracy: 0.7338 - val_loss: 0.8258 - val_accuracy: 0.6723\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.8093 - accuracy: 0.6728 - val_loss: 0.7182 - val_accuracy: 0.7210\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6194 - accuracy: 0.7586 - val_loss: 0.6391 - val_accuracy: 0.7557\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5977 - accuracy: 0.7667 - val_loss: 0.6193 - val_accuracy: 0.7609\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5889 - accuracy: 0.7692 - val_loss: 0.6314 - val_accuracy: 0.7582\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5910 - accuracy: 0.7686 - val_loss: 0.6279 - val_accuracy: 0.7565\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5844 - accuracy: 0.7700 - val_loss: 0.6147 - val_accuracy: 0.7645\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5839 - accuracy: 0.7705 - val_loss: 0.6132 - val_accuracy: 0.7642\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5836 - accuracy: 0.7703 - val_loss: 0.6139 - val_accuracy: 0.7632\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.7346 - accuracy: 0.7157 - val_loss: 0.8527 - val_accuracy: 0.6614\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6997 - accuracy: 0.7272 - val_loss: 0.6172 - val_accuracy: 0.7621\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5906 - accuracy: 0.7695 - val_loss: 0.6118 - val_accuracy: 0.7642\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5874 - accuracy: 0.7706 - val_loss: 0.6418 - val_accuracy: 0.7593\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5861 - accuracy: 0.7700 - val_loss: 0.6177 - val_accuracy: 0.7616\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5869 - accuracy: 0.7706 - val_loss: 0.6212 - val_accuracy: 0.7606\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5838 - accuracy: 0.7708 - val_loss: 0.6176 - val_accuracy: 0.7633\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5844 - accuracy: 0.7713 - val_loss: 0.6347 - val_accuracy: 0.7566\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5880 - accuracy: 0.7694 - val_loss: 0.6145 - val_accuracy: 0.7630\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5926 - accuracy: 0.7684 - val_loss: 1.0486 - val_accuracy: 0.6193\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5917 - accuracy: 0.7685 - val_loss: 0.6170 - val_accuracy: 0.7630\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5828 - accuracy: 0.7708 - val_loss: 0.6106 - val_accuracy: 0.7669\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5827 - accuracy: 0.7708 - val_loss: 0.6189 - val_accuracy: 0.7627\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5823 - accuracy: 0.7708 - val_loss: 0.6128 - val_accuracy: 0.7665\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5815 - accuracy: 0.7718 - val_loss: 0.6213 - val_accuracy: 0.7623\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5805 - accuracy: 0.7720 - val_loss: 0.6154 - val_accuracy: 0.7621\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5797 - accuracy: 0.7712 - val_loss: 0.6142 - val_accuracy: 0.7632\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5794 - accuracy: 0.7720 - val_loss: 0.6192 - val_accuracy: 0.7645\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5811 - accuracy: 0.7711 - val_loss: 0.6202 - val_accuracy: 0.7628\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5787 - accuracy: 0.7711 - val_loss: 0.6108 - val_accuracy: 0.7666\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5838 - accuracy: 0.7707 - val_loss: 0.6405 - val_accuracy: 0.7578\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5812 - accuracy: 0.7722 - val_loss: 0.6135 - val_accuracy: 0.7647\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5800 - accuracy: 0.7723 - val_loss: 0.6217 - val_accuracy: 0.7614\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5835 - accuracy: 0.7707 - val_loss: 0.6297 - val_accuracy: 0.7615\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5825 - accuracy: 0.7715 - val_loss: 0.6181 - val_accuracy: 0.7644\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5838 - accuracy: 0.7707 - val_loss: 0.6123 - val_accuracy: 0.7657\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5791 - accuracy: 0.7721 - val_loss: 0.6376 - val_accuracy: 0.7574\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5783 - accuracy: 0.7727 - val_loss: 0.6216 - val_accuracy: 0.7646\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5790 - accuracy: 0.7734 - val_loss: 0.6152 - val_accuracy: 0.7636\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5788 - accuracy: 0.7719 - val_loss: 0.6158 - val_accuracy: 0.7637\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5793 - accuracy: 0.7723 - val_loss: 0.6166 - val_accuracy: 0.7657\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5809 - accuracy: 0.7716 - val_loss: 0.6346 - val_accuracy: 0.7613\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5792 - accuracy: 0.7720 - val_loss: 0.6225 - val_accuracy: 0.7618\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5781 - accuracy: 0.7733 - val_loss: 0.6194 - val_accuracy: 0.7640\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5761 - accuracy: 0.7733 - val_loss: 0.6143 - val_accuracy: 0.7644\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5802 - accuracy: 0.7717 - val_loss: 0.6166 - val_accuracy: 0.7651\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5767 - accuracy: 0.7731 - val_loss: 0.6152 - val_accuracy: 0.7651\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5773 - accuracy: 0.7732 - val_loss: 0.6190 - val_accuracy: 0.7623\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5764 - accuracy: 0.7735 - val_loss: 0.6216 - val_accuracy: 0.7627\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5789 - accuracy: 0.7721 - val_loss: 0.6143 - val_accuracy: 0.7640\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5831 - accuracy: 0.7707 - val_loss: 0.6226 - val_accuracy: 0.7612\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5797 - accuracy: 0.7721 - val_loss: 0.6131 - val_accuracy: 0.7649\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5759 - accuracy: 0.7722 - val_loss: 0.6190 - val_accuracy: 0.7633\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5772 - accuracy: 0.7726 - val_loss: 0.6135 - val_accuracy: 0.7668\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5746 - accuracy: 0.7739 - val_loss: 0.6155 - val_accuracy: 0.7644\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5891 - accuracy: 0.7687 - val_loss: 0.6249 - val_accuracy: 0.7603\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5948 - accuracy: 0.7679 - val_loss: 0.6147 - val_accuracy: 0.7651\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5821 - accuracy: 0.7709 - val_loss: 0.6293 - val_accuracy: 0.7596\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5792 - accuracy: 0.7715 - val_loss: 0.6221 - val_accuracy: 0.7633\n",
      "accuracy: 76.33%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5930 - accuracy: 0.7688 - val_loss: 0.5880 - val_accuracy: 0.7684\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5909 - accuracy: 0.7698 - val_loss: 0.6031 - val_accuracy: 0.7624\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5895 - accuracy: 0.7700 - val_loss: 0.5933 - val_accuracy: 0.7659\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5861 - accuracy: 0.7708 - val_loss: 0.5816 - val_accuracy: 0.7697\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5855 - accuracy: 0.7708 - val_loss: 0.5844 - val_accuracy: 0.7701\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5866 - accuracy: 0.7704 - val_loss: 0.5877 - val_accuracy: 0.7691\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5893 - accuracy: 0.7699 - val_loss: 0.6093 - val_accuracy: 0.7607\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5871 - accuracy: 0.7702 - val_loss: 0.5849 - val_accuracy: 0.7699\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5846 - accuracy: 0.7708 - val_loss: 0.5912 - val_accuracy: 0.7676\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5851 - accuracy: 0.7711 - val_loss: 0.5938 - val_accuracy: 0.7680\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5907 - accuracy: 0.7692 - val_loss: 0.5946 - val_accuracy: 0.7652\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5853 - accuracy: 0.7713 - val_loss: 0.6045 - val_accuracy: 0.7602\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5818 - accuracy: 0.7716 - val_loss: 0.6094 - val_accuracy: 0.7596\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5929 - accuracy: 0.7690 - val_loss: 0.5893 - val_accuracy: 0.7674\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5826 - accuracy: 0.7714 - val_loss: 0.5921 - val_accuracy: 0.7673\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5838 - accuracy: 0.7720 - val_loss: 0.6032 - val_accuracy: 0.7617\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5849 - accuracy: 0.7712 - val_loss: 0.5969 - val_accuracy: 0.7650\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5802 - accuracy: 0.7727 - val_loss: 0.5954 - val_accuracy: 0.7661\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5830 - accuracy: 0.7710 - val_loss: 0.6297 - val_accuracy: 0.7546\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5820 - accuracy: 0.7707 - val_loss: 0.5880 - val_accuracy: 0.7679\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5801 - accuracy: 0.7721 - val_loss: 0.5953 - val_accuracy: 0.7662\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5818 - accuracy: 0.7715 - val_loss: 0.5981 - val_accuracy: 0.7665\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5793 - accuracy: 0.7727 - val_loss: 0.6047 - val_accuracy: 0.7638\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5837 - accuracy: 0.7707 - val_loss: 0.5964 - val_accuracy: 0.7671\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5845 - accuracy: 0.7712 - val_loss: 0.5933 - val_accuracy: 0.7656\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5816 - accuracy: 0.7714 - val_loss: 0.5937 - val_accuracy: 0.7688\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5786 - accuracy: 0.7717 - val_loss: 0.5919 - val_accuracy: 0.7671\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5812 - accuracy: 0.7722 - val_loss: 0.5934 - val_accuracy: 0.7670\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5804 - accuracy: 0.7714 - val_loss: 0.5918 - val_accuracy: 0.7674\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5788 - accuracy: 0.7729 - val_loss: 0.6019 - val_accuracy: 0.7653\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5790 - accuracy: 0.7722 - val_loss: 0.6121 - val_accuracy: 0.7591\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 209s 1ms/step - loss: 0.5777 - accuracy: 0.7724 - val_loss: 0.6486 - val_accuracy: 0.7457\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 209s 1ms/step - loss: 0.5811 - accuracy: 0.7720 - val_loss: 0.6067 - val_accuracy: 0.7636\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5800 - accuracy: 0.7726 - val_loss: 0.6073 - val_accuracy: 0.7653\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5772 - accuracy: 0.7727 - val_loss: 0.5925 - val_accuracy: 0.7670\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5787 - accuracy: 0.7723 - val_loss: 0.6024 - val_accuracy: 0.7650\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5805 - accuracy: 0.7721 - val_loss: 0.6076 - val_accuracy: 0.7635\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5783 - accuracy: 0.7728 - val_loss: 0.6073 - val_accuracy: 0.7643\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5793 - accuracy: 0.7725 - val_loss: 0.6270 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5771 - accuracy: 0.7735 - val_loss: 0.6079 - val_accuracy: 0.7630\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5748 - accuracy: 0.7742 - val_loss: 0.6012 - val_accuracy: 0.7665\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5752 - accuracy: 0.7734 - val_loss: 0.6048 - val_accuracy: 0.7648\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5771 - accuracy: 0.7730 - val_loss: 0.5998 - val_accuracy: 0.7652\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5777 - accuracy: 0.7736 - val_loss: 0.5972 - val_accuracy: 0.7684\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5753 - accuracy: 0.7737 - val_loss: 0.6069 - val_accuracy: 0.7634\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5749 - accuracy: 0.7734 - val_loss: 0.5949 - val_accuracy: 0.7677\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5742 - accuracy: 0.7736 - val_loss: 0.5974 - val_accuracy: 0.7655\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5770 - accuracy: 0.7734 - val_loss: 0.6157 - val_accuracy: 0.7622\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5734 - accuracy: 0.7746 - val_loss: 0.6028 - val_accuracy: 0.7638\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5785 - accuracy: 0.7724 - val_loss: 0.5967 - val_accuracy: 0.7677\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5757 - accuracy: 0.7732 - val_loss: 0.6111 - val_accuracy: 0.7629\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5740 - accuracy: 0.7744 - val_loss: 0.6243 - val_accuracy: 0.7535\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5815 - accuracy: 0.7718 - val_loss: 0.6419 - val_accuracy: 0.7520\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5732 - accuracy: 0.7743 - val_loss: 0.6012 - val_accuracy: 0.7663\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5746 - accuracy: 0.7737 - val_loss: 0.5965 - val_accuracy: 0.7658\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5821 - accuracy: 0.7708 - val_loss: 0.6062 - val_accuracy: 0.7667\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5750 - accuracy: 0.7737 - val_loss: 0.6061 - val_accuracy: 0.7643\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5743 - accuracy: 0.7731 - val_loss: 0.6011 - val_accuracy: 0.7637\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5763 - accuracy: 0.7731 - val_loss: 0.6002 - val_accuracy: 0.7667\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5753 - accuracy: 0.7735 - val_loss: 0.6047 - val_accuracy: 0.7643\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5769 - accuracy: 0.7736 - val_loss: 0.5989 - val_accuracy: 0.7666\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5771 - accuracy: 0.7729 - val_loss: 0.6103 - val_accuracy: 0.7635\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5741 - accuracy: 0.7734 - val_loss: 0.6019 - val_accuracy: 0.7660\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5764 - accuracy: 0.7738 - val_loss: 0.6109 - val_accuracy: 0.7628\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5757 - accuracy: 0.7735 - val_loss: 0.6278 - val_accuracy: 0.7561\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5814 - accuracy: 0.7722 - val_loss: 0.6409 - val_accuracy: 0.7519\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5733 - accuracy: 0.7741 - val_loss: 0.6042 - val_accuracy: 0.7647\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5748 - accuracy: 0.7740 - val_loss: 0.6055 - val_accuracy: 0.7642\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5734 - accuracy: 0.7742 - val_loss: 0.6044 - val_accuracy: 0.7651\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5718 - accuracy: 0.7748 - val_loss: 0.6018 - val_accuracy: 0.7646\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5764 - accuracy: 0.7736 - val_loss: 0.6138 - val_accuracy: 0.7612\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5747 - accuracy: 0.7739 - val_loss: 0.6034 - val_accuracy: 0.7650\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5765 - accuracy: 0.7733 - val_loss: 0.6051 - val_accuracy: 0.7650\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5708 - accuracy: 0.7752 - val_loss: 0.6112 - val_accuracy: 0.7640\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5754 - accuracy: 0.7737 - val_loss: 0.6002 - val_accuracy: 0.7661\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5713 - accuracy: 0.7751 - val_loss: 0.5989 - val_accuracy: 0.7664\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5785 - accuracy: 0.7729 - val_loss: 0.6055 - val_accuracy: 0.7627\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5731 - accuracy: 0.7743 - val_loss: 0.5979 - val_accuracy: 0.7675\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5727 - accuracy: 0.7744 - val_loss: 0.6079 - val_accuracy: 0.7625\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5770 - accuracy: 0.7728 - val_loss: 0.6018 - val_accuracy: 0.7660\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5738 - accuracy: 0.7738 - val_loss: 0.6006 - val_accuracy: 0.7655\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5730 - accuracy: 0.7744 - val_loss: 0.6051 - val_accuracy: 0.7635\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5716 - accuracy: 0.7743 - val_loss: 0.6106 - val_accuracy: 0.7628\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5731 - accuracy: 0.7735 - val_loss: 0.6033 - val_accuracy: 0.7644\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5783 - accuracy: 0.7720 - val_loss: 0.6254 - val_accuracy: 0.7602\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5754 - accuracy: 0.7736 - val_loss: 0.6046 - val_accuracy: 0.7645\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5751 - accuracy: 0.7726 - val_loss: 0.6136 - val_accuracy: 0.7622\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5720 - accuracy: 0.7743 - val_loss: 0.6088 - val_accuracy: 0.7622\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.6466 - accuracy: 0.7567 - val_loss: 0.5987 - val_accuracy: 0.7656\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5762 - accuracy: 0.7737 - val_loss: 0.6009 - val_accuracy: 0.7674\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5743 - accuracy: 0.7745 - val_loss: 0.6233 - val_accuracy: 0.7564\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5741 - accuracy: 0.7735 - val_loss: 0.6353 - val_accuracy: 0.7563\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5722 - accuracy: 0.7751 - val_loss: 0.6088 - val_accuracy: 0.7630\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5778 - accuracy: 0.7726 - val_loss: 0.6087 - val_accuracy: 0.7634\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5796 - accuracy: 0.7722 - val_loss: 0.6104 - val_accuracy: 0.7646\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5732 - accuracy: 0.7739 - val_loss: 0.6152 - val_accuracy: 0.7622\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5723 - accuracy: 0.7738 - val_loss: 0.6125 - val_accuracy: 0.7640\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5768 - accuracy: 0.7731 - val_loss: 0.6052 - val_accuracy: 0.7649\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5730 - accuracy: 0.7748 - val_loss: 0.6094 - val_accuracy: 0.7629\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5714 - accuracy: 0.7740 - val_loss: 0.6011 - val_accuracy: 0.7675\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5881 - accuracy: 0.7701 - val_loss: 0.6068 - val_accuracy: 0.7634\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5708 - accuracy: 0.7748 - val_loss: 0.6017 - val_accuracy: 0.7657\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5729 - accuracy: 0.7744 - val_loss: 0.6148 - val_accuracy: 0.7624\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5683 - accuracy: 0.7758 - val_loss: 0.6021 - val_accuracy: 0.7672\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5729 - accuracy: 0.7749 - val_loss: 0.5980 - val_accuracy: 0.7676\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5714 - accuracy: 0.7755 - val_loss: 0.6008 - val_accuracy: 0.7657\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5721 - accuracy: 0.7752 - val_loss: 0.6070 - val_accuracy: 0.7663\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5722 - accuracy: 0.7750 - val_loss: 0.6041 - val_accuracy: 0.7667\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5698 - accuracy: 0.7754 - val_loss: 0.6022 - val_accuracy: 0.7676\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5671 - accuracy: 0.7768 - val_loss: 0.6186 - val_accuracy: 0.7610\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5727 - accuracy: 0.7745 - val_loss: 0.6066 - val_accuracy: 0.7650\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5701 - accuracy: 0.7756 - val_loss: 0.6149 - val_accuracy: 0.7618\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5696 - accuracy: 0.7755 - val_loss: 0.6014 - val_accuracy: 0.7669\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5689 - accuracy: 0.7763 - val_loss: 0.6152 - val_accuracy: 0.7613\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5706 - accuracy: 0.7753 - val_loss: 0.6404 - val_accuracy: 0.7488\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5742 - accuracy: 0.7744 - val_loss: 0.6265 - val_accuracy: 0.7575\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5679 - accuracy: 0.7757 - val_loss: 0.6071 - val_accuracy: 0.7654\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5813 - accuracy: 0.7714 - val_loss: 0.6279 - val_accuracy: 0.7535\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5738 - accuracy: 0.7744 - val_loss: 0.6162 - val_accuracy: 0.7574\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5689 - accuracy: 0.7763 - val_loss: 0.6064 - val_accuracy: 0.7653\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5680 - accuracy: 0.7756 - val_loss: 0.6166 - val_accuracy: 0.7625\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5682 - accuracy: 0.7758 - val_loss: 0.6184 - val_accuracy: 0.7621\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5694 - accuracy: 0.7753 - val_loss: 0.6219 - val_accuracy: 0.7613\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5671 - accuracy: 0.7766 - val_loss: 0.6248 - val_accuracy: 0.7606\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5699 - accuracy: 0.7756 - val_loss: 0.6165 - val_accuracy: 0.7622\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5695 - accuracy: 0.7754 - val_loss: 0.6073 - val_accuracy: 0.7657\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5663 - accuracy: 0.7761 - val_loss: 0.6282 - val_accuracy: 0.7513\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5699 - accuracy: 0.7748 - val_loss: 0.6257 - val_accuracy: 0.7568\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5739 - accuracy: 0.7743 - val_loss: 0.6129 - val_accuracy: 0.7616\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5701 - accuracy: 0.7752 - val_loss: 0.6256 - val_accuracy: 0.7608\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5800 - accuracy: 0.7720 - val_loss: 0.6145 - val_accuracy: 0.7605\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5691 - accuracy: 0.7757 - val_loss: 0.6091 - val_accuracy: 0.7625\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5690 - accuracy: 0.7755 - val_loss: 0.6059 - val_accuracy: 0.7663\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5703 - accuracy: 0.7755 - val_loss: 0.6039 - val_accuracy: 0.7650\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5674 - accuracy: 0.7763 - val_loss: 0.6045 - val_accuracy: 0.7655\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5658 - accuracy: 0.7766 - val_loss: 0.6246 - val_accuracy: 0.7600\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5682 - accuracy: 0.7757 - val_loss: 0.6069 - val_accuracy: 0.7679\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5656 - accuracy: 0.7766 - val_loss: 0.6052 - val_accuracy: 0.7663\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5663 - accuracy: 0.7763 - val_loss: 0.6505 - val_accuracy: 0.7458\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5672 - accuracy: 0.7762 - val_loss: 0.6210 - val_accuracy: 0.7622\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5664 - accuracy: 0.7769 - val_loss: 0.6166 - val_accuracy: 0.7629\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5669 - accuracy: 0.7762 - val_loss: 0.6152 - val_accuracy: 0.7630\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5697 - accuracy: 0.7755 - val_loss: 0.6118 - val_accuracy: 0.7655\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5684 - accuracy: 0.7757 - val_loss: 0.6121 - val_accuracy: 0.7656\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5662 - accuracy: 0.7772 - val_loss: 0.6083 - val_accuracy: 0.7662\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5711 - accuracy: 0.7749 - val_loss: 0.6032 - val_accuracy: 0.7664\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5673 - accuracy: 0.7762 - val_loss: 0.6138 - val_accuracy: 0.7636\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5646 - accuracy: 0.7777 - val_loss: 0.6066 - val_accuracy: 0.7659\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5654 - accuracy: 0.7770 - val_loss: 0.6149 - val_accuracy: 0.7651\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5681 - accuracy: 0.7750 - val_loss: 0.6053 - val_accuracy: 0.7666\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5645 - accuracy: 0.7778 - val_loss: 0.6118 - val_accuracy: 0.7631\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5681 - accuracy: 0.7756 - val_loss: 0.6430 - val_accuracy: 0.7496\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5642 - accuracy: 0.7771 - val_loss: 0.6124 - val_accuracy: 0.7636\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5673 - accuracy: 0.7757 - val_loss: 0.6090 - val_accuracy: 0.7661\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5657 - accuracy: 0.7767 - val_loss: 0.6054 - val_accuracy: 0.7684\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5674 - accuracy: 0.7769 - val_loss: 0.6078 - val_accuracy: 0.7652\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5666 - accuracy: 0.7758 - val_loss: 0.6119 - val_accuracy: 0.7636\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5702 - accuracy: 0.7754 - val_loss: 0.6058 - val_accuracy: 0.7659\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5666 - accuracy: 0.7760 - val_loss: 0.6007 - val_accuracy: 0.7671\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5637 - accuracy: 0.7774 - val_loss: 0.6270 - val_accuracy: 0.7604\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6531 - accuracy: 0.7461 - val_loss: 0.6284 - val_accuracy: 0.7578\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5697 - accuracy: 0.7763 - val_loss: 0.6065 - val_accuracy: 0.7651\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5677 - accuracy: 0.7766 - val_loss: 0.6087 - val_accuracy: 0.7655\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5664 - accuracy: 0.7757 - val_loss: 0.6149 - val_accuracy: 0.7627\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5649 - accuracy: 0.7762 - val_loss: 0.6205 - val_accuracy: 0.7590\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5642 - accuracy: 0.7772 - val_loss: 0.6096 - val_accuracy: 0.7634\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5653 - accuracy: 0.7775 - val_loss: 0.6162 - val_accuracy: 0.7633\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5647 - accuracy: 0.7769 - val_loss: 0.6115 - val_accuracy: 0.7661\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5649 - accuracy: 0.7764 - val_loss: 0.6085 - val_accuracy: 0.7657\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5654 - accuracy: 0.7762 - val_loss: 0.6274 - val_accuracy: 0.7578\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5620 - accuracy: 0.7779 - val_loss: 0.6191 - val_accuracy: 0.7635\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5662 - accuracy: 0.7769 - val_loss: 0.6124 - val_accuracy: 0.7638\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5650 - accuracy: 0.7765 - val_loss: 0.6193 - val_accuracy: 0.7632\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5665 - accuracy: 0.7772 - val_loss: 0.6184 - val_accuracy: 0.7622\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5719 - accuracy: 0.7748 - val_loss: 0.6171 - val_accuracy: 0.7625\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5662 - accuracy: 0.7769 - val_loss: 0.6099 - val_accuracy: 0.7628\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5635 - accuracy: 0.7774 - val_loss: 0.6077 - val_accuracy: 0.7649\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5645 - accuracy: 0.7766 - val_loss: 0.6048 - val_accuracy: 0.7667\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5626 - accuracy: 0.7780 - val_loss: 0.6062 - val_accuracy: 0.7661\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5644 - accuracy: 0.7769 - val_loss: 0.6135 - val_accuracy: 0.7645\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5705 - accuracy: 0.7744 - val_loss: 0.6104 - val_accuracy: 0.7656\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5623 - accuracy: 0.7778 - val_loss: 0.6257 - val_accuracy: 0.7577\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5663 - accuracy: 0.7762 - val_loss: 0.6054 - val_accuracy: 0.7671\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5635 - accuracy: 0.7775 - val_loss: 0.6162 - val_accuracy: 0.7630\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5623 - accuracy: 0.7773 - val_loss: 0.6097 - val_accuracy: 0.7657\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5700 - accuracy: 0.7757 - val_loss: 0.6147 - val_accuracy: 0.7631\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5707 - accuracy: 0.7754 - val_loss: 0.6186 - val_accuracy: 0.7591\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5653 - accuracy: 0.7766 - val_loss: 0.6424 - val_accuracy: 0.7544\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5693 - accuracy: 0.7751 - val_loss: 0.6147 - val_accuracy: 0.7621\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5685 - accuracy: 0.7761 - val_loss: 0.6129 - val_accuracy: 0.7635\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5646 - accuracy: 0.7774 - val_loss: 0.6141 - val_accuracy: 0.7623\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5650 - accuracy: 0.7769 - val_loss: 0.6138 - val_accuracy: 0.7624\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5639 - accuracy: 0.7778 - val_loss: 0.6133 - val_accuracy: 0.7645\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5623 - accuracy: 0.7780 - val_loss: 0.6224 - val_accuracy: 0.7594\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5632 - accuracy: 0.7775 - val_loss: 0.6288 - val_accuracy: 0.7550\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5655 - accuracy: 0.7769 - val_loss: 0.6091 - val_accuracy: 0.7675\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5652 - accuracy: 0.7764 - val_loss: 0.6310 - val_accuracy: 0.7549\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5739 - accuracy: 0.7736 - val_loss: 0.6309 - val_accuracy: 0.7570\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5755 - accuracy: 0.7735 - val_loss: 0.6155 - val_accuracy: 0.7648\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5701 - accuracy: 0.7754 - val_loss: 0.6166 - val_accuracy: 0.7635\n",
      "accuracy: 76.35%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5830 - accuracy: 0.7717 - val_loss: 0.5792 - val_accuracy: 0.7732\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5758 - accuracy: 0.7734 - val_loss: 0.5706 - val_accuracy: 0.7762\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5767 - accuracy: 0.7723 - val_loss: 0.5649 - val_accuracy: 0.7780\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5737 - accuracy: 0.7736 - val_loss: 0.5806 - val_accuracy: 0.7754\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5748 - accuracy: 0.7732 - val_loss: 0.6185 - val_accuracy: 0.7578\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5985 - accuracy: 0.7660 - val_loss: 1.0179 - val_accuracy: 0.6207\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.9529 - accuracy: 0.6326 - val_loss: 0.9532 - val_accuracy: 0.6350\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.9593 - accuracy: 0.6315 - val_loss: 0.9451 - val_accuracy: 0.6357\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.8989 - accuracy: 0.6507 - val_loss: 0.8681 - val_accuracy: 0.6627\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.8649 - accuracy: 0.6617 - val_loss: 0.8570 - val_accuracy: 0.6615\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.8555 - accuracy: 0.6632 - val_loss: 0.8424 - val_accuracy: 0.6670\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.8486 - accuracy: 0.6641 - val_loss: 0.8550 - val_accuracy: 0.6678\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.8418 - accuracy: 0.6660 - val_loss: 0.8389 - val_accuracy: 0.6665\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.8525 - accuracy: 0.6637 - val_loss: 0.8429 - val_accuracy: 0.6673\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.8477 - accuracy: 0.6634 - val_loss: 0.8280 - val_accuracy: 0.6682\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.8605 - accuracy: 0.6612 - val_loss: 0.8362 - val_accuracy: 0.6665\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.7728 - accuracy: 0.6936 - val_loss: 0.7203 - val_accuracy: 0.7191\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.7116 - accuracy: 0.7239 - val_loss: 0.7031 - val_accuracy: 0.7256\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6759 - accuracy: 0.7380 - val_loss: 0.6534 - val_accuracy: 0.7491\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.6525 - accuracy: 0.7473 - val_loss: 0.6452 - val_accuracy: 0.7534\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6387 - accuracy: 0.7524 - val_loss: 0.6419 - val_accuracy: 0.7544\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6325 - accuracy: 0.7551 - val_loss: 0.6283 - val_accuracy: 0.7591\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.6247 - accuracy: 0.7579 - val_loss: 0.6253 - val_accuracy: 0.7605\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6212 - accuracy: 0.7582 - val_loss: 0.6253 - val_accuracy: 0.7584\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6267 - accuracy: 0.7566 - val_loss: 0.6203 - val_accuracy: 0.7624\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.6139 - accuracy: 0.7614 - val_loss: 0.6202 - val_accuracy: 0.7611\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.6122 - accuracy: 0.7620 - val_loss: 0.6158 - val_accuracy: 0.7658\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6077 - accuracy: 0.7625 - val_loss: 0.6195 - val_accuracy: 0.7604\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6080 - accuracy: 0.7630 - val_loss: 0.6198 - val_accuracy: 0.7627\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6066 - accuracy: 0.7632 - val_loss: 0.6118 - val_accuracy: 0.7661\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6052 - accuracy: 0.7637 - val_loss: 0.6079 - val_accuracy: 0.7666\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6027 - accuracy: 0.7647 - val_loss: 0.6105 - val_accuracy: 0.7647\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6011 - accuracy: 0.7641 - val_loss: 0.6162 - val_accuracy: 0.7635\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5993 - accuracy: 0.7651 - val_loss: 0.6049 - val_accuracy: 0.7683\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5998 - accuracy: 0.7654 - val_loss: 0.6410 - val_accuracy: 0.7517\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5961 - accuracy: 0.7663 - val_loss: 0.6061 - val_accuracy: 0.7672\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5971 - accuracy: 0.7664 - val_loss: 0.6175 - val_accuracy: 0.7653\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5953 - accuracy: 0.7665 - val_loss: 0.6177 - val_accuracy: 0.7638\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5933 - accuracy: 0.7674 - val_loss: 0.6121 - val_accuracy: 0.7655\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5932 - accuracy: 0.7676 - val_loss: 0.6287 - val_accuracy: 0.7601\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5916 - accuracy: 0.7679 - val_loss: 0.6192 - val_accuracy: 0.7614\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5905 - accuracy: 0.7684 - val_loss: 0.6085 - val_accuracy: 0.7667\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5913 - accuracy: 0.7681 - val_loss: 0.6160 - val_accuracy: 0.7641\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5912 - accuracy: 0.7679 - val_loss: 0.6060 - val_accuracy: 0.7689\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5898 - accuracy: 0.7690 - val_loss: 0.6099 - val_accuracy: 0.7683\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5976 - accuracy: 0.7664 - val_loss: 0.6136 - val_accuracy: 0.7646\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5906 - accuracy: 0.7675 - val_loss: 0.6081 - val_accuracy: 0.7671\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5877 - accuracy: 0.7685 - val_loss: 0.6080 - val_accuracy: 0.7670\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5899 - accuracy: 0.7682 - val_loss: 0.6043 - val_accuracy: 0.7685\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5872 - accuracy: 0.7694 - val_loss: 0.6043 - val_accuracy: 0.7691\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5859 - accuracy: 0.7694 - val_loss: 0.6055 - val_accuracy: 0.7677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5858 - accuracy: 0.7701 - val_loss: 0.6060 - val_accuracy: 0.7683\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5863 - accuracy: 0.7696 - val_loss: 0.6067 - val_accuracy: 0.7669\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5850 - accuracy: 0.7704 - val_loss: 0.6174 - val_accuracy: 0.7645\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5857 - accuracy: 0.7703 - val_loss: 0.6187 - val_accuracy: 0.7657\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5838 - accuracy: 0.7707 - val_loss: 0.6048 - val_accuracy: 0.7703\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.7016 - accuracy: 0.7300 - val_loss: 0.8702 - val_accuracy: 0.6634\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.7074 - accuracy: 0.7251 - val_loss: 0.6114 - val_accuracy: 0.7667\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5895 - accuracy: 0.7689 - val_loss: 0.6053 - val_accuracy: 0.7683\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5892 - accuracy: 0.7687 - val_loss: 0.6078 - val_accuracy: 0.7674\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5848 - accuracy: 0.7705 - val_loss: 0.6046 - val_accuracy: 0.7684\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5847 - accuracy: 0.7707 - val_loss: 0.6102 - val_accuracy: 0.7678\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5817 - accuracy: 0.7714 - val_loss: 0.6160 - val_accuracy: 0.7624\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.5824 - accuracy: 0.7717 - val_loss: 0.6097 - val_accuracy: 0.7672\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5815 - accuracy: 0.7717 - val_loss: 0.6056 - val_accuracy: 0.7700\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 228s 2ms/step - loss: 0.5819 - accuracy: 0.7720 - val_loss: 0.6235 - val_accuracy: 0.7602\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 234s 2ms/step - loss: 0.5833 - accuracy: 0.7712 - val_loss: 0.6168 - val_accuracy: 0.7638\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 225s 2ms/step - loss: 0.5800 - accuracy: 0.7716 - val_loss: 0.6090 - val_accuracy: 0.7679\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 222s 2ms/step - loss: 0.5784 - accuracy: 0.7730 - val_loss: 0.6107 - val_accuracy: 0.7676\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5808 - accuracy: 0.7726 - val_loss: 0.6398 - val_accuracy: 0.7564\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5919 - accuracy: 0.7687 - val_loss: 0.6091 - val_accuracy: 0.7673\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5779 - accuracy: 0.7723 - val_loss: 0.6081 - val_accuracy: 0.7683\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5785 - accuracy: 0.7725 - val_loss: 0.6119 - val_accuracy: 0.7649\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5783 - accuracy: 0.7720 - val_loss: 0.6136 - val_accuracy: 0.7663\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5852 - accuracy: 0.7714 - val_loss: 0.6226 - val_accuracy: 0.7632\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5788 - accuracy: 0.7724 - val_loss: 0.6171 - val_accuracy: 0.7667\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5773 - accuracy: 0.7725 - val_loss: 0.6018 - val_accuracy: 0.7699\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5769 - accuracy: 0.7727 - val_loss: 0.6087 - val_accuracy: 0.7678\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5745 - accuracy: 0.7731 - val_loss: 0.6103 - val_accuracy: 0.7679\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5769 - accuracy: 0.7726 - val_loss: 0.6086 - val_accuracy: 0.7686\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5792 - accuracy: 0.7723 - val_loss: 0.6223 - val_accuracy: 0.7663\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5738 - accuracy: 0.7741 - val_loss: 0.6049 - val_accuracy: 0.7682\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5758 - accuracy: 0.7735 - val_loss: 0.6065 - val_accuracy: 0.7679\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.6338 - accuracy: 0.7528 - val_loss: 0.9088 - val_accuracy: 0.6440\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.7755 - accuracy: 0.6997 - val_loss: 0.6317 - val_accuracy: 0.7591\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5927 - accuracy: 0.7694 - val_loss: 0.6128 - val_accuracy: 0.7675\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5787 - accuracy: 0.7726 - val_loss: 0.6118 - val_accuracy: 0.7672\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.5763 - accuracy: 0.7732 - val_loss: 0.6105 - val_accuracy: 0.7671\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.5765 - accuracy: 0.7741 - val_loss: 0.6097 - val_accuracy: 0.7699\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.8922 - accuracy: 0.6584 - val_loss: 0.8519 - val_accuracy: 0.6633\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.8626 - accuracy: 0.6602 - val_loss: 0.8439 - val_accuracy: 0.6613\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.8563 - accuracy: 0.6615 - val_loss: 0.8490 - val_accuracy: 0.6631\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.8560 - accuracy: 0.6626 - val_loss: 0.8609 - val_accuracy: 0.6643\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.8408 - accuracy: 0.6637 - val_loss: 0.8257 - val_accuracy: 0.6660\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.8250 - accuracy: 0.6666 - val_loss: 0.8274 - val_accuracy: 0.6638\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 209s 1ms/step - loss: 0.8000 - accuracy: 0.6740 - val_loss: 0.7852 - val_accuracy: 0.6838\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.7568 - accuracy: 0.6991 - val_loss: 0.7386 - val_accuracy: 0.7062\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.7321 - accuracy: 0.7099 - val_loss: 0.7236 - val_accuracy: 0.7178\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.7186 - accuracy: 0.7173 - val_loss: 0.7100 - val_accuracy: 0.7257\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.7081 - accuracy: 0.7241 - val_loss: 0.7054 - val_accuracy: 0.7275\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.7013 - accuracy: 0.7261 - val_loss: 0.6936 - val_accuracy: 0.7334\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.6932 - accuracy: 0.7305 - val_loss: 0.6866 - val_accuracy: 0.7365\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6860 - accuracy: 0.7353 - val_loss: 0.6909 - val_accuracy: 0.7330\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6813 - accuracy: 0.7363 - val_loss: 0.6760 - val_accuracy: 0.7374\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6732 - accuracy: 0.7390 - val_loss: 0.6678 - val_accuracy: 0.7432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6680 - accuracy: 0.7412 - val_loss: 0.6633 - val_accuracy: 0.7442\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6648 - accuracy: 0.7428 - val_loss: 0.6566 - val_accuracy: 0.7469\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.6596 - accuracy: 0.7446 - val_loss: 0.6547 - val_accuracy: 0.7472\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6556 - accuracy: 0.7459 - val_loss: 0.6569 - val_accuracy: 0.7481\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6523 - accuracy: 0.7476 - val_loss: 0.6542 - val_accuracy: 0.7474\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6499 - accuracy: 0.7475 - val_loss: 0.6501 - val_accuracy: 0.7503\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6484 - accuracy: 0.7489 - val_loss: 0.6551 - val_accuracy: 0.7478\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.6465 - accuracy: 0.7491 - val_loss: 0.6456 - val_accuracy: 0.7519\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6427 - accuracy: 0.7506 - val_loss: 0.6411 - val_accuracy: 0.7524\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.6403 - accuracy: 0.7515 - val_loss: 0.6387 - val_accuracy: 0.7529\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6378 - accuracy: 0.7523 - val_loss: 0.6559 - val_accuracy: 0.7461\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6361 - accuracy: 0.7532 - val_loss: 0.6384 - val_accuracy: 0.7538\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6344 - accuracy: 0.7536 - val_loss: 0.6454 - val_accuracy: 0.7518\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6402 - accuracy: 0.7526 - val_loss: 0.6331 - val_accuracy: 0.7558\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6329 - accuracy: 0.7538 - val_loss: 0.6353 - val_accuracy: 0.7545\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6288 - accuracy: 0.7558 - val_loss: 0.6341 - val_accuracy: 0.7584\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6296 - accuracy: 0.7548 - val_loss: 0.6363 - val_accuracy: 0.7565\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6276 - accuracy: 0.7557 - val_loss: 0.6490 - val_accuracy: 0.7529\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6270 - accuracy: 0.7562 - val_loss: 0.6341 - val_accuracy: 0.7549\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6243 - accuracy: 0.7565 - val_loss: 0.6289 - val_accuracy: 0.7589\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6238 - accuracy: 0.7571 - val_loss: 0.6350 - val_accuracy: 0.7557\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6249 - accuracy: 0.7569 - val_loss: 0.6554 - val_accuracy: 0.7493\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6248 - accuracy: 0.7574 - val_loss: 0.6331 - val_accuracy: 0.7570\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6225 - accuracy: 0.7570 - val_loss: 0.6357 - val_accuracy: 0.7549\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6189 - accuracy: 0.7584 - val_loss: 0.6294 - val_accuracy: 0.7564\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6192 - accuracy: 0.7582 - val_loss: 0.6331 - val_accuracy: 0.7563\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6196 - accuracy: 0.7584 - val_loss: 0.6238 - val_accuracy: 0.7605\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6198 - accuracy: 0.7587 - val_loss: 0.6317 - val_accuracy: 0.7574\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6183 - accuracy: 0.7593 - val_loss: 0.6296 - val_accuracy: 0.7585\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6178 - accuracy: 0.7594 - val_loss: 0.6310 - val_accuracy: 0.7569\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6162 - accuracy: 0.7595 - val_loss: 0.7187 - val_accuracy: 0.7335\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6142 - accuracy: 0.7600 - val_loss: 0.6338 - val_accuracy: 0.7568\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6137 - accuracy: 0.7607 - val_loss: 0.6261 - val_accuracy: 0.7607\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6145 - accuracy: 0.7608 - val_loss: 0.6311 - val_accuracy: 0.7578\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6137 - accuracy: 0.7605 - val_loss: 0.6306 - val_accuracy: 0.7565\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6140 - accuracy: 0.7606 - val_loss: 0.6312 - val_accuracy: 0.7598\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6138 - accuracy: 0.7614 - val_loss: 0.6227 - val_accuracy: 0.7616\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6114 - accuracy: 0.7616 - val_loss: 0.6355 - val_accuracy: 0.7587\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6107 - accuracy: 0.7616 - val_loss: 0.6239 - val_accuracy: 0.7620\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6079 - accuracy: 0.7629 - val_loss: 0.6249 - val_accuracy: 0.7611\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6084 - accuracy: 0.7627 - val_loss: 0.6256 - val_accuracy: 0.7613\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6098 - accuracy: 0.7625 - val_loss: 0.6273 - val_accuracy: 0.7596\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6064 - accuracy: 0.7632 - val_loss: 0.6341 - val_accuracy: 0.7577\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6076 - accuracy: 0.7630 - val_loss: 0.6303 - val_accuracy: 0.7584\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6066 - accuracy: 0.7640 - val_loss: 0.6359 - val_accuracy: 0.7585\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6074 - accuracy: 0.7632 - val_loss: 0.6237 - val_accuracy: 0.7625\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6069 - accuracy: 0.7633 - val_loss: 0.6184 - val_accuracy: 0.7641\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6029 - accuracy: 0.7641 - val_loss: 0.6271 - val_accuracy: 0.7589\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6026 - accuracy: 0.7648 - val_loss: 0.6235 - val_accuracy: 0.7627\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6070 - accuracy: 0.7623 - val_loss: 0.6478 - val_accuracy: 0.7489\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6071 - accuracy: 0.7628 - val_loss: 0.6264 - val_accuracy: 0.7623\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6029 - accuracy: 0.7643 - val_loss: 0.6279 - val_accuracy: 0.7612\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.6026 - accuracy: 0.7638 - val_loss: 0.6250 - val_accuracy: 0.7606\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.6019 - accuracy: 0.7643 - val_loss: 0.6283 - val_accuracy: 0.7609\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.6021 - accuracy: 0.7640 - val_loss: 0.6281 - val_accuracy: 0.7609\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5997 - accuracy: 0.7648 - val_loss: 0.6181 - val_accuracy: 0.7642\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5990 - accuracy: 0.7655 - val_loss: 0.6347 - val_accuracy: 0.7592\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.6014 - accuracy: 0.7643 - val_loss: 0.6229 - val_accuracy: 0.7622\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5984 - accuracy: 0.7658 - val_loss: 0.6338 - val_accuracy: 0.7581\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6016 - accuracy: 0.7642 - val_loss: 0.6178 - val_accuracy: 0.7648\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5981 - accuracy: 0.7654 - val_loss: 0.6306 - val_accuracy: 0.7608\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5956 - accuracy: 0.7659 - val_loss: 0.6206 - val_accuracy: 0.7640\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5973 - accuracy: 0.7656 - val_loss: 0.6218 - val_accuracy: 0.7624\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5953 - accuracy: 0.7661 - val_loss: 0.6207 - val_accuracy: 0.7621\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5960 - accuracy: 0.7651 - val_loss: 0.6249 - val_accuracy: 0.7632\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5963 - accuracy: 0.7669 - val_loss: 0.6275 - val_accuracy: 0.7617\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5960 - accuracy: 0.7661 - val_loss: 0.6250 - val_accuracy: 0.7627\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5953 - accuracy: 0.7665 - val_loss: 0.6187 - val_accuracy: 0.7632\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5947 - accuracy: 0.7670 - val_loss: 0.6398 - val_accuracy: 0.7536\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5947 - accuracy: 0.7666 - val_loss: 0.6138 - val_accuracy: 0.7669\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5927 - accuracy: 0.7670 - val_loss: 0.6210 - val_accuracy: 0.7634\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5950 - accuracy: 0.7664 - val_loss: 0.6282 - val_accuracy: 0.7606\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5908 - accuracy: 0.7683 - val_loss: 0.6224 - val_accuracy: 0.7638\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5922 - accuracy: 0.7669 - val_loss: 0.6192 - val_accuracy: 0.7643\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5929 - accuracy: 0.7673 - val_loss: 0.6216 - val_accuracy: 0.7637\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5983 - accuracy: 0.7665 - val_loss: 0.6232 - val_accuracy: 0.7615\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5925 - accuracy: 0.7679 - val_loss: 0.6254 - val_accuracy: 0.7621\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5894 - accuracy: 0.7686 - val_loss: 0.6265 - val_accuracy: 0.7610\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.5911 - accuracy: 0.7675 - val_loss: 0.6268 - val_accuracy: 0.7620\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5992 - accuracy: 0.7652 - val_loss: 0.6197 - val_accuracy: 0.7622\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5887 - accuracy: 0.7684 - val_loss: 0.6297 - val_accuracy: 0.7614\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5895 - accuracy: 0.7683 - val_loss: 0.6285 - val_accuracy: 0.7615\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5887 - accuracy: 0.7686 - val_loss: 0.6231 - val_accuracy: 0.7642\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5888 - accuracy: 0.7686 - val_loss: 0.6231 - val_accuracy: 0.7630\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5918 - accuracy: 0.7684 - val_loss: 0.6266 - val_accuracy: 0.7632\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5947 - accuracy: 0.7667 - val_loss: 0.6255 - val_accuracy: 0.7622\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5903 - accuracy: 0.7685 - val_loss: 0.6235 - val_accuracy: 0.7653\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5864 - accuracy: 0.7699 - val_loss: 0.6212 - val_accuracy: 0.7660\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5921 - accuracy: 0.7674 - val_loss: 0.6184 - val_accuracy: 0.7667\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5861 - accuracy: 0.7690 - val_loss: 0.6238 - val_accuracy: 0.7616\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5880 - accuracy: 0.7688 - val_loss: 0.6155 - val_accuracy: 0.7670\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5846 - accuracy: 0.7702 - val_loss: 0.6273 - val_accuracy: 0.7646\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5857 - accuracy: 0.7699 - val_loss: 0.6174 - val_accuracy: 0.7654\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5892 - accuracy: 0.7691 - val_loss: 0.6239 - val_accuracy: 0.7636\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.5872 - accuracy: 0.7699 - val_loss: 0.6220 - val_accuracy: 0.7637\n",
      "accuracy: 76.37%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  6\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5948 - accuracy: 0.7675 - val_loss: 0.5852 - val_accuracy: 0.7726\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5974 - accuracy: 0.7665 - val_loss: 0.5814 - val_accuracy: 0.7721\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5914 - accuracy: 0.7683 - val_loss: 0.5844 - val_accuracy: 0.7715\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5941 - accuracy: 0.7679 - val_loss: 0.5916 - val_accuracy: 0.7712\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5931 - accuracy: 0.7676 - val_loss: 0.5901 - val_accuracy: 0.7716\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5911 - accuracy: 0.7679 - val_loss: 0.5895 - val_accuracy: 0.7697\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5922 - accuracy: 0.7682 - val_loss: 0.5885 - val_accuracy: 0.7722\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5900 - accuracy: 0.7684 - val_loss: 0.5930 - val_accuracy: 0.7699\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5901 - accuracy: 0.7690 - val_loss: 0.6038 - val_accuracy: 0.7667\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5911 - accuracy: 0.7681 - val_loss: 0.6214 - val_accuracy: 0.7592\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5871 - accuracy: 0.7695 - val_loss: 0.5900 - val_accuracy: 0.7706\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5883 - accuracy: 0.7685 - val_loss: 0.5869 - val_accuracy: 0.7720\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5870 - accuracy: 0.7703 - val_loss: 0.5906 - val_accuracy: 0.7718\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5862 - accuracy: 0.7691 - val_loss: 0.5878 - val_accuracy: 0.7715\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5854 - accuracy: 0.7696 - val_loss: 0.5972 - val_accuracy: 0.7717\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.5849 - accuracy: 0.7705 - val_loss: 0.5978 - val_accuracy: 0.7697\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5859 - accuracy: 0.7690 - val_loss: 0.5944 - val_accuracy: 0.7703\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5855 - accuracy: 0.7700 - val_loss: 0.6149 - val_accuracy: 0.7647\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5852 - accuracy: 0.7705 - val_loss: 0.5955 - val_accuracy: 0.7713\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5890 - accuracy: 0.7693 - val_loss: 0.5900 - val_accuracy: 0.7730\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5841 - accuracy: 0.7696 - val_loss: 0.5905 - val_accuracy: 0.7720\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5840 - accuracy: 0.7703 - val_loss: 0.5947 - val_accuracy: 0.7701\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5845 - accuracy: 0.7703 - val_loss: 0.5983 - val_accuracy: 0.7698\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5842 - accuracy: 0.7700 - val_loss: 0.5912 - val_accuracy: 0.7709\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5840 - accuracy: 0.7703 - val_loss: 0.6147 - val_accuracy: 0.7620\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5878 - accuracy: 0.7697 - val_loss: 0.6019 - val_accuracy: 0.7663\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5822 - accuracy: 0.7713 - val_loss: 0.5971 - val_accuracy: 0.7703\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5809 - accuracy: 0.7719 - val_loss: 0.5877 - val_accuracy: 0.7724\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5797 - accuracy: 0.7723 - val_loss: 0.6102 - val_accuracy: 0.7671\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5807 - accuracy: 0.7719 - val_loss: 0.5958 - val_accuracy: 0.7710\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5804 - accuracy: 0.7713 - val_loss: 0.5890 - val_accuracy: 0.7722\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5801 - accuracy: 0.7720 - val_loss: 0.6065 - val_accuracy: 0.7683\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.6176 - accuracy: 0.7596 - val_loss: 0.5950 - val_accuracy: 0.7710\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5813 - accuracy: 0.7716 - val_loss: 0.5942 - val_accuracy: 0.7722\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5803 - accuracy: 0.7718 - val_loss: 0.6005 - val_accuracy: 0.7676\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5789 - accuracy: 0.7718 - val_loss: 0.5932 - val_accuracy: 0.7711\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5779 - accuracy: 0.7729 - val_loss: 0.5919 - val_accuracy: 0.7719\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5822 - accuracy: 0.7711 - val_loss: 0.5973 - val_accuracy: 0.7715\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5817 - accuracy: 0.7716 - val_loss: 0.6008 - val_accuracy: 0.7683\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5842 - accuracy: 0.7704 - val_loss: 0.5924 - val_accuracy: 0.7720\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5768 - accuracy: 0.7722 - val_loss: 0.5922 - val_accuracy: 0.7723\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5769 - accuracy: 0.7729 - val_loss: 0.5942 - val_accuracy: 0.7721\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5800 - accuracy: 0.7714 - val_loss: 0.5965 - val_accuracy: 0.7720\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5799 - accuracy: 0.7716 - val_loss: 0.5990 - val_accuracy: 0.7700\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5793 - accuracy: 0.7724 - val_loss: 0.5985 - val_accuracy: 0.7692\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5773 - accuracy: 0.7720 - val_loss: 0.5899 - val_accuracy: 0.7737\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5750 - accuracy: 0.7732 - val_loss: 0.6067 - val_accuracy: 0.7705\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5765 - accuracy: 0.7728 - val_loss: 0.5934 - val_accuracy: 0.7728\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5789 - accuracy: 0.7726 - val_loss: 0.6147 - val_accuracy: 0.7644\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5797 - accuracy: 0.7721 - val_loss: 0.6028 - val_accuracy: 0.7692\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5799 - accuracy: 0.7716 - val_loss: 0.6128 - val_accuracy: 0.7691\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5854 - accuracy: 0.7708 - val_loss: 0.5970 - val_accuracy: 0.7714\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5769 - accuracy: 0.7724 - val_loss: 0.5964 - val_accuracy: 0.7700\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5776 - accuracy: 0.7727 - val_loss: 0.6058 - val_accuracy: 0.7683\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5796 - accuracy: 0.7711 - val_loss: 0.5977 - val_accuracy: 0.7699\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5775 - accuracy: 0.7730 - val_loss: 0.6022 - val_accuracy: 0.7693\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5753 - accuracy: 0.7737 - val_loss: 0.5997 - val_accuracy: 0.7707\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5766 - accuracy: 0.7729 - val_loss: 0.6058 - val_accuracy: 0.7651\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5750 - accuracy: 0.7735 - val_loss: 0.5999 - val_accuracy: 0.7695\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5787 - accuracy: 0.7718 - val_loss: 0.6072 - val_accuracy: 0.7677\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5752 - accuracy: 0.7737 - val_loss: 0.6059 - val_accuracy: 0.7695\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5758 - accuracy: 0.7733 - val_loss: 0.5947 - val_accuracy: 0.7737\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.5740 - accuracy: 0.7741 - val_loss: 0.6017 - val_accuracy: 0.7689\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.5722 - accuracy: 0.7751 - val_loss: 0.5996 - val_accuracy: 0.7697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5719 - accuracy: 0.7739 - val_loss: 0.6116 - val_accuracy: 0.7650\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5723 - accuracy: 0.7737 - val_loss: 0.6072 - val_accuracy: 0.7707\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5775 - accuracy: 0.7721 - val_loss: 0.6304 - val_accuracy: 0.7586\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5949 - accuracy: 0.7682 - val_loss: 0.6256 - val_accuracy: 0.7596\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5809 - accuracy: 0.7723 - val_loss: 0.6013 - val_accuracy: 0.7697\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5732 - accuracy: 0.7735 - val_loss: 0.6136 - val_accuracy: 0.7667\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5768 - accuracy: 0.7729 - val_loss: 0.6027 - val_accuracy: 0.7720\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5763 - accuracy: 0.7725 - val_loss: 0.6015 - val_accuracy: 0.7708\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5745 - accuracy: 0.7732 - val_loss: 0.6092 - val_accuracy: 0.7692\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5731 - accuracy: 0.7740 - val_loss: 0.5939 - val_accuracy: 0.7719\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.5729 - accuracy: 0.7743 - val_loss: 0.5962 - val_accuracy: 0.7719\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.5727 - accuracy: 0.7738 - val_loss: 0.6087 - val_accuracy: 0.7691\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 209s 1ms/step - loss: 0.5691 - accuracy: 0.7756 - val_loss: 0.6056 - val_accuracy: 0.7693\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5733 - accuracy: 0.7741 - val_loss: 0.5964 - val_accuracy: 0.7729\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5729 - accuracy: 0.7745 - val_loss: 0.5987 - val_accuracy: 0.7726\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5703 - accuracy: 0.7747 - val_loss: 0.5997 - val_accuracy: 0.7700\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.5718 - accuracy: 0.7745 - val_loss: 0.6016 - val_accuracy: 0.7718\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5709 - accuracy: 0.7745 - val_loss: 0.5968 - val_accuracy: 0.7717\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5737 - accuracy: 0.7741 - val_loss: 0.6212 - val_accuracy: 0.7612\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5754 - accuracy: 0.7730 - val_loss: 0.6033 - val_accuracy: 0.7710\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.5765 - accuracy: 0.7730 - val_loss: 0.6007 - val_accuracy: 0.7714\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.5681 - accuracy: 0.7757 - val_loss: 0.5959 - val_accuracy: 0.7730\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.5671 - accuracy: 0.7757 - val_loss: 0.6031 - val_accuracy: 0.7713\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5691 - accuracy: 0.7739 - val_loss: 0.6327 - val_accuracy: 0.7578\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5674 - accuracy: 0.7753 - val_loss: 0.6233 - val_accuracy: 0.7645\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5686 - accuracy: 0.7755 - val_loss: 0.6025 - val_accuracy: 0.7709\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5692 - accuracy: 0.7742 - val_loss: 0.6019 - val_accuracy: 0.7712\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.5721 - accuracy: 0.7743 - val_loss: 0.6017 - val_accuracy: 0.7715\n",
      "Epoch 93/200\n",
      " 31136/140272 [=====>........................] - ETA: 2:25 - loss: 0.5741 - accuracy: 0.7746"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "for i in range(folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    XTrain, XVal, yTrain, yVal = train_test_split(X, Y, test_size=0.2, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    cnn.fit(XTrain, yTrain, nb_epoch=200, validation_data=(XVal, yVal))\n",
    "    scores = cnn.evaluate(XVal, yVal, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (cnn.metrics_names[1], scores[1]*100))\n",
    "    a.append(scores[1] * 100)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
