{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "#traindata=traindata.drop('id',axis=1)\n",
    "#testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "traindata['attack_cat'] = lb_make.fit_transform(traindata['attack_cat'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "testdata['attack_cat'] = lb_make.fit_transform(testdata['attack_cat'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-2]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr = X.values\n",
    "arr = x.values\n",
    "\n",
    "import librosa\n",
    "Arr_Delta = librosa.feature.delta(Arr)\n",
    "arr_delta = librosa.feature.delta(arr)\n",
    "\n",
    "Delta = librosa.feature.delta(Arr_Delta)\n",
    "delta = librosa.feature.delta(arr_delta)\n",
    "\n",
    "Delta1 = pd.DataFrame(Arr_Delta)\n",
    "delta1 = pd.DataFrame(arr_delta)\n",
    "Delta2 = pd.DataFrame(Delta)\n",
    "delta2 = pd.DataFrame(delta)\n",
    "\n",
    "XDelta1 = pd.concat([X, Delta1, Delta2], axis=1)\n",
    "xdelta1 = pd.concat([x, delta1, delta2], axis=1)\n",
    "\n",
    "scaler = Normalizer().fit(XDelta1)\n",
    "XDelta1 = scaler.transform(XDelta1)\n",
    "scaler = Normalizer().fit(xdelta1)\n",
    "xdelta1 = scaler.transform(xdelta1)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "XDelta1 = np.reshape(XDelta1, (XDelta1.shape[0],1,XDelta1.shape[1]))\n",
    "xdelta1 = np.reshape(xdelta1, (xdelta1.shape[0],1,xdelta1.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, input_shape=(None, 123...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 4)                 2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,098\n",
      "Trainable params: 2,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4,input_dim=123)) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/200\n",
      "175341/175341 [==============================] - 46s 264us/step - loss: 1.4899 - accuracy: 0.5206 - val_loss: 1.2993 - val_accuracy: 0.6175\n",
      "Epoch 2/200\n",
      "175341/175341 [==============================] - 48s 276us/step - loss: 1.3984 - accuracy: 0.5276 - val_loss: 1.2922 - val_accuracy: 0.6175\n",
      "Epoch 3/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.3862 - accuracy: 0.5292 - val_loss: 1.2962 - val_accuracy: 0.6181\n",
      "Epoch 4/200\n",
      "175341/175341 [==============================] - 48s 271us/step - loss: 1.3743 - accuracy: 0.5322 - val_loss: 1.2925 - val_accuracy: 0.6187\n",
      "Epoch 5/200\n",
      "175341/175341 [==============================] - 50s 283us/step - loss: 1.3646 - accuracy: 0.5325 - val_loss: 1.2784 - val_accuracy: 0.6189\n",
      "Epoch 6/200\n",
      "175341/175341 [==============================] - 48s 274us/step - loss: 1.3542 - accuracy: 0.5330 - val_loss: 1.2704 - val_accuracy: 0.6192\n",
      "Epoch 7/200\n",
      "175341/175341 [==============================] - 51s 290us/step - loss: 1.3403 - accuracy: 0.5334 - val_loss: 1.2463 - val_accuracy: 0.6194\n",
      "Epoch 8/200\n",
      "175341/175341 [==============================] - 45s 258us/step - loss: 1.3227 - accuracy: 0.5334 - val_loss: 1.2540 - val_accuracy: 0.6193\n",
      "Epoch 9/200\n",
      "175341/175341 [==============================] - 47s 270us/step - loss: 1.3031 - accuracy: 0.5339 - val_loss: 1.2341 - val_accuracy: 0.6202\n",
      "Epoch 10/200\n",
      "175341/175341 [==============================] - 48s 275us/step - loss: 1.2834 - accuracy: 0.5362 - val_loss: 1.2302 - val_accuracy: 0.6202\n",
      "Epoch 11/200\n",
      "175341/175341 [==============================] - 48s 273us/step - loss: 1.2652 - accuracy: 0.5395 - val_loss: 1.2133 - val_accuracy: 0.6204\n",
      "Epoch 12/200\n",
      "175341/175341 [==============================] - 46s 263us/step - loss: 1.2500 - accuracy: 0.5458 - val_loss: 1.1989 - val_accuracy: 0.6204\n",
      "Epoch 13/200\n",
      "175341/175341 [==============================] - 49s 279us/step - loss: 1.2366 - accuracy: 0.5607 - val_loss: 1.1980 - val_accuracy: 0.6509\n",
      "Epoch 14/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.2254 - accuracy: 0.5753 - val_loss: 1.1947 - val_accuracy: 0.6508\n",
      "Epoch 15/200\n",
      "175341/175341 [==============================] - 57s 326us/step - loss: 1.2164 - accuracy: 0.5829 - val_loss: 1.2020 - val_accuracy: 0.6519\n",
      "Epoch 16/200\n",
      "175341/175341 [==============================] - 53s 300us/step - loss: 1.2090 - accuracy: 0.5857 - val_loss: 1.2001 - val_accuracy: 0.6524\n",
      "Epoch 17/200\n",
      "175341/175341 [==============================] - 56s 322us/step - loss: 1.2033 - accuracy: 0.5877 - val_loss: 1.2056 - val_accuracy: 0.6523\n",
      "Epoch 18/200\n",
      "175341/175341 [==============================] - 59s 335us/step - loss: 1.1990 - accuracy: 0.5892 - val_loss: 1.2008 - val_accuracy: 0.6524\n",
      "Epoch 19/200\n",
      "175341/175341 [==============================] - 49s 282us/step - loss: 1.1941 - accuracy: 0.5906 - val_loss: 1.2061 - val_accuracy: 0.6524\n",
      "Epoch 20/200\n",
      "175341/175341 [==============================] - 46s 265us/step - loss: 1.1904 - accuracy: 0.5914 - val_loss: 1.2182 - val_accuracy: 0.6504\n",
      "Epoch 21/200\n",
      "175341/175341 [==============================] - 49s 278us/step - loss: 1.1876 - accuracy: 0.5927 - val_loss: 1.1906 - val_accuracy: 0.6522\n",
      "Epoch 22/200\n",
      "175341/175341 [==============================] - 50s 284us/step - loss: 1.1846 - accuracy: 0.5926 - val_loss: 1.2098 - val_accuracy: 0.6478\n",
      "Epoch 23/200\n",
      "175341/175341 [==============================] - 49s 278us/step - loss: 1.1820 - accuracy: 0.5941 - val_loss: 1.2077 - val_accuracy: 0.6518\n",
      "Epoch 24/200\n",
      "175341/175341 [==============================] - 46s 263us/step - loss: 1.1813 - accuracy: 0.5940 - val_loss: 1.2033 - val_accuracy: 0.6496\n",
      "Epoch 25/200\n",
      "175341/175341 [==============================] - 47s 270us/step - loss: 1.1780 - accuracy: 0.5938 - val_loss: 1.2105 - val_accuracy: 0.6499\n",
      "Epoch 26/200\n",
      "175341/175341 [==============================] - 48s 273us/step - loss: 1.1763 - accuracy: 0.5942 - val_loss: 1.1993 - val_accuracy: 0.6526\n",
      "Epoch 27/200\n",
      "175341/175341 [==============================] - 47s 269us/step - loss: 1.1756 - accuracy: 0.5943 - val_loss: 1.2437 - val_accuracy: 0.6452\n",
      "Epoch 28/200\n",
      "175341/175341 [==============================] - 46s 261us/step - loss: 1.1749 - accuracy: 0.5950 - val_loss: 1.2236 - val_accuracy: 0.6421\n",
      "Epoch 29/200\n",
      "175341/175341 [==============================] - 48s 271us/step - loss: 1.1734 - accuracy: 0.5941 - val_loss: 1.2007 - val_accuracy: 0.6518\n",
      "Epoch 30/200\n",
      "175341/175341 [==============================] - 48s 275us/step - loss: 1.1723 - accuracy: 0.5949 - val_loss: 1.2179 - val_accuracy: 0.6461\n",
      "Epoch 31/200\n",
      "175341/175341 [==============================] - 47s 265us/step - loss: 1.1702 - accuracy: 0.5954 - val_loss: 1.1950 - val_accuracy: 0.6504\n",
      "Epoch 32/200\n",
      "175341/175341 [==============================] - 47s 270us/step - loss: 1.1700 - accuracy: 0.5952 - val_loss: 1.2027 - val_accuracy: 0.6514\n",
      "Epoch 33/200\n",
      "175341/175341 [==============================] - 48s 274us/step - loss: 1.1683 - accuracy: 0.5952 - val_loss: 1.2085 - val_accuracy: 0.6508\n",
      "Epoch 34/200\n",
      "175341/175341 [==============================] - 47s 270us/step - loss: 1.1670 - accuracy: 0.5950 - val_loss: 1.2024 - val_accuracy: 0.6507\n",
      "Epoch 35/200\n",
      "175341/175341 [==============================] - 46s 261us/step - loss: 1.1665 - accuracy: 0.5949 - val_loss: 1.2039 - val_accuracy: 0.6489\n",
      "Epoch 36/200\n",
      "175341/175341 [==============================] - 48s 273us/step - loss: 1.1666 - accuracy: 0.5953 - val_loss: 1.2064 - val_accuracy: 0.6459\n",
      "Epoch 37/200\n",
      "175341/175341 [==============================] - 48s 275us/step - loss: 1.1663 - accuracy: 0.5954 - val_loss: 1.2206 - val_accuracy: 0.6403\n",
      "Epoch 38/200\n",
      "175341/175341 [==============================] - 47s 271us/step - loss: 1.1652 - accuracy: 0.5948 - val_loss: 1.2073 - val_accuracy: 0.6494\n",
      "Epoch 39/200\n",
      "175341/175341 [==============================] - 45s 256us/step - loss: 1.1645 - accuracy: 0.5948 - val_loss: 1.1992 - val_accuracy: 0.6460\n",
      "Epoch 40/200\n",
      "175341/175341 [==============================] - 46s 260us/step - loss: 1.1651 - accuracy: 0.5952 - val_loss: 1.2039 - val_accuracy: 0.6468\n",
      "Epoch 41/200\n",
      "175341/175341 [==============================] - 47s 269us/step - loss: 1.1633 - accuracy: 0.5961 - val_loss: 1.2092 - val_accuracy: 0.6414\n",
      "Epoch 42/200\n",
      "175341/175341 [==============================] - 48s 275us/step - loss: 1.1622 - accuracy: 0.5954 - val_loss: 1.1988 - val_accuracy: 0.6482\n",
      "Epoch 43/200\n",
      "175341/175341 [==============================] - 45s 255us/step - loss: 1.1622 - accuracy: 0.5953 - val_loss: 1.2074 - val_accuracy: 0.6437\n",
      "Epoch 44/200\n",
      "175341/175341 [==============================] - 48s 273us/step - loss: 1.1627 - accuracy: 0.5954 - val_loss: 1.2104 - val_accuracy: 0.6397\n",
      "Epoch 45/200\n",
      "175341/175341 [==============================] - 49s 280us/step - loss: 1.1610 - accuracy: 0.5954 - val_loss: 1.1962 - val_accuracy: 0.6505\n",
      "Epoch 46/200\n",
      "175341/175341 [==============================] - 49s 280us/step - loss: 1.1615 - accuracy: 0.5956 - val_loss: 1.2016 - val_accuracy: 0.6479\n",
      "Epoch 47/200\n",
      "175341/175341 [==============================] - 46s 260us/step - loss: 1.1605 - accuracy: 0.5954 - val_loss: 1.1981 - val_accuracy: 0.6500\n",
      "Epoch 48/200\n",
      "175341/175341 [==============================] - 49s 278us/step - loss: 1.1606 - accuracy: 0.5957 - val_loss: 1.2115 - val_accuracy: 0.6439\n",
      "Epoch 49/200\n",
      "175341/175341 [==============================] - 48s 273us/step - loss: 1.1598 - accuracy: 0.5956 - val_loss: 1.2124 - val_accuracy: 0.6406\n",
      "Epoch 50/200\n",
      "175341/175341 [==============================] - 48s 273us/step - loss: 1.1597 - accuracy: 0.5957 - val_loss: 1.2018 - val_accuracy: 0.6424\n",
      "Epoch 51/200\n",
      "175341/175341 [==============================] - 46s 265us/step - loss: 1.1588 - accuracy: 0.5964 - val_loss: 1.2008 - val_accuracy: 0.6480\n",
      "Epoch 52/200\n",
      "175341/175341 [==============================] - 49s 279us/step - loss: 1.1577 - accuracy: 0.5956 - val_loss: 1.2016 - val_accuracy: 0.6457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "175341/175341 [==============================] - 51s 290us/step - loss: 1.1572 - accuracy: 0.5965 - val_loss: 1.2043 - val_accuracy: 0.6441\n",
      "Epoch 54/200\n",
      "175341/175341 [==============================] - 54s 306us/step - loss: 1.1578 - accuracy: 0.5962 - val_loss: 1.2051 - val_accuracy: 0.6440\n",
      "Epoch 55/200\n",
      "175341/175341 [==============================] - 51s 291us/step - loss: 1.1575 - accuracy: 0.5959 - val_loss: 1.2154 - val_accuracy: 0.6306\n",
      "Epoch 56/200\n",
      "175341/175341 [==============================] - 55s 313us/step - loss: 1.1563 - accuracy: 0.5962 - val_loss: 1.2022 - val_accuracy: 0.6440\n",
      "Epoch 57/200\n",
      "175341/175341 [==============================] - 49s 280us/step - loss: 1.1558 - accuracy: 0.5958 - val_loss: 1.2031 - val_accuracy: 0.6438\n",
      "Epoch 58/200\n",
      "175341/175341 [==============================] - 50s 285us/step - loss: 1.1555 - accuracy: 0.5952 - val_loss: 1.2139 - val_accuracy: 0.6366\n",
      "Epoch 59/200\n",
      "175341/175341 [==============================] - 49s 277us/step - loss: 1.1533 - accuracy: 0.5958 - val_loss: 1.1804 - val_accuracy: 0.6429\n",
      "Epoch 60/200\n",
      "175341/175341 [==============================] - 52s 297us/step - loss: 1.1545 - accuracy: 0.5962 - val_loss: 1.1917 - val_accuracy: 0.6457\n",
      "Epoch 61/200\n",
      "175341/175341 [==============================] - 50s 286us/step - loss: 1.1523 - accuracy: 0.5955 - val_loss: 1.2043 - val_accuracy: 0.6226\n",
      "Epoch 62/200\n",
      "175341/175341 [==============================] - 52s 294us/step - loss: 1.1507 - accuracy: 0.5967 - val_loss: 1.2028 - val_accuracy: 0.6426\n",
      "Epoch 63/200\n",
      "175341/175341 [==============================] - 49s 280us/step - loss: 1.1499 - accuracy: 0.5966 - val_loss: 1.2004 - val_accuracy: 0.6434\n",
      "Epoch 64/200\n",
      "175341/175341 [==============================] - 52s 294us/step - loss: 1.1506 - accuracy: 0.5965 - val_loss: 1.2020 - val_accuracy: 0.6465\n",
      "Epoch 65/200\n",
      "175341/175341 [==============================] - 51s 291us/step - loss: 1.1496 - accuracy: 0.5965 - val_loss: 1.1932 - val_accuracy: 0.6487\n",
      "Epoch 66/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1483 - accuracy: 0.5959 - val_loss: 1.1719 - val_accuracy: 0.6465\n",
      "Epoch 67/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1495 - accuracy: 0.5967 - val_loss: 1.1975 - val_accuracy: 0.6434\n",
      "Epoch 68/200\n",
      "175341/175341 [==============================] - 53s 303us/step - loss: 1.1494 - accuracy: 0.5975 - val_loss: 1.2054 - val_accuracy: 0.6361\n",
      "Epoch 69/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1477 - accuracy: 0.5961 - val_loss: 1.1789 - val_accuracy: 0.6404\n",
      "Epoch 70/200\n",
      "175341/175341 [==============================] - 51s 291us/step - loss: 1.1474 - accuracy: 0.5962 - val_loss: 1.1983 - val_accuracy: 0.6257\n",
      "Epoch 71/200\n",
      "175341/175341 [==============================] - 52s 298us/step - loss: 1.1477 - accuracy: 0.5958 - val_loss: 1.1894 - val_accuracy: 0.6469\n",
      "Epoch 72/200\n",
      "175341/175341 [==============================] - 55s 312us/step - loss: 1.1479 - accuracy: 0.5961 - val_loss: 1.2125 - val_accuracy: 0.5894\n",
      "Epoch 73/200\n",
      "175341/175341 [==============================] - 55s 313us/step - loss: 1.1478 - accuracy: 0.5970 - val_loss: 1.2070 - val_accuracy: 0.6224\n",
      "Epoch 74/200\n",
      "175341/175341 [==============================] - 54s 308us/step - loss: 1.1468 - accuracy: 0.5971 - val_loss: 1.1934 - val_accuracy: 0.6327\n",
      "Epoch 75/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1480 - accuracy: 0.5963 - val_loss: 1.2236 - val_accuracy: 0.6086\n",
      "Epoch 76/200\n",
      "175341/175341 [==============================] - 56s 318us/step - loss: 1.1462 - accuracy: 0.5969 - val_loss: 1.1842 - val_accuracy: 0.6509\n",
      "Epoch 77/200\n",
      "175341/175341 [==============================] - 55s 314us/step - loss: 1.1470 - accuracy: 0.5961 - val_loss: 1.1836 - val_accuracy: 0.6450\n",
      "Epoch 78/200\n",
      "175341/175341 [==============================] - 53s 300us/step - loss: 1.1449 - accuracy: 0.5975 - val_loss: 1.1992 - val_accuracy: 0.6376\n",
      "Epoch 79/200\n",
      "175341/175341 [==============================] - 52s 294us/step - loss: 1.1459 - accuracy: 0.5969 - val_loss: 1.2004 - val_accuracy: 0.6327\n",
      "Epoch 80/200\n",
      "175341/175341 [==============================] - 55s 316us/step - loss: 1.1462 - accuracy: 0.5968 - val_loss: 1.2160 - val_accuracy: 0.6130\n",
      "Epoch 81/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1465 - accuracy: 0.5967 - val_loss: 1.2092 - val_accuracy: 0.6330\n",
      "Epoch 82/200\n",
      "175341/175341 [==============================] - 51s 292us/step - loss: 1.1455 - accuracy: 0.5963 - val_loss: 1.1931 - val_accuracy: 0.6409\n",
      "Epoch 83/200\n",
      "175341/175341 [==============================] - 48s 273us/step - loss: 1.1468 - accuracy: 0.5957 - val_loss: 1.2175 - val_accuracy: 0.6063\n",
      "Epoch 84/200\n",
      "175341/175341 [==============================] - 51s 289us/step - loss: 1.1452 - accuracy: 0.5970 - val_loss: 1.1946 - val_accuracy: 0.6372\n",
      "Epoch 85/200\n",
      "175341/175341 [==============================] - 50s 282us/step - loss: 1.1431 - accuracy: 0.5966 - val_loss: 1.1990 - val_accuracy: 0.6341\n",
      "Epoch 86/200\n",
      "175341/175341 [==============================] - 49s 281us/step - loss: 1.1450 - accuracy: 0.5971 - val_loss: 1.1792 - val_accuracy: 0.6499\n",
      "Epoch 87/200\n",
      "175341/175341 [==============================] - 49s 279us/step - loss: 1.1448 - accuracy: 0.5975 - val_loss: 1.2081 - val_accuracy: 0.6116\n",
      "Epoch 88/200\n",
      "175341/175341 [==============================] - 54s 305us/step - loss: 1.1445 - accuracy: 0.5966 - val_loss: 1.2208 - val_accuracy: 0.6061\n",
      "Epoch 89/200\n",
      "175341/175341 [==============================] - 55s 311us/step - loss: 1.1449 - accuracy: 0.5963 - val_loss: 1.1744 - val_accuracy: 0.6527\n",
      "Epoch 90/200\n",
      "175341/175341 [==============================] - 54s 306us/step - loss: 1.1438 - accuracy: 0.5964 - val_loss: 1.2129 - val_accuracy: 0.6324\n",
      "Epoch 91/200\n",
      "175341/175341 [==============================] - 50s 286us/step - loss: 1.1439 - accuracy: 0.5968 - val_loss: 1.1831 - val_accuracy: 0.6374\n",
      "Epoch 92/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1443 - accuracy: 0.5968 - val_loss: 1.1997 - val_accuracy: 0.6243\n",
      "Epoch 93/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1433 - accuracy: 0.5968 - val_loss: 1.1874 - val_accuracy: 0.6350\n",
      "Epoch 94/200\n",
      "175341/175341 [==============================] - 55s 315us/step - loss: 1.1444 - accuracy: 0.5962 - val_loss: 1.1869 - val_accuracy: 0.6462\n",
      "Epoch 95/200\n",
      "175341/175341 [==============================] - 51s 292us/step - loss: 1.1434 - accuracy: 0.5960 - val_loss: 1.1762 - val_accuracy: 0.6463\n",
      "Epoch 96/200\n",
      "175341/175341 [==============================] - 55s 311us/step - loss: 1.1438 - accuracy: 0.5966 - val_loss: 1.1760 - val_accuracy: 0.6439\n",
      "Epoch 97/200\n",
      "175341/175341 [==============================] - 54s 307us/step - loss: 1.1432 - accuracy: 0.5974 - val_loss: 1.1869 - val_accuracy: 0.6328\n",
      "Epoch 98/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1428 - accuracy: 0.5977 - val_loss: 1.1976 - val_accuracy: 0.6251\n",
      "Epoch 99/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1418 - accuracy: 0.5973 - val_loss: 1.1796 - val_accuracy: 0.6483\n",
      "Epoch 100/200\n",
      "175341/175341 [==============================] - 54s 311us/step - loss: 1.1420 - accuracy: 0.5973 - val_loss: 1.2060 - val_accuracy: 0.6247\n",
      "Epoch 101/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1417 - accuracy: 0.5974 - val_loss: 1.2000 - val_accuracy: 0.6237\n",
      "Epoch 102/200\n",
      "175341/175341 [==============================] - 55s 316us/step - loss: 1.1415 - accuracy: 0.5982 - val_loss: 1.2102 - val_accuracy: 0.6225\n",
      "Epoch 103/200\n",
      "175341/175341 [==============================] - 54s 306us/step - loss: 1.1418 - accuracy: 0.5970 - val_loss: 1.1925 - val_accuracy: 0.6397\n",
      "Epoch 104/200\n",
      "175341/175341 [==============================] - 56s 318us/step - loss: 1.1408 - accuracy: 0.5974 - val_loss: 1.1762 - val_accuracy: 0.6487\n",
      "Epoch 105/200\n",
      "175341/175341 [==============================] - 55s 312us/step - loss: 1.1417 - accuracy: 0.5967 - val_loss: 1.2133 - val_accuracy: 0.6013\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 54s 310us/step - loss: 1.1417 - accuracy: 0.5970 - val_loss: 1.2304 - val_accuracy: 0.5304\n",
      "Epoch 107/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1417 - accuracy: 0.5971 - val_loss: 1.2258 - val_accuracy: 0.5305\n",
      "Epoch 108/200\n",
      "175341/175341 [==============================] - 56s 321us/step - loss: 1.1425 - accuracy: 0.5970 - val_loss: 1.1901 - val_accuracy: 0.6378\n",
      "Epoch 109/200\n",
      "175341/175341 [==============================] - 55s 314us/step - loss: 1.1415 - accuracy: 0.5968 - val_loss: 1.1871 - val_accuracy: 0.6354\n",
      "Epoch 110/200\n",
      "175341/175341 [==============================] - 54s 310us/step - loss: 1.1412 - accuracy: 0.5969 - val_loss: 1.1874 - val_accuracy: 0.6470\n",
      "Epoch 111/200\n",
      "175341/175341 [==============================] - 51s 288us/step - loss: 1.1398 - accuracy: 0.5973 - val_loss: 1.2124 - val_accuracy: 0.6261\n",
      "Epoch 112/200\n",
      "175341/175341 [==============================] - 54s 306us/step - loss: 1.1407 - accuracy: 0.5973 - val_loss: 1.1848 - val_accuracy: 0.6310\n",
      "Epoch 113/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1410 - accuracy: 0.5963 - val_loss: 1.2064 - val_accuracy: 0.5857\n",
      "Epoch 114/200\n",
      "175341/175341 [==============================] - 56s 322us/step - loss: 1.1411 - accuracy: 0.5963 - val_loss: 1.1810 - val_accuracy: 0.6463\n",
      "Epoch 115/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1404 - accuracy: 0.5968 - val_loss: 1.2016 - val_accuracy: 0.6350\n",
      "Epoch 116/200\n",
      "175341/175341 [==============================] - 51s 292us/step - loss: 1.1410 - accuracy: 0.5974 - val_loss: 1.2225 - val_accuracy: 0.6122\n",
      "Epoch 117/200\n",
      "175341/175341 [==============================] - 51s 291us/step - loss: 1.1413 - accuracy: 0.5969 - val_loss: 1.1817 - val_accuracy: 0.6331\n",
      "Epoch 118/200\n",
      "175341/175341 [==============================] - 53s 303us/step - loss: 1.1421 - accuracy: 0.5972 - val_loss: 1.1825 - val_accuracy: 0.6380\n",
      "Epoch 119/200\n",
      "175341/175341 [==============================] - 53s 303us/step - loss: 1.1414 - accuracy: 0.5965 - val_loss: 1.1848 - val_accuracy: 0.6402\n",
      "Epoch 120/200\n",
      "175341/175341 [==============================] - 57s 325us/step - loss: 1.1412 - accuracy: 0.5968 - val_loss: 1.1968 - val_accuracy: 0.6396\n",
      "Epoch 121/200\n",
      "175341/175341 [==============================] - 56s 317us/step - loss: 1.1392 - accuracy: 0.5975 - val_loss: 1.1934 - val_accuracy: 0.6293\n",
      "Epoch 122/200\n",
      "175341/175341 [==============================] - 54s 305us/step - loss: 1.1397 - accuracy: 0.5962 - val_loss: 1.1846 - val_accuracy: 0.6476\n",
      "Epoch 123/200\n",
      "175341/175341 [==============================] - 52s 297us/step - loss: 1.1410 - accuracy: 0.5969 - val_loss: 1.1807 - val_accuracy: 0.6420\n",
      "Epoch 124/200\n",
      "175341/175341 [==============================] - 54s 305us/step - loss: 1.1400 - accuracy: 0.5970 - val_loss: 1.1886 - val_accuracy: 0.6371\n",
      "Epoch 125/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1395 - accuracy: 0.5972 - val_loss: 1.2044 - val_accuracy: 0.6272\n",
      "Epoch 126/200\n",
      "175341/175341 [==============================] - 52s 296us/step - loss: 1.1392 - accuracy: 0.5967 - val_loss: 1.1831 - val_accuracy: 0.6422\n",
      "Epoch 127/200\n",
      "175341/175341 [==============================] - 51s 293us/step - loss: 1.1392 - accuracy: 0.5972 - val_loss: 1.1906 - val_accuracy: 0.6402\n",
      "Epoch 128/200\n",
      "175341/175341 [==============================] - 53s 300us/step - loss: 1.1391 - accuracy: 0.5966 - val_loss: 1.2057 - val_accuracy: 0.6174\n",
      "Epoch 129/200\n",
      "175341/175341 [==============================] - 52s 296us/step - loss: 1.1396 - accuracy: 0.5967 - val_loss: 1.1960 - val_accuracy: 0.6267\n",
      "Epoch 130/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1390 - accuracy: 0.5968 - val_loss: 1.1956 - val_accuracy: 0.6204\n",
      "Epoch 131/200\n",
      "175341/175341 [==============================] - 50s 288us/step - loss: 1.1385 - accuracy: 0.5971 - val_loss: 1.1970 - val_accuracy: 0.6260\n",
      "Epoch 132/200\n",
      "175341/175341 [==============================] - 54s 306us/step - loss: 1.1388 - accuracy: 0.5976 - val_loss: 1.2161 - val_accuracy: 0.6250\n",
      "Epoch 133/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1392 - accuracy: 0.5965 - val_loss: 1.1945 - val_accuracy: 0.6298\n",
      "Epoch 134/200\n",
      "175341/175341 [==============================] - 52s 298us/step - loss: 1.1380 - accuracy: 0.5977 - val_loss: 1.1736 - val_accuracy: 0.6338\n",
      "Epoch 135/200\n",
      "175341/175341 [==============================] - 51s 288us/step - loss: 1.1393 - accuracy: 0.5970 - val_loss: 1.1919 - val_accuracy: 0.6313\n",
      "Epoch 136/200\n",
      "175341/175341 [==============================] - 53s 303us/step - loss: 1.1386 - accuracy: 0.5964 - val_loss: 1.2069 - val_accuracy: 0.6185\n",
      "Epoch 137/200\n",
      "175341/175341 [==============================] - 54s 308us/step - loss: 1.1379 - accuracy: 0.5970 - val_loss: 1.1953 - val_accuracy: 0.6277\n",
      "Epoch 138/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1394 - accuracy: 0.5971 - val_loss: 1.1795 - val_accuracy: 0.6420\n",
      "Epoch 139/200\n",
      "175341/175341 [==============================] - 50s 285us/step - loss: 1.1380 - accuracy: 0.5971 - val_loss: 1.1998 - val_accuracy: 0.6186\n",
      "Epoch 140/200\n",
      "175341/175341 [==============================] - 51s 289us/step - loss: 1.1379 - accuracy: 0.5965 - val_loss: 1.1906 - val_accuracy: 0.6369\n",
      "Epoch 141/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1378 - accuracy: 0.5972 - val_loss: 1.1865 - val_accuracy: 0.6341\n",
      "Epoch 142/200\n",
      "175341/175341 [==============================] - 51s 293us/step - loss: 1.1375 - accuracy: 0.5969 - val_loss: 1.2026 - val_accuracy: 0.6141\n",
      "Epoch 143/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1383 - accuracy: 0.5979 - val_loss: 1.1969 - val_accuracy: 0.6385\n",
      "Epoch 144/200\n",
      "175341/175341 [==============================] - 55s 312us/step - loss: 1.1384 - accuracy: 0.5971 - val_loss: 1.2148 - val_accuracy: 0.6240\n",
      "Epoch 145/200\n",
      "175341/175341 [==============================] - 55s 316us/step - loss: 1.1372 - accuracy: 0.5971 - val_loss: 1.2092 - val_accuracy: 0.5923\n",
      "Epoch 146/200\n",
      "175341/175341 [==============================] - 54s 306us/step - loss: 1.1376 - accuracy: 0.5972 - val_loss: 1.1839 - val_accuracy: 0.6334\n",
      "Epoch 147/200\n",
      "175341/175341 [==============================] - 52s 297us/step - loss: 1.1375 - accuracy: 0.5967 - val_loss: 1.1827 - val_accuracy: 0.6410\n",
      "Epoch 148/200\n",
      "175341/175341 [==============================] - 54s 307us/step - loss: 1.1368 - accuracy: 0.5978 - val_loss: 1.1681 - val_accuracy: 0.6514\n",
      "Epoch 149/200\n",
      "175341/175341 [==============================] - 54s 307us/step - loss: 1.1370 - accuracy: 0.5972 - val_loss: 1.1879 - val_accuracy: 0.6278\n",
      "Epoch 150/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1365 - accuracy: 0.5976 - val_loss: 1.1937 - val_accuracy: 0.6143\n",
      "Epoch 151/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1381 - accuracy: 0.5973 - val_loss: 1.1987 - val_accuracy: 0.6275\n",
      "Epoch 152/200\n",
      "175341/175341 [==============================] - 55s 315us/step - loss: 1.1365 - accuracy: 0.5980 - val_loss: 1.2089 - val_accuracy: 0.6254\n",
      "Epoch 153/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1371 - accuracy: 0.5974 - val_loss: 1.1927 - val_accuracy: 0.6355\n",
      "Epoch 154/200\n",
      "175341/175341 [==============================] - 50s 284us/step - loss: 1.1379 - accuracy: 0.5978 - val_loss: 1.1874 - val_accuracy: 0.6439\n",
      "Epoch 155/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1374 - accuracy: 0.5980 - val_loss: 1.1907 - val_accuracy: 0.6441\n",
      "Epoch 156/200\n",
      "175341/175341 [==============================] - 54s 308us/step - loss: 1.1367 - accuracy: 0.5973 - val_loss: 1.1806 - val_accuracy: 0.6406\n",
      "Epoch 157/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1372 - accuracy: 0.5974 - val_loss: 1.1977 - val_accuracy: 0.6175\n",
      "Epoch 158/200\n",
      "175341/175341 [==============================] - 52s 296us/step - loss: 1.1370 - accuracy: 0.5971 - val_loss: 1.1794 - val_accuracy: 0.6334\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1360 - accuracy: 0.5978 - val_loss: 1.2094 - val_accuracy: 0.6197\n",
      "Epoch 160/200\n",
      "175341/175341 [==============================] - 51s 293us/step - loss: 1.1362 - accuracy: 0.5977 - val_loss: 1.1823 - val_accuracy: 0.6385\n",
      "Epoch 161/200\n",
      "175341/175341 [==============================] - 50s 286us/step - loss: 1.1359 - accuracy: 0.5975 - val_loss: 1.1791 - val_accuracy: 0.6399\n",
      "Epoch 162/200\n",
      "175341/175341 [==============================] - 50s 285us/step - loss: 1.1363 - accuracy: 0.5974 - val_loss: 1.1887 - val_accuracy: 0.6345\n",
      "Epoch 163/200\n",
      "175341/175341 [==============================] - 53s 303us/step - loss: 1.1372 - accuracy: 0.5976 - val_loss: 1.1777 - val_accuracy: 0.6438\n",
      "Epoch 164/200\n",
      "175341/175341 [==============================] - 52s 295us/step - loss: 1.1355 - accuracy: 0.5971 - val_loss: 1.2029 - val_accuracy: 0.6292\n",
      "Epoch 165/200\n",
      "175341/175341 [==============================] - 54s 306us/step - loss: 1.1359 - accuracy: 0.5971 - val_loss: 1.2164 - val_accuracy: 0.6070\n",
      "Epoch 166/200\n",
      "175341/175341 [==============================] - 51s 289us/step - loss: 1.1363 - accuracy: 0.5975 - val_loss: 1.1907 - val_accuracy: 0.6121\n",
      "Epoch 167/200\n",
      "175341/175341 [==============================] - 49s 281us/step - loss: 1.1354 - accuracy: 0.5972 - val_loss: 1.1906 - val_accuracy: 0.6344\n",
      "Epoch 168/200\n",
      "175341/175341 [==============================] - 54s 307us/step - loss: 1.1357 - accuracy: 0.5973 - val_loss: 1.1820 - val_accuracy: 0.6351\n",
      "Epoch 169/200\n",
      "175341/175341 [==============================] - 53s 302us/step - loss: 1.1357 - accuracy: 0.5976 - val_loss: 1.1887 - val_accuracy: 0.6389\n",
      "Epoch 170/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1365 - accuracy: 0.5972 - val_loss: 1.1986 - val_accuracy: 0.6182\n",
      "Epoch 171/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1354 - accuracy: 0.5978 - val_loss: 1.1989 - val_accuracy: 0.6234\n",
      "Epoch 172/200\n",
      "175341/175341 [==============================] - 53s 300us/step - loss: 1.1351 - accuracy: 0.5971 - val_loss: 1.1830 - val_accuracy: 0.6299\n",
      "Epoch 173/200\n",
      "175341/175341 [==============================] - 57s 322us/step - loss: 1.1360 - accuracy: 0.5971 - val_loss: 1.1957 - val_accuracy: 0.6190\n",
      "Epoch 174/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1367 - accuracy: 0.5970 - val_loss: 1.1763 - val_accuracy: 0.6377\n",
      "Epoch 175/200\n",
      "175341/175341 [==============================] - 52s 294us/step - loss: 1.1357 - accuracy: 0.5981 - val_loss: 1.2356 - val_accuracy: 0.6049\n",
      "Epoch 176/200\n",
      "175341/175341 [==============================] - 53s 305us/step - loss: 1.1350 - accuracy: 0.5979 - val_loss: 1.2469 - val_accuracy: 0.5363\n",
      "Epoch 177/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1356 - accuracy: 0.5976 - val_loss: 1.1990 - val_accuracy: 0.6346\n",
      "Epoch 178/200\n",
      "175341/175341 [==============================] - 52s 298us/step - loss: 1.1350 - accuracy: 0.5981 - val_loss: 1.2007 - val_accuracy: 0.6119\n",
      "Epoch 179/200\n",
      "175341/175341 [==============================] - 51s 292us/step - loss: 1.1361 - accuracy: 0.5973 - val_loss: 1.1997 - val_accuracy: 0.6290\n",
      "Epoch 180/200\n",
      "175341/175341 [==============================] - 52s 294us/step - loss: 1.1362 - accuracy: 0.5979 - val_loss: 1.1873 - val_accuracy: 0.6307\n",
      "Epoch 181/200\n",
      "175341/175341 [==============================] - 51s 289us/step - loss: 1.1356 - accuracy: 0.5969 - val_loss: 1.1987 - val_accuracy: 0.6255\n",
      "Epoch 182/200\n",
      "175341/175341 [==============================] - 49s 278us/step - loss: 1.1345 - accuracy: 0.5976 - val_loss: 1.1949 - val_accuracy: 0.6279\n",
      "Epoch 183/200\n",
      "175341/175341 [==============================] - 53s 300us/step - loss: 1.1342 - accuracy: 0.5976 - val_loss: 1.1997 - val_accuracy: 0.6220\n",
      "Epoch 184/200\n",
      "175341/175341 [==============================] - 53s 301us/step - loss: 1.1356 - accuracy: 0.5974 - val_loss: 1.2154 - val_accuracy: 0.6096\n",
      "Epoch 185/200\n",
      "175341/175341 [==============================] - 53s 302us/step - loss: 1.1355 - accuracy: 0.5975 - val_loss: 1.2084 - val_accuracy: 0.6153\n",
      "Epoch 186/200\n",
      "175341/175341 [==============================] - 52s 296us/step - loss: 1.1341 - accuracy: 0.5972 - val_loss: 1.1920 - val_accuracy: 0.6379\n",
      "Epoch 187/200\n",
      "175341/175341 [==============================] - 52s 297us/step - loss: 1.1346 - accuracy: 0.5981 - val_loss: 1.1854 - val_accuracy: 0.6319\n",
      "Epoch 188/200\n",
      "175341/175341 [==============================] - 53s 303us/step - loss: 1.1336 - accuracy: 0.5972 - val_loss: 1.1773 - val_accuracy: 0.6375\n",
      "Epoch 189/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1345 - accuracy: 0.5976 - val_loss: 1.2075 - val_accuracy: 0.6062\n",
      "Epoch 190/200\n",
      "175341/175341 [==============================] - 50s 285us/step - loss: 1.1341 - accuracy: 0.5975 - val_loss: 1.2236 - val_accuracy: 0.5993\n",
      "Epoch 191/200\n",
      "175341/175341 [==============================] - 54s 309us/step - loss: 1.1350 - accuracy: 0.5976 - val_loss: 1.1917 - val_accuracy: 0.6206\n",
      "Epoch 192/200\n",
      "175341/175341 [==============================] - 53s 302us/step - loss: 1.1358 - accuracy: 0.5971 - val_loss: 1.2308 - val_accuracy: 0.5806\n",
      "Epoch 193/200\n",
      "175341/175341 [==============================] - 53s 304us/step - loss: 1.1347 - accuracy: 0.5973 - val_loss: 1.1874 - val_accuracy: 0.6252\n",
      "Epoch 194/200\n",
      "175341/175341 [==============================] - 54s 307us/step - loss: 1.1353 - accuracy: 0.5974 - val_loss: 1.1837 - val_accuracy: 0.6331\n",
      "Epoch 195/200\n",
      "175341/175341 [==============================] - 54s 310us/step - loss: 1.1336 - accuracy: 0.5973 - val_loss: 1.2059 - val_accuracy: 0.6107\n",
      "Epoch 196/200\n",
      "175341/175341 [==============================] - 52s 299us/step - loss: 1.1350 - accuracy: 0.5984 - val_loss: 1.2169 - val_accuracy: 0.6155\n",
      "Epoch 197/200\n",
      "175341/175341 [==============================] - 53s 305us/step - loss: 1.1343 - accuracy: 0.5980 - val_loss: 1.1779 - val_accuracy: 0.6415\n",
      "Epoch 198/200\n",
      "175341/175341 [==============================] - 50s 288us/step - loss: 1.1348 - accuracy: 0.5974 - val_loss: 1.1872 - val_accuracy: 0.6297\n",
      "Epoch 199/200\n",
      "175341/175341 [==============================] - 54s 307us/step - loss: 1.1351 - accuracy: 0.5974 - val_loss: 1.2158 - val_accuracy: 0.6171\n",
      "Epoch 200/200\n",
      "175341/175341 [==============================] - 53s 303us/step - loss: 1.1339 - accuracy: 0.5977 - val_loss: 1.1876 - val_accuracy: 0.6245\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(XDelta1, Y, epochs=200, validation_data=(xdelta1, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict([xdelta1])\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#pred = np.zeros((82332,1), dtype=int)\n",
    "for i in range(0, predictions.shape[0]):\n",
    "    pred = np.where(predictions[i] == np.amax(predictions[i]))\n",
    "    for j in range(0,10):\n",
    "        predictions[i,j] = 0\n",
    "    predictions[i,pred]=1\n",
    "    \n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6244595054170917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       677\n",
      "           1       0.00      0.00      0.00       583\n",
      "           2       0.26      0.00      0.01      4089\n",
      "           3       0.23      0.39      0.29     11132\n",
      "           4       0.43      0.00      0.01      6062\n",
      "           5       0.84      0.96      0.89     18871\n",
      "           6       0.70      0.78      0.74     37000\n",
      "           7       0.00      0.00      0.00      3496\n",
      "           8       0.00      0.00      0.00       378\n",
      "           9       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     82332\n",
      "   macro avg       0.25      0.21      0.19     82332\n",
      "weighted avg       0.58      0.62      0.58     82332\n",
      " samples avg       0.62      0.62      0.62     82332\n",
      "\n",
      "[[    0     0     0   629     0     2    46     0     0     0]\n",
      " [    0     0     2   533     2     5    41     0     0     0]\n",
      " [    0     0    11  3044     7   138   889     0     0     0]\n",
      " [    0     0    24  4391     5   126  6586     0     0     0]\n",
      " [    0     0     0  2702    26   387  2947     0     0     0]\n",
      " [    0     0     4   236     2 18168   461     0     0     0]\n",
      " [    0     0     1  5339    18  2825 28817     0     0     0]\n",
      " [    0     0     1  2017     0    45  1433     0     0     0]\n",
      " [    0     0     0   193     0    35   150     0     0     0]\n",
      " [    0     0     0    10     0     2    32     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy: \",accuracy_score(y,predictions))\n",
    "from sklearn.metrics import multilabel_confusion_matrix,classification_report,confusion_matrix\n",
    "print(\"Classification Report: \\n\",classification_report(y,predictions))\n",
    "conmat = np.array(confusion_matrix(y.argmax(axis=1), predictions.argmax(axis=1)))\n",
    "confusion = pd.DataFrame(conmat, index=['0','1','2','3','4','5','6','7','8','9'],\n",
    "                        columns=[['0','1','2','3','4','5','6','7','8','9']])\n",
    "print (conmat)\n",
    "conmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
