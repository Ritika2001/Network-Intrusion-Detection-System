{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "#traindata=traindata.drop('id',axis=1)\n",
    "#testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "traindata['attack_cat'] = lb_make.fit_transform(traindata['attack_cat'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "testdata['attack_cat'] = lb_make.fit_transform(testdata['attack_cat'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-2]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr = X.values\n",
    "arr = x.values\n",
    "\n",
    "import librosa\n",
    "Arr_Delta = librosa.feature.delta(Arr)\n",
    "arr_delta = librosa.feature.delta(arr)\n",
    "\n",
    "Delta = librosa.feature.delta(Arr_Delta)\n",
    "delta = librosa.feature.delta(arr_delta)\n",
    "\n",
    "Delta1 = pd.DataFrame(Arr_Delta)\n",
    "delta1 = pd.DataFrame(arr_delta)\n",
    "Delta2 = pd.DataFrame(Delta)\n",
    "delta2 = pd.DataFrame(delta)\n",
    "\n",
    "XDelta1 = pd.concat([X, Delta1, Delta2], axis=1)\n",
    "xdelta1 = pd.concat([x, delta1, delta2], axis=1)\n",
    "\n",
    "scaler = Normalizer().fit(XDelta1)\n",
    "XDelta1 = scaler.transform(XDelta1)\n",
    "scaler = Normalizer().fit(xdelta1)\n",
    "xdelta1 = scaler.transform(xdelta1)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "XDelta1 = np.reshape(XDelta1, (XDelta1.shape[0],XDelta1.shape[1],1))\n",
    "xdelta1 = np.reshape(xdelta1, (xdelta1.shape[0],xdelta1.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(123, 1), padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "lstm_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(123, 1)))\n",
    "cnn.add(MaxPooling1D(pool_size=(2)))\n",
    "cnn.add(Bidirectional(LSTM(lstm_output_size)))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/200\n",
      "175341/175341 [==============================] - 1339s 8ms/step - loss: 1.3756 - accuracy: 0.5306 - val_loss: 1.3032 - val_accuracy: 0.5930\n",
      "Epoch 2/200\n",
      "175341/175341 [==============================] - 1276s 7ms/step - loss: 1.3295 - accuracy: 0.5469 - val_loss: 1.3024 - val_accuracy: 0.5771\n",
      "Epoch 3/200\n",
      "175341/175341 [==============================] - 1497s 9ms/step - loss: 1.3190 - accuracy: 0.5495 - val_loss: 1.2524 - val_accuracy: 0.5856\n",
      "Epoch 4/200\n",
      "175341/175341 [==============================] - 1529s 9ms/step - loss: 1.3151 - accuracy: 0.5498 - val_loss: 1.2660 - val_accuracy: 0.5832\n",
      "Epoch 5/200\n",
      "175341/175341 [==============================] - 1474s 8ms/step - loss: 1.3107 - accuracy: 0.5511 - val_loss: 1.2921 - val_accuracy: 0.5802\n",
      "Epoch 6/200\n",
      "175341/175341 [==============================] - 1501s 9ms/step - loss: 1.3080 - accuracy: 0.5518 - val_loss: 1.2788 - val_accuracy: 0.5842\n",
      "Epoch 7/200\n",
      "175341/175341 [==============================] - 1501s 9ms/step - loss: 1.2939 - accuracy: 0.5535 - val_loss: 1.1758 - val_accuracy: 0.5797\n",
      "Epoch 8/200\n",
      "175341/175341 [==============================] - 1140s 6ms/step - loss: 1.0156 - accuracy: 0.6268 - val_loss: 0.9455 - val_accuracy: 0.6531\n",
      "Epoch 9/200\n",
      "175341/175341 [==============================] - 1104s 6ms/step - loss: 0.9540 - accuracy: 0.6416 - val_loss: 0.8949 - val_accuracy: 0.6515\n",
      "Epoch 10/200\n",
      "175341/175341 [==============================] - 1063s 6ms/step - loss: 0.9222 - accuracy: 0.6471 - val_loss: 0.9600 - val_accuracy: 0.6420\n",
      "Epoch 11/200\n",
      "175341/175341 [==============================] - 1002s 6ms/step - loss: 0.9131 - accuracy: 0.6505 - val_loss: 0.8676 - val_accuracy: 0.6602\n",
      "Epoch 12/200\n",
      "175341/175341 [==============================] - 1000s 6ms/step - loss: 0.9386 - accuracy: 0.6422 - val_loss: 0.8825 - val_accuracy: 0.6601\n",
      "Epoch 13/200\n",
      "175341/175341 [==============================] - 994s 6ms/step - loss: 0.9435 - accuracy: 0.6411 - val_loss: 0.9006 - val_accuracy: 0.6205\n",
      "Epoch 14/200\n",
      "175341/175341 [==============================] - 989s 6ms/step - loss: 0.9103 - accuracy: 0.6502 - val_loss: 0.8796 - val_accuracy: 0.6524\n",
      "Epoch 15/200\n",
      "175341/175341 [==============================] - 984s 6ms/step - loss: 0.9161 - accuracy: 0.6478 - val_loss: 1.1323 - val_accuracy: 0.6137\n",
      "Epoch 16/200\n",
      "175341/175341 [==============================] - 981s 6ms/step - loss: 0.9039 - accuracy: 0.6502 - val_loss: 0.8700 - val_accuracy: 0.6612\n",
      "Epoch 17/200\n",
      "175341/175341 [==============================] - 984s 6ms/step - loss: 0.9003 - accuracy: 0.6515 - val_loss: 0.8687 - val_accuracy: 0.6306\n",
      "Epoch 18/200\n",
      "175341/175341 [==============================] - 987s 6ms/step - loss: 0.8902 - accuracy: 0.6546 - val_loss: 0.9410 - val_accuracy: 0.6499\n",
      "Epoch 19/200\n",
      "175341/175341 [==============================] - 980s 6ms/step - loss: 0.8756 - accuracy: 0.6571 - val_loss: 0.8884 - val_accuracy: 0.6344\n",
      "Epoch 20/200\n",
      "175341/175341 [==============================] - 982s 6ms/step - loss: 0.8872 - accuracy: 0.6544 - val_loss: 0.8561 - val_accuracy: 0.6437\n",
      "Epoch 21/200\n",
      "175341/175341 [==============================] - 982s 6ms/step - loss: 0.8647 - accuracy: 0.6589 - val_loss: 0.8783 - val_accuracy: 0.6094\n",
      "Epoch 22/200\n",
      "175341/175341 [==============================] - 982s 6ms/step - loss: 0.8599 - accuracy: 0.6607 - val_loss: 0.8725 - val_accuracy: 0.6242\n",
      "Epoch 23/200\n",
      "175341/175341 [==============================] - 1031s 6ms/step - loss: 0.8591 - accuracy: 0.6603 - val_loss: 0.8592 - val_accuracy: 0.6539\n",
      "Epoch 24/200\n",
      "175341/175341 [==============================] - 1034s 6ms/step - loss: 0.8575 - accuracy: 0.6602 - val_loss: 0.8703 - val_accuracy: 0.6289\n",
      "Epoch 25/200\n",
      "175341/175341 [==============================] - 1033s 6ms/step - loss: 0.8674 - accuracy: 0.6584 - val_loss: 1.0953 - val_accuracy: 0.6078\n",
      "Epoch 26/200\n",
      "175341/175341 [==============================] - 1025s 6ms/step - loss: 0.9272 - accuracy: 0.6421 - val_loss: 1.2812 - val_accuracy: 0.5846\n",
      "Epoch 27/200\n",
      "175341/175341 [==============================] - 1015s 6ms/step - loss: 0.9301 - accuracy: 0.6416 - val_loss: 0.8624 - val_accuracy: 0.6388\n",
      "Epoch 28/200\n",
      "175341/175341 [==============================] - 1018s 6ms/step - loss: 0.8650 - accuracy: 0.6584 - val_loss: 0.9728 - val_accuracy: 0.6445\n",
      "Epoch 29/200\n",
      "175341/175341 [==============================] - 1014s 6ms/step - loss: 0.8591 - accuracy: 0.6596 - val_loss: 0.8868 - val_accuracy: 0.6364\n",
      "Epoch 30/200\n",
      "175341/175341 [==============================] - 1003s 6ms/step - loss: 0.8627 - accuracy: 0.6585 - val_loss: 0.8490 - val_accuracy: 0.6384\n",
      "Epoch 31/200\n",
      "175341/175341 [==============================] - 682s 4ms/step - loss: 0.8520 - accuracy: 0.6609 - val_loss: 0.8584 - val_accuracy: 0.6153\n",
      "Epoch 32/200\n",
      "175341/175341 [==============================] - 676s 4ms/step - loss: 0.8496 - accuracy: 0.6614 - val_loss: 0.8746 - val_accuracy: 0.6212\n",
      "Epoch 33/200\n",
      "175341/175341 [==============================] - 672s 4ms/step - loss: 0.8489 - accuracy: 0.6616 - val_loss: 0.8528 - val_accuracy: 0.6568\n",
      "Epoch 34/200\n",
      "175341/175341 [==============================] - 673s 4ms/step - loss: 0.8494 - accuracy: 0.6609 - val_loss: 0.8573 - val_accuracy: 0.6357\n",
      "Epoch 35/200\n",
      "175341/175341 [==============================] - 670s 4ms/step - loss: 0.8437 - accuracy: 0.6621 - val_loss: 0.8533 - val_accuracy: 0.6416\n",
      "Epoch 36/200\n",
      "175341/175341 [==============================] - 671s 4ms/step - loss: 0.8336 - accuracy: 0.6644 - val_loss: 0.8755 - val_accuracy: 0.6050\n",
      "Epoch 37/200\n",
      "175341/175341 [==============================] - 675s 4ms/step - loss: 0.8353 - accuracy: 0.6635 - val_loss: 0.8541 - val_accuracy: 0.6370\n",
      "Epoch 38/200\n",
      "175341/175341 [==============================] - 674s 4ms/step - loss: 0.8283 - accuracy: 0.6644 - val_loss: 0.8540 - val_accuracy: 0.6390\n",
      "Epoch 39/200\n",
      "175341/175341 [==============================] - 676s 4ms/step - loss: 0.8254 - accuracy: 0.6653 - val_loss: 0.8498 - val_accuracy: 0.6430\n",
      "Epoch 40/200\n",
      "175341/175341 [==============================] - 674s 4ms/step - loss: 0.8283 - accuracy: 0.6650 - val_loss: 0.8548 - val_accuracy: 0.6330\n",
      "Epoch 41/200\n",
      "175341/175341 [==============================] - 677s 4ms/step - loss: 0.9187 - accuracy: 0.6422 - val_loss: 0.9108 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "175341/175341 [==============================] - 669s 4ms/step - loss: 0.8724 - accuracy: 0.6552 - val_loss: 0.8712 - val_accuracy: 0.6231\n",
      "Epoch 43/200\n",
      "175341/175341 [==============================] - 670s 4ms/step - loss: 0.8216 - accuracy: 0.6656 - val_loss: 0.8382 - val_accuracy: 0.6197\n",
      "Epoch 44/200\n",
      "175341/175341 [==============================] - 667s 4ms/step - loss: 0.8186 - accuracy: 0.6665 - val_loss: 0.8345 - val_accuracy: 0.6374\n",
      "Epoch 45/200\n",
      "175341/175341 [==============================] - 667s 4ms/step - loss: 0.8150 - accuracy: 0.6667 - val_loss: 0.8347 - val_accuracy: 0.6301\n",
      "Epoch 46/200\n",
      "175341/175341 [==============================] - 666s 4ms/step - loss: 0.8087 - accuracy: 0.6688 - val_loss: 0.8331 - val_accuracy: 0.6054\n",
      "Epoch 47/200\n",
      "175341/175341 [==============================] - 666s 4ms/step - loss: 0.8056 - accuracy: 0.6700 - val_loss: 0.8366 - val_accuracy: 0.6064\n",
      "Epoch 48/200\n",
      "175341/175341 [==============================] - 654s 4ms/step - loss: 0.8017 - accuracy: 0.6716 - val_loss: 0.8657 - val_accuracy: 0.5842\n",
      "Epoch 49/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.9383 - accuracy: 0.6389 - val_loss: 0.8793 - val_accuracy: 0.6594\n",
      "Epoch 50/200\n",
      "175341/175341 [==============================] - 654s 4ms/step - loss: 0.8688 - accuracy: 0.6572 - val_loss: 0.8660 - val_accuracy: 0.6005\n",
      "Epoch 51/200\n",
      "175341/175341 [==============================] - 654s 4ms/step - loss: 0.8449 - accuracy: 0.6619 - val_loss: 0.8492 - val_accuracy: 0.6409\n",
      "Epoch 52/200\n",
      "175341/175341 [==============================] - 654s 4ms/step - loss: 0.8268 - accuracy: 0.6636 - val_loss: 0.8556 - val_accuracy: 0.6126\n",
      "Epoch 53/200\n",
      "175341/175341 [==============================] - 654s 4ms/step - loss: 0.8113 - accuracy: 0.6693 - val_loss: 0.8687 - val_accuracy: 0.5925\n",
      "Epoch 54/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.8029 - accuracy: 0.6719 - val_loss: 0.8413 - val_accuracy: 0.6051\n",
      "Epoch 55/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.7992 - accuracy: 0.6746 - val_loss: 0.8321 - val_accuracy: 0.6915\n",
      "Epoch 56/200\n",
      "175341/175341 [==============================] - 654s 4ms/step - loss: 0.7944 - accuracy: 0.6761 - val_loss: 0.8298 - val_accuracy: 0.6100\n",
      "Epoch 57/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.7920 - accuracy: 0.6775 - val_loss: 0.8484 - val_accuracy: 0.5895\n",
      "Epoch 58/200\n",
      "175341/175341 [==============================] - 654s 4ms/step - loss: 0.7876 - accuracy: 0.6797 - val_loss: 0.8300 - val_accuracy: 0.6095\n",
      "Epoch 59/200\n",
      "175341/175341 [==============================] - 653s 4ms/step - loss: 0.7862 - accuracy: 0.6808 - val_loss: 0.8641 - val_accuracy: 0.6046\n",
      "Epoch 60/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.7828 - accuracy: 0.6822 - val_loss: 0.8295 - val_accuracy: 0.6061\n",
      "Epoch 61/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.7808 - accuracy: 0.6824 - val_loss: 0.8240 - val_accuracy: 0.6083\n",
      "Epoch 62/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.7810 - accuracy: 0.6849 - val_loss: 0.8073 - val_accuracy: 0.6652\n",
      "Epoch 63/200\n",
      "175341/175341 [==============================] - 656s 4ms/step - loss: 0.7758 - accuracy: 0.6854 - val_loss: 0.8262 - val_accuracy: 0.6174\n",
      "Epoch 64/200\n",
      "175341/175341 [==============================] - 655s 4ms/step - loss: 0.7738 - accuracy: 0.6872 - val_loss: 0.8181 - val_accuracy: 0.6149\n",
      "Epoch 65/200\n",
      "175341/175341 [==============================] - 656s 4ms/step - loss: 0.7698 - accuracy: 0.6880 - val_loss: 0.8042 - val_accuracy: 0.6271\n",
      "Epoch 66/200\n",
      "175341/175341 [==============================] - 656s 4ms/step - loss: 0.7903 - accuracy: 0.6826 - val_loss: 0.7953 - val_accuracy: 0.6833\n",
      "Epoch 67/200\n",
      "175341/175341 [==============================] - 656s 4ms/step - loss: 0.7719 - accuracy: 0.6882 - val_loss: 0.8142 - val_accuracy: 0.6145\n",
      "Epoch 68/200\n",
      "175341/175341 [==============================] - 656s 4ms/step - loss: 0.7698 - accuracy: 0.6898 - val_loss: 0.8129 - val_accuracy: 0.6157\n",
      "Epoch 69/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7648 - accuracy: 0.6914 - val_loss: 0.8421 - val_accuracy: 0.6106\n",
      "Epoch 70/200\n",
      "175341/175341 [==============================] - 656s 4ms/step - loss: 0.7614 - accuracy: 0.6931 - val_loss: 0.8099 - val_accuracy: 0.6280\n",
      "Epoch 71/200\n",
      "175341/175341 [==============================] - 703s 4ms/step - loss: 0.7573 - accuracy: 0.6955 - val_loss: 0.7943 - val_accuracy: 0.6385\n",
      "Epoch 72/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7829 - accuracy: 0.6887 - val_loss: 0.8218 - val_accuracy: 0.6242\n",
      "Epoch 73/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7563 - accuracy: 0.6960 - val_loss: 0.8089 - val_accuracy: 0.6355\n",
      "Epoch 74/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7530 - accuracy: 0.6986 - val_loss: 0.8005 - val_accuracy: 0.6416\n",
      "Epoch 75/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7492 - accuracy: 0.7006 - val_loss: 0.7945 - val_accuracy: 0.6583\n",
      "Epoch 76/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7489 - accuracy: 0.7004 - val_loss: 0.8187 - val_accuracy: 0.6259\n",
      "Epoch 77/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7437 - accuracy: 0.7035 - val_loss: 0.7897 - val_accuracy: 0.6583\n",
      "Epoch 78/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.7839 - accuracy: 0.6927 - val_loss: 0.7836 - val_accuracy: 0.6587\n",
      "Epoch 79/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7560 - accuracy: 0.7030 - val_loss: 0.7990 - val_accuracy: 0.6418\n",
      "Epoch 80/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7459 - accuracy: 0.7036 - val_loss: 0.7687 - val_accuracy: 0.6732\n",
      "Epoch 81/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7403 - accuracy: 0.7056 - val_loss: 0.8274 - val_accuracy: 0.6261\n",
      "Epoch 82/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7439 - accuracy: 0.7035 - val_loss: 0.7722 - val_accuracy: 0.6646\n",
      "Epoch 83/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7341 - accuracy: 0.7085 - val_loss: 0.7644 - val_accuracy: 0.6634\n",
      "Epoch 84/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7302 - accuracy: 0.7106 - val_loss: 0.7916 - val_accuracy: 0.6577\n",
      "Epoch 85/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7321 - accuracy: 0.7098 - val_loss: 0.7730 - val_accuracy: 0.6570\n",
      "Epoch 86/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7281 - accuracy: 0.7116 - val_loss: 0.7559 - val_accuracy: 0.6635\n",
      "Epoch 87/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7239 - accuracy: 0.7135 - val_loss: 0.7624 - val_accuracy: 0.6739\n",
      "Epoch 88/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7210 - accuracy: 0.7143 - val_loss: 0.7513 - val_accuracy: 0.7099\n",
      "Epoch 89/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.7197 - accuracy: 0.7138 - val_loss: 0.7674 - val_accuracy: 0.6638\n",
      "Epoch 90/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.8508 - accuracy: 0.6665 - val_loss: 1.0661 - val_accuracy: 0.5703\n",
      "Epoch 91/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.8598 - accuracy: 0.6585 - val_loss: 0.8944 - val_accuracy: 0.5906\n",
      "Epoch 92/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.8450 - accuracy: 0.6622 - val_loss: 0.8283 - val_accuracy: 0.6507\n",
      "Epoch 93/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.8193 - accuracy: 0.6654 - val_loss: 0.8467 - val_accuracy: 0.6043\n",
      "Epoch 94/200\n",
      "175341/175341 [==============================] - 649s 4ms/step - loss: 0.8024 - accuracy: 0.6727 - val_loss: 0.8237 - val_accuracy: 0.6194\n",
      "Epoch 95/200\n",
      "175341/175341 [==============================] - 650s 4ms/step - loss: 0.7932 - accuracy: 0.6782 - val_loss: 0.8339 - val_accuracy: 0.6089\n",
      "Epoch 96/200\n",
      "175341/175341 [==============================] - 649s 4ms/step - loss: 0.7878 - accuracy: 0.6809 - val_loss: 0.8232 - val_accuracy: 0.6084\n",
      "Epoch 97/200\n",
      "175341/175341 [==============================] - 650s 4ms/step - loss: 0.7808 - accuracy: 0.6834 - val_loss: 0.8403 - val_accuracy: 0.5901\n",
      "Epoch 98/200\n",
      "175341/175341 [==============================] - 650s 4ms/step - loss: 0.7785 - accuracy: 0.6859 - val_loss: 0.8094 - val_accuracy: 0.6400\n",
      "Epoch 99/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.7744 - accuracy: 0.6869 - val_loss: 0.8024 - val_accuracy: 0.6484\n",
      "Epoch 100/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.7766 - accuracy: 0.6870 - val_loss: 0.8217 - val_accuracy: 0.6216\n",
      "Epoch 101/200\n",
      "175341/175341 [==============================] - 640s 4ms/step - loss: 0.7718 - accuracy: 0.6878 - val_loss: 0.8098 - val_accuracy: 0.6134\n",
      "Epoch 102/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.7676 - accuracy: 0.6884 - val_loss: 0.8151 - val_accuracy: 0.6191\n",
      "Epoch 103/200\n",
      "175341/175341 [==============================] - 640s 4ms/step - loss: 0.7680 - accuracy: 0.6885 - val_loss: 0.8128 - val_accuracy: 0.6152\n",
      "Epoch 104/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.7598 - accuracy: 0.6926 - val_loss: 0.8943 - val_accuracy: 0.5932\n",
      "Epoch 105/200\n",
      "175341/175341 [==============================] - 643s 4ms/step - loss: 0.7645 - accuracy: 0.6911 - val_loss: 0.8008 - val_accuracy: 0.6263\n",
      "Epoch 106/200\n",
      "175341/175341 [==============================] - 642s 4ms/step - loss: 0.7564 - accuracy: 0.6938 - val_loss: 0.8054 - val_accuracy: 0.6226\n",
      "Epoch 107/200\n",
      "175341/175341 [==============================] - 642s 4ms/step - loss: 0.7543 - accuracy: 0.6960 - val_loss: 0.7867 - val_accuracy: 0.6522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "175341/175341 [==============================] - 642s 4ms/step - loss: 0.7474 - accuracy: 0.6994 - val_loss: 0.7821 - val_accuracy: 0.6723\n",
      "Epoch 109/200\n",
      "175341/175341 [==============================] - 642s 4ms/step - loss: 0.7453 - accuracy: 0.7028 - val_loss: 0.7964 - val_accuracy: 0.6340\n",
      "Epoch 110/200\n",
      "175341/175341 [==============================] - 642s 4ms/step - loss: 0.8103 - accuracy: 0.6831 - val_loss: 0.9454 - val_accuracy: 0.6611\n",
      "Epoch 111/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.9072 - accuracy: 0.6498 - val_loss: 0.9251 - val_accuracy: 0.6742\n",
      "Epoch 112/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.8717 - accuracy: 0.6581 - val_loss: 0.8578 - val_accuracy: 0.6626\n",
      "Epoch 113/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.8539 - accuracy: 0.6606 - val_loss: 0.8505 - val_accuracy: 0.6570\n",
      "Epoch 114/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.8408 - accuracy: 0.6635 - val_loss: 0.8568 - val_accuracy: 0.6595\n",
      "Epoch 115/200\n",
      "175341/175341 [==============================] - 643s 4ms/step - loss: 0.8343 - accuracy: 0.6643 - val_loss: 0.8443 - val_accuracy: 0.6301\n",
      "Epoch 116/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.8309 - accuracy: 0.6650 - val_loss: 0.8216 - val_accuracy: 0.6698\n",
      "Epoch 117/200\n",
      "175341/175341 [==============================] - 642s 4ms/step - loss: 0.8176 - accuracy: 0.6681 - val_loss: 0.8697 - val_accuracy: 0.5905\n",
      "Epoch 118/200\n",
      "175341/175341 [==============================] - 641s 4ms/step - loss: 0.8098 - accuracy: 0.6692 - val_loss: 0.8568 - val_accuracy: 0.6271\n",
      "Epoch 119/200\n",
      "175341/175341 [==============================] - 642s 4ms/step - loss: 0.8031 - accuracy: 0.6707 - val_loss: 0.8332 - val_accuracy: 0.6073\n",
      "Epoch 120/200\n",
      "175341/175341 [==============================] - 682s 4ms/step - loss: 0.7972 - accuracy: 0.6738 - val_loss: 0.8266 - val_accuracy: 0.6086\n",
      "Epoch 121/200\n",
      "175341/175341 [==============================] - 716s 4ms/step - loss: 0.7856 - accuracy: 0.6786 - val_loss: 0.8239 - val_accuracy: 0.6246\n",
      "Epoch 122/200\n",
      "175341/175341 [==============================] - 661s 4ms/step - loss: 0.7780 - accuracy: 0.6821 - val_loss: 0.8272 - val_accuracy: 0.6195\n",
      "Epoch 123/200\n",
      "175341/175341 [==============================] - 666s 4ms/step - loss: 0.7710 - accuracy: 0.6875 - val_loss: 0.8333 - val_accuracy: 0.6152\n",
      "Epoch 124/200\n",
      "175341/175341 [==============================] - 686s 4ms/step - loss: 0.7623 - accuracy: 0.6919 - val_loss: 0.7826 - val_accuracy: 0.6515\n",
      "Epoch 125/200\n",
      "175341/175341 [==============================] - 677s 4ms/step - loss: 0.7510 - accuracy: 0.6995 - val_loss: 0.8314 - val_accuracy: 0.6292\n",
      "Epoch 126/200\n",
      "175341/175341 [==============================] - 681s 4ms/step - loss: 0.7430 - accuracy: 0.7035 - val_loss: 0.7649 - val_accuracy: 0.6678\n",
      "Epoch 127/200\n",
      "175341/175341 [==============================] - 699s 4ms/step - loss: 0.7365 - accuracy: 0.7073 - val_loss: 0.7932 - val_accuracy: 0.6274\n",
      "Epoch 128/200\n",
      "175341/175341 [==============================] - 676s 4ms/step - loss: 0.7333 - accuracy: 0.7091 - val_loss: 0.7788 - val_accuracy: 0.6625\n",
      "Epoch 129/200\n",
      "175341/175341 [==============================] - 675s 4ms/step - loss: 0.7265 - accuracy: 0.7136 - val_loss: 0.7599 - val_accuracy: 0.7106\n",
      "Epoch 130/200\n",
      "175341/175341 [==============================] - 676s 4ms/step - loss: 0.7251 - accuracy: 0.7136 - val_loss: 0.7599 - val_accuracy: 0.6699\n",
      "Epoch 131/200\n",
      "175341/175341 [==============================] - 676s 4ms/step - loss: 0.7194 - accuracy: 0.7168 - val_loss: 0.7735 - val_accuracy: 0.6457\n",
      "Epoch 132/200\n",
      "175341/175341 [==============================] - 676s 4ms/step - loss: 0.7166 - accuracy: 0.7177 - val_loss: 0.7543 - val_accuracy: 0.6802\n",
      "Epoch 133/200\n",
      "175341/175341 [==============================] - 669s 4ms/step - loss: 0.7148 - accuracy: 0.7190 - val_loss: 0.7548 - val_accuracy: 0.6716\n",
      "Epoch 134/200\n",
      "175341/175341 [==============================] - 670s 4ms/step - loss: 0.7118 - accuracy: 0.7205 - val_loss: 0.7774 - val_accuracy: 0.6624\n",
      "Epoch 135/200\n",
      "175341/175341 [==============================] - 668s 4ms/step - loss: 0.7103 - accuracy: 0.7214 - val_loss: 0.7591 - val_accuracy: 0.6692\n",
      "Epoch 136/200\n",
      "175341/175341 [==============================] - 670s 4ms/step - loss: 0.7146 - accuracy: 0.7195 - val_loss: 0.7964 - val_accuracy: 0.6730\n",
      "Epoch 137/200\n",
      "175341/175341 [==============================] - 673s 4ms/step - loss: 0.7134 - accuracy: 0.7209 - val_loss: 0.7573 - val_accuracy: 0.6700\n",
      "Epoch 138/200\n",
      "175341/175341 [==============================] - 672s 4ms/step - loss: 0.7045 - accuracy: 0.7241 - val_loss: 0.7421 - val_accuracy: 0.6748\n",
      "Epoch 139/200\n",
      "175341/175341 [==============================] - 671s 4ms/step - loss: 0.7018 - accuracy: 0.7249 - val_loss: 0.7440 - val_accuracy: 0.6777\n",
      "Epoch 140/200\n",
      "175341/175341 [==============================] - 672s 4ms/step - loss: 0.6996 - accuracy: 0.7258 - val_loss: 0.7412 - val_accuracy: 0.6706\n",
      "Epoch 141/200\n",
      "175341/175341 [==============================] - 671s 4ms/step - loss: 0.6990 - accuracy: 0.7260 - val_loss: 0.7394 - val_accuracy: 0.6861\n",
      "Epoch 142/200\n",
      "175341/175341 [==============================] - 671s 4ms/step - loss: 0.6987 - accuracy: 0.7262 - val_loss: 0.7327 - val_accuracy: 0.6799\n",
      "Epoch 143/200\n",
      "175341/175341 [==============================] - 673s 4ms/step - loss: 0.6961 - accuracy: 0.7283 - val_loss: 0.7511 - val_accuracy: 0.6678\n",
      "Epoch 144/200\n",
      "175341/175341 [==============================] - 674s 4ms/step - loss: 0.6950 - accuracy: 0.7292 - val_loss: 0.7475 - val_accuracy: 0.6747\n",
      "Epoch 145/200\n",
      "175341/175341 [==============================] - 673s 4ms/step - loss: 0.6900 - accuracy: 0.7318 - val_loss: 0.7330 - val_accuracy: 0.6899\n",
      "Epoch 146/200\n",
      "175341/175341 [==============================] - 673s 4ms/step - loss: 0.6952 - accuracy: 0.7303 - val_loss: 0.7215 - val_accuracy: 0.6969\n",
      "Epoch 147/200\n",
      "175341/175341 [==============================] - 675s 4ms/step - loss: 0.6885 - accuracy: 0.7327 - val_loss: 0.7320 - val_accuracy: 0.6859\n",
      "Epoch 148/200\n",
      "175341/175341 [==============================] - 674s 4ms/step - loss: 0.6873 - accuracy: 0.7331 - val_loss: 0.7313 - val_accuracy: 0.6824\n",
      "Epoch 149/200\n",
      "175341/175341 [==============================] - 672s 4ms/step - loss: 0.6839 - accuracy: 0.7339 - val_loss: 0.7387 - val_accuracy: 0.6785\n",
      "Epoch 150/200\n",
      "175341/175341 [==============================] - 674s 4ms/step - loss: 0.6820 - accuracy: 0.7350 - val_loss: 0.7238 - val_accuracy: 0.7009\n",
      "Epoch 151/200\n",
      "175341/175341 [==============================] - 673s 4ms/step - loss: 0.6813 - accuracy: 0.7357 - val_loss: 0.7197 - val_accuracy: 0.6952\n",
      "Epoch 152/200\n",
      "175341/175341 [==============================] - 672s 4ms/step - loss: 0.6836 - accuracy: 0.7341 - val_loss: 0.7173 - val_accuracy: 0.6870\n",
      "Epoch 153/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.6825 - accuracy: 0.7345 - val_loss: 0.7353 - val_accuracy: 0.6845\n",
      "Epoch 154/200\n",
      "175341/175341 [==============================] - 656s 4ms/step - loss: 0.6844 - accuracy: 0.7339 - val_loss: 0.7230 - val_accuracy: 0.6771\n",
      "Epoch 155/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.6974 - accuracy: 0.7293 - val_loss: 0.7261 - val_accuracy: 0.6848\n",
      "Epoch 156/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.6757 - accuracy: 0.7366 - val_loss: 0.7174 - val_accuracy: 0.6854\n",
      "Epoch 157/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6777 - accuracy: 0.7362 - val_loss: 0.7211 - val_accuracy: 0.6881\n",
      "Epoch 158/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.6796 - accuracy: 0.7362 - val_loss: 0.7241 - val_accuracy: 0.6934\n",
      "Epoch 159/200\n",
      "175341/175341 [==============================] - 657s 4ms/step - loss: 0.6815 - accuracy: 0.7354 - val_loss: 0.7225 - val_accuracy: 0.6858\n",
      "Epoch 160/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6752 - accuracy: 0.7376 - val_loss: 0.7244 - val_accuracy: 0.6813\n",
      "Epoch 161/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.6724 - accuracy: 0.7383 - val_loss: 0.7147 - val_accuracy: 0.6887\n",
      "Epoch 162/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.6711 - accuracy: 0.7402 - val_loss: 0.7316 - val_accuracy: 0.6874\n",
      "Epoch 163/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6695 - accuracy: 0.7403 - val_loss: 0.7250 - val_accuracy: 0.6877\n",
      "Epoch 164/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.6699 - accuracy: 0.7408 - val_loss: 0.7024 - val_accuracy: 0.6919\n",
      "Epoch 165/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6722 - accuracy: 0.7391 - val_loss: 0.7181 - val_accuracy: 0.6867\n",
      "Epoch 166/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6665 - accuracy: 0.7426 - val_loss: 0.7333 - val_accuracy: 0.6809\n",
      "Epoch 167/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.7769 - accuracy: 0.6989 - val_loss: 0.8568 - val_accuracy: 0.6319\n",
      "Epoch 168/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.6987 - accuracy: 0.7270 - val_loss: 0.7607 - val_accuracy: 0.6724\n",
      "Epoch 169/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6700 - accuracy: 0.7406 - val_loss: 0.7384 - val_accuracy: 0.6870\n",
      "Epoch 170/200\n",
      "175341/175341 [==============================] - 658s 4ms/step - loss: 0.6675 - accuracy: 0.7414 - val_loss: 0.7237 - val_accuracy: 0.6989\n",
      "Epoch 171/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.7855 - accuracy: 0.7013 - val_loss: 0.7413 - val_accuracy: 0.6778\n",
      "Epoch 172/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6730 - accuracy: 0.7401 - val_loss: 0.7256 - val_accuracy: 0.6882\n",
      "Epoch 173/200\n",
      "175341/175341 [==============================] - 659s 4ms/step - loss: 0.6691 - accuracy: 0.7405 - val_loss: 0.7115 - val_accuracy: 0.6867\n",
      "Epoch 174/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.6655 - accuracy: 0.7429 - val_loss: 0.7153 - val_accuracy: 0.7002\n",
      "Epoch 175/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.6673 - accuracy: 0.7416 - val_loss: 0.7170 - val_accuracy: 0.6974\n",
      "Epoch 176/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.6617 - accuracy: 0.7442 - val_loss: 0.7151 - val_accuracy: 0.6871\n",
      "Epoch 177/200\n",
      "175341/175341 [==============================] - 661s 4ms/step - loss: 0.6614 - accuracy: 0.7442 - val_loss: 0.7112 - val_accuracy: 0.6904\n",
      "Epoch 178/200\n",
      "175341/175341 [==============================] - 661s 4ms/step - loss: 0.6611 - accuracy: 0.7440 - val_loss: 0.7169 - val_accuracy: 0.6998\n",
      "Epoch 179/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.6592 - accuracy: 0.7450 - val_loss: 0.6993 - val_accuracy: 0.7051\n",
      "Epoch 180/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.6589 - accuracy: 0.7454 - val_loss: 0.7206 - val_accuracy: 0.6825\n",
      "Epoch 181/200\n",
      "175341/175341 [==============================] - 661s 4ms/step - loss: 0.6597 - accuracy: 0.7444 - val_loss: 0.7152 - val_accuracy: 0.6837\n",
      "Epoch 182/200\n",
      "175341/175341 [==============================] - 660s 4ms/step - loss: 0.6873 - accuracy: 0.7311 - val_loss: 0.7275 - val_accuracy: 0.6865\n",
      "Epoch 183/200\n",
      "175341/175341 [==============================] - 662s 4ms/step - loss: 0.6545 - accuracy: 0.7469 - val_loss: 0.7008 - val_accuracy: 0.6985\n",
      "Epoch 184/200\n",
      "175341/175341 [==============================] - 661s 4ms/step - loss: 0.6564 - accuracy: 0.7455 - val_loss: 0.7160 - val_accuracy: 0.6805\n",
      "Epoch 185/200\n",
      "175341/175341 [==============================] - 662s 4ms/step - loss: 0.6598 - accuracy: 0.7454 - val_loss: 0.6956 - val_accuracy: 0.6904\n",
      "Epoch 186/200\n",
      "175341/175341 [==============================] - 661s 4ms/step - loss: 0.6535 - accuracy: 0.7467 - val_loss: 0.7069 - val_accuracy: 0.6949\n",
      "Epoch 187/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6535 - accuracy: 0.7473 - val_loss: 0.7000 - val_accuracy: 0.6934\n",
      "Epoch 188/200\n",
      "175341/175341 [==============================] - 662s 4ms/step - loss: 0.6517 - accuracy: 0.7468 - val_loss: 0.7433 - val_accuracy: 0.6707\n",
      "Epoch 189/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6500 - accuracy: 0.7483 - val_loss: 0.7176 - val_accuracy: 0.6829\n",
      "Epoch 190/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6500 - accuracy: 0.7480 - val_loss: 0.7008 - val_accuracy: 0.6907\n",
      "Epoch 191/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6504 - accuracy: 0.7482 - val_loss: 0.6929 - val_accuracy: 0.6918\n",
      "Epoch 192/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6519 - accuracy: 0.7481 - val_loss: 0.6783 - val_accuracy: 0.7244\n",
      "Epoch 193/200\n",
      "175341/175341 [==============================] - 662s 4ms/step - loss: 0.6548 - accuracy: 0.7470 - val_loss: 0.7595 - val_accuracy: 0.6852\n",
      "Epoch 194/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6538 - accuracy: 0.7470 - val_loss: 0.6834 - val_accuracy: 0.7020\n",
      "Epoch 195/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6493 - accuracy: 0.7483 - val_loss: 0.7044 - val_accuracy: 0.6878\n",
      "Epoch 196/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6700 - accuracy: 0.7424 - val_loss: 0.6853 - val_accuracy: 0.7016\n",
      "Epoch 197/200\n",
      "175341/175341 [==============================] - 663s 4ms/step - loss: 0.6497 - accuracy: 0.7488 - val_loss: 0.6897 - val_accuracy: 0.7124\n",
      "Epoch 198/200\n",
      "175341/175341 [==============================] - 466s 3ms/step - loss: 1.3636 - accuracy: 0.5596 - val_loss: 1.3198 - val_accuracy: 0.5460\n",
      "Epoch 199/200\n",
      "175341/175341 [==============================] - 350s 2ms/step - loss: 1.4004 - accuracy: 0.5231 - val_loss: 1.1289 - val_accuracy: 0.6406\n",
      "Epoch 200/200\n",
      "175341/175341 [==============================] - 350s 2ms/step - loss: 1.1108 - accuracy: 0.5939 - val_loss: 0.9125 - val_accuracy: 0.6452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffa4331f550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(XDelta1, Y, epochs=200, validation_data=(xdelta1, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = cnn.predict([xdelta1])\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#pred = np.zeros((82332,1), dtype=int)\n",
    "for i in range(0, predictions.shape[0]):\n",
    "    pred = np.where(predictions[i] == np.amax(predictions[i]))\n",
    "    for j in range(0,10):\n",
    "        predictions[i,j] = 0\n",
    "    predictions[i,pred]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6451926346985376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       677\n",
      "           1       0.11      0.00      0.00       583\n",
      "           2       0.30      0.01      0.02      4089\n",
      "           3       0.29      0.47      0.36     11132\n",
      "           4       0.16      0.16      0.16      6062\n",
      "           5       0.99      0.96      0.98     18871\n",
      "           6       0.72      0.74      0.73     37000\n",
      "           7       0.91      0.37      0.52      3496\n",
      "           8       0.00      0.00      0.00       378\n",
      "           9       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     82332\n",
      "   macro avg       0.35      0.27      0.28     82332\n",
      "weighted avg       0.65      0.65      0.63     82332\n",
      " samples avg       0.65      0.65      0.65     82332\n",
      "\n",
      "[[    0     0     0   629     1     0    46     1     0     0]\n",
      " [    0     1     6   526     3     3    41     3     0     0]\n",
      " [    0     2    36  3029   150    49   783    40     0     0]\n",
      " [    0     6    50  5236   187    50  5562    41     0     0]\n",
      " [    0     0    12  2446   953     3  2642     6     0     0]\n",
      " [    0     0     3   227   112 18151   372     6     0     0]\n",
      " [    0     0     2  5155  4329    26 27466    21     0     1]\n",
      " [    0     0    10   870    19    29  1291  1277     0     0]\n",
      " [    0     0     0   166    48    25   127    12     0     0]\n",
      " [    0     0     0    12     6     0    26     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy: \",accuracy_score(y,predictions))\n",
    "from sklearn.metrics import multilabel_confusion_matrix,classification_report,confusion_matrix\n",
    "print(\"Classification Report: \\n\",classification_report(y,predictions))\n",
    "conmat = np.array(confusion_matrix(y.argmax(axis=1), predictions.argmax(axis=1)))\n",
    "confusion = pd.DataFrame(conmat, index=['0','1','2','3','4','5','6','7','8','9'],\n",
    "                        columns=[['0','1','2','3','4','5','6','7','8','9']])\n",
    "print (conmat)\n",
    "conmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
