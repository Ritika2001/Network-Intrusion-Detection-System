{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata=traindata.drop('id',axis=1)\n",
    "#testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "traindata['attack_cat'] = lb_make.fit_transform(traindata['attack_cat'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "testdata['attack_cat'] = lb_make.fit_transform(testdata['attack_cat'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-2]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr = X.values\n",
    "arr = x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "Arr_Delta = librosa.feature.delta(Arr)\n",
    "arr_delta = librosa.feature.delta(arr)\n",
    "\n",
    "Delta1 = pd.DataFrame(Arr_Delta)\n",
    "delta1 = pd.DataFrame(arr_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "XDelta1 = pd.concat([X, Delta1], axis=1)\n",
    "xdelta1 = pd.concat([x, delta1], axis=1)\n",
    "\n",
    "scaler = Normalizer().fit(XDelta1)\n",
    "XDelta1 = scaler.transform(XDelta1)\n",
    "scaler = Normalizer().fit(xdelta1)\n",
    "xdelta1 = scaler.transform(xdelta1)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "XDelta1 = np.reshape(XDelta1, (XDelta1.shape[0],XDelta1.shape[1],1))\n",
    "xdelta1 = np.reshape(xdelta1, (xdelta1.shape[0],xdelta1.shape[1],1))\n",
    "\n",
    "lstm_output_size = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, input_shape=(82, 1), activation=\"relu\", padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/200\n",
      "175341/175341 [==============================] - 270s 2ms/step - loss: 1.3819 - accuracy: 0.5282 - val_loss: 1.2940 - val_accuracy: 0.5931\n",
      "Epoch 2/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 1.3362 - accuracy: 0.5432 - val_loss: 1.2930 - val_accuracy: 0.5942\n",
      "Epoch 3/200\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 1.3253 - accuracy: 0.5474 - val_loss: 1.2779 - val_accuracy: 0.5870\n",
      "Epoch 4/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 1.3195 - accuracy: 0.5492 - val_loss: 1.2795 - val_accuracy: 0.5802\n",
      "Epoch 5/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.3135 - accuracy: 0.5510 - val_loss: 1.2747 - val_accuracy: 0.5922\n",
      "Epoch 6/200\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 1.3067 - accuracy: 0.5521 - val_loss: 1.2738 - val_accuracy: 0.5804\n",
      "Epoch 7/200\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 1.1169 - accuracy: 0.6007 - val_loss: 1.3163 - val_accuracy: 0.5640\n",
      "Epoch 8/200\n",
      "175341/175341 [==============================] - 273s 2ms/step - loss: 1.3208 - accuracy: 0.5506 - val_loss: 1.2587 - val_accuracy: 0.5863\n",
      "Epoch 9/200\n",
      "175341/175341 [==============================] - 279s 2ms/step - loss: 1.1690 - accuracy: 0.5886 - val_loss: 0.9334 - val_accuracy: 0.6576\n",
      "Epoch 10/200\n",
      "175341/175341 [==============================] - 340s 2ms/step - loss: 0.9421 - accuracy: 0.6404 - val_loss: 0.9549 - val_accuracy: 0.6392\n",
      "Epoch 11/200\n",
      "175341/175341 [==============================] - 281s 2ms/step - loss: 0.9643 - accuracy: 0.6337 - val_loss: 0.8855 - val_accuracy: 0.6504\n",
      "Epoch 12/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.9178 - accuracy: 0.6460 - val_loss: 0.8934 - val_accuracy: 0.6580\n",
      "Epoch 13/200\n",
      "175341/175341 [==============================] - 287s 2ms/step - loss: 0.8956 - accuracy: 0.6526 - val_loss: 0.9175 - val_accuracy: 0.6398\n",
      "Epoch 14/200\n",
      "175341/175341 [==============================] - 277s 2ms/step - loss: 0.8945 - accuracy: 0.6518 - val_loss: 0.8761 - val_accuracy: 0.6485\n",
      "Epoch 15/200\n",
      "175341/175341 [==============================] - 304s 2ms/step - loss: 0.8825 - accuracy: 0.6550 - val_loss: 0.9057 - val_accuracy: 0.6084\n",
      "Epoch 16/200\n",
      "175341/175341 [==============================] - 343s 2ms/step - loss: 1.0789 - accuracy: 0.6053 - val_loss: 0.9668 - val_accuracy: 0.6177\n",
      "Epoch 17/200\n",
      "175341/175341 [==============================] - 348s 2ms/step - loss: 0.9799 - accuracy: 0.6263 - val_loss: 0.9541 - val_accuracy: 0.5933\n",
      "Epoch 18/200\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.9377 - accuracy: 0.6406 - val_loss: 0.8797 - val_accuracy: 0.6576\n",
      "Epoch 19/200\n",
      "175341/175341 [==============================] - 265s 2ms/step - loss: 0.8999 - accuracy: 0.6529 - val_loss: 0.8657 - val_accuracy: 0.6579\n",
      "Epoch 20/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.8730 - accuracy: 0.6583 - val_loss: 0.8562 - val_accuracy: 0.6484\n",
      "Epoch 21/200\n",
      "175341/175341 [==============================] - 265s 2ms/step - loss: 0.8858 - accuracy: 0.6553 - val_loss: 0.8752 - val_accuracy: 0.6458\n",
      "Epoch 22/200\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 0.8635 - accuracy: 0.6595 - val_loss: 0.8861 - val_accuracy: 0.6034\n",
      "Epoch 23/200\n",
      "175341/175341 [==============================] - 348s 2ms/step - loss: 0.8521 - accuracy: 0.6621 - val_loss: 0.8549 - val_accuracy: 0.6301\n",
      "Epoch 24/200\n",
      "175341/175341 [==============================] - 368s 2ms/step - loss: 0.8456 - accuracy: 0.6631 - val_loss: 0.8665 - val_accuracy: 0.6343\n",
      "Epoch 25/200\n",
      "175341/175341 [==============================] - 270s 2ms/step - loss: 0.8407 - accuracy: 0.6644 - val_loss: 0.8534 - val_accuracy: 0.6371\n",
      "Epoch 26/200\n",
      "175341/175341 [==============================] - 271s 2ms/step - loss: 0.8368 - accuracy: 0.6644 - val_loss: 0.8501 - val_accuracy: 0.6316\n",
      "Epoch 27/200\n",
      "175341/175341 [==============================] - 268s 2ms/step - loss: 0.8325 - accuracy: 0.6649 - val_loss: 0.8482 - val_accuracy: 0.6256\n",
      "Epoch 28/200\n",
      "175341/175341 [==============================] - 269s 2ms/step - loss: 0.8345 - accuracy: 0.6643 - val_loss: 0.8233 - val_accuracy: 0.6648\n",
      "Epoch 29/200\n",
      "175341/175341 [==============================] - 270s 2ms/step - loss: 0.8294 - accuracy: 0.6652 - val_loss: 0.8530 - val_accuracy: 0.6216\n",
      "Epoch 30/200\n",
      "175341/175341 [==============================] - 270s 2ms/step - loss: 0.8250 - accuracy: 0.6654 - val_loss: 0.8476 - val_accuracy: 0.6575\n",
      "Epoch 31/200\n",
      "175341/175341 [==============================] - 272s 2ms/step - loss: 0.8220 - accuracy: 0.6667 - val_loss: 0.8485 - val_accuracy: 0.6365\n",
      "Epoch 32/200\n",
      "175341/175341 [==============================] - 272s 2ms/step - loss: 0.8193 - accuracy: 0.6667 - val_loss: 0.8378 - val_accuracy: 0.6338\n",
      "Epoch 33/200\n",
      "175341/175341 [==============================] - 272s 2ms/step - loss: 0.8139 - accuracy: 0.6668 - val_loss: 0.8348 - val_accuracy: 0.6655\n",
      "Epoch 34/200\n",
      "175341/175341 [==============================] - 266s 2ms/step - loss: 0.8088 - accuracy: 0.6696 - val_loss: 0.8444 - val_accuracy: 0.6125\n",
      "Epoch 35/200\n",
      "175341/175341 [==============================] - 265s 2ms/step - loss: 0.8024 - accuracy: 0.6722 - val_loss: 0.8363 - val_accuracy: 0.6103\n",
      "Epoch 36/200\n",
      "175341/175341 [==============================] - 266s 2ms/step - loss: 0.7993 - accuracy: 0.6743 - val_loss: 0.8536 - val_accuracy: 0.6185\n",
      "Epoch 37/200\n",
      "175341/175341 [==============================] - 265s 2ms/step - loss: 0.7977 - accuracy: 0.6752 - val_loss: 0.8383 - val_accuracy: 0.6049\n",
      "Epoch 38/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.7921 - accuracy: 0.6781 - val_loss: 0.8338 - val_accuracy: 0.6049\n",
      "Epoch 39/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7909 - accuracy: 0.6791 - val_loss: 0.8345 - val_accuracy: 0.6031\n",
      "Epoch 40/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7876 - accuracy: 0.6801 - val_loss: 0.8637 - val_accuracy: 0.5787\n",
      "Epoch 41/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7887 - accuracy: 0.6796 - val_loss: 0.8265 - val_accuracy: 0.6115\n",
      "Epoch 42/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7838 - accuracy: 0.6815 - val_loss: 0.8170 - val_accuracy: 0.6162\n",
      "Epoch 43/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.7821 - accuracy: 0.6821 - val_loss: 0.8341 - val_accuracy: 0.6052\n",
      "Epoch 44/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7813 - accuracy: 0.6832 - val_loss: 0.8153 - val_accuracy: 0.6082\n",
      "Epoch 45/200\n",
      "175341/175341 [==============================] - 261s 1ms/step - loss: 0.7753 - accuracy: 0.6854 - val_loss: 0.8238 - val_accuracy: 0.6132\n",
      "Epoch 46/200\n",
      "175341/175341 [==============================] - 261s 1ms/step - loss: 0.7724 - accuracy: 0.6861 - val_loss: 0.8210 - val_accuracy: 0.6163\n",
      "Epoch 47/200\n",
      "175341/175341 [==============================] - 261s 1ms/step - loss: 0.7690 - accuracy: 0.6880 - val_loss: 0.8153 - val_accuracy: 0.6113\n",
      "Epoch 48/200\n",
      "175341/175341 [==============================] - 261s 1ms/step - loss: 0.7666 - accuracy: 0.6886 - val_loss: 0.8139 - val_accuracy: 0.6204\n",
      "Epoch 49/200\n",
      "175341/175341 [==============================] - 262s 1ms/step - loss: 0.7652 - accuracy: 0.6900 - val_loss: 0.8181 - val_accuracy: 0.6196\n",
      "Epoch 50/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7593 - accuracy: 0.6925 - val_loss: 0.8829 - val_accuracy: 0.6047\n",
      "Epoch 51/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.7554 - accuracy: 0.6946 - val_loss: 0.8005 - val_accuracy: 0.6435\n",
      "Epoch 52/200\n",
      "175341/175341 [==============================] - 262s 1ms/step - loss: 0.7531 - accuracy: 0.6976 - val_loss: 0.7875 - val_accuracy: 0.6439\n",
      "Epoch 53/200\n",
      "175341/175341 [==============================] - 262s 1ms/step - loss: 0.7538 - accuracy: 0.6977 - val_loss: 0.7863 - val_accuracy: 0.6568\n",
      "Epoch 54/200\n",
      "175341/175341 [==============================] - 253s 1ms/step - loss: 0.8716 - accuracy: 0.6610 - val_loss: 0.9304 - val_accuracy: 0.5974\n",
      "Epoch 55/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.8850 - accuracy: 0.6548 - val_loss: 1.1123 - val_accuracy: 0.5621\n",
      "Epoch 56/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.8732 - accuracy: 0.6578 - val_loss: 0.8499 - val_accuracy: 0.6498\n",
      "Epoch 57/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.8582 - accuracy: 0.6592 - val_loss: 0.8662 - val_accuracy: 0.6232\n",
      "Epoch 58/200\n",
      "175341/175341 [==============================] - 253s 1ms/step - loss: 0.8394 - accuracy: 0.6642 - val_loss: 0.8492 - val_accuracy: 0.6226\n",
      "Epoch 59/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.8245 - accuracy: 0.6657 - val_loss: 0.8379 - val_accuracy: 0.6508\n",
      "Epoch 60/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.8099 - accuracy: 0.6695 - val_loss: 0.8219 - val_accuracy: 0.6169\n",
      "Epoch 61/200\n",
      "175341/175341 [==============================] - 253s 1ms/step - loss: 0.7948 - accuracy: 0.6773 - val_loss: 0.8286 - val_accuracy: 0.6128\n",
      "Epoch 62/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7838 - accuracy: 0.6826 - val_loss: 0.8186 - val_accuracy: 0.6120\n",
      "Epoch 63/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7795 - accuracy: 0.6852 - val_loss: 0.8286 - val_accuracy: 0.6118\n",
      "Epoch 64/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7705 - accuracy: 0.6894 - val_loss: 0.7959 - val_accuracy: 0.6769\n",
      "Epoch 65/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7637 - accuracy: 0.6945 - val_loss: 0.7838 - val_accuracy: 0.6580\n",
      "Epoch 66/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7601 - accuracy: 0.6964 - val_loss: 0.7791 - val_accuracy: 0.6656\n",
      "Epoch 67/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7458 - accuracy: 0.7039 - val_loss: 0.7745 - val_accuracy: 0.6700\n",
      "Epoch 68/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.7432 - accuracy: 0.7050 - val_loss: 0.7873 - val_accuracy: 0.6569\n",
      "Epoch 69/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7488 - accuracy: 0.7025 - val_loss: 0.7646 - val_accuracy: 0.6758\n",
      "Epoch 70/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7388 - accuracy: 0.7067 - val_loss: 0.7707 - val_accuracy: 0.6722\n",
      "Epoch 71/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7642 - accuracy: 0.6940 - val_loss: 0.7922 - val_accuracy: 0.6506\n",
      "Epoch 72/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7309 - accuracy: 0.7106 - val_loss: 0.7588 - val_accuracy: 0.6957\n",
      "Epoch 73/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.7240 - accuracy: 0.7142 - val_loss: 0.7677 - val_accuracy: 0.6791\n",
      "Epoch 74/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.7192 - accuracy: 0.7170 - val_loss: 0.7678 - val_accuracy: 0.6637\n",
      "Epoch 75/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.7228 - accuracy: 0.7145 - val_loss: 0.8247 - val_accuracy: 0.6066\n",
      "Epoch 76/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7168 - accuracy: 0.7177 - val_loss: 0.7470 - val_accuracy: 0.6717\n",
      "Epoch 77/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.7058 - accuracy: 0.7231 - val_loss: 0.7497 - val_accuracy: 0.6799\n",
      "Epoch 78/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7091 - accuracy: 0.7236 - val_loss: 0.7931 - val_accuracy: 0.6670\n",
      "Epoch 79/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.6966 - accuracy: 0.7275 - val_loss: 0.7414 - val_accuracy: 0.6780\n",
      "Epoch 80/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7100 - accuracy: 0.7208 - val_loss: 0.7256 - val_accuracy: 0.6800\n",
      "Epoch 81/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.6942 - accuracy: 0.7287 - val_loss: 0.7341 - val_accuracy: 0.6791\n",
      "Epoch 82/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7394 - accuracy: 0.7070 - val_loss: 0.8173 - val_accuracy: 0.6166\n",
      "Epoch 83/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7559 - accuracy: 0.6965 - val_loss: 0.7879 - val_accuracy: 0.6578\n",
      "Epoch 84/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7607 - accuracy: 0.7060 - val_loss: 0.7154 - val_accuracy: 0.6846\n",
      "Epoch 85/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.6913 - accuracy: 0.7303 - val_loss: 0.7476 - val_accuracy: 0.6699\n",
      "Epoch 86/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.6897 - accuracy: 0.7318 - val_loss: 0.7304 - val_accuracy: 0.6813\n",
      "Epoch 87/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.7013 - accuracy: 0.7256 - val_loss: 0.7045 - val_accuracy: 0.6986\n",
      "Epoch 88/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.6813 - accuracy: 0.7359 - val_loss: 0.7221 - val_accuracy: 0.6825\n",
      "Epoch 89/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.6783 - accuracy: 0.7366 - val_loss: 0.7123 - val_accuracy: 0.7024\n",
      "Epoch 90/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.7033 - accuracy: 0.7243 - val_loss: 0.7096 - val_accuracy: 0.6947\n",
      "Epoch 91/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.6754 - accuracy: 0.7378 - val_loss: 0.7123 - val_accuracy: 0.6824\n",
      "Epoch 92/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6808 - accuracy: 0.7348 - val_loss: 0.7265 - val_accuracy: 0.6767\n",
      "Epoch 93/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7861 - accuracy: 0.6821 - val_loss: 0.8250 - val_accuracy: 0.6045\n",
      "Epoch 94/200\n",
      "175341/175341 [==============================] - 286s 2ms/step - loss: 0.6991 - accuracy: 0.7255 - val_loss: 0.7197 - val_accuracy: 0.6843\n",
      "Epoch 95/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7087 - accuracy: 0.7218 - val_loss: 0.7050 - val_accuracy: 0.7088\n",
      "Epoch 96/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.6686 - accuracy: 0.7410 - val_loss: 0.7484 - val_accuracy: 0.6695\n",
      "Epoch 97/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6719 - accuracy: 0.7398 - val_loss: 0.7119 - val_accuracy: 0.6936\n",
      "Epoch 98/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.7125 - accuracy: 0.7190 - val_loss: 0.7097 - val_accuracy: 0.6832\n",
      "Epoch 99/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.6814 - accuracy: 0.7357 - val_loss: 0.6916 - val_accuracy: 0.7017\n",
      "Epoch 100/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6758 - accuracy: 0.7395 - val_loss: 0.7282 - val_accuracy: 0.6738\n",
      "Epoch 101/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.6590 - accuracy: 0.7454 - val_loss: 0.7129 - val_accuracy: 0.6950\n",
      "Epoch 102/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.7696 - accuracy: 0.7045 - val_loss: 0.8684 - val_accuracy: 0.6568\n",
      "Epoch 103/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.8757 - accuracy: 0.6574 - val_loss: 0.8811 - val_accuracy: 0.6351\n",
      "Epoch 104/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.8595 - accuracy: 0.6614 - val_loss: 0.8780 - val_accuracy: 0.6092\n",
      "Epoch 105/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.8366 - accuracy: 0.6654 - val_loss: 0.8622 - val_accuracy: 0.6476\n",
      "Epoch 106/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.8235 - accuracy: 0.6670 - val_loss: 0.8764 - val_accuracy: 0.5910\n",
      "Epoch 107/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.8028 - accuracy: 0.6718 - val_loss: 0.8383 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7885 - accuracy: 0.6762 - val_loss: 0.8332 - val_accuracy: 0.6151\n",
      "Epoch 109/200\n",
      "175341/175341 [==============================] - 251s 1ms/step - loss: 0.7770 - accuracy: 0.6844 - val_loss: 0.8117 - val_accuracy: 0.6309\n",
      "Epoch 110/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.7646 - accuracy: 0.6926 - val_loss: 0.7912 - val_accuracy: 0.6584\n",
      "Epoch 111/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7453 - accuracy: 0.7016 - val_loss: 0.7769 - val_accuracy: 0.6480\n",
      "Epoch 112/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7441 - accuracy: 0.7024 - val_loss: 0.8141 - val_accuracy: 0.6969\n",
      "Epoch 113/200\n",
      "175341/175341 [==============================] - 251s 1ms/step - loss: 0.7343 - accuracy: 0.7081 - val_loss: 0.7716 - val_accuracy: 0.6489\n",
      "Epoch 114/200\n",
      "175341/175341 [==============================] - 253s 1ms/step - loss: 0.7306 - accuracy: 0.7097 - val_loss: 0.7694 - val_accuracy: 0.6774\n",
      "Epoch 115/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.7242 - accuracy: 0.7142 - val_loss: 0.7778 - val_accuracy: 0.6562\n",
      "Epoch 116/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7247 - accuracy: 0.7130 - val_loss: 0.7702 - val_accuracy: 0.6705\n",
      "Epoch 117/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7325 - accuracy: 0.7096 - val_loss: 0.7797 - val_accuracy: 0.6761\n",
      "Epoch 118/200\n",
      "175341/175341 [==============================] - 253s 1ms/step - loss: 0.7076 - accuracy: 0.7218 - val_loss: 0.7688 - val_accuracy: 0.6615\n",
      "Epoch 119/200\n",
      "175341/175341 [==============================] - 252s 1ms/step - loss: 0.7250 - accuracy: 0.7123 - val_loss: 0.7918 - val_accuracy: 0.7020\n",
      "Epoch 120/200\n",
      "175341/175341 [==============================] - 252s 1ms/step - loss: 0.7051 - accuracy: 0.7224 - val_loss: 0.7818 - val_accuracy: 0.6894\n",
      "Epoch 121/200\n",
      "175341/175341 [==============================] - 252s 1ms/step - loss: 0.7021 - accuracy: 0.7236 - val_loss: 0.7290 - val_accuracy: 0.6987\n",
      "Epoch 122/200\n",
      "175341/175341 [==============================] - 301s 2ms/step - loss: 0.6924 - accuracy: 0.7286 - val_loss: 0.7569 - val_accuracy: 0.6858\n",
      "Epoch 123/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.6930 - accuracy: 0.7286 - val_loss: 0.7232 - val_accuracy: 0.6908\n",
      "Epoch 124/200\n",
      "175341/175341 [==============================] - 253s 1ms/step - loss: 0.7840 - accuracy: 0.7002 - val_loss: 0.8689 - val_accuracy: 0.6635\n",
      "Epoch 125/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.8989 - accuracy: 0.6521 - val_loss: 0.8736 - val_accuracy: 0.6087\n",
      "Epoch 126/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.8654 - accuracy: 0.6577 - val_loss: 0.8723 - val_accuracy: 0.5982\n",
      "Epoch 127/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.7838 - accuracy: 0.6891 - val_loss: 0.7397 - val_accuracy: 0.6784\n",
      "Epoch 128/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.6976 - accuracy: 0.7275 - val_loss: 0.8532 - val_accuracy: 0.6590\n",
      "Epoch 129/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.6924 - accuracy: 0.7297 - val_loss: 0.7437 - val_accuracy: 0.6690\n",
      "Epoch 130/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7546 - accuracy: 0.7110 - val_loss: 0.7562 - val_accuracy: 0.6872\n",
      "Epoch 131/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.8558 - accuracy: 0.6596 - val_loss: 0.8546 - val_accuracy: 0.6366\n",
      "Epoch 132/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.8353 - accuracy: 0.6630 - val_loss: 0.8301 - val_accuracy: 0.6067\n",
      "Epoch 133/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.7934 - accuracy: 0.6755 - val_loss: 0.8504 - val_accuracy: 0.6290\n",
      "Epoch 134/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.8319 - accuracy: 0.6677 - val_loss: 0.8483 - val_accuracy: 0.6089\n",
      "Epoch 135/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7575 - accuracy: 0.6999 - val_loss: 0.7837 - val_accuracy: 0.6349\n",
      "Epoch 136/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7113 - accuracy: 0.7207 - val_loss: 0.7474 - val_accuracy: 0.6746\n",
      "Epoch 137/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6968 - accuracy: 0.7281 - val_loss: 0.7379 - val_accuracy: 0.6752\n",
      "Epoch 138/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6871 - accuracy: 0.7331 - val_loss: 0.7419 - val_accuracy: 0.6767\n",
      "Epoch 139/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.6836 - accuracy: 0.7336 - val_loss: 0.7965 - val_accuracy: 0.6463\n",
      "Epoch 140/200\n",
      "175341/175341 [==============================] - 255s 1ms/step - loss: 0.7030 - accuracy: 0.7237 - val_loss: 0.7359 - val_accuracy: 0.6666\n",
      "Epoch 141/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.6819 - accuracy: 0.7334 - val_loss: 0.7289 - val_accuracy: 0.6779\n",
      "Epoch 142/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6785 - accuracy: 0.7357 - val_loss: 0.7350 - val_accuracy: 0.6874\n",
      "Epoch 143/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6738 - accuracy: 0.7380 - val_loss: 0.7470 - val_accuracy: 0.6858\n",
      "Epoch 144/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7265 - accuracy: 0.7158 - val_loss: 0.8766 - val_accuracy: 0.6047\n",
      "Epoch 145/200\n",
      "175341/175341 [==============================] - 254s 1ms/step - loss: 0.7710 - accuracy: 0.6926 - val_loss: 0.7559 - val_accuracy: 0.6678\n",
      "Epoch 146/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.6786 - accuracy: 0.7377 - val_loss: 0.7372 - val_accuracy: 0.6677\n",
      "Epoch 147/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.6714 - accuracy: 0.7399 - val_loss: 0.7139 - val_accuracy: 0.6990\n",
      "Epoch 148/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6697 - accuracy: 0.7403 - val_loss: 0.7167 - val_accuracy: 0.6836\n",
      "Epoch 149/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.7033 - accuracy: 0.7249 - val_loss: 0.7230 - val_accuracy: 0.6844\n",
      "Epoch 150/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6703 - accuracy: 0.7409 - val_loss: 0.7029 - val_accuracy: 0.7008\n",
      "Epoch 151/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6667 - accuracy: 0.7408 - val_loss: 0.7259 - val_accuracy: 0.6880\n",
      "Epoch 152/200\n",
      "175341/175341 [==============================] - 256s 1ms/step - loss: 0.7124 - accuracy: 0.7190 - val_loss: 0.7387 - val_accuracy: 0.6849\n",
      "Epoch 153/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6657 - accuracy: 0.7414 - val_loss: 0.6996 - val_accuracy: 0.6942\n",
      "Epoch 154/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6753 - accuracy: 0.7363 - val_loss: 0.7175 - val_accuracy: 0.6880\n",
      "Epoch 155/200\n",
      "175341/175341 [==============================] - 257s 1ms/step - loss: 0.6669 - accuracy: 0.7410 - val_loss: 0.7246 - val_accuracy: 0.6814\n",
      "Epoch 156/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.6851 - accuracy: 0.7325 - val_loss: 0.7406 - val_accuracy: 0.6698\n",
      "Epoch 157/200\n",
      "175341/175341 [==============================] - 269s 2ms/step - loss: 0.6626 - accuracy: 0.7432 - val_loss: 0.7127 - val_accuracy: 0.6907\n",
      "Epoch 158/200\n",
      "175341/175341 [==============================] - 266s 2ms/step - loss: 0.6667 - accuracy: 0.7410 - val_loss: 0.7104 - val_accuracy: 0.6847\n",
      "Epoch 159/200\n",
      "175341/175341 [==============================] - 267s 2ms/step - loss: 0.6588 - accuracy: 0.7436 - val_loss: 0.7085 - val_accuracy: 0.6938\n",
      "Epoch 160/200\n",
      "175341/175341 [==============================] - 266s 2ms/step - loss: 0.7260 - accuracy: 0.7118 - val_loss: 0.7869 - val_accuracy: 0.6344\n",
      "Epoch 161/200\n",
      "175341/175341 [==============================] - 271s 2ms/step - loss: 0.6827 - accuracy: 0.7325 - val_loss: 0.7120 - val_accuracy: 0.6840\n",
      "Epoch 162/200\n",
      "175341/175341 [==============================] - 272s 2ms/step - loss: 0.7612 - accuracy: 0.6975 - val_loss: 0.8290 - val_accuracy: 0.6223\n",
      "Epoch 163/200\n",
      "175341/175341 [==============================] - 276s 2ms/step - loss: 0.7379 - accuracy: 0.7067 - val_loss: 0.7342 - val_accuracy: 0.6916\n",
      "Epoch 164/200\n",
      "175341/175341 [==============================] - 272s 2ms/step - loss: 0.6810 - accuracy: 0.7358 - val_loss: 0.7069 - val_accuracy: 0.6969\n",
      "Epoch 165/200\n",
      "175341/175341 [==============================] - 275s 2ms/step - loss: 0.6670 - accuracy: 0.7415 - val_loss: 0.7275 - val_accuracy: 0.6835\n",
      "Epoch 166/200\n",
      "175341/175341 [==============================] - 277s 2ms/step - loss: 0.6799 - accuracy: 0.7351 - val_loss: 0.7301 - val_accuracy: 0.6808\n",
      "Epoch 167/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.6678 - accuracy: 0.7403 - val_loss: 0.8603 - val_accuracy: 0.5830\n",
      "Epoch 168/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.7815 - accuracy: 0.6882 - val_loss: 0.7958 - val_accuracy: 0.6361\n",
      "Epoch 169/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.7264 - accuracy: 0.7107 - val_loss: 0.7350 - val_accuracy: 0.6894\n",
      "Epoch 170/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.7317 - accuracy: 0.7118 - val_loss: 0.8157 - val_accuracy: 0.6192\n",
      "Epoch 171/200\n",
      "175341/175341 [==============================] - 258s 1ms/step - loss: 0.7321 - accuracy: 0.7069 - val_loss: 0.8285 - val_accuracy: 0.6368\n",
      "Epoch 172/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.6969 - accuracy: 0.7263 - val_loss: 0.7385 - val_accuracy: 0.6789\n",
      "Epoch 173/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.6617 - accuracy: 0.7439 - val_loss: 0.7200 - val_accuracy: 0.6929\n",
      "Epoch 174/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.6674 - accuracy: 0.7403 - val_loss: 0.7328 - val_accuracy: 0.6924\n",
      "Epoch 175/200\n",
      "175341/175341 [==============================] - 259s 1ms/step - loss: 0.6583 - accuracy: 0.7446 - val_loss: 0.8053 - val_accuracy: 0.6213\n",
      "Epoch 176/200\n",
      "175341/175341 [==============================] - 260s 1ms/step - loss: 0.6699 - accuracy: 0.7401 - val_loss: 0.6942 - val_accuracy: 0.7106\n",
      "Epoch 177/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.6909 - accuracy: 0.7305 - val_loss: 0.7527 - val_accuracy: 0.6675\n",
      "Epoch 178/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.6667 - accuracy: 0.7411 - val_loss: 0.7062 - val_accuracy: 0.7014\n",
      "Epoch 179/200\n",
      "175341/175341 [==============================] - 263s 1ms/step - loss: 0.6539 - accuracy: 0.7460 - val_loss: 0.7013 - val_accuracy: 0.6889\n",
      "Epoch 180/200\n",
      "175341/175341 [==============================] - 263s 2ms/step - loss: 0.6550 - accuracy: 0.7455 - val_loss: 0.7135 - val_accuracy: 0.6792\n",
      "Epoch 181/200\n",
      "175341/175341 [==============================] - 263s 2ms/step - loss: 0.6535 - accuracy: 0.7460 - val_loss: 0.7316 - val_accuracy: 0.6841\n",
      "Epoch 182/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.6526 - accuracy: 0.7469 - val_loss: 0.7068 - val_accuracy: 0.6983\n",
      "Epoch 183/200\n",
      "175341/175341 [==============================] - 274s 2ms/step - loss: 0.6488 - accuracy: 0.7480 - val_loss: 0.7189 - val_accuracy: 0.6857\n",
      "Epoch 184/200\n",
      "175341/175341 [==============================] - 268s 2ms/step - loss: 0.6534 - accuracy: 0.7458 - val_loss: 0.6906 - val_accuracy: 0.6944\n",
      "Epoch 185/200\n",
      "175341/175341 [==============================] - 263s 1ms/step - loss: 0.6493 - accuracy: 0.7475 - val_loss: 0.8087 - val_accuracy: 0.6485\n",
      "Epoch 186/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.6526 - accuracy: 0.7465 - val_loss: 0.7055 - val_accuracy: 0.6810\n",
      "Epoch 187/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.6466 - accuracy: 0.7487 - val_loss: 0.7157 - val_accuracy: 0.6830\n",
      "Epoch 188/200\n",
      "175341/175341 [==============================] - 332s 2ms/step - loss: 0.6540 - accuracy: 0.7454 - val_loss: 0.6799 - val_accuracy: 0.7083\n",
      "Epoch 189/200\n",
      "175341/175341 [==============================] - 277s 2ms/step - loss: 0.6462 - accuracy: 0.7492 - val_loss: 0.6993 - val_accuracy: 0.6870\n",
      "Epoch 190/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.6460 - accuracy: 0.7492 - val_loss: 0.7152 - val_accuracy: 0.6909\n",
      "Epoch 191/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.7118 - accuracy: 0.7177 - val_loss: 0.7406 - val_accuracy: 0.6788\n",
      "Epoch 192/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.6593 - accuracy: 0.7442 - val_loss: 0.6931 - val_accuracy: 0.7023\n",
      "Epoch 193/200\n",
      "175341/175341 [==============================] - 263s 2ms/step - loss: 0.6461 - accuracy: 0.7493 - val_loss: 0.7091 - val_accuracy: 0.6882\n",
      "Epoch 194/200\n",
      "175341/175341 [==============================] - 272s 2ms/step - loss: 0.6480 - accuracy: 0.7481 - val_loss: 0.6881 - val_accuracy: 0.6962\n",
      "Epoch 195/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.6460 - accuracy: 0.7492 - val_loss: 0.7027 - val_accuracy: 0.6951\n",
      "Epoch 196/200\n",
      "175341/175341 [==============================] - 345s 2ms/step - loss: 0.7690 - accuracy: 0.6949 - val_loss: 0.7162 - val_accuracy: 0.6834\n",
      "Epoch 197/200\n",
      "175341/175341 [==============================] - 302s 2ms/step - loss: 0.6836 - accuracy: 0.7317 - val_loss: 0.6885 - val_accuracy: 0.6983\n",
      "Epoch 198/200\n",
      "175341/175341 [==============================] - 264s 2ms/step - loss: 0.6989 - accuracy: 0.7248 - val_loss: 0.7076 - val_accuracy: 0.6873\n",
      "Epoch 199/200\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.6509 - accuracy: 0.7473 - val_loss: 0.6995 - val_accuracy: 0.7035\n",
      "Epoch 200/200\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 0.6437 - accuracy: 0.7496 - val_loss: 0.6946 - val_accuracy: 0.7008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6e17f05668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(82, 1)))\n",
    "cnn.add(MaxPooling1D(pool_size=(2)))\n",
    "cnn.add(Bidirectional(LSTM(lstm_output_size)))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(XDelta1, Y, epochs=200, validation_data=(xdelta1, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = cnn.predict([xdelta1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pred = np.zeros((82332,1), dtype=int)\n",
    "for i in range(0, predictions.shape[0]):\n",
    "    pred[i] = np.where(predictions[i] == np.amax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = to_categorical(pred)\n",
    "z = np.zeros((82332,1), dtype=int)\n",
    "pred = np.append(pred, z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7007967740368265\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",accuracy_score(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.00      0.00       677\n",
      "           1       1.00      0.01      0.01       583\n",
      "           2       0.61      0.02      0.04      4089\n",
      "           3       0.44      0.82      0.58     11132\n",
      "           4       0.25      0.51      0.33      6062\n",
      "           5       1.00      0.96      0.98     18871\n",
      "           6       0.92      0.67      0.77     37000\n",
      "           7       0.67      0.71      0.69      3496\n",
      "           8       0.22      0.12      0.16       378\n",
      "           9       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     82332\n",
      "   macro avg       0.52      0.38      0.36     82332\n",
      "weighted avg       0.79      0.70      0.71     82332\n",
      " samples avg       0.70      0.70      0.70     82332\n",
      "\n",
      "[[    1     0     0   658     2     0    16     0     0     0]\n",
      " [    0     4     0   544    18     0    15     2     0     0]\n",
      " [    0     0    75  3460   308     6   215    22     3     0]\n",
      " [    0     0    17  9114   906     0  1019    63    13     0]\n",
      " [    0     0     4  1914  3104     0   753   256    31     0]\n",
      " [    0     0    12   403   149 18146   148    10     3     0]\n",
      " [    8     0     6  3574  7714     1 24735   851   111     0]\n",
      " [    0     0     6   726   253     4    34  2473     0     0]\n",
      " [    0     0     2    91   187     6    20    26    46     0]\n",
      " [    0     0     0    34     4     0     6     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,classification_report,confusion_matrix\n",
    "print(\"Classification Report: \\n\",classification_report(y,pred))\n",
    "conmat = np.array(confusion_matrix(y.argmax(axis=1), pred.argmax(axis=1)))\n",
    "confusion = pd.DataFrame(conmat, index=['0','1','2','3','4','5','6','7','8','9'],\n",
    "                        columns=[['0','1','2','3','4','5','6','7','8','9']])\n",
    "print (conmat)\n",
    "conmat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.11      0.00      0.00       677\n",
    "           1       1.00      0.01      0.01       583\n",
    "           2       0.61      0.02      0.04      4089\n",
    "           3       0.44      0.82      0.58     11132\n",
    "           4       0.25      0.51      0.33      6062\n",
    "           5       1.00      0.96      0.98     18871\n",
    "           6       0.92      0.67      0.77     37000\n",
    "           7       0.67      0.71      0.69      3496\n",
    "           8       0.22      0.12      0.16       378\n",
    "           9       0.00      0.00      0.00        44\n",
    "\n",
    "   micro avg       0.70      0.70      0.70     82332\n",
    "   macro avg       0.52      0.38      0.36     82332\n",
    "weighted avg       0.79      0.70      0.71     82332\n",
    " samples avg       0.70      0.70      0.70     82332\n",
    "\n",
    "[[    1     0     0   658     2     0    16     0     0     0]\n",
    " [    0     4     0   544    18     0    15     2     0     0]\n",
    " [    0     0    75  3460   308     6   215    22     3     0]\n",
    " [    0     0    17  9114   906     0  1019    63    13     0]\n",
    " [    0     0     4  1914  3104     0   753   256    31     0]\n",
    " [    0     0    12   403   149 18146   148    10     3     0]\n",
    " [    8     0     6  3574  7714     1 24735   851   111     0]\n",
    " [    0     0     6   726   253     4    34  2473     0     0]\n",
    " [    0     0     2    91   187     6    20    26    46     0]\n",
    " [    0     0     0    34     4     0     6     0     0     0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
