{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-1]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-1]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],X.shape[1],1))\n",
    "x = np.reshape(x, (x.shape[0],x.shape[1],1))\n",
    "\n",
    "lstm_output_size = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\", input_shape=(41, 1))`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.4129 - accuracy: 0.7747 - val_loss: 0.3751 - val_accuracy: 0.8157\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3681 - accuracy: 0.8194 - val_loss: 0.3648 - val_accuracy: 0.8145\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3598 - accuracy: 0.8246 - val_loss: 0.3465 - val_accuracy: 0.8307\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3548 - accuracy: 0.8294 - val_loss: 0.3478 - val_accuracy: 0.8344\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3517 - accuracy: 0.8308 - val_loss: 0.3655 - val_accuracy: 0.8356\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3488 - accuracy: 0.8323 - val_loss: 0.3392 - val_accuracy: 0.8359\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3474 - accuracy: 0.8326 - val_loss: 0.3389 - val_accuracy: 0.8366\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3459 - accuracy: 0.8333 - val_loss: 0.3419 - val_accuracy: 0.8331\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.3453 - accuracy: 0.8329 - val_loss: 0.3367 - val_accuracy: 0.8353\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.3432 - accuracy: 0.8344 - val_loss: 0.3356 - val_accuracy: 0.8370\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.3415 - accuracy: 0.8355 - val_loss: 0.3381 - val_accuracy: 0.8374\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.3424 - accuracy: 0.8353 - val_loss: 0.3308 - val_accuracy: 0.8405\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.3422 - accuracy: 0.8353 - val_loss: 0.3381 - val_accuracy: 0.8336\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.3404 - accuracy: 0.8359 - val_loss: 0.3495 - val_accuracy: 0.8365\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3396 - accuracy: 0.8361 - val_loss: 0.3402 - val_accuracy: 0.8405\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.3396 - accuracy: 0.8373 - val_loss: 0.3348 - val_accuracy: 0.8409\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3396 - accuracy: 0.8374 - val_loss: 0.3315 - val_accuracy: 0.8399\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3336 - accuracy: 0.8442 - val_loss: 0.3175 - val_accuracy: 0.8548\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3406 - accuracy: 0.8362 - val_loss: 0.3273 - val_accuracy: 0.8486\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3252 - accuracy: 0.8490 - val_loss: 0.3244 - val_accuracy: 0.8486\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.3151 - accuracy: 0.8588 - val_loss: 0.3050 - val_accuracy: 0.8666\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3106 - accuracy: 0.8620 - val_loss: 0.2986 - val_accuracy: 0.8697\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3067 - accuracy: 0.8655 - val_loss: 0.3027 - val_accuracy: 0.8696\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3083 - accuracy: 0.8642 - val_loss: 0.3066 - val_accuracy: 0.8674\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3075 - accuracy: 0.8646 - val_loss: 0.3051 - val_accuracy: 0.8681\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.3068 - accuracy: 0.8649 - val_loss: 0.3236 - val_accuracy: 0.8505\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.3059 - accuracy: 0.8657 - val_loss: 0.3149 - val_accuracy: 0.8560\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.3062 - accuracy: 0.8646 - val_loss: 0.2979 - val_accuracy: 0.8713\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3047 - accuracy: 0.8673 - val_loss: 0.3009 - val_accuracy: 0.8701\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3037 - accuracy: 0.8678 - val_loss: 0.3054 - val_accuracy: 0.8670\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.3030 - accuracy: 0.8689 - val_loss: 0.3012 - val_accuracy: 0.8717\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2982 - accuracy: 0.8737 - val_loss: 0.2874 - val_accuracy: 0.8809\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2929 - accuracy: 0.8767 - val_loss: 0.2962 - val_accuracy: 0.8731\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2903 - accuracy: 0.8788 - val_loss: 0.2839 - val_accuracy: 0.8829\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2881 - accuracy: 0.8801 - val_loss: 0.2771 - val_accuracy: 0.8866\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2833 - accuracy: 0.8844 - val_loss: 0.2763 - val_accuracy: 0.8886\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2980 - accuracy: 0.8726 - val_loss: 0.2976 - val_accuracy: 0.8729\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2867 - accuracy: 0.8816 - val_loss: 0.2724 - val_accuracy: 0.8934\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2776 - accuracy: 0.8891 - val_loss: 0.2698 - val_accuracy: 0.8938\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2762 - accuracy: 0.8904 - val_loss: 0.2714 - val_accuracy: 0.8931\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2868 - accuracy: 0.8819 - val_loss: 0.2976 - val_accuracy: 0.8704\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2774 - accuracy: 0.8891 - val_loss: 0.2684 - val_accuracy: 0.8944\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2750 - accuracy: 0.8910 - val_loss: 0.2685 - val_accuracy: 0.8951\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2745 - accuracy: 0.8913 - val_loss: 0.2682 - val_accuracy: 0.8937\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2740 - accuracy: 0.8915 - val_loss: 0.2664 - val_accuracy: 0.8953\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2739 - accuracy: 0.8917 - val_loss: 0.2688 - val_accuracy: 0.8950\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2726 - accuracy: 0.8920 - val_loss: 0.2671 - val_accuracy: 0.8953\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2903 - accuracy: 0.8786 - val_loss: 0.2936 - val_accuracy: 0.8760\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2905 - accuracy: 0.8781 - val_loss: 0.2712 - val_accuracy: 0.8926\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2730 - accuracy: 0.8925 - val_loss: 0.2676 - val_accuracy: 0.8948\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2722 - accuracy: 0.8930 - val_loss: 0.2663 - val_accuracy: 0.8957\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2855 - accuracy: 0.8826 - val_loss: 0.2867 - val_accuracy: 0.8799\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2868 - accuracy: 0.8819 - val_loss: 0.2772 - val_accuracy: 0.8906\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2816 - accuracy: 0.8869 - val_loss: 0.2805 - val_accuracy: 0.8845\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2773 - accuracy: 0.8890 - val_loss: 0.2689 - val_accuracy: 0.8934\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2712 - accuracy: 0.8926 - val_loss: 0.2626 - val_accuracy: 0.8980\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2708 - accuracy: 0.8928 - val_loss: 0.2629 - val_accuracy: 0.8983\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2695 - accuracy: 0.8937 - val_loss: 0.2645 - val_accuracy: 0.8959\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2696 - accuracy: 0.8936 - val_loss: 0.2649 - val_accuracy: 0.8962\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2818 - accuracy: 0.8858 - val_loss: 0.2701 - val_accuracy: 0.8957\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2772 - accuracy: 0.8900 - val_loss: 0.2671 - val_accuracy: 0.8985\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2743 - accuracy: 0.8924 - val_loss: 0.2666 - val_accuracy: 0.8990\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2722 - accuracy: 0.8935 - val_loss: 0.2690 - val_accuracy: 0.8964\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2738 - accuracy: 0.8909 - val_loss: 0.2717 - val_accuracy: 0.8917\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2724 - accuracy: 0.8912 - val_loss: 0.2639 - val_accuracy: 0.8975\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2724 - accuracy: 0.8910 - val_loss: 0.2631 - val_accuracy: 0.8976\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2710 - accuracy: 0.8930 - val_loss: 0.2624 - val_accuracy: 0.8991\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2669 - accuracy: 0.8966 - val_loss: 0.2645 - val_accuracy: 0.8974\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2703 - accuracy: 0.8940 - val_loss: 0.2603 - val_accuracy: 0.9011\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2675 - accuracy: 0.8962 - val_loss: 0.2596 - val_accuracy: 0.9004\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2657 - accuracy: 0.8968 - val_loss: 0.2623 - val_accuracy: 0.8999\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2657 - accuracy: 0.8974 - val_loss: 0.2945 - val_accuracy: 0.8837\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2650 - accuracy: 0.8977 - val_loss: 0.2581 - val_accuracy: 0.9030\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2750 - accuracy: 0.8892 - val_loss: 0.2588 - val_accuracy: 0.9011\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2646 - accuracy: 0.8974 - val_loss: 0.2593 - val_accuracy: 0.9016\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2640 - accuracy: 0.8980 - val_loss: 0.2595 - val_accuracy: 0.9009\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2641 - accuracy: 0.8981 - val_loss: 0.2573 - val_accuracy: 0.9030\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2636 - accuracy: 0.8983 - val_loss: 0.2611 - val_accuracy: 0.8992\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2628 - accuracy: 0.8986 - val_loss: 0.2556 - val_accuracy: 0.9032\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2628 - accuracy: 0.8986 - val_loss: 0.2578 - val_accuracy: 0.9016\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2625 - accuracy: 0.8989 - val_loss: 0.2559 - val_accuracy: 0.9032\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2622 - accuracy: 0.8991 - val_loss: 0.2616 - val_accuracy: 0.8998\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2636 - accuracy: 0.8983 - val_loss: 0.2555 - val_accuracy: 0.9031\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2628 - accuracy: 0.8985 - val_loss: 0.2596 - val_accuracy: 0.9017\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2754 - accuracy: 0.8913 - val_loss: 0.2572 - val_accuracy: 0.9022\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2635 - accuracy: 0.8986 - val_loss: 0.2548 - val_accuracy: 0.9036\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2621 - accuracy: 0.8989 - val_loss: 0.2548 - val_accuracy: 0.9032\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2617 - accuracy: 0.8992 - val_loss: 0.2577 - val_accuracy: 0.9030\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2735 - accuracy: 0.8910 - val_loss: 0.2792 - val_accuracy: 0.8872\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2658 - accuracy: 0.8960 - val_loss: 0.2602 - val_accuracy: 0.9019\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2630 - accuracy: 0.8979 - val_loss: 0.2770 - val_accuracy: 0.8987\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2638 - accuracy: 0.8979 - val_loss: 0.2573 - val_accuracy: 0.9035\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2611 - accuracy: 0.8996 - val_loss: 0.2605 - val_accuracy: 0.9006\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2605 - accuracy: 0.9000 - val_loss: 0.2558 - val_accuracy: 0.9030\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2575 - accuracy: 0.8997 - val_loss: 0.2567 - val_accuracy: 0.9009\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2460 - accuracy: 0.9002 - val_loss: 0.2701 - val_accuracy: 0.9056\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2314 - accuracy: 0.9012 - val_loss: 0.2248 - val_accuracy: 0.9047\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2299 - accuracy: 0.9006 - val_loss: 0.2280 - val_accuracy: 0.9010\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2287 - accuracy: 0.9012 - val_loss: 0.2277 - val_accuracy: 0.9058\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2289 - accuracy: 0.9007 - val_loss: 0.2263 - val_accuracy: 0.9024\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2291 - accuracy: 0.9006 - val_loss: 0.2239 - val_accuracy: 0.9050\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2267 - accuracy: 0.9011 - val_loss: 0.2230 - val_accuracy: 0.9066\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2258 - accuracy: 0.9012 - val_loss: 0.2191 - val_accuracy: 0.9060\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2254 - accuracy: 0.9019 - val_loss: 0.2209 - val_accuracy: 0.9054\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2252 - accuracy: 0.9017 - val_loss: 0.2206 - val_accuracy: 0.9038\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2248 - accuracy: 0.9023 - val_loss: 0.2219 - val_accuracy: 0.9046\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2225 - accuracy: 0.9023 - val_loss: 0.2193 - val_accuracy: 0.9055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2239 - accuracy: 0.9019 - val_loss: 0.2136 - val_accuracy: 0.9061\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2221 - accuracy: 0.9024 - val_loss: 0.2116 - val_accuracy: 0.9067\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2265 - accuracy: 0.8986 - val_loss: 0.2205 - val_accuracy: 0.9015\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2256 - accuracy: 0.8994 - val_loss: 0.2358 - val_accuracy: 0.8897\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2254 - accuracy: 0.8990 - val_loss: 0.2128 - val_accuracy: 0.9058\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2213 - accuracy: 0.9022 - val_loss: 0.2130 - val_accuracy: 0.9051\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2198 - accuracy: 0.9019 - val_loss: 0.2171 - val_accuracy: 0.9076\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2183 - accuracy: 0.9030 - val_loss: 0.2139 - val_accuracy: 0.9060\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2169 - accuracy: 0.9039 - val_loss: 0.2096 - val_accuracy: 0.9074\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2177 - accuracy: 0.9026 - val_loss: 0.2089 - val_accuracy: 0.9084\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2164 - accuracy: 0.9038 - val_loss: 0.2086 - val_accuracy: 0.9079\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2162 - accuracy: 0.9035 - val_loss: 0.2081 - val_accuracy: 0.9078\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2145 - accuracy: 0.9040 - val_loss: 0.2089 - val_accuracy: 0.9084\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2151 - accuracy: 0.9037 - val_loss: 0.2108 - val_accuracy: 0.9068\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2167 - accuracy: 0.9032 - val_loss: 0.2166 - val_accuracy: 0.9040\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2173 - accuracy: 0.9025 - val_loss: 0.2182 - val_accuracy: 0.9007\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2160 - accuracy: 0.9029 - val_loss: 0.2119 - val_accuracy: 0.9050\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2584 - accuracy: 0.8954 - val_loss: 0.2186 - val_accuracy: 0.9048\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2208 - accuracy: 0.9020 - val_loss: 0.2132 - val_accuracy: 0.9068\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2209 - accuracy: 0.9015 - val_loss: 0.2112 - val_accuracy: 0.9060\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2176 - accuracy: 0.9025 - val_loss: 0.2120 - val_accuracy: 0.9058\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2183 - accuracy: 0.9027 - val_loss: 0.2130 - val_accuracy: 0.9062\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2170 - accuracy: 0.9022 - val_loss: 0.2127 - val_accuracy: 0.9056\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2159 - accuracy: 0.9027 - val_loss: 0.2120 - val_accuracy: 0.9066\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2187 - accuracy: 0.9021 - val_loss: 0.2118 - val_accuracy: 0.9066\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2152 - accuracy: 0.9031 - val_loss: 0.2108 - val_accuracy: 0.9066\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2158 - accuracy: 0.9028 - val_loss: 0.2118 - val_accuracy: 0.9065\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2144 - accuracy: 0.9030 - val_loss: 0.2103 - val_accuracy: 0.9071\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2158 - accuracy: 0.9026 - val_loss: 0.2132 - val_accuracy: 0.9006\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2140 - accuracy: 0.9030 - val_loss: 0.2112 - val_accuracy: 0.9060\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2147 - accuracy: 0.9027 - val_loss: 0.2186 - val_accuracy: 0.9021\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2152 - accuracy: 0.9020 - val_loss: 0.2562 - val_accuracy: 0.8791\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2153 - accuracy: 0.9020 - val_loss: 0.2093 - val_accuracy: 0.9066\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2137 - accuracy: 0.9032 - val_loss: 0.2100 - val_accuracy: 0.9062\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2123 - accuracy: 0.9036 - val_loss: 0.2109 - val_accuracy: 0.9067\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2141 - accuracy: 0.9036 - val_loss: 0.2145 - val_accuracy: 0.9032\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2123 - accuracy: 0.9038 - val_loss: 0.2105 - val_accuracy: 0.9062\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2127 - accuracy: 0.9033 - val_loss: 0.2133 - val_accuracy: 0.9049\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2115 - accuracy: 0.9041 - val_loss: 0.2093 - val_accuracy: 0.9079\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2108 - accuracy: 0.9041 - val_loss: 0.2075 - val_accuracy: 0.9079\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2123 - accuracy: 0.9040 - val_loss: 0.2079 - val_accuracy: 0.9076\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2152 - accuracy: 0.9009 - val_loss: 0.2134 - val_accuracy: 0.9070\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2126 - accuracy: 0.9033 - val_loss: 0.2069 - val_accuracy: 0.9082\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2130 - accuracy: 0.9031 - val_loss: 0.2117 - val_accuracy: 0.9064\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2129 - accuracy: 0.9027 - val_loss: 0.2116 - val_accuracy: 0.9062\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.2118 - accuracy: 0.9037 - val_loss: 0.2084 - val_accuracy: 0.9072\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.2126 - accuracy: 0.9037 - val_loss: 0.2108 - val_accuracy: 0.9064\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.2112 - accuracy: 0.9044 - val_loss: 0.2102 - val_accuracy: 0.9073\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 211s 2ms/step - loss: 0.2105 - accuracy: 0.9046 - val_loss: 0.2102 - val_accuracy: 0.9047\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.2100 - accuracy: 0.9043 - val_loss: 0.2096 - val_accuracy: 0.9068\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 214s 2ms/step - loss: 0.2106 - accuracy: 0.9047 - val_loss: 0.2079 - val_accuracy: 0.9083\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.2120 - accuracy: 0.9034 - val_loss: 0.2066 - val_accuracy: 0.9080\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.2107 - accuracy: 0.9047 - val_loss: 0.2086 - val_accuracy: 0.9072\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2087 - accuracy: 0.9051 - val_loss: 0.2080 - val_accuracy: 0.9084\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2089 - accuracy: 0.9048 - val_loss: 0.2127 - val_accuracy: 0.9048\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2087 - accuracy: 0.9052 - val_loss: 0.2088 - val_accuracy: 0.9075\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2093 - accuracy: 0.9045 - val_loss: 0.2115 - val_accuracy: 0.9065\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2125 - accuracy: 0.9048 - val_loss: 0.2083 - val_accuracy: 0.9078\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2086 - accuracy: 0.9055 - val_loss: 0.2100 - val_accuracy: 0.9082\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2114 - accuracy: 0.9049 - val_loss: 0.2078 - val_accuracy: 0.9092\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2092 - accuracy: 0.9054 - val_loss: 0.2097 - val_accuracy: 0.9079\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2087 - accuracy: 0.9056 - val_loss: 0.2106 - val_accuracy: 0.9069\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2082 - accuracy: 0.9055 - val_loss: 0.2067 - val_accuracy: 0.9098\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2080 - accuracy: 0.9056 - val_loss: 0.2112 - val_accuracy: 0.9061\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2087 - accuracy: 0.9058 - val_loss: 0.2089 - val_accuracy: 0.9081\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2087 - accuracy: 0.9053 - val_loss: 0.2080 - val_accuracy: 0.9079\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2077 - accuracy: 0.9058 - val_loss: 0.2066 - val_accuracy: 0.9090\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2093 - accuracy: 0.9053 - val_loss: 0.2235 - val_accuracy: 0.9054\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2135 - accuracy: 0.9048 - val_loss: 0.2102 - val_accuracy: 0.9086\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2077 - accuracy: 0.9059 - val_loss: 0.2066 - val_accuracy: 0.9096\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2083 - accuracy: 0.9055 - val_loss: 0.2117 - val_accuracy: 0.9046\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2091 - accuracy: 0.9053 - val_loss: 0.2070 - val_accuracy: 0.9086\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2076 - accuracy: 0.9060 - val_loss: 0.2094 - val_accuracy: 0.9074\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2069 - accuracy: 0.9059 - val_loss: 0.2055 - val_accuracy: 0.9097\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2062 - accuracy: 0.9065 - val_loss: 0.2060 - val_accuracy: 0.9085\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2053 - accuracy: 0.9065 - val_loss: 0.2072 - val_accuracy: 0.9089\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2083 - accuracy: 0.9049 - val_loss: 0.2096 - val_accuracy: 0.9079\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2068 - accuracy: 0.9060 - val_loss: 0.2118 - val_accuracy: 0.9029\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2096 - accuracy: 0.9048 - val_loss: 0.2141 - val_accuracy: 0.9072\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2083 - accuracy: 0.9058 - val_loss: 0.2080 - val_accuracy: 0.9081\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2075 - accuracy: 0.9056 - val_loss: 0.2080 - val_accuracy: 0.9081\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2065 - accuracy: 0.9062 - val_loss: 0.2060 - val_accuracy: 0.9097\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2065 - accuracy: 0.9062 - val_loss: 0.2099 - val_accuracy: 0.9076\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2058 - accuracy: 0.9064 - val_loss: 0.2102 - val_accuracy: 0.9069\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2049 - accuracy: 0.9067 - val_loss: 0.2126 - val_accuracy: 0.9059\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2101 - accuracy: 0.9048 - val_loss: 0.2088 - val_accuracy: 0.9082\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2073 - accuracy: 0.9059 - val_loss: 0.2084 - val_accuracy: 0.9081\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2066 - accuracy: 0.9062 - val_loss: 0.2064 - val_accuracy: 0.9092\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2051 - accuracy: 0.9066 - val_loss: 0.2111 - val_accuracy: 0.9063\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2067 - accuracy: 0.9060 - val_loss: 0.2079 - val_accuracy: 0.9075\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2054 - accuracy: 0.9066 - val_loss: 0.2090 - val_accuracy: 0.9085\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2051 - accuracy: 0.9064 - val_loss: 0.2089 - val_accuracy: 0.9076\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2063 - accuracy: 0.9062 - val_loss: 0.2098 - val_accuracy: 0.9077\n",
      "accuracy: 90.77%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2064 - accuracy: 0.9064 - val_loss: 0.2306 - val_accuracy: 0.8942\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2075 - accuracy: 0.9057 - val_loss: 0.2067 - val_accuracy: 0.9071\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2065 - accuracy: 0.9064 - val_loss: 0.2030 - val_accuracy: 0.9081\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2042 - accuracy: 0.9072 - val_loss: 0.2037 - val_accuracy: 0.9071\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2043 - accuracy: 0.9072 - val_loss: 0.2053 - val_accuracy: 0.9085\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2068 - accuracy: 0.9065 - val_loss: 0.2074 - val_accuracy: 0.9064\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2067 - accuracy: 0.9054 - val_loss: 0.2069 - val_accuracy: 0.9059\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2068 - accuracy: 0.9059 - val_loss: 0.2057 - val_accuracy: 0.9077\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2061 - accuracy: 0.9058 - val_loss: 0.2101 - val_accuracy: 0.9059\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2084 - accuracy: 0.9057 - val_loss: 0.2045 - val_accuracy: 0.9070\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2075 - accuracy: 0.9057 - val_loss: 0.2055 - val_accuracy: 0.9079\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2069 - accuracy: 0.9059 - val_loss: 0.2091 - val_accuracy: 0.9071\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2077 - accuracy: 0.9052 - val_loss: 0.2058 - val_accuracy: 0.9069\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2178 - accuracy: 0.9022 - val_loss: 0.3048 - val_accuracy: 0.8731\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2631 - accuracy: 0.8913 - val_loss: 0.2214 - val_accuracy: 0.9054\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2215 - accuracy: 0.9038 - val_loss: 0.2167 - val_accuracy: 0.9058\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2164 - accuracy: 0.9048 - val_loss: 0.2202 - val_accuracy: 0.9063\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2160 - accuracy: 0.9053 - val_loss: 0.2204 - val_accuracy: 0.9053\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2123 - accuracy: 0.9063 - val_loss: 0.2136 - val_accuracy: 0.9066\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2121 - accuracy: 0.9063 - val_loss: 0.2136 - val_accuracy: 0.9071\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2099 - accuracy: 0.9061 - val_loss: 0.2073 - val_accuracy: 0.9070\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2090 - accuracy: 0.9070 - val_loss: 0.2072 - val_accuracy: 0.9074\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2104 - accuracy: 0.9064 - val_loss: 0.2082 - val_accuracy: 0.9071\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2104 - accuracy: 0.9068 - val_loss: 0.2084 - val_accuracy: 0.9069\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2087 - accuracy: 0.9068 - val_loss: 0.2087 - val_accuracy: 0.9058\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2083 - accuracy: 0.9072 - val_loss: 0.2111 - val_accuracy: 0.9058\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2073 - accuracy: 0.9074 - val_loss: 0.2058 - val_accuracy: 0.9083\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2071 - accuracy: 0.9074 - val_loss: 0.2086 - val_accuracy: 0.9066\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2079 - accuracy: 0.9072 - val_loss: 0.2110 - val_accuracy: 0.9060\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2062 - accuracy: 0.9081 - val_loss: 0.2158 - val_accuracy: 0.9078\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2114 - accuracy: 0.9044 - val_loss: 0.2130 - val_accuracy: 0.9051\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2067 - accuracy: 0.9071 - val_loss: 0.2053 - val_accuracy: 0.9072\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2065 - accuracy: 0.9079 - val_loss: 0.2093 - val_accuracy: 0.9062\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2120 - accuracy: 0.9044 - val_loss: 0.2087 - val_accuracy: 0.9072\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2194 - accuracy: 0.9024 - val_loss: 0.2125 - val_accuracy: 0.9072\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2094 - accuracy: 0.9067 - val_loss: 0.2218 - val_accuracy: 0.9054\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2079 - accuracy: 0.9074 - val_loss: 0.2080 - val_accuracy: 0.9070\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2065 - accuracy: 0.9080 - val_loss: 0.2052 - val_accuracy: 0.9082\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2058 - accuracy: 0.9081 - val_loss: 0.2070 - val_accuracy: 0.9077\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2109 - accuracy: 0.9062 - val_loss: 0.2055 - val_accuracy: 0.9085\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.2106 - accuracy: 0.9060 - val_loss: 0.2325 - val_accuracy: 0.8921\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2123 - accuracy: 0.9038 - val_loss: 0.2558 - val_accuracy: 0.8865\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.2087 - accuracy: 0.9070 - val_loss: 0.2099 - val_accuracy: 0.9062\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2059 - accuracy: 0.9077 - val_loss: 0.2064 - val_accuracy: 0.9081\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2056 - accuracy: 0.9080 - val_loss: 0.2056 - val_accuracy: 0.9073\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2095 - accuracy: 0.9062 - val_loss: 0.2054 - val_accuracy: 0.9076\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2056 - accuracy: 0.9077 - val_loss: 0.2054 - val_accuracy: 0.9082\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2089 - accuracy: 0.9070 - val_loss: 0.2066 - val_accuracy: 0.9076\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2039 - accuracy: 0.9077 - val_loss: 0.2110 - val_accuracy: 0.9061\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2038 - accuracy: 0.9071 - val_loss: 0.2080 - val_accuracy: 0.9070\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2289 - accuracy: 0.9012 - val_loss: 0.2291 - val_accuracy: 0.9059\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2081 - accuracy: 0.9079 - val_loss: 0.2090 - val_accuracy: 0.9056\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2077 - accuracy: 0.9058 - val_loss: 0.2047 - val_accuracy: 0.9078\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2012 - accuracy: 0.9089 - val_loss: 0.2043 - val_accuracy: 0.9084\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2150 - accuracy: 0.9004 - val_loss: 0.2316 - val_accuracy: 0.8908\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2202 - accuracy: 0.8994 - val_loss: 0.2311 - val_accuracy: 0.8914\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2256 - accuracy: 0.8974 - val_loss: 0.2171 - val_accuracy: 0.9036\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2170 - accuracy: 0.9019 - val_loss: 0.2119 - val_accuracy: 0.9037\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2138 - accuracy: 0.9034 - val_loss: 0.2192 - val_accuracy: 0.9053\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2124 - accuracy: 0.9042 - val_loss: 0.2140 - val_accuracy: 0.9042\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2106 - accuracy: 0.9044 - val_loss: 0.2120 - val_accuracy: 0.9038\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2088 - accuracy: 0.9051 - val_loss: 0.2082 - val_accuracy: 0.9064\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2079 - accuracy: 0.9052 - val_loss: 0.2160 - val_accuracy: 0.9035\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2085 - accuracy: 0.9059 - val_loss: 0.2067 - val_accuracy: 0.9075\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2081 - accuracy: 0.9059 - val_loss: 0.2089 - val_accuracy: 0.9073\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2068 - accuracy: 0.9064 - val_loss: 0.2066 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2138 - accuracy: 0.9045 - val_loss: 0.2445 - val_accuracy: 0.9016\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2133 - accuracy: 0.9059 - val_loss: 0.2093 - val_accuracy: 0.9065\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2082 - accuracy: 0.9065 - val_loss: 0.2074 - val_accuracy: 0.9084\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2061 - accuracy: 0.9065 - val_loss: 0.2116 - val_accuracy: 0.9028\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2109 - accuracy: 0.9060 - val_loss: 0.2081 - val_accuracy: 0.9072\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2076 - accuracy: 0.9071 - val_loss: 0.2098 - val_accuracy: 0.9046\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2067 - accuracy: 0.9082 - val_loss: 0.2216 - val_accuracy: 0.8894\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2056 - accuracy: 0.9072 - val_loss: 0.2102 - val_accuracy: 0.9067\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2057 - accuracy: 0.9069 - val_loss: 0.2125 - val_accuracy: 0.9059\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2037 - accuracy: 0.9077 - val_loss: 0.2082 - val_accuracy: 0.9071\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2097 - accuracy: 0.9040 - val_loss: 0.2099 - val_accuracy: 0.9051\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2036 - accuracy: 0.9081 - val_loss: 0.2061 - val_accuracy: 0.9080\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2017 - accuracy: 0.9088 - val_loss: 0.2283 - val_accuracy: 0.9055\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2036 - accuracy: 0.9085 - val_loss: 0.2067 - val_accuracy: 0.9082\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2040 - accuracy: 0.9085 - val_loss: 0.2091 - val_accuracy: 0.9079\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2025 - accuracy: 0.9086 - val_loss: 0.2066 - val_accuracy: 0.9082\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2033 - accuracy: 0.9079 - val_loss: 0.2071 - val_accuracy: 0.9072\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2014 - accuracy: 0.9084 - val_loss: 0.2107 - val_accuracy: 0.9063\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2011 - accuracy: 0.9092 - val_loss: 0.2090 - val_accuracy: 0.9049\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2055 - accuracy: 0.9076 - val_loss: 0.2072 - val_accuracy: 0.9074\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2025 - accuracy: 0.9089 - val_loss: 0.2067 - val_accuracy: 0.9082\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2044 - accuracy: 0.9087 - val_loss: 0.2313 - val_accuracy: 0.9052\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2029 - accuracy: 0.9089 - val_loss: 0.2080 - val_accuracy: 0.9070\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2027 - accuracy: 0.9086 - val_loss: 0.2115 - val_accuracy: 0.9062\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2008 - accuracy: 0.9089 - val_loss: 0.2083 - val_accuracy: 0.9069\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2015 - accuracy: 0.9092 - val_loss: 0.2079 - val_accuracy: 0.9076\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2015 - accuracy: 0.9088 - val_loss: 0.2065 - val_accuracy: 0.9086\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1999 - accuracy: 0.9094 - val_loss: 0.2073 - val_accuracy: 0.9072\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2025 - accuracy: 0.9093 - val_loss: 0.2092 - val_accuracy: 0.9072\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2026 - accuracy: 0.9087 - val_loss: 0.2058 - val_accuracy: 0.9082\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2039 - accuracy: 0.9073 - val_loss: 0.2112 - val_accuracy: 0.9042\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2023 - accuracy: 0.9086 - val_loss: 0.2085 - val_accuracy: 0.9073\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2004 - accuracy: 0.9094 - val_loss: 0.2053 - val_accuracy: 0.9090\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2017 - accuracy: 0.9086 - val_loss: 0.2048 - val_accuracy: 0.9082\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2026 - accuracy: 0.9087 - val_loss: 0.2065 - val_accuracy: 0.9079\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2004 - accuracy: 0.9094 - val_loss: 0.2082 - val_accuracy: 0.9063\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2093 - accuracy: 0.9067 - val_loss: 0.2088 - val_accuracy: 0.9072\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2010 - accuracy: 0.9097 - val_loss: 0.2086 - val_accuracy: 0.9079\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2007 - accuracy: 0.9093 - val_loss: 0.2155 - val_accuracy: 0.9043\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2003 - accuracy: 0.9097 - val_loss: 0.2131 - val_accuracy: 0.9051\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2006 - accuracy: 0.9096 - val_loss: 0.2071 - val_accuracy: 0.9077\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1984 - accuracy: 0.9101 - val_loss: 0.2068 - val_accuracy: 0.9070\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.1991 - accuracy: 0.9099 - val_loss: 0.2079 - val_accuracy: 0.9087\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1987 - accuracy: 0.9104 - val_loss: 0.2091 - val_accuracy: 0.9065\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.2008 - accuracy: 0.9099 - val_loss: 0.2050 - val_accuracy: 0.9094\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1985 - accuracy: 0.9105 - val_loss: 0.2085 - val_accuracy: 0.9073\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1984 - accuracy: 0.9104 - val_loss: 0.2106 - val_accuracy: 0.9068\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1991 - accuracy: 0.9098 - val_loss: 0.2107 - val_accuracy: 0.9060\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.1987 - accuracy: 0.9103 - val_loss: 0.2130 - val_accuracy: 0.9050\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.2017 - accuracy: 0.9092 - val_loss: 0.2119 - val_accuracy: 0.9043\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1989 - accuracy: 0.9102 - val_loss: 0.2051 - val_accuracy: 0.9090\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1978 - accuracy: 0.9112 - val_loss: 0.2073 - val_accuracy: 0.9084\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1978 - accuracy: 0.9107 - val_loss: 0.2194 - val_accuracy: 0.9038\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2060 - accuracy: 0.9080 - val_loss: 0.2078 - val_accuracy: 0.9069\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1989 - accuracy: 0.9098 - val_loss: 0.2086 - val_accuracy: 0.9071\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1985 - accuracy: 0.9103 - val_loss: 0.2074 - val_accuracy: 0.9089\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2000 - accuracy: 0.9095 - val_loss: 0.2110 - val_accuracy: 0.9063\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1977 - accuracy: 0.9106 - val_loss: 0.2102 - val_accuracy: 0.9063\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1981 - accuracy: 0.9104 - val_loss: 0.2123 - val_accuracy: 0.9036\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1966 - accuracy: 0.9111 - val_loss: 0.2082 - val_accuracy: 0.9084\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1967 - accuracy: 0.9109 - val_loss: 0.2112 - val_accuracy: 0.9064\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1973 - accuracy: 0.9114 - val_loss: 0.2078 - val_accuracy: 0.9078\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1975 - accuracy: 0.9103 - val_loss: 0.2072 - val_accuracy: 0.9094\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1984 - accuracy: 0.9099 - val_loss: 0.2084 - val_accuracy: 0.9084\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2055 - accuracy: 0.9075 - val_loss: 0.2871 - val_accuracy: 0.8554\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2103 - accuracy: 0.9046 - val_loss: 0.2055 - val_accuracy: 0.9084\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1994 - accuracy: 0.9100 - val_loss: 0.2066 - val_accuracy: 0.9080\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1987 - accuracy: 0.9099 - val_loss: 0.2082 - val_accuracy: 0.9071\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1966 - accuracy: 0.9107 - val_loss: 0.2069 - val_accuracy: 0.9092\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1978 - accuracy: 0.9110 - val_loss: 0.2140 - val_accuracy: 0.9017\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1982 - accuracy: 0.9103 - val_loss: 0.2105 - val_accuracy: 0.9051\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1964 - accuracy: 0.9106 - val_loss: 0.2069 - val_accuracy: 0.9084\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1983 - accuracy: 0.9099 - val_loss: 0.2057 - val_accuracy: 0.9092\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1974 - accuracy: 0.9107 - val_loss: 0.2147 - val_accuracy: 0.9059\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1981 - accuracy: 0.9103 - val_loss: 0.2062 - val_accuracy: 0.9089\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1967 - accuracy: 0.9113 - val_loss: 0.2078 - val_accuracy: 0.9083\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1977 - accuracy: 0.9109 - val_loss: 0.2072 - val_accuracy: 0.9086\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1975 - accuracy: 0.9099 - val_loss: 0.2092 - val_accuracy: 0.9062\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2039 - accuracy: 0.9082 - val_loss: 0.2117 - val_accuracy: 0.9084\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1962 - accuracy: 0.9119 - val_loss: 0.2054 - val_accuracy: 0.9094\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1996 - accuracy: 0.9093 - val_loss: 0.2206 - val_accuracy: 0.8981\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1956 - accuracy: 0.9114 - val_loss: 0.2084 - val_accuracy: 0.9082\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1955 - accuracy: 0.9113 - val_loss: 0.2068 - val_accuracy: 0.9084\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1957 - accuracy: 0.9111 - val_loss: 0.2065 - val_accuracy: 0.9088\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1981 - accuracy: 0.9106 - val_loss: 0.2067 - val_accuracy: 0.9084\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1968 - accuracy: 0.9104 - val_loss: 0.2078 - val_accuracy: 0.9082\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1956 - accuracy: 0.9114 - val_loss: 0.2070 - val_accuracy: 0.9084\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1949 - accuracy: 0.9116 - val_loss: 0.2062 - val_accuracy: 0.9094\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1957 - accuracy: 0.9112 - val_loss: 0.2108 - val_accuracy: 0.9072\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1943 - accuracy: 0.9121 - val_loss: 0.2063 - val_accuracy: 0.9083\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1942 - accuracy: 0.9120 - val_loss: 0.2110 - val_accuracy: 0.9072\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1941 - accuracy: 0.9121 - val_loss: 0.2086 - val_accuracy: 0.9075\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1974 - accuracy: 0.9103 - val_loss: 0.2119 - val_accuracy: 0.9055\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.2100 - val_accuracy: 0.9062\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1954 - accuracy: 0.9113 - val_loss: 0.2081 - val_accuracy: 0.9077\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1945 - accuracy: 0.9122 - val_loss: 0.2089 - val_accuracy: 0.9074\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1946 - accuracy: 0.9117 - val_loss: 0.2074 - val_accuracy: 0.9073\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1958 - accuracy: 0.9113 - val_loss: 0.2092 - val_accuracy: 0.9078\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1965 - accuracy: 0.9111 - val_loss: 0.2119 - val_accuracy: 0.9056\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1944 - accuracy: 0.9124 - val_loss: 0.2088 - val_accuracy: 0.9069\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1953 - accuracy: 0.9117 - val_loss: 0.2074 - val_accuracy: 0.9083\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1950 - accuracy: 0.9113 - val_loss: 0.2122 - val_accuracy: 0.9035\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1998 - accuracy: 0.9087 - val_loss: 0.2091 - val_accuracy: 0.9056\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1958 - accuracy: 0.9103 - val_loss: 0.2071 - val_accuracy: 0.9074\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1954 - accuracy: 0.9112 - val_loss: 0.2072 - val_accuracy: 0.9086\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1956 - accuracy: 0.9111 - val_loss: 0.2080 - val_accuracy: 0.9073\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1948 - accuracy: 0.9116 - val_loss: 0.2075 - val_accuracy: 0.9062\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1948 - accuracy: 0.9114 - val_loss: 0.2067 - val_accuracy: 0.9084\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1941 - accuracy: 0.9121 - val_loss: 0.2110 - val_accuracy: 0.9074\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1938 - accuracy: 0.9122 - val_loss: 0.2106 - val_accuracy: 0.9073\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1946 - accuracy: 0.9115 - val_loss: 0.2080 - val_accuracy: 0.9075\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1945 - accuracy: 0.9115 - val_loss: 0.2085 - val_accuracy: 0.9068\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1962 - accuracy: 0.9107 - val_loss: 0.2067 - val_accuracy: 0.9081\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1953 - accuracy: 0.9111 - val_loss: 0.2104 - val_accuracy: 0.9074\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1957 - accuracy: 0.9116 - val_loss: 0.2088 - val_accuracy: 0.9076\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1952 - accuracy: 0.9109 - val_loss: 0.2090 - val_accuracy: 0.9063\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1933 - accuracy: 0.9119 - val_loss: 0.2065 - val_accuracy: 0.9089\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1934 - accuracy: 0.9116 - val_loss: 0.2074 - val_accuracy: 0.9085\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1963 - accuracy: 0.9105 - val_loss: 0.2088 - val_accuracy: 0.9076\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1963 - accuracy: 0.9108 - val_loss: 0.2094 - val_accuracy: 0.9079\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1958 - accuracy: 0.9112 - val_loss: 0.2079 - val_accuracy: 0.9074\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1960 - accuracy: 0.9105 - val_loss: 0.2060 - val_accuracy: 0.9081\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1956 - accuracy: 0.9109 - val_loss: 0.2063 - val_accuracy: 0.9089\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1949 - accuracy: 0.9113 - val_loss: 0.2098 - val_accuracy: 0.9075\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1938 - accuracy: 0.9120 - val_loss: 0.2123 - val_accuracy: 0.9062\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1958 - accuracy: 0.9107 - val_loss: 0.2069 - val_accuracy: 0.9082\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1933 - accuracy: 0.9116 - val_loss: 0.2094 - val_accuracy: 0.9073\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1936 - accuracy: 0.9119 - val_loss: 0.2064 - val_accuracy: 0.9077\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1940 - accuracy: 0.9113 - val_loss: 0.2062 - val_accuracy: 0.9086\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1962 - accuracy: 0.9111 - val_loss: 0.2092 - val_accuracy: 0.9080\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1953 - accuracy: 0.9116 - val_loss: 0.2072 - val_accuracy: 0.9080\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1936 - accuracy: 0.9116 - val_loss: 0.2152 - val_accuracy: 0.9050\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2165 - accuracy: 0.8997 - val_loss: 0.2443 - val_accuracy: 0.8821\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2025 - accuracy: 0.9073 - val_loss: 0.2194 - val_accuracy: 0.9038\n",
      "accuracy: 90.38%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2000 - accuracy: 0.9093 - val_loss: 0.1942 - val_accuracy: 0.9125\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1990 - accuracy: 0.9095 - val_loss: 0.1971 - val_accuracy: 0.9098\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1986 - accuracy: 0.9097 - val_loss: 0.1936 - val_accuracy: 0.9123\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1985 - accuracy: 0.9104 - val_loss: 0.1986 - val_accuracy: 0.9102\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2009 - accuracy: 0.9093 - val_loss: 0.1960 - val_accuracy: 0.9114\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1979 - accuracy: 0.9106 - val_loss: 0.2002 - val_accuracy: 0.9090\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1987 - accuracy: 0.9100 - val_loss: 0.1984 - val_accuracy: 0.9104\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1977 - accuracy: 0.9099 - val_loss: 0.2034 - val_accuracy: 0.9096\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1988 - accuracy: 0.9096 - val_loss: 0.2012 - val_accuracy: 0.9082\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1972 - accuracy: 0.9104 - val_loss: 0.1975 - val_accuracy: 0.9107\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1964 - accuracy: 0.9109 - val_loss: 0.2008 - val_accuracy: 0.9101\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1963 - accuracy: 0.9105 - val_loss: 0.1989 - val_accuracy: 0.9092\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1976 - accuracy: 0.9100 - val_loss: 0.2024 - val_accuracy: 0.9084\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1983 - accuracy: 0.9095 - val_loss: 0.2008 - val_accuracy: 0.9093\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1960 - accuracy: 0.9111 - val_loss: 0.2062 - val_accuracy: 0.9061\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2005 - accuracy: 0.9085 - val_loss: 0.1979 - val_accuracy: 0.9111\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1985 - accuracy: 0.9100 - val_loss: 0.2023 - val_accuracy: 0.9079\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1968 - accuracy: 0.9106 - val_loss: 0.1993 - val_accuracy: 0.9110\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1947 - accuracy: 0.9119 - val_loss: 0.2004 - val_accuracy: 0.9100\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1958 - accuracy: 0.9113 - val_loss: 0.2056 - val_accuracy: 0.9068\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1962 - accuracy: 0.9105 - val_loss: 0.1996 - val_accuracy: 0.9110\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1966 - accuracy: 0.9106 - val_loss: 0.2044 - val_accuracy: 0.9062\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1941 - accuracy: 0.9115 - val_loss: 0.2012 - val_accuracy: 0.9095\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1946 - accuracy: 0.9122 - val_loss: 0.1975 - val_accuracy: 0.9109\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1947 - accuracy: 0.9116 - val_loss: 0.2008 - val_accuracy: 0.9095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1949 - accuracy: 0.9115 - val_loss: 0.1985 - val_accuracy: 0.9107\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1997 - accuracy: 0.9086 - val_loss: 0.1990 - val_accuracy: 0.9100\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1947 - accuracy: 0.9116 - val_loss: 0.1999 - val_accuracy: 0.9097\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1938 - accuracy: 0.9114 - val_loss: 0.1992 - val_accuracy: 0.9113\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1952 - accuracy: 0.9115 - val_loss: 0.2050 - val_accuracy: 0.9068\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1993 - accuracy: 0.9104 - val_loss: 0.2029 - val_accuracy: 0.9097\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1976 - accuracy: 0.9105 - val_loss: 0.2002 - val_accuracy: 0.9095\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1964 - accuracy: 0.9109 - val_loss: 0.2038 - val_accuracy: 0.9094\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1965 - accuracy: 0.9113 - val_loss: 0.2029 - val_accuracy: 0.9103\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1970 - accuracy: 0.9109 - val_loss: 0.2020 - val_accuracy: 0.9090\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1949 - accuracy: 0.9120 - val_loss: 0.2083 - val_accuracy: 0.9054\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1962 - accuracy: 0.9109 - val_loss: 0.2008 - val_accuracy: 0.9102\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1972 - accuracy: 0.9110 - val_loss: 0.2010 - val_accuracy: 0.9103\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1952 - accuracy: 0.9119 - val_loss: 0.1990 - val_accuracy: 0.9108\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1953 - accuracy: 0.9119 - val_loss: 0.2056 - val_accuracy: 0.9082\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1941 - accuracy: 0.9117 - val_loss: 0.1982 - val_accuracy: 0.9106\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1938 - accuracy: 0.9115 - val_loss: 0.1989 - val_accuracy: 0.9106\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1956 - accuracy: 0.9113 - val_loss: 0.2020 - val_accuracy: 0.9088\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1935 - accuracy: 0.9121 - val_loss: 0.2032 - val_accuracy: 0.9085\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1929 - accuracy: 0.9125 - val_loss: 0.2012 - val_accuracy: 0.9098\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1961 - accuracy: 0.9112 - val_loss: 0.2048 - val_accuracy: 0.9082\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1921 - accuracy: 0.9129 - val_loss: 0.1985 - val_accuracy: 0.9113\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1943 - accuracy: 0.9120 - val_loss: 0.2071 - val_accuracy: 0.9088\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1937 - accuracy: 0.9123 - val_loss: 0.2031 - val_accuracy: 0.9089\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1952 - accuracy: 0.9114 - val_loss: 0.1996 - val_accuracy: 0.9117\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1973 - accuracy: 0.9104 - val_loss: 0.2021 - val_accuracy: 0.9096\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1957 - accuracy: 0.9111 - val_loss: 0.1997 - val_accuracy: 0.9102\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1936 - accuracy: 0.9123 - val_loss: 0.2034 - val_accuracy: 0.9086\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1942 - accuracy: 0.9115 - val_loss: 0.1998 - val_accuracy: 0.9092\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1929 - accuracy: 0.9120 - val_loss: 0.2019 - val_accuracy: 0.9083\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1922 - accuracy: 0.9122 - val_loss: 0.2105 - val_accuracy: 0.9054\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1960 - accuracy: 0.9116 - val_loss: 0.1999 - val_accuracy: 0.9109\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1949 - accuracy: 0.9115 - val_loss: 0.2007 - val_accuracy: 0.9107\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.2001 - val_accuracy: 0.9099\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1922 - accuracy: 0.9126 - val_loss: 0.2039 - val_accuracy: 0.9090\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1950 - accuracy: 0.9115 - val_loss: 0.2023 - val_accuracy: 0.9091\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1944 - accuracy: 0.9115 - val_loss: 0.2011 - val_accuracy: 0.9089\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1939 - accuracy: 0.9119 - val_loss: 0.2025 - val_accuracy: 0.9104\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1929 - accuracy: 0.9122 - val_loss: 0.2039 - val_accuracy: 0.9084\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1942 - accuracy: 0.9123 - val_loss: 0.2065 - val_accuracy: 0.9071\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1942 - accuracy: 0.9116 - val_loss: 0.2099 - val_accuracy: 0.9052\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1943 - accuracy: 0.9115 - val_loss: 0.2075 - val_accuracy: 0.9063\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1956 - accuracy: 0.9112 - val_loss: 0.2024 - val_accuracy: 0.9094\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1953 - accuracy: 0.9113 - val_loss: 0.2025 - val_accuracy: 0.9098\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1940 - accuracy: 0.9123 - val_loss: 0.2045 - val_accuracy: 0.9077\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1959 - accuracy: 0.9109 - val_loss: 0.2037 - val_accuracy: 0.9079\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1941 - accuracy: 0.9119 - val_loss: 0.2014 - val_accuracy: 0.9106\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1935 - accuracy: 0.9121 - val_loss: 0.2013 - val_accuracy: 0.9098\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1934 - accuracy: 0.9123 - val_loss: 0.2226 - val_accuracy: 0.9005\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1932 - accuracy: 0.9125 - val_loss: 0.2009 - val_accuracy: 0.9097\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1932 - accuracy: 0.9120 - val_loss: 0.2043 - val_accuracy: 0.9090\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1924 - accuracy: 0.9130 - val_loss: 0.2023 - val_accuracy: 0.9096\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2030 - accuracy: 0.9092 - val_loss: 0.2078 - val_accuracy: 0.9074\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2010 - accuracy: 0.9110 - val_loss: 0.2092 - val_accuracy: 0.9070\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1972 - accuracy: 0.9115 - val_loss: 0.2062 - val_accuracy: 0.9086\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2072 - accuracy: 0.9081 - val_loss: 0.2064 - val_accuracy: 0.9090\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1972 - accuracy: 0.9114 - val_loss: 0.2235 - val_accuracy: 0.9023\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2347 - accuracy: 0.8932 - val_loss: 0.2327 - val_accuracy: 0.8935\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2117 - accuracy: 0.9054 - val_loss: 0.2110 - val_accuracy: 0.9066\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2095 - accuracy: 0.9068 - val_loss: 0.2054 - val_accuracy: 0.9084\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2005 - accuracy: 0.9102 - val_loss: 0.2058 - val_accuracy: 0.9089\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1984 - accuracy: 0.9108 - val_loss: 0.2044 - val_accuracy: 0.9088\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2045 - accuracy: 0.9086 - val_loss: 0.2078 - val_accuracy: 0.9063\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1974 - accuracy: 0.9111 - val_loss: 0.2024 - val_accuracy: 0.9099\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1988 - accuracy: 0.9110 - val_loss: 0.2085 - val_accuracy: 0.9089\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1954 - accuracy: 0.9129 - val_loss: 0.2061 - val_accuracy: 0.9086\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1977 - accuracy: 0.9106 - val_loss: 0.2051 - val_accuracy: 0.9092\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1946 - accuracy: 0.9121 - val_loss: 0.2043 - val_accuracy: 0.9086\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1968 - accuracy: 0.9109 - val_loss: 0.2023 - val_accuracy: 0.9103\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1938 - accuracy: 0.9129 - val_loss: 0.2048 - val_accuracy: 0.9076\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1953 - accuracy: 0.9117 - val_loss: 0.2048 - val_accuracy: 0.9096\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2130 - accuracy: 0.9045 - val_loss: 0.2228 - val_accuracy: 0.9050\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1979 - accuracy: 0.9115 - val_loss: 0.2078 - val_accuracy: 0.9082\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2003 - accuracy: 0.9098 - val_loss: 0.2054 - val_accuracy: 0.9097\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1968 - accuracy: 0.9117 - val_loss: 0.2045 - val_accuracy: 0.9098\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1958 - accuracy: 0.9113 - val_loss: 0.2066 - val_accuracy: 0.9083\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1934 - accuracy: 0.9126 - val_loss: 0.2070 - val_accuracy: 0.9076\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1944 - accuracy: 0.9121 - val_loss: 0.2040 - val_accuracy: 0.9095\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1954 - accuracy: 0.9116 - val_loss: 0.2044 - val_accuracy: 0.9092\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.2077 - val_accuracy: 0.9064\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1934 - accuracy: 0.9124 - val_loss: 0.2039 - val_accuracy: 0.9093\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1927 - accuracy: 0.9126 - val_loss: 0.2039 - val_accuracy: 0.9095\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1951 - accuracy: 0.9117 - val_loss: 0.2083 - val_accuracy: 0.9079\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1951 - accuracy: 0.9113 - val_loss: 0.2028 - val_accuracy: 0.9095\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1999 - accuracy: 0.9100 - val_loss: 0.2028 - val_accuracy: 0.9094\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1930 - accuracy: 0.9122 - val_loss: 0.2044 - val_accuracy: 0.9094\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1941 - accuracy: 0.9121 - val_loss: 0.2032 - val_accuracy: 0.9092\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.2016 - val_accuracy: 0.9099\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1941 - accuracy: 0.9119 - val_loss: 0.2075 - val_accuracy: 0.9074\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1965 - accuracy: 0.9113 - val_loss: 0.2040 - val_accuracy: 0.9089\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1935 - accuracy: 0.9122 - val_loss: 0.2062 - val_accuracy: 0.9095\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1955 - accuracy: 0.9117 - val_loss: 0.2756 - val_accuracy: 0.9054\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1936 - accuracy: 0.9120 - val_loss: 0.2044 - val_accuracy: 0.9092\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1931 - accuracy: 0.9119 - val_loss: 0.2053 - val_accuracy: 0.9080\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1935 - accuracy: 0.9120 - val_loss: 0.2049 - val_accuracy: 0.9086\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1928 - accuracy: 0.9124 - val_loss: 0.2057 - val_accuracy: 0.9090\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1937 - accuracy: 0.9121 - val_loss: 0.2088 - val_accuracy: 0.9056\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1955 - accuracy: 0.9111 - val_loss: 0.2226 - val_accuracy: 0.8941\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1951 - accuracy: 0.9122 - val_loss: 0.2041 - val_accuracy: 0.9100\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1928 - accuracy: 0.9125 - val_loss: 0.2059 - val_accuracy: 0.9088\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1930 - accuracy: 0.9123 - val_loss: 0.2030 - val_accuracy: 0.9097\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2038 - accuracy: 0.9073 - val_loss: 0.2038 - val_accuracy: 0.9098\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1927 - accuracy: 0.9124 - val_loss: 0.2045 - val_accuracy: 0.9095\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1934 - accuracy: 0.9119 - val_loss: 0.2045 - val_accuracy: 0.9094\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1956 - accuracy: 0.9106 - val_loss: 0.2064 - val_accuracy: 0.9077\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1927 - accuracy: 0.9126 - val_loss: 0.2033 - val_accuracy: 0.9086\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1953 - accuracy: 0.9118 - val_loss: 0.2381 - val_accuracy: 0.8904\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1950 - accuracy: 0.9119 - val_loss: 0.2036 - val_accuracy: 0.9097\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1921 - accuracy: 0.9127 - val_loss: 0.2026 - val_accuracy: 0.9098\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1986 - accuracy: 0.9100 - val_loss: 0.2035 - val_accuracy: 0.9095\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1978 - accuracy: 0.9104 - val_loss: 0.2151 - val_accuracy: 0.9049\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1956 - accuracy: 0.9114 - val_loss: 0.2074 - val_accuracy: 0.9072\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1974 - accuracy: 0.9107 - val_loss: 0.2106 - val_accuracy: 0.9065\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1934 - accuracy: 0.9128 - val_loss: 0.2041 - val_accuracy: 0.9095\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1967 - accuracy: 0.9113 - val_loss: 0.2124 - val_accuracy: 0.9053\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2270 - accuracy: 0.8944 - val_loss: 0.2429 - val_accuracy: 0.8825\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2335 - accuracy: 0.8897 - val_loss: 0.2984 - val_accuracy: 0.8802\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2319 - accuracy: 0.8931 - val_loss: 0.2261 - val_accuracy: 0.8970\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2221 - accuracy: 0.8997 - val_loss: 0.2205 - val_accuracy: 0.9018\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2222 - accuracy: 0.8994 - val_loss: 0.2206 - val_accuracy: 0.9007\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2147 - accuracy: 0.9038 - val_loss: 0.2162 - val_accuracy: 0.9032\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2132 - accuracy: 0.9042 - val_loss: 0.2128 - val_accuracy: 0.9045\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2099 - accuracy: 0.9054 - val_loss: 0.2112 - val_accuracy: 0.9043\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2096 - accuracy: 0.9053 - val_loss: 0.2122 - val_accuracy: 0.9052\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2057 - accuracy: 0.9066 - val_loss: 0.2073 - val_accuracy: 0.9061\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2025 - accuracy: 0.9084 - val_loss: 0.2049 - val_accuracy: 0.9088\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2023 - accuracy: 0.9083 - val_loss: 0.2061 - val_accuracy: 0.9070\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2006 - accuracy: 0.9091 - val_loss: 0.2076 - val_accuracy: 0.9063\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1993 - accuracy: 0.9098 - val_loss: 0.2123 - val_accuracy: 0.9013\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1975 - accuracy: 0.9104 - val_loss: 0.2074 - val_accuracy: 0.9070\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1983 - accuracy: 0.9100 - val_loss: 0.2061 - val_accuracy: 0.9080\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1961 - accuracy: 0.9109 - val_loss: 0.2227 - val_accuracy: 0.8966\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1956 - accuracy: 0.9109 - val_loss: 0.2074 - val_accuracy: 0.9062\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1976 - accuracy: 0.9105 - val_loss: 0.2074 - val_accuracy: 0.9078\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1991 - accuracy: 0.9095 - val_loss: 0.2081 - val_accuracy: 0.9057\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1963 - accuracy: 0.9110 - val_loss: 0.2034 - val_accuracy: 0.9091\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1956 - accuracy: 0.9113 - val_loss: 0.2041 - val_accuracy: 0.9093\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1955 - accuracy: 0.9113 - val_loss: 0.2063 - val_accuracy: 0.9091\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1957 - accuracy: 0.9107 - val_loss: 0.2051 - val_accuracy: 0.9088\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1945 - accuracy: 0.9116 - val_loss: 0.2046 - val_accuracy: 0.9092\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1954 - accuracy: 0.9117 - val_loss: 0.2092 - val_accuracy: 0.9059\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1947 - accuracy: 0.9119 - val_loss: 0.2054 - val_accuracy: 0.9080\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1958 - accuracy: 0.9109 - val_loss: 0.2044 - val_accuracy: 0.9076\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1940 - accuracy: 0.9117 - val_loss: 0.2132 - val_accuracy: 0.9044\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1951 - accuracy: 0.9115 - val_loss: 0.2061 - val_accuracy: 0.9082\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1947 - accuracy: 0.9117 - val_loss: 0.2076 - val_accuracy: 0.9071\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1943 - accuracy: 0.9120 - val_loss: 0.2049 - val_accuracy: 0.9093\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1928 - accuracy: 0.9123 - val_loss: 0.2037 - val_accuracy: 0.9095\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1942 - accuracy: 0.9116 - val_loss: 0.2038 - val_accuracy: 0.9086\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1994 - accuracy: 0.9094 - val_loss: 0.2096 - val_accuracy: 0.9072\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1977 - accuracy: 0.9096 - val_loss: 0.2075 - val_accuracy: 0.9076\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1965 - accuracy: 0.9103 - val_loss: 0.2105 - val_accuracy: 0.9048\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1928 - accuracy: 0.9125 - val_loss: 0.2045 - val_accuracy: 0.9094\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1988 - accuracy: 0.9103 - val_loss: 0.2042 - val_accuracy: 0.9097\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1928 - accuracy: 0.9125 - val_loss: 0.2051 - val_accuracy: 0.9093\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1940 - accuracy: 0.9119 - val_loss: 0.2044 - val_accuracy: 0.9105\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1927 - accuracy: 0.9121 - val_loss: 0.2063 - val_accuracy: 0.9065\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1928 - accuracy: 0.9124 - val_loss: 0.2042 - val_accuracy: 0.9095\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1975 - accuracy: 0.9105 - val_loss: 0.2088 - val_accuracy: 0.9054\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1936 - accuracy: 0.9119 - val_loss: 0.2052 - val_accuracy: 0.9088\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1938 - accuracy: 0.9122 - val_loss: 0.2059 - val_accuracy: 0.9084\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1932 - accuracy: 0.9122 - val_loss: 0.2038 - val_accuracy: 0.9087\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1948 - accuracy: 0.9122 - val_loss: 0.2058 - val_accuracy: 0.9088\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1916 - accuracy: 0.9135 - val_loss: 0.2067 - val_accuracy: 0.9077\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1946 - accuracy: 0.9112 - val_loss: 0.2030 - val_accuracy: 0.9100\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1938 - accuracy: 0.9114 - val_loss: 0.2035 - val_accuracy: 0.9093\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.1937 - accuracy: 0.9117 - val_loss: 0.2034 - val_accuracy: 0.9088\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1918 - accuracy: 0.9121 - val_loss: 0.2071 - val_accuracy: 0.9092\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1919 - accuracy: 0.9126 - val_loss: 0.2025 - val_accuracy: 0.9107\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1952 - accuracy: 0.9116 - val_loss: 0.2023 - val_accuracy: 0.9110\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1959 - accuracy: 0.9116 - val_loss: 0.2062 - val_accuracy: 0.9077\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1924 - accuracy: 0.9127 - val_loss: 0.2088 - val_accuracy: 0.9071\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1933 - accuracy: 0.9122 - val_loss: 0.2092 - val_accuracy: 0.9078\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1925 - accuracy: 0.9128 - val_loss: 0.2086 - val_accuracy: 0.9073\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1920 - accuracy: 0.9132 - val_loss: 0.2063 - val_accuracy: 0.9094\n",
      "accuracy: 90.94%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1994 - accuracy: 0.9104 - val_loss: 0.1978 - val_accuracy: 0.9103\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1966 - accuracy: 0.9119 - val_loss: 0.2025 - val_accuracy: 0.9082\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1983 - accuracy: 0.9104 - val_loss: 0.2001 - val_accuracy: 0.9079\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1972 - accuracy: 0.9103 - val_loss: 0.1946 - val_accuracy: 0.9103\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1974 - accuracy: 0.9105 - val_loss: 0.1948 - val_accuracy: 0.9113\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1957 - accuracy: 0.9117 - val_loss: 0.1944 - val_accuracy: 0.9112\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1961 - accuracy: 0.9115 - val_loss: 0.2001 - val_accuracy: 0.9098\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1960 - accuracy: 0.9113 - val_loss: 0.1977 - val_accuracy: 0.9088\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1955 - accuracy: 0.9111 - val_loss: 0.1969 - val_accuracy: 0.9114\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1953 - accuracy: 0.9121 - val_loss: 0.1960 - val_accuracy: 0.9111\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1990 - accuracy: 0.9093 - val_loss: 0.2004 - val_accuracy: 0.9082\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1988 - accuracy: 0.9092 - val_loss: 0.2006 - val_accuracy: 0.9098\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1963 - accuracy: 0.9110 - val_loss: 0.2001 - val_accuracy: 0.9095\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1947 - accuracy: 0.9118 - val_loss: 0.1954 - val_accuracy: 0.9110\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1960 - accuracy: 0.9114 - val_loss: 0.1978 - val_accuracy: 0.9097\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1948 - accuracy: 0.9117 - val_loss: 0.1983 - val_accuracy: 0.9089\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1952 - accuracy: 0.9117 - val_loss: 0.2032 - val_accuracy: 0.9068\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1961 - accuracy: 0.9107 - val_loss: 0.1969 - val_accuracy: 0.9099\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2052 - accuracy: 0.9065 - val_loss: 0.2078 - val_accuracy: 0.9062\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1986 - accuracy: 0.9098 - val_loss: 0.2019 - val_accuracy: 0.9083\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2014 - accuracy: 0.9090 - val_loss: 0.1983 - val_accuracy: 0.9097\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1981 - accuracy: 0.9102 - val_loss: 0.2013 - val_accuracy: 0.9086\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2168 - accuracy: 0.9067 - val_loss: 0.2335 - val_accuracy: 0.9030\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1999 - accuracy: 0.9101 - val_loss: 0.2041 - val_accuracy: 0.9079\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1964 - accuracy: 0.9111 - val_loss: 0.2066 - val_accuracy: 0.9066\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1950 - accuracy: 0.9118 - val_loss: 0.2052 - val_accuracy: 0.9069\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1954 - accuracy: 0.9116 - val_loss: 0.1970 - val_accuracy: 0.9108\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1959 - accuracy: 0.9111 - val_loss: 0.1998 - val_accuracy: 0.9101\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1941 - accuracy: 0.9116 - val_loss: 0.2049 - val_accuracy: 0.9072\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1948 - accuracy: 0.9117 - val_loss: 0.2104 - val_accuracy: 0.9065\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1945 - accuracy: 0.9117 - val_loss: 0.1987 - val_accuracy: 0.9103\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1939 - accuracy: 0.9119 - val_loss: 0.2004 - val_accuracy: 0.9077\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1948 - accuracy: 0.9118 - val_loss: 0.1990 - val_accuracy: 0.9097\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1973 - accuracy: 0.9106 - val_loss: 0.2085 - val_accuracy: 0.9029\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.2003 - accuracy: 0.9107 - val_loss: 0.2082 - val_accuracy: 0.9063\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1971 - accuracy: 0.9103 - val_loss: 0.2032 - val_accuracy: 0.9076\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1965 - accuracy: 0.9110 - val_loss: 0.2157 - val_accuracy: 0.8996\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1975 - accuracy: 0.9111 - val_loss: 0.1978 - val_accuracy: 0.9108\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.1981 - accuracy: 0.9103 - val_loss: 0.2340 - val_accuracy: 0.8921\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1961 - accuracy: 0.9110 - val_loss: 0.2002 - val_accuracy: 0.9100\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1944 - accuracy: 0.9117 - val_loss: 0.1999 - val_accuracy: 0.9100\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.1949 - accuracy: 0.9117 - val_loss: 0.2021 - val_accuracy: 0.9095\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1937 - accuracy: 0.9121 - val_loss: 0.2070 - val_accuracy: 0.9035\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1941 - accuracy: 0.9117 - val_loss: 0.2001 - val_accuracy: 0.9086\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1930 - accuracy: 0.9122 - val_loss: 0.2146 - val_accuracy: 0.9034\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2003 - accuracy: 0.9078 - val_loss: 0.2031 - val_accuracy: 0.9072\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1942 - accuracy: 0.9119 - val_loss: 0.2229 - val_accuracy: 0.9059\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1939 - accuracy: 0.9117 - val_loss: 0.2031 - val_accuracy: 0.9092\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1935 - accuracy: 0.9125 - val_loss: 0.2049 - val_accuracy: 0.9087\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1939 - accuracy: 0.9123 - val_loss: 0.2015 - val_accuracy: 0.9098\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2126 - accuracy: 0.9019 - val_loss: 0.2276 - val_accuracy: 0.8962\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 201s 1ms/step - loss: 0.2125 - accuracy: 0.9046 - val_loss: 0.2884 - val_accuracy: 0.8791\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2611 - accuracy: 0.8916 - val_loss: 0.2556 - val_accuracy: 0.8964\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2378 - accuracy: 0.9024 - val_loss: 0.2754 - val_accuracy: 0.8941\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2212 - accuracy: 0.9063 - val_loss: 0.2074 - val_accuracy: 0.9056\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2234 - accuracy: 0.9060 - val_loss: 0.2272 - val_accuracy: 0.9056\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2193 - accuracy: 0.9076 - val_loss: 0.2472 - val_accuracy: 0.9030\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2165 - accuracy: 0.9078 - val_loss: 0.2103 - val_accuracy: 0.9048\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2037 - accuracy: 0.9075 - val_loss: 0.2044 - val_accuracy: 0.9069\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2051 - accuracy: 0.9064 - val_loss: 0.2333 - val_accuracy: 0.8920\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2021 - accuracy: 0.9081 - val_loss: 0.2058 - val_accuracy: 0.9065\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1969 - accuracy: 0.9114 - val_loss: 0.2054 - val_accuracy: 0.9076\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1966 - accuracy: 0.9111 - val_loss: 0.2269 - val_accuracy: 0.8960\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1958 - accuracy: 0.9112 - val_loss: 0.2040 - val_accuracy: 0.9082\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2004 - accuracy: 0.9089 - val_loss: 0.2173 - val_accuracy: 0.9057\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1983 - accuracy: 0.9104 - val_loss: 0.2029 - val_accuracy: 0.9094\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1960 - accuracy: 0.9112 - val_loss: 0.2082 - val_accuracy: 0.9050\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1991 - accuracy: 0.9105 - val_loss: 0.2043 - val_accuracy: 0.9082\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1957 - accuracy: 0.9110 - val_loss: 0.2048 - val_accuracy: 0.9082\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1983 - accuracy: 0.9099 - val_loss: 0.2084 - val_accuracy: 0.9061\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1960 - accuracy: 0.9112 - val_loss: 0.2046 - val_accuracy: 0.9073\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1949 - accuracy: 0.9117 - val_loss: 0.2034 - val_accuracy: 0.9089\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1957 - accuracy: 0.9113 - val_loss: 0.2015 - val_accuracy: 0.9094\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.2044 - val_accuracy: 0.9080\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1963 - accuracy: 0.9112 - val_loss: 0.3098 - val_accuracy: 0.8777\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1994 - accuracy: 0.9102 - val_loss: 0.2040 - val_accuracy: 0.9074\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1947 - accuracy: 0.9111 - val_loss: 0.2029 - val_accuracy: 0.9079\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1931 - accuracy: 0.9128 - val_loss: 0.2002 - val_accuracy: 0.9099\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1928 - accuracy: 0.9124 - val_loss: 0.2090 - val_accuracy: 0.9052\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1920 - accuracy: 0.9126 - val_loss: 0.2026 - val_accuracy: 0.9090\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1973 - accuracy: 0.9102 - val_loss: 0.2107 - val_accuracy: 0.9054\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1923 - accuracy: 0.9119 - val_loss: 0.2059 - val_accuracy: 0.9083\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1928 - accuracy: 0.9127 - val_loss: 0.2061 - val_accuracy: 0.9059\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1983 - accuracy: 0.9095 - val_loss: 0.2501 - val_accuracy: 0.8785\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2312 - accuracy: 0.8921 - val_loss: 0.2220 - val_accuracy: 0.8966\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2125 - accuracy: 0.9037 - val_loss: 0.2118 - val_accuracy: 0.9049\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2067 - accuracy: 0.9059 - val_loss: 0.2098 - val_accuracy: 0.9045\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2111 - accuracy: 0.9038 - val_loss: 0.2070 - val_accuracy: 0.9048\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2049 - accuracy: 0.9066 - val_loss: 0.2143 - val_accuracy: 0.9022\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2064 - accuracy: 0.9058 - val_loss: 0.2036 - val_accuracy: 0.9072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2010 - accuracy: 0.9084 - val_loss: 0.2102 - val_accuracy: 0.9052\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2006 - accuracy: 0.9088 - val_loss: 0.2076 - val_accuracy: 0.9053\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1995 - accuracy: 0.9093 - val_loss: 0.2366 - val_accuracy: 0.8857\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1991 - accuracy: 0.9094 - val_loss: 0.2063 - val_accuracy: 0.9072\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2043 - accuracy: 0.9063 - val_loss: 0.2045 - val_accuracy: 0.9072\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1978 - accuracy: 0.9102 - val_loss: 0.2036 - val_accuracy: 0.9086\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2270 - accuracy: 0.8933 - val_loss: 0.2503 - val_accuracy: 0.8778\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2139 - accuracy: 0.8999 - val_loss: 0.2035 - val_accuracy: 0.9086\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1998 - accuracy: 0.9101 - val_loss: 0.2090 - val_accuracy: 0.9046\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1991 - accuracy: 0.9088 - val_loss: 0.2104 - val_accuracy: 0.9038\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1977 - accuracy: 0.9103 - val_loss: 0.2024 - val_accuracy: 0.9093\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1966 - accuracy: 0.9115 - val_loss: 0.2023 - val_accuracy: 0.9090\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1970 - accuracy: 0.9101 - val_loss: 0.2050 - val_accuracy: 0.9080\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1960 - accuracy: 0.9113 - val_loss: 0.2054 - val_accuracy: 0.9070\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1948 - accuracy: 0.9113 - val_loss: 0.2137 - val_accuracy: 0.9021\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1956 - accuracy: 0.9108 - val_loss: 0.2040 - val_accuracy: 0.9083\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1934 - accuracy: 0.9123 - val_loss: 0.2059 - val_accuracy: 0.9079\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1953 - accuracy: 0.9112 - val_loss: 0.2009 - val_accuracy: 0.9095\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1966 - accuracy: 0.9110 - val_loss: 0.2029 - val_accuracy: 0.9088\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1948 - accuracy: 0.9116 - val_loss: 0.2046 - val_accuracy: 0.9078\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1977 - accuracy: 0.9097 - val_loss: 0.2086 - val_accuracy: 0.9054\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1953 - accuracy: 0.9111 - val_loss: 0.2258 - val_accuracy: 0.8905\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.2023 - val_accuracy: 0.9082\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1938 - accuracy: 0.9117 - val_loss: 0.2032 - val_accuracy: 0.9087\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1927 - accuracy: 0.9123 - val_loss: 0.2016 - val_accuracy: 0.9102\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1927 - accuracy: 0.9124 - val_loss: 0.2061 - val_accuracy: 0.9059\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1940 - accuracy: 0.9122 - val_loss: 0.2144 - val_accuracy: 0.9043\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1930 - accuracy: 0.9120 - val_loss: 0.2067 - val_accuracy: 0.9056\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1942 - accuracy: 0.9119 - val_loss: 0.2014 - val_accuracy: 0.9093\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1929 - accuracy: 0.9124 - val_loss: 0.2324 - val_accuracy: 0.8989\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2647 - accuracy: 0.8819 - val_loss: 0.2236 - val_accuracy: 0.8979\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2150 - accuracy: 0.9027 - val_loss: 0.2127 - val_accuracy: 0.9054\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2046 - accuracy: 0.9074 - val_loss: 0.2071 - val_accuracy: 0.9069\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2014 - accuracy: 0.9088 - val_loss: 0.2068 - val_accuracy: 0.9058\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1987 - accuracy: 0.9105 - val_loss: 0.2053 - val_accuracy: 0.9067\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1987 - accuracy: 0.9101 - val_loss: 0.2105 - val_accuracy: 0.9046\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1980 - accuracy: 0.9110 - val_loss: 0.2055 - val_accuracy: 0.9070\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1971 - accuracy: 0.9106 - val_loss: 0.2051 - val_accuracy: 0.9083\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1978 - accuracy: 0.9102 - val_loss: 0.2051 - val_accuracy: 0.9067\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1981 - accuracy: 0.9096 - val_loss: 0.2043 - val_accuracy: 0.9071\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1959 - accuracy: 0.9113 - val_loss: 0.2043 - val_accuracy: 0.9082\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1979 - accuracy: 0.9100 - val_loss: 0.2062 - val_accuracy: 0.9098\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1955 - accuracy: 0.9110 - val_loss: 0.2050 - val_accuracy: 0.9080\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1942 - accuracy: 0.9120 - val_loss: 0.2074 - val_accuracy: 0.9051\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1945 - accuracy: 0.9119 - val_loss: 0.2038 - val_accuracy: 0.9084\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1952 - accuracy: 0.9114 - val_loss: 0.2059 - val_accuracy: 0.9078\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1968 - accuracy: 0.9104 - val_loss: 0.2051 - val_accuracy: 0.9084\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.2065 - val_accuracy: 0.9081\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1942 - accuracy: 0.9119 - val_loss: 0.2056 - val_accuracy: 0.9070\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1957 - accuracy: 0.9105 - val_loss: 0.2053 - val_accuracy: 0.9067\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1939 - accuracy: 0.9123 - val_loss: 0.2323 - val_accuracy: 0.8990\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.2069 - val_accuracy: 0.9070\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1945 - accuracy: 0.9119 - val_loss: 0.2109 - val_accuracy: 0.9052\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1947 - accuracy: 0.9116 - val_loss: 0.2107 - val_accuracy: 0.9061\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2053 - accuracy: 0.9069 - val_loss: 0.2041 - val_accuracy: 0.9070\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1946 - accuracy: 0.9119 - val_loss: 0.2089 - val_accuracy: 0.9067\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1959 - accuracy: 0.9113 - val_loss: 0.2056 - val_accuracy: 0.9073\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.2137 - val_accuracy: 0.9045\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1955 - accuracy: 0.9112 - val_loss: 0.2074 - val_accuracy: 0.9067\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1947 - accuracy: 0.9116 - val_loss: 0.2062 - val_accuracy: 0.9068\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1941 - accuracy: 0.9112 - val_loss: 0.2051 - val_accuracy: 0.9072\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1951 - accuracy: 0.9117 - val_loss: 0.2059 - val_accuracy: 0.9071\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1964 - accuracy: 0.9113 - val_loss: 0.2081 - val_accuracy: 0.9076\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1925 - accuracy: 0.9127 - val_loss: 0.2059 - val_accuracy: 0.9075\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1960 - accuracy: 0.9110 - val_loss: 0.2096 - val_accuracy: 0.9067\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1954 - accuracy: 0.9112 - val_loss: 0.2069 - val_accuracy: 0.9074\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2243 - accuracy: 0.8976 - val_loss: 0.2298 - val_accuracy: 0.8881\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2134 - accuracy: 0.9024 - val_loss: 0.2134 - val_accuracy: 0.9021\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2169 - accuracy: 0.9031 - val_loss: 0.2213 - val_accuracy: 0.9009\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2242 - accuracy: 0.9007 - val_loss: 0.2119 - val_accuracy: 0.9034\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2058 - accuracy: 0.9066 - val_loss: 0.2162 - val_accuracy: 0.8993\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2009 - accuracy: 0.9099 - val_loss: 0.2046 - val_accuracy: 0.9078\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2000 - accuracy: 0.9098 - val_loss: 0.2079 - val_accuracy: 0.9067\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2006 - accuracy: 0.9102 - val_loss: 0.2150 - val_accuracy: 0.9042\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2002 - accuracy: 0.9100 - val_loss: 0.2051 - val_accuracy: 0.9091\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1961 - accuracy: 0.9116 - val_loss: 0.2481 - val_accuracy: 0.8946\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1979 - accuracy: 0.9107 - val_loss: 0.2048 - val_accuracy: 0.9076\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1953 - accuracy: 0.9114 - val_loss: 0.2113 - val_accuracy: 0.9069\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1948 - accuracy: 0.9112 - val_loss: 0.2009 - val_accuracy: 0.9096\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1949 - accuracy: 0.9117 - val_loss: 0.2080 - val_accuracy: 0.9069\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1949 - accuracy: 0.9116 - val_loss: 0.2039 - val_accuracy: 0.9085\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1945 - accuracy: 0.9115 - val_loss: 0.2040 - val_accuracy: 0.9090\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1976 - accuracy: 0.9101 - val_loss: 0.2065 - val_accuracy: 0.9066\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1925 - accuracy: 0.9129 - val_loss: 0.2017 - val_accuracy: 0.9092\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1922 - accuracy: 0.9127 - val_loss: 0.2026 - val_accuracy: 0.9094\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2495 - accuracy: 0.8764 - val_loss: 0.2657 - val_accuracy: 0.8645\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2548 - accuracy: 0.8756 - val_loss: 0.2321 - val_accuracy: 0.8888\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2131 - accuracy: 0.9041 - val_loss: 0.2128 - val_accuracy: 0.9035\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2084 - accuracy: 0.9056 - val_loss: 0.2323 - val_accuracy: 0.8934\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2160 - accuracy: 0.9023 - val_loss: 0.2117 - val_accuracy: 0.9038\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2047 - accuracy: 0.9069 - val_loss: 0.2077 - val_accuracy: 0.9061\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2062 - accuracy: 0.9063 - val_loss: 0.2072 - val_accuracy: 0.9061\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1997 - accuracy: 0.9097 - val_loss: 0.2061 - val_accuracy: 0.9065\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2000 - accuracy: 0.9096 - val_loss: 0.2041 - val_accuracy: 0.9078\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1996 - accuracy: 0.9089 - val_loss: 0.2035 - val_accuracy: 0.9087\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2005 - accuracy: 0.9086 - val_loss: 0.2026 - val_accuracy: 0.9087\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1957 - accuracy: 0.9114 - val_loss: 0.2032 - val_accuracy: 0.9096\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1956 - accuracy: 0.9111 - val_loss: 0.2036 - val_accuracy: 0.9084\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2061 - accuracy: 0.9049 - val_loss: 0.2081 - val_accuracy: 0.9067\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1954 - accuracy: 0.9110 - val_loss: 0.2110 - val_accuracy: 0.9040\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1943 - accuracy: 0.9116 - val_loss: 0.2017 - val_accuracy: 0.9097\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1930 - accuracy: 0.9123 - val_loss: 0.2026 - val_accuracy: 0.9098\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2094 - accuracy: 0.9041 - val_loss: 0.2121 - val_accuracy: 0.9035\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1966 - accuracy: 0.9100 - val_loss: 0.2040 - val_accuracy: 0.9082\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1957 - accuracy: 0.9105 - val_loss: 0.2039 - val_accuracy: 0.9084\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1952 - accuracy: 0.9107 - val_loss: 0.2116 - val_accuracy: 0.9056\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1969 - accuracy: 0.9105 - val_loss: 0.2159 - val_accuracy: 0.9038\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1982 - accuracy: 0.9101 - val_loss: 0.2098 - val_accuracy: 0.9058\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1972 - accuracy: 0.9106 - val_loss: 0.2242 - val_accuracy: 0.8985\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2042 - accuracy: 0.9077 - val_loss: 0.2073 - val_accuracy: 0.9064\n",
      "accuracy: 90.64%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2002 - accuracy: 0.9093 - val_loss: 0.1981 - val_accuracy: 0.9106\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1985 - accuracy: 0.9098 - val_loss: 0.2026 - val_accuracy: 0.9083\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1977 - accuracy: 0.9104 - val_loss: 0.1975 - val_accuracy: 0.9098\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1946 - accuracy: 0.9116 - val_loss: 0.1988 - val_accuracy: 0.9072\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1967 - accuracy: 0.9111 - val_loss: 0.1984 - val_accuracy: 0.9098\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.2277 - val_accuracy: 0.8933\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2249 - accuracy: 0.8947 - val_loss: 0.2137 - val_accuracy: 0.9015\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2016 - accuracy: 0.9086 - val_loss: 0.2028 - val_accuracy: 0.9086\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1986 - accuracy: 0.9097 - val_loss: 0.1994 - val_accuracy: 0.9094\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1961 - accuracy: 0.9111 - val_loss: 0.1976 - val_accuracy: 0.9104\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1962 - accuracy: 0.9108 - val_loss: 0.2029 - val_accuracy: 0.9073\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1972 - accuracy: 0.9105 - val_loss: 0.2016 - val_accuracy: 0.9089\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1939 - accuracy: 0.9122 - val_loss: 0.2038 - val_accuracy: 0.9077\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2052 - accuracy: 0.9068 - val_loss: 0.2021 - val_accuracy: 0.9088\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1969 - accuracy: 0.9105 - val_loss: 0.2020 - val_accuracy: 0.9086\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.2051 - val_accuracy: 0.9073\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1935 - accuracy: 0.9123 - val_loss: 0.2008 - val_accuracy: 0.9078\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1947 - accuracy: 0.9114 - val_loss: 0.1996 - val_accuracy: 0.9106\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1947 - accuracy: 0.9112 - val_loss: 0.2001 - val_accuracy: 0.9099\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1933 - accuracy: 0.9119 - val_loss: 0.2014 - val_accuracy: 0.9087\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1953 - accuracy: 0.9113 - val_loss: 0.2027 - val_accuracy: 0.9079\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.2005 - val_accuracy: 0.9105\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1988 - accuracy: 0.9094 - val_loss: 0.2030 - val_accuracy: 0.9086\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1995 - accuracy: 0.9090 - val_loss: 0.2146 - val_accuracy: 0.9022\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2007 - accuracy: 0.9091 - val_loss: 0.2019 - val_accuracy: 0.9097\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1967 - accuracy: 0.9108 - val_loss: 0.2010 - val_accuracy: 0.9096\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2185 - accuracy: 0.8975 - val_loss: 0.2033 - val_accuracy: 0.9085\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1960 - accuracy: 0.9112 - val_loss: 0.2065 - val_accuracy: 0.9092\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1947 - accuracy: 0.9124 - val_loss: 0.2368 - val_accuracy: 0.8868\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2209 - accuracy: 0.8975 - val_loss: 0.2041 - val_accuracy: 0.9076\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1971 - accuracy: 0.9104 - val_loss: 0.2028 - val_accuracy: 0.9096\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1983 - accuracy: 0.9099 - val_loss: 0.2100 - val_accuracy: 0.9050\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2042 - accuracy: 0.9066 - val_loss: 0.2062 - val_accuracy: 0.9065\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1980 - accuracy: 0.9096 - val_loss: 0.2361 - val_accuracy: 0.8911\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1955 - accuracy: 0.9110 - val_loss: 0.2046 - val_accuracy: 0.9084\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1939 - accuracy: 0.9117 - val_loss: 0.2005 - val_accuracy: 0.9096\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1935 - accuracy: 0.9120 - val_loss: 0.2054 - val_accuracy: 0.9082\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1949 - accuracy: 0.9109 - val_loss: 0.2148 - val_accuracy: 0.9020\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1971 - accuracy: 0.9104 - val_loss: 0.2045 - val_accuracy: 0.9074\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1936 - accuracy: 0.9119 - val_loss: 0.2049 - val_accuracy: 0.9083\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.2060 - val_accuracy: 0.9072\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1935 - accuracy: 0.9124 - val_loss: 0.2006 - val_accuracy: 0.9097\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1943 - accuracy: 0.9115 - val_loss: 0.2022 - val_accuracy: 0.9099\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1929 - accuracy: 0.9122 - val_loss: 0.2035 - val_accuracy: 0.9094\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1929 - accuracy: 0.9123 - val_loss: 0.2045 - val_accuracy: 0.9092\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.1940 - accuracy: 0.9123 - val_loss: 0.2021 - val_accuracy: 0.9089\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1932 - accuracy: 0.9117 - val_loss: 0.2037 - val_accuracy: 0.9069\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1921 - accuracy: 0.9125 - val_loss: 0.2032 - val_accuracy: 0.9089\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.2028 - val_accuracy: 0.9094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1931 - accuracy: 0.9126 - val_loss: 0.2028 - val_accuracy: 0.9101\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1930 - accuracy: 0.9126 - val_loss: 0.2051 - val_accuracy: 0.9052\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1922 - accuracy: 0.9125 - val_loss: 0.2042 - val_accuracy: 0.9095\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1930 - accuracy: 0.9119 - val_loss: 0.2041 - val_accuracy: 0.9092\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1920 - accuracy: 0.9127 - val_loss: 0.2006 - val_accuracy: 0.9102\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1924 - accuracy: 0.9126 - val_loss: 0.2069 - val_accuracy: 0.9077\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1917 - accuracy: 0.9125 - val_loss: 0.2048 - val_accuracy: 0.9088\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1910 - accuracy: 0.9131 - val_loss: 0.2029 - val_accuracy: 0.9087\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1915 - accuracy: 0.9127 - val_loss: 0.2063 - val_accuracy: 0.9100\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1918 - accuracy: 0.9130 - val_loss: 0.2019 - val_accuracy: 0.9110\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1903 - accuracy: 0.9133 - val_loss: 0.2040 - val_accuracy: 0.9099\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1912 - accuracy: 0.9128 - val_loss: 0.2014 - val_accuracy: 0.9097\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1934 - accuracy: 0.9121 - val_loss: 0.2026 - val_accuracy: 0.9102\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1903 - accuracy: 0.9134 - val_loss: 0.2023 - val_accuracy: 0.9097\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1916 - accuracy: 0.9126 - val_loss: 0.2032 - val_accuracy: 0.9100\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1926 - accuracy: 0.9127 - val_loss: 0.2041 - val_accuracy: 0.9096\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2014 - accuracy: 0.9072 - val_loss: 0.2052 - val_accuracy: 0.9079\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1912 - accuracy: 0.9133 - val_loss: 0.2057 - val_accuracy: 0.9083\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1913 - accuracy: 0.9122 - val_loss: 0.2058 - val_accuracy: 0.9076\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 236s 2ms/step - loss: 0.1925 - accuracy: 0.9125 - val_loss: 0.2110 - val_accuracy: 0.9064\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 230s 2ms/step - loss: 0.1950 - accuracy: 0.9112 - val_loss: 0.2029 - val_accuracy: 0.9100\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 220s 2ms/step - loss: 0.1916 - accuracy: 0.9131 - val_loss: 0.2039 - val_accuracy: 0.9084\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 217s 2ms/step - loss: 0.1925 - accuracy: 0.9121 - val_loss: 0.2102 - val_accuracy: 0.9054\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1899 - accuracy: 0.9133 - val_loss: 0.2027 - val_accuracy: 0.9085\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.2103 - val_accuracy: 0.9038\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1918 - accuracy: 0.9120 - val_loss: 0.2059 - val_accuracy: 0.9083\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1915 - accuracy: 0.9129 - val_loss: 0.2068 - val_accuracy: 0.9070\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1920 - accuracy: 0.9121 - val_loss: 0.2028 - val_accuracy: 0.9088\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1907 - accuracy: 0.9131 - val_loss: 0.2034 - val_accuracy: 0.9086\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1913 - accuracy: 0.9128 - val_loss: 0.2038 - val_accuracy: 0.9101\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1932 - accuracy: 0.9120 - val_loss: 0.2056 - val_accuracy: 0.9085\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1917 - accuracy: 0.9122 - val_loss: 0.2075 - val_accuracy: 0.9084\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1898 - accuracy: 0.9134 - val_loss: 0.2034 - val_accuracy: 0.9105\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1908 - accuracy: 0.9132 - val_loss: 0.2064 - val_accuracy: 0.9078\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1917 - accuracy: 0.9127 - val_loss: 0.2075 - val_accuracy: 0.9082\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1919 - accuracy: 0.9126 - val_loss: 0.2056 - val_accuracy: 0.9085\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1927 - accuracy: 0.9120 - val_loss: 0.2049 - val_accuracy: 0.9086\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1931 - accuracy: 0.9123 - val_loss: 0.2055 - val_accuracy: 0.9082\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1930 - accuracy: 0.9124 - val_loss: 0.2086 - val_accuracy: 0.9078\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1899 - accuracy: 0.9139 - val_loss: 0.2100 - val_accuracy: 0.9093\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2020 - accuracy: 0.9064 - val_loss: 0.2026 - val_accuracy: 0.9099\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1901 - accuracy: 0.9133 - val_loss: 0.2023 - val_accuracy: 0.9093\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.1907 - accuracy: 0.9130 - val_loss: 0.2093 - val_accuracy: 0.9069\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1900 - accuracy: 0.9129 - val_loss: 0.2108 - val_accuracy: 0.9064\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1919 - accuracy: 0.9126 - val_loss: 0.2032 - val_accuracy: 0.9096\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.1916 - accuracy: 0.9127 - val_loss: 0.2088 - val_accuracy: 0.9074\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1958 - accuracy: 0.9100 - val_loss: 0.2056 - val_accuracy: 0.9085\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1915 - accuracy: 0.9125 - val_loss: 0.2059 - val_accuracy: 0.9083\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 208s 1ms/step - loss: 0.1894 - accuracy: 0.9135 - val_loss: 0.2070 - val_accuracy: 0.9080\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.1948 - accuracy: 0.9113 - val_loss: 0.2158 - val_accuracy: 0.9033\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1950 - accuracy: 0.9113 - val_loss: 0.2043 - val_accuracy: 0.9076\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1904 - accuracy: 0.9131 - val_loss: 0.2084 - val_accuracy: 0.9078\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1908 - accuracy: 0.9127 - val_loss: 0.2041 - val_accuracy: 0.9091\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1893 - accuracy: 0.9140 - val_loss: 0.2045 - val_accuracy: 0.9084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.1901 - accuracy: 0.9139 - val_loss: 0.2066 - val_accuracy: 0.9083\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1899 - accuracy: 0.9139 - val_loss: 0.2114 - val_accuracy: 0.9041\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1899 - accuracy: 0.9133 - val_loss: 0.2031 - val_accuracy: 0.9096\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.1988 - accuracy: 0.9093 - val_loss: 0.2048 - val_accuracy: 0.9087\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1906 - accuracy: 0.9127 - val_loss: 0.2033 - val_accuracy: 0.9098\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1914 - accuracy: 0.9135 - val_loss: 0.2075 - val_accuracy: 0.9078\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1899 - accuracy: 0.9134 - val_loss: 0.2045 - val_accuracy: 0.9100\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2205 - accuracy: 0.8946 - val_loss: 0.2529 - val_accuracy: 0.8738\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2547 - accuracy: 0.8758 - val_loss: 0.2800 - val_accuracy: 0.8620\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2582 - accuracy: 0.8753 - val_loss: 0.2448 - val_accuracy: 0.8845\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2346 - accuracy: 0.8924 - val_loss: 0.2251 - val_accuracy: 0.8977\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2213 - accuracy: 0.8998 - val_loss: 0.2205 - val_accuracy: 0.8999\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2135 - accuracy: 0.9032 - val_loss: 0.2482 - val_accuracy: 0.8849\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2126 - accuracy: 0.9044 - val_loss: 0.2111 - val_accuracy: 0.9049\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2047 - accuracy: 0.9072 - val_loss: 0.2192 - val_accuracy: 0.9062\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2006 - accuracy: 0.9094 - val_loss: 0.2079 - val_accuracy: 0.9061\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1968 - accuracy: 0.9110 - val_loss: 0.2086 - val_accuracy: 0.9070\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1981 - accuracy: 0.9104 - val_loss: 0.2068 - val_accuracy: 0.9078\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1957 - accuracy: 0.9112 - val_loss: 0.2065 - val_accuracy: 0.9068\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1943 - accuracy: 0.9120 - val_loss: 0.2092 - val_accuracy: 0.9052\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1932 - accuracy: 0.9120 - val_loss: 0.2062 - val_accuracy: 0.9076\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1939 - accuracy: 0.9117 - val_loss: 0.2044 - val_accuracy: 0.9084\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1943 - accuracy: 0.9115 - val_loss: 0.2062 - val_accuracy: 0.9083\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1931 - accuracy: 0.9125 - val_loss: 0.2061 - val_accuracy: 0.9072\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1920 - accuracy: 0.9123 - val_loss: 0.2024 - val_accuracy: 0.9096\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1928 - accuracy: 0.9123 - val_loss: 0.2056 - val_accuracy: 0.9084\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1918 - accuracy: 0.9130 - val_loss: 0.2069 - val_accuracy: 0.9073\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1911 - accuracy: 0.9128 - val_loss: 0.2057 - val_accuracy: 0.9088\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2105 - accuracy: 0.9026 - val_loss: 0.2117 - val_accuracy: 0.9053\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1951 - accuracy: 0.9120 - val_loss: 0.2044 - val_accuracy: 0.9093\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1923 - accuracy: 0.9125 - val_loss: 0.2040 - val_accuracy: 0.9097\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1928 - accuracy: 0.9121 - val_loss: 0.2057 - val_accuracy: 0.9082\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1920 - accuracy: 0.9124 - val_loss: 0.2046 - val_accuracy: 0.9090\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1916 - accuracy: 0.9130 - val_loss: 0.2055 - val_accuracy: 0.9090\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1921 - accuracy: 0.9125 - val_loss: 0.2086 - val_accuracy: 0.9074\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1902 - accuracy: 0.9137 - val_loss: 0.2111 - val_accuracy: 0.9083\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1905 - accuracy: 0.9137 - val_loss: 0.2074 - val_accuracy: 0.9073\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1908 - accuracy: 0.9124 - val_loss: 0.2057 - val_accuracy: 0.9086\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1896 - accuracy: 0.9139 - val_loss: 0.2063 - val_accuracy: 0.9089\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2021 - accuracy: 0.9076 - val_loss: 0.2164 - val_accuracy: 0.9048\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.2114 - val_accuracy: 0.9060\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1904 - accuracy: 0.9136 - val_loss: 0.2054 - val_accuracy: 0.9092\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1910 - accuracy: 0.9130 - val_loss: 0.2083 - val_accuracy: 0.9089\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.2034 - val_accuracy: 0.9097\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1902 - accuracy: 0.9136 - val_loss: 0.2068 - val_accuracy: 0.9094\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1900 - accuracy: 0.9134 - val_loss: 0.2068 - val_accuracy: 0.9080\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1899 - accuracy: 0.9137 - val_loss: 0.2078 - val_accuracy: 0.9064\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1926 - accuracy: 0.9130 - val_loss: 0.2139 - val_accuracy: 0.9048\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1973 - accuracy: 0.9098 - val_loss: 0.2063 - val_accuracy: 0.9076\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1943 - accuracy: 0.9117 - val_loss: 0.2075 - val_accuracy: 0.9082\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1917 - accuracy: 0.9124 - val_loss: 0.2075 - val_accuracy: 0.9077\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1924 - accuracy: 0.9130 - val_loss: 0.2081 - val_accuracy: 0.9072\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1917 - accuracy: 0.9128 - val_loss: 0.2080 - val_accuracy: 0.9091\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1899 - accuracy: 0.9138 - val_loss: 0.2042 - val_accuracy: 0.9087\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1908 - accuracy: 0.9129 - val_loss: 0.2056 - val_accuracy: 0.9093\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2195 - accuracy: 0.8978 - val_loss: 0.2133 - val_accuracy: 0.9041\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2290 - accuracy: 0.8917 - val_loss: 0.2561 - val_accuracy: 0.8749\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2115 - accuracy: 0.9028 - val_loss: 0.2279 - val_accuracy: 0.8975\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2016 - accuracy: 0.9086 - val_loss: 0.2086 - val_accuracy: 0.9060\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.1949 - accuracy: 0.9111 - val_loss: 0.2054 - val_accuracy: 0.9092\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.2060 - val_accuracy: 0.9082\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1946 - accuracy: 0.9114 - val_loss: 0.2090 - val_accuracy: 0.9056\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1931 - accuracy: 0.9124 - val_loss: 0.2057 - val_accuracy: 0.9084\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1908 - accuracy: 0.9134 - val_loss: 0.2056 - val_accuracy: 0.9098\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1914 - accuracy: 0.9128 - val_loss: 0.2101 - val_accuracy: 0.9068\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1911 - accuracy: 0.9134 - val_loss: 0.2084 - val_accuracy: 0.9092\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1917 - accuracy: 0.9127 - val_loss: 0.2191 - val_accuracy: 0.9004\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1901 - accuracy: 0.9132 - val_loss: 0.2041 - val_accuracy: 0.9105\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1925 - accuracy: 0.9121 - val_loss: 0.2060 - val_accuracy: 0.9098\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1893 - accuracy: 0.9135 - val_loss: 0.2053 - val_accuracy: 0.9088\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1905 - accuracy: 0.9130 - val_loss: 0.2048 - val_accuracy: 0.9097\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1891 - accuracy: 0.9139 - val_loss: 0.2074 - val_accuracy: 0.9095\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1906 - accuracy: 0.9131 - val_loss: 0.2152 - val_accuracy: 0.9063\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1911 - accuracy: 0.9133 - val_loss: 0.2071 - val_accuracy: 0.9089\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1900 - accuracy: 0.9130 - val_loss: 0.2078 - val_accuracy: 0.9076\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1901 - accuracy: 0.9130 - val_loss: 0.2066 - val_accuracy: 0.9084\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1985 - accuracy: 0.9090 - val_loss: 0.2053 - val_accuracy: 0.9082\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1897 - accuracy: 0.9138 - val_loss: 0.2110 - val_accuracy: 0.9073\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1900 - accuracy: 0.9131 - val_loss: 0.2054 - val_accuracy: 0.9095\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1893 - accuracy: 0.9136 - val_loss: 0.2074 - val_accuracy: 0.9083\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1904 - accuracy: 0.9132 - val_loss: 0.2063 - val_accuracy: 0.9092\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1891 - accuracy: 0.9135 - val_loss: 0.2539 - val_accuracy: 0.8812\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 207s 1ms/step - loss: 0.1942 - accuracy: 0.9107 - val_loss: 0.2078 - val_accuracy: 0.9095\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1875 - accuracy: 0.9145 - val_loss: 0.2069 - val_accuracy: 0.9094\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1881 - accuracy: 0.9142 - val_loss: 0.2088 - val_accuracy: 0.9075\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1898 - accuracy: 0.9132 - val_loss: 0.2123 - val_accuracy: 0.9075\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1911 - accuracy: 0.9134 - val_loss: 0.2069 - val_accuracy: 0.9097\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1889 - accuracy: 0.9139 - val_loss: 0.2057 - val_accuracy: 0.9087\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1898 - accuracy: 0.9136 - val_loss: 0.2071 - val_accuracy: 0.9095\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1924 - accuracy: 0.9127 - val_loss: 0.2031 - val_accuracy: 0.9105\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1880 - accuracy: 0.9143 - val_loss: 0.2046 - val_accuracy: 0.9100\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1893 - accuracy: 0.9132 - val_loss: 0.2144 - val_accuracy: 0.9066\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1983 - accuracy: 0.9085 - val_loss: 0.2073 - val_accuracy: 0.9080\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1883 - accuracy: 0.9141 - val_loss: 0.2048 - val_accuracy: 0.9090\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1881 - accuracy: 0.9144 - val_loss: 0.2083 - val_accuracy: 0.9082\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2184 - accuracy: 0.8982 - val_loss: 0.2136 - val_accuracy: 0.9034\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.2043 - val_accuracy: 0.9097\n",
      "accuracy: 90.97%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  6\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.1939 - accuracy: 0.9120 - val_loss: 0.1935 - val_accuracy: 0.9120\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1938 - accuracy: 0.9124 - val_loss: 0.1916 - val_accuracy: 0.9121\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1920 - accuracy: 0.9130 - val_loss: 0.1960 - val_accuracy: 0.9086\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1932 - accuracy: 0.9126 - val_loss: 0.2028 - val_accuracy: 0.9078\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1916 - accuracy: 0.9135 - val_loss: 0.1953 - val_accuracy: 0.9096\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1913 - accuracy: 0.9131 - val_loss: 0.1984 - val_accuracy: 0.9087\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1911 - accuracy: 0.9133 - val_loss: 0.2011 - val_accuracy: 0.9076\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1914 - accuracy: 0.9130 - val_loss: 0.1967 - val_accuracy: 0.9095\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.1905 - accuracy: 0.9136 - val_loss: 0.1931 - val_accuracy: 0.9115\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1909 - accuracy: 0.9132 - val_loss: 0.1934 - val_accuracy: 0.9125\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1907 - accuracy: 0.9133 - val_loss: 0.1942 - val_accuracy: 0.9112\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.1925 - accuracy: 0.9133 - val_loss: 0.1948 - val_accuracy: 0.9112\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1915 - accuracy: 0.9139 - val_loss: 0.2638 - val_accuracy: 0.8812\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1999 - accuracy: 0.9094 - val_loss: 0.1979 - val_accuracy: 0.9096\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1922 - accuracy: 0.9132 - val_loss: 0.1938 - val_accuracy: 0.9115\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1900 - accuracy: 0.9140 - val_loss: 0.1967 - val_accuracy: 0.9099\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1909 - accuracy: 0.9135 - val_loss: 0.1963 - val_accuracy: 0.9112\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1907 - accuracy: 0.9135 - val_loss: 0.2012 - val_accuracy: 0.9079\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1930 - accuracy: 0.9127 - val_loss: 0.1959 - val_accuracy: 0.9101\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1908 - accuracy: 0.9136 - val_loss: 0.1983 - val_accuracy: 0.9098\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1928 - accuracy: 0.9125 - val_loss: 0.1961 - val_accuracy: 0.9107\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1905 - accuracy: 0.9137 - val_loss: 0.1969 - val_accuracy: 0.9104\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1901 - accuracy: 0.9134 - val_loss: 0.1968 - val_accuracy: 0.9105\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1921 - accuracy: 0.9129 - val_loss: 0.1977 - val_accuracy: 0.9092\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1901 - accuracy: 0.9143 - val_loss: 0.1969 - val_accuracy: 0.9108\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.1908 - accuracy: 0.9133 - val_loss: 0.1984 - val_accuracy: 0.9087\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.1900 - accuracy: 0.9134 - val_loss: 0.1985 - val_accuracy: 0.9093\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1950 - accuracy: 0.9110 - val_loss: 0.2023 - val_accuracy: 0.9076\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2106 - accuracy: 0.9064 - val_loss: 0.2064 - val_accuracy: 0.9080\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.1971 - accuracy: 0.9109 - val_loss: 0.2140 - val_accuracy: 0.9001\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2193 - accuracy: 0.9059 - val_loss: 0.3156 - val_accuracy: 0.8785\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.4195 - accuracy: 0.8168 - val_loss: 0.3791 - val_accuracy: 0.8231\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3681 - accuracy: 0.8245 - val_loss: 0.3466 - val_accuracy: 0.8295\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.3540 - accuracy: 0.8307 - val_loss: 0.3425 - val_accuracy: 0.8324\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3403 - accuracy: 0.8357 - val_loss: 0.3368 - val_accuracy: 0.8384\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3415 - accuracy: 0.8358 - val_loss: 0.3318 - val_accuracy: 0.8392\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3267 - accuracy: 0.8501 - val_loss: 0.3155 - val_accuracy: 0.8585\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3239 - accuracy: 0.8552 - val_loss: 0.3082 - val_accuracy: 0.8613\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3092 - accuracy: 0.8665 - val_loss: 0.3102 - val_accuracy: 0.8625\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.3072 - accuracy: 0.8691 - val_loss: 0.2963 - val_accuracy: 0.8741\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3028 - accuracy: 0.8732 - val_loss: 0.2998 - val_accuracy: 0.8701\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2982 - accuracy: 0.8754 - val_loss: 0.2967 - val_accuracy: 0.8726\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2941 - accuracy: 0.8768 - val_loss: 0.2924 - val_accuracy: 0.8752\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.3041 - accuracy: 0.8725 - val_loss: 0.2974 - val_accuracy: 0.8725\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.3011 - accuracy: 0.8737 - val_loss: 0.3004 - val_accuracy: 0.8693\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.3024 - accuracy: 0.8714 - val_loss: 0.3127 - val_accuracy: 0.8606\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.3028 - accuracy: 0.8671 - val_loss: 0.2857 - val_accuracy: 0.8709\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2844 - accuracy: 0.8712 - val_loss: 0.2714 - val_accuracy: 0.8723\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2744 - accuracy: 0.8735 - val_loss: 0.2761 - val_accuracy: 0.8709\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 198s 1ms/step - loss: 0.2768 - accuracy: 0.8729 - val_loss: 0.2764 - val_accuracy: 0.8749\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2733 - accuracy: 0.8757 - val_loss: 0.2626 - val_accuracy: 0.8780\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2680 - accuracy: 0.8782 - val_loss: 0.2696 - val_accuracy: 0.8794\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2655 - accuracy: 0.8793 - val_loss: 0.2686 - val_accuracy: 0.8733\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2653 - accuracy: 0.8794 - val_loss: 0.2563 - val_accuracy: 0.8788\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2616 - accuracy: 0.8797 - val_loss: 0.2822 - val_accuracy: 0.8798\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2582 - accuracy: 0.8812 - val_loss: 0.2502 - val_accuracy: 0.8800\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2579 - accuracy: 0.8818 - val_loss: 0.3226 - val_accuracy: 0.8838\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2571 - accuracy: 0.8841 - val_loss: 0.2494 - val_accuracy: 0.8821\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2506 - accuracy: 0.8868 - val_loss: 0.2688 - val_accuracy: 0.8750\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2505 - accuracy: 0.8851 - val_loss: 0.2554 - val_accuracy: 0.8821\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2463 - accuracy: 0.8888 - val_loss: 0.2428 - val_accuracy: 0.8961\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2413 - accuracy: 0.8924 - val_loss: 0.2441 - val_accuracy: 0.8942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2954 - accuracy: 0.8596 - val_loss: 0.2904 - val_accuracy: 0.8579\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2644 - accuracy: 0.8763 - val_loss: 0.2503 - val_accuracy: 0.8793\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 200s 1ms/step - loss: 0.2528 - accuracy: 0.8828 - val_loss: 0.2494 - val_accuracy: 0.8816\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 199s 1ms/step - loss: 0.2462 - accuracy: 0.8864 - val_loss: 0.2435 - val_accuracy: 0.8912\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2481 - accuracy: 0.8891 - val_loss: 0.2436 - val_accuracy: 0.8894\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 195s 1ms/step - loss: 0.2461 - accuracy: 0.8898 - val_loss: 0.2555 - val_accuracy: 0.8819\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2402 - accuracy: 0.8915 - val_loss: 0.2279 - val_accuracy: 0.8945\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2378 - accuracy: 0.8934 - val_loss: 0.2343 - val_accuracy: 0.8961\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2403 - accuracy: 0.8904 - val_loss: 0.2276 - val_accuracy: 0.8943\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2484 - accuracy: 0.8943 - val_loss: 0.2702 - val_accuracy: 0.8933\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2753 - accuracy: 0.8878 - val_loss: 0.2770 - val_accuracy: 0.8894\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2719 - accuracy: 0.8879 - val_loss: 0.2604 - val_accuracy: 0.8919\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2415 - accuracy: 0.8943 - val_loss: 0.2286 - val_accuracy: 0.8949\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2340 - accuracy: 0.8970 - val_loss: 0.2288 - val_accuracy: 0.8991\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.2330 - accuracy: 0.8972 - val_loss: 0.2444 - val_accuracy: 0.8959\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 196s 1ms/step - loss: 0.2307 - accuracy: 0.8972 - val_loss: 0.2282 - val_accuracy: 0.8948\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 209s 1ms/step - loss: 0.2300 - accuracy: 0.8983 - val_loss: 0.2210 - val_accuracy: 0.9014\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2280 - accuracy: 0.8990 - val_loss: 0.2291 - val_accuracy: 0.8973\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 206s 1ms/step - loss: 0.2259 - accuracy: 0.8991 - val_loss: 0.2228 - val_accuracy: 0.8984\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2237 - accuracy: 0.9010 - val_loss: 0.2207 - val_accuracy: 0.9017\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2283 - accuracy: 0.9002 - val_loss: 0.2253 - val_accuracy: 0.9010\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.2253 - accuracy: 0.9015 - val_loss: 0.2919 - val_accuracy: 0.8729\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2567 - accuracy: 0.8881 - val_loss: 0.2452 - val_accuracy: 0.8922\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2504 - accuracy: 0.8931 - val_loss: 0.2817 - val_accuracy: 0.8923\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2449 - accuracy: 0.8925 - val_loss: 0.2264 - val_accuracy: 0.8970\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 205s 1ms/step - loss: 0.2392 - accuracy: 0.8947 - val_loss: 0.2595 - val_accuracy: 0.8934\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.2372 - accuracy: 0.8951 - val_loss: 0.2307 - val_accuracy: 0.8969\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2388 - accuracy: 0.8929 - val_loss: 0.2244 - val_accuracy: 0.8979\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2348 - accuracy: 0.8950 - val_loss: 0.2331 - val_accuracy: 0.8964\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2350 - accuracy: 0.8941 - val_loss: 0.2515 - val_accuracy: 0.8922\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2323 - accuracy: 0.8947 - val_loss: 0.2252 - val_accuracy: 0.8975\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 203s 1ms/step - loss: 0.2361 - accuracy: 0.8947 - val_loss: 0.2384 - val_accuracy: 0.8961\n",
      "Epoch 95/200\n",
      " 56896/140272 [===========>..................] - ETA: 1:54 - loss: 0.2345 - accuracy: 0.8957"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Bidirectional(LSTM(lstm_output_size)))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "folds=10\n",
    "   \n",
    "a=[]\n",
    "for i in range(folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    XTrain, XVal, yTrain, yVal = train_test_split(X, Y, test_size=0.2, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    cnn.fit(XTrain, yTrain, nb_epoch=200, validation_data=(XVal, yVal))\n",
    "    scores = cnn.evaluate(XVal, yVal, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (cnn.metrics_names[1], scores[1]*100))\n",
    "    a.append(scores[1] * 100)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\", input_shape=(41, 1))`\n",
      "  \n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 41, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 140)               75600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 141       \n",
      "=================================================================\n",
      "Total params: 75,997\n",
      "Trainable params: 75,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Bidirectional(LSTM(lstm_output_size)))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
