{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-1]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-1]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],X.shape[1],1))\n",
    "x = np.reshape(x, (x.shape[0],x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 41, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 164,353\n",
      "Trainable params: 164,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(41, 1), padding=\"same\")`\n",
      "  \n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "cnn.summary()\n",
    "a=[]\n",
    "folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 26s 188us/step - loss: 0.3975 - accuracy: 0.7954 - val_loss: 0.3744 - val_accuracy: 0.8110\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 25s 181us/step - loss: 0.3674 - accuracy: 0.8200 - val_loss: 0.3558 - val_accuracy: 0.8216\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 25s 179us/step - loss: 0.3595 - accuracy: 0.8235 - val_loss: 0.3544 - val_accuracy: 0.8223\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 25s 181us/step - loss: 0.3556 - accuracy: 0.8253 - val_loss: 0.3456 - val_accuracy: 0.8266\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 25s 179us/step - loss: 0.3527 - accuracy: 0.8270 - val_loss: 0.3442 - val_accuracy: 0.8262\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 26s 186us/step - loss: 0.3504 - accuracy: 0.8273 - val_loss: 0.3453 - val_accuracy: 0.8282\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 26s 183us/step - loss: 0.3486 - accuracy: 0.8278 - val_loss: 0.3410 - val_accuracy: 0.8298\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.3462 - accuracy: 0.8300 - val_loss: 0.3405 - val_accuracy: 0.8282\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 24s 170us/step - loss: 0.3428 - accuracy: 0.8343 - val_loss: 0.3333 - val_accuracy: 0.8490\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 24s 174us/step - loss: 0.3352 - accuracy: 0.8455 - val_loss: 0.3198 - val_accuracy: 0.8581\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 29s 207us/step - loss: 0.3247 - accuracy: 0.8557 - val_loss: 0.3123 - val_accuracy: 0.8675\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 28s 196us/step - loss: 0.3144 - accuracy: 0.8632 - val_loss: 0.3008 - val_accuracy: 0.8711\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 30s 213us/step - loss: 0.3092 - accuracy: 0.8672 - val_loss: 0.2955 - val_accuracy: 0.8750\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 27s 195us/step - loss: 0.3027 - accuracy: 0.8693 - val_loss: 0.2891 - val_accuracy: 0.8770\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 28s 203us/step - loss: 0.2951 - accuracy: 0.8719 - val_loss: 0.2856 - val_accuracy: 0.8762\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 25s 181us/step - loss: 0.2895 - accuracy: 0.8738 - val_loss: 0.2808 - val_accuracy: 0.8780\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.2866 - accuracy: 0.8747 - val_loss: 0.2828 - val_accuracy: 0.8758\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 25s 178us/step - loss: 0.2860 - accuracy: 0.8751 - val_loss: 0.2784 - val_accuracy: 0.8796\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 25s 177us/step - loss: 0.2841 - accuracy: 0.8761 - val_loss: 0.2757 - val_accuracy: 0.8786\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 39s 277us/step - loss: 0.2828 - accuracy: 0.8767 - val_loss: 0.2758 - val_accuracy: 0.8789\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 0.2809 - accuracy: 0.8776 - val_loss: 0.2745 - val_accuracy: 0.8776\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 0.2795 - accuracy: 0.8773 - val_loss: 0.2731 - val_accuracy: 0.8793\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 43s 307us/step - loss: 0.2774 - accuracy: 0.8774 - val_loss: 0.2757 - val_accuracy: 0.8697\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 0.2752 - accuracy: 0.8771 - val_loss: 0.2696 - val_accuracy: 0.8780\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 43s 307us/step - loss: 0.2714 - accuracy: 0.8783 - val_loss: 0.2622 - val_accuracy: 0.8811\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 43s 309us/step - loss: 0.2693 - accuracy: 0.8781 - val_loss: 0.2593 - val_accuracy: 0.8806\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 44s 311us/step - loss: 0.2679 - accuracy: 0.8779 - val_loss: 0.2573 - val_accuracy: 0.8827\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.2660 - accuracy: 0.8786 - val_loss: 0.2573 - val_accuracy: 0.8811\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.2658 - accuracy: 0.8784 - val_loss: 0.2556 - val_accuracy: 0.8826\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 0.2660 - accuracy: 0.8782 - val_loss: 0.2705 - val_accuracy: 0.8685\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 44s 313us/step - loss: 0.2644 - accuracy: 0.8785 - val_loss: 0.2653 - val_accuracy: 0.8809\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 44s 313us/step - loss: 0.2644 - accuracy: 0.8777 - val_loss: 0.2536 - val_accuracy: 0.8815\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.2635 - accuracy: 0.8779 - val_loss: 0.2547 - val_accuracy: 0.8801\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 44s 313us/step - loss: 0.2628 - accuracy: 0.8786 - val_loss: 0.2545 - val_accuracy: 0.8808\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 44s 312us/step - loss: 0.2636 - accuracy: 0.8787 - val_loss: 0.2552 - val_accuracy: 0.8806\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.2626 - accuracy: 0.8789 - val_loss: 0.2545 - val_accuracy: 0.8803\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.2625 - accuracy: 0.8787 - val_loss: 0.2569 - val_accuracy: 0.8804\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.2623 - accuracy: 0.8778 - val_loss: 0.2560 - val_accuracy: 0.8818\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 45s 318us/step - loss: 0.2614 - accuracy: 0.8789 - val_loss: 0.2521 - val_accuracy: 0.8819\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.2622 - accuracy: 0.8790 - val_loss: 0.2558 - val_accuracy: 0.8833\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 45s 318us/step - loss: 0.2610 - accuracy: 0.8788 - val_loss: 0.2526 - val_accuracy: 0.8818\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.2610 - accuracy: 0.8786 - val_loss: 0.2527 - val_accuracy: 0.8809\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 0.2609 - accuracy: 0.8791 - val_loss: 0.2522 - val_accuracy: 0.8812\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 0.2609 - accuracy: 0.8791 - val_loss: 0.2496 - val_accuracy: 0.8827\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.2610 - accuracy: 0.8792 - val_loss: 0.2562 - val_accuracy: 0.8822\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 45s 320us/step - loss: 0.2605 - accuracy: 0.8793 - val_loss: 0.2576 - val_accuracy: 0.8767\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 45s 317us/step - loss: 0.2601 - accuracy: 0.8795 - val_loss: 0.2655 - val_accuracy: 0.8819\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.2594 - accuracy: 0.8791 - val_loss: 0.2513 - val_accuracy: 0.8814\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 45s 318us/step - loss: 0.2588 - accuracy: 0.8799 - val_loss: 0.2504 - val_accuracy: 0.8814\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 45s 319us/step - loss: 0.2595 - accuracy: 0.8789 - val_loss: 0.2471 - val_accuracy: 0.8837\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 45s 319us/step - loss: 0.2593 - accuracy: 0.8790 - val_loss: 0.2472 - val_accuracy: 0.8820\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 45s 323us/step - loss: 0.2592 - accuracy: 0.8797 - val_loss: 0.2511 - val_accuracy: 0.8810\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 44s 312us/step - loss: 0.2596 - accuracy: 0.8801 - val_loss: 0.2595 - val_accuracy: 0.8854\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 44s 311us/step - loss: 0.2587 - accuracy: 0.8796 - val_loss: 0.2495 - val_accuracy: 0.8815\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 0.2591 - accuracy: 0.8795 - val_loss: 0.2491 - val_accuracy: 0.8835\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 44s 310us/step - loss: 0.2587 - accuracy: 0.8796 - val_loss: 0.2460 - val_accuracy: 0.8834\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 43s 309us/step - loss: 0.2588 - accuracy: 0.8795 - val_loss: 0.2473 - val_accuracy: 0.8816\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 44s 311us/step - loss: 0.2581 - accuracy: 0.8794 - val_loss: 0.2498 - val_accuracy: 0.8811\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 0.2585 - accuracy: 0.8799 - val_loss: 0.2495 - val_accuracy: 0.8820\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 44s 310us/step - loss: 0.2579 - accuracy: 0.8796 - val_loss: 0.2458 - val_accuracy: 0.8832\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 0.2573 - accuracy: 0.8798 - val_loss: 0.2471 - val_accuracy: 0.8836\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 44s 313us/step - loss: 0.2566 - accuracy: 0.8810 - val_loss: 0.2518 - val_accuracy: 0.8820\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 42s 301us/step - loss: 0.2573 - accuracy: 0.8804 - val_loss: 0.2500 - val_accuracy: 0.8821\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 42s 302us/step - loss: 0.2569 - accuracy: 0.8796 - val_loss: 0.2457 - val_accuracy: 0.8829\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 42s 302us/step - loss: 0.2567 - accuracy: 0.8799 - val_loss: 0.2579 - val_accuracy: 0.8723\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 42s 302us/step - loss: 0.2568 - accuracy: 0.8799 - val_loss: 0.2457 - val_accuracy: 0.8824\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 42s 302us/step - loss: 0.2569 - accuracy: 0.8802 - val_loss: 0.2506 - val_accuracy: 0.8838\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 42s 301us/step - loss: 0.2563 - accuracy: 0.8802 - val_loss: 0.2457 - val_accuracy: 0.8844\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 42s 300us/step - loss: 0.2572 - accuracy: 0.8804 - val_loss: 0.2450 - val_accuracy: 0.8828\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 43s 303us/step - loss: 0.2556 - accuracy: 0.8808 - val_loss: 0.2440 - val_accuracy: 0.8850\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2563 - accuracy: 0.8807 - val_loss: 0.2453 - val_accuracy: 0.8864\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2559 - accuracy: 0.8807 - val_loss: 0.2473 - val_accuracy: 0.8841\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2559 - accuracy: 0.8807 - val_loss: 0.2498 - val_accuracy: 0.8842\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2550 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8832\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2558 - accuracy: 0.8809 - val_loss: 0.2505 - val_accuracy: 0.8764\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2555 - accuracy: 0.8808 - val_loss: 0.2433 - val_accuracy: 0.8853\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2546 - accuracy: 0.8811 - val_loss: 0.2475 - val_accuracy: 0.8855\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2546 - accuracy: 0.8821 - val_loss: 0.2500 - val_accuracy: 0.8825\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2553 - accuracy: 0.8810 - val_loss: 0.2462 - val_accuracy: 0.8834\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2563 - accuracy: 0.8801 - val_loss: 0.2450 - val_accuracy: 0.8842\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2563 - accuracy: 0.8813 - val_loss: 0.2468 - val_accuracy: 0.8842\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2559 - accuracy: 0.8813 - val_loss: 0.2415 - val_accuracy: 0.8851\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2554 - accuracy: 0.8812 - val_loss: 0.2424 - val_accuracy: 0.8855\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2544 - accuracy: 0.8815 - val_loss: 0.2457 - val_accuracy: 0.8841\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2556 - accuracy: 0.8813 - val_loss: 0.2509 - val_accuracy: 0.8827\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2541 - accuracy: 0.8813 - val_loss: 0.2519 - val_accuracy: 0.8812\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2543 - accuracy: 0.8813 - val_loss: 0.2480 - val_accuracy: 0.8845\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2559 - accuracy: 0.8813 - val_loss: 0.2485 - val_accuracy: 0.8825\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2545 - accuracy: 0.8813 - val_loss: 0.2463 - val_accuracy: 0.8834\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2544 - accuracy: 0.8820 - val_loss: 0.2436 - val_accuracy: 0.8852\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2545 - accuracy: 0.8816 - val_loss: 0.2444 - val_accuracy: 0.8850\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2542 - accuracy: 0.8819 - val_loss: 0.2425 - val_accuracy: 0.8835\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2545 - accuracy: 0.8819 - val_loss: 0.2439 - val_accuracy: 0.8849\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2548 - accuracy: 0.8817 - val_loss: 0.2440 - val_accuracy: 0.8851\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2532 - accuracy: 0.8822 - val_loss: 0.2418 - val_accuracy: 0.8865\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2544 - accuracy: 0.8822 - val_loss: 0.2402 - val_accuracy: 0.8853\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2537 - accuracy: 0.8819 - val_loss: 0.2497 - val_accuracy: 0.8792\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2541 - accuracy: 0.8819 - val_loss: 0.2430 - val_accuracy: 0.8850\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2538 - accuracy: 0.8821 - val_loss: 0.2428 - val_accuracy: 0.8821\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2533 - accuracy: 0.8828 - val_loss: 0.2454 - val_accuracy: 0.8812\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2540 - accuracy: 0.8819 - val_loss: 0.2421 - val_accuracy: 0.8870\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2543 - accuracy: 0.8817 - val_loss: 0.2416 - val_accuracy: 0.8858\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2545 - accuracy: 0.8824 - val_loss: 0.2728 - val_accuracy: 0.8660\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2533 - accuracy: 0.8824 - val_loss: 0.2480 - val_accuracy: 0.8819\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2533 - accuracy: 0.8825 - val_loss: 0.2407 - val_accuracy: 0.8843\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2539 - accuracy: 0.8825 - val_loss: 0.2446 - val_accuracy: 0.8863\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2532 - accuracy: 0.8831 - val_loss: 0.2493 - val_accuracy: 0.8797\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2531 - accuracy: 0.8823 - val_loss: 0.2580 - val_accuracy: 0.8744\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2529 - accuracy: 0.8827 - val_loss: 0.2411 - val_accuracy: 0.8862\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2529 - accuracy: 0.8831 - val_loss: 0.2453 - val_accuracy: 0.8807\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2519 - accuracy: 0.8833 - val_loss: 0.2485 - val_accuracy: 0.8833\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2531 - accuracy: 0.8823 - val_loss: 0.2429 - val_accuracy: 0.8855\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2537 - accuracy: 0.8824 - val_loss: 0.2483 - val_accuracy: 0.8824\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2531 - accuracy: 0.8825 - val_loss: 0.2457 - val_accuracy: 0.8825\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2529 - accuracy: 0.8828 - val_loss: 0.2391 - val_accuracy: 0.8859\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2525 - accuracy: 0.8825 - val_loss: 0.2455 - val_accuracy: 0.8862\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2519 - accuracy: 0.8827 - val_loss: 0.2436 - val_accuracy: 0.8848\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2514 - accuracy: 0.8836 - val_loss: 0.2441 - val_accuracy: 0.8840\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2526 - accuracy: 0.8828 - val_loss: 0.2438 - val_accuracy: 0.8839\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2530 - accuracy: 0.8821 - val_loss: 0.2394 - val_accuracy: 0.8848\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2523 - accuracy: 0.8830 - val_loss: 0.2468 - val_accuracy: 0.8828\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2515 - accuracy: 0.8831 - val_loss: 0.2399 - val_accuracy: 0.8861\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2513 - accuracy: 0.8831 - val_loss: 0.2380 - val_accuracy: 0.8874\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2518 - accuracy: 0.8828 - val_loss: 0.2443 - val_accuracy: 0.8803\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2517 - accuracy: 0.8827 - val_loss: 0.2455 - val_accuracy: 0.8869\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2528 - accuracy: 0.8823 - val_loss: 0.2400 - val_accuracy: 0.8855\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2519 - accuracy: 0.8836 - val_loss: 0.2426 - val_accuracy: 0.8855\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2519 - accuracy: 0.8838 - val_loss: 0.2466 - val_accuracy: 0.8785\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2533 - accuracy: 0.8829 - val_loss: 0.2399 - val_accuracy: 0.8864\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2524 - accuracy: 0.8830 - val_loss: 0.2407 - val_accuracy: 0.8861\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2523 - accuracy: 0.8835 - val_loss: 0.2471 - val_accuracy: 0.8844\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2515 - accuracy: 0.8837 - val_loss: 0.2406 - val_accuracy: 0.8838\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2522 - accuracy: 0.8832 - val_loss: 0.2444 - val_accuracy: 0.8803\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2517 - accuracy: 0.8835 - val_loss: 0.2433 - val_accuracy: 0.8825\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2526 - accuracy: 0.8832 - val_loss: 0.2397 - val_accuracy: 0.8877\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2519 - accuracy: 0.8835 - val_loss: 0.2461 - val_accuracy: 0.8820\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2520 - accuracy: 0.8833 - val_loss: 0.2436 - val_accuracy: 0.8826\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2518 - accuracy: 0.8833 - val_loss: 0.2450 - val_accuracy: 0.8817\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2511 - accuracy: 0.8834 - val_loss: 0.2387 - val_accuracy: 0.8846\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2518 - accuracy: 0.8831 - val_loss: 0.2379 - val_accuracy: 0.8867\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2509 - accuracy: 0.8840 - val_loss: 0.2417 - val_accuracy: 0.8877\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2514 - accuracy: 0.8842 - val_loss: 0.2430 - val_accuracy: 0.8802\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2511 - accuracy: 0.8842 - val_loss: 0.2410 - val_accuracy: 0.8844\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2530 - accuracy: 0.8831 - val_loss: 0.2407 - val_accuracy: 0.8869\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2514 - accuracy: 0.8836 - val_loss: 0.2451 - val_accuracy: 0.8795\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2508 - accuracy: 0.8841 - val_loss: 0.2446 - val_accuracy: 0.8818\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2520 - accuracy: 0.8838 - val_loss: 0.2481 - val_accuracy: 0.8805\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2527 - accuracy: 0.8830 - val_loss: 0.2392 - val_accuracy: 0.8853\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2524 - accuracy: 0.8831 - val_loss: 0.2463 - val_accuracy: 0.8849\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2521 - accuracy: 0.8836 - val_loss: 0.2554 - val_accuracy: 0.8699\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2517 - accuracy: 0.8833 - val_loss: 0.2403 - val_accuracy: 0.8848\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2505 - accuracy: 0.8838 - val_loss: 0.2502 - val_accuracy: 0.8870\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2511 - accuracy: 0.8835 - val_loss: 0.2673 - val_accuracy: 0.8835\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2503 - accuracy: 0.8839 - val_loss: 0.2392 - val_accuracy: 0.8859\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2512 - accuracy: 0.8840 - val_loss: 0.2413 - val_accuracy: 0.8868\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2514 - accuracy: 0.8835 - val_loss: 0.2407 - val_accuracy: 0.8843\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2517 - accuracy: 0.8845 - val_loss: 0.2571 - val_accuracy: 0.8855\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2520 - accuracy: 0.8836 - val_loss: 0.2374 - val_accuracy: 0.8877\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2513 - accuracy: 0.8842 - val_loss: 0.2468 - val_accuracy: 0.8821\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2509 - accuracy: 0.8843 - val_loss: 0.2380 - val_accuracy: 0.8855\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2510 - accuracy: 0.8836 - val_loss: 0.2431 - val_accuracy: 0.8829\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2520 - accuracy: 0.8835 - val_loss: 0.2368 - val_accuracy: 0.8861\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2504 - accuracy: 0.8846 - val_loss: 0.2363 - val_accuracy: 0.8861\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2499 - accuracy: 0.8841 - val_loss: 0.2389 - val_accuracy: 0.8877\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2504 - accuracy: 0.8840 - val_loss: 0.2379 - val_accuracy: 0.8861\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2500 - accuracy: 0.8840 - val_loss: 0.2408 - val_accuracy: 0.8835\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2506 - accuracy: 0.8841 - val_loss: 0.2614 - val_accuracy: 0.8700\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2508 - accuracy: 0.8841 - val_loss: 0.2383 - val_accuracy: 0.8881\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2499 - accuracy: 0.8841 - val_loss: 0.2411 - val_accuracy: 0.8860\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2503 - accuracy: 0.8841 - val_loss: 0.2379 - val_accuracy: 0.8852\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2500 - accuracy: 0.8839 - val_loss: 0.2374 - val_accuracy: 0.8855\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2508 - accuracy: 0.8840 - val_loss: 0.2396 - val_accuracy: 0.8892\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2516 - accuracy: 0.8835 - val_loss: 0.2374 - val_accuracy: 0.8860\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2502 - accuracy: 0.8834 - val_loss: 0.2439 - val_accuracy: 0.8839\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2500 - accuracy: 0.8844 - val_loss: 0.2451 - val_accuracy: 0.8862\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2506 - accuracy: 0.8842 - val_loss: 0.2430 - val_accuracy: 0.8830\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2504 - accuracy: 0.8843 - val_loss: 0.2407 - val_accuracy: 0.8839\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2495 - accuracy: 0.8846 - val_loss: 0.2475 - val_accuracy: 0.8828\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2503 - accuracy: 0.8842 - val_loss: 0.2398 - val_accuracy: 0.8859\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2498 - accuracy: 0.8843 - val_loss: 0.2424 - val_accuracy: 0.8852\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2505 - accuracy: 0.8839 - val_loss: 0.2391 - val_accuracy: 0.8889\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2515 - accuracy: 0.8835 - val_loss: 0.2475 - val_accuracy: 0.8867\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2509 - accuracy: 0.8845 - val_loss: 0.2369 - val_accuracy: 0.8872\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2504 - accuracy: 0.8843 - val_loss: 0.2381 - val_accuracy: 0.8860\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2512 - accuracy: 0.8839 - val_loss: 0.2385 - val_accuracy: 0.8865\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2511 - accuracy: 0.8842 - val_loss: 0.2399 - val_accuracy: 0.8844\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2508 - accuracy: 0.8833 - val_loss: 0.2378 - val_accuracy: 0.8888\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2499 - accuracy: 0.8851 - val_loss: 0.2388 - val_accuracy: 0.8903\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2505 - accuracy: 0.8845 - val_loss: 0.2383 - val_accuracy: 0.8862\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2498 - accuracy: 0.8851 - val_loss: 0.2378 - val_accuracy: 0.8861\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 42s 299us/step - loss: 0.2498 - accuracy: 0.8847 - val_loss: 0.2398 - val_accuracy: 0.8841\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 51s 363us/step - loss: 0.2494 - accuracy: 0.8848 - val_loss: 0.2409 - val_accuracy: 0.8872\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2497 - accuracy: 0.8843 - val_loss: 0.2415 - val_accuracy: 0.8870\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2483 - accuracy: 0.8848 - val_loss: 0.2377 - val_accuracy: 0.8902\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2491 - accuracy: 0.8849 - val_loss: 0.2508 - val_accuracy: 0.8815\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2492 - accuracy: 0.8846 - val_loss: 0.2374 - val_accuracy: 0.8869\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2496 - accuracy: 0.8845 - val_loss: 0.2455 - val_accuracy: 0.8831\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2505 - accuracy: 0.8844 - val_loss: 0.2499 - val_accuracy: 0.8776\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2495 - accuracy: 0.8844 - val_loss: 0.2371 - val_accuracy: 0.8890\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2499 - accuracy: 0.8849 - val_loss: 0.2387 - val_accuracy: 0.8897\n",
      "accuracy: 88.97%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2492 - accuracy: 0.8848 - val_loss: 0.2382 - val_accuracy: 0.8890\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2486 - accuracy: 0.8842 - val_loss: 0.2356 - val_accuracy: 0.8917\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2487 - accuracy: 0.8846 - val_loss: 0.2386 - val_accuracy: 0.8887\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2491 - accuracy: 0.8845 - val_loss: 0.2412 - val_accuracy: 0.8907\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2492 - accuracy: 0.8844 - val_loss: 0.2402 - val_accuracy: 0.8861\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2492 - accuracy: 0.8844 - val_loss: 0.2412 - val_accuracy: 0.8890\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2497 - accuracy: 0.8844 - val_loss: 0.2404 - val_accuracy: 0.8878\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2485 - accuracy: 0.8853 - val_loss: 0.2390 - val_accuracy: 0.8920\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2490 - accuracy: 0.8844 - val_loss: 0.2402 - val_accuracy: 0.8851\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2495 - accuracy: 0.8843 - val_loss: 0.2356 - val_accuracy: 0.8916\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2477 - accuracy: 0.8852 - val_loss: 0.2417 - val_accuracy: 0.8865\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2488 - accuracy: 0.8842 - val_loss: 0.2489 - val_accuracy: 0.8903\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2484 - accuracy: 0.8849 - val_loss: 0.2371 - val_accuracy: 0.8916\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2493 - accuracy: 0.8848 - val_loss: 0.2403 - val_accuracy: 0.8904\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2486 - accuracy: 0.8847 - val_loss: 0.2382 - val_accuracy: 0.8910\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2497 - accuracy: 0.8842 - val_loss: 0.2381 - val_accuracy: 0.8930\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2487 - accuracy: 0.8850 - val_loss: 0.2401 - val_accuracy: 0.8890\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 0.2443 - val_accuracy: 0.8860\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2493 - accuracy: 0.8843 - val_loss: 0.2522 - val_accuracy: 0.8791\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2492 - accuracy: 0.8844 - val_loss: 0.2396 - val_accuracy: 0.8888\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2490 - accuracy: 0.8842 - val_loss: 0.2366 - val_accuracy: 0.8898\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2488 - accuracy: 0.8845 - val_loss: 0.2461 - val_accuracy: 0.8865\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2485 - accuracy: 0.8849 - val_loss: 0.2376 - val_accuracy: 0.8917\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2486 - accuracy: 0.8849 - val_loss: 0.2565 - val_accuracy: 0.8867\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2490 - accuracy: 0.8847 - val_loss: 0.2414 - val_accuracy: 0.8878\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2482 - accuracy: 0.8850 - val_loss: 0.2412 - val_accuracy: 0.8859\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2490 - accuracy: 0.8851 - val_loss: 0.2461 - val_accuracy: 0.8858\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.2490 - accuracy: 0.8841 - val_loss: 0.2385 - val_accuracy: 0.8882\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2486 - accuracy: 0.8836 - val_loss: 0.2403 - val_accuracy: 0.8893\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2485 - accuracy: 0.8848 - val_loss: 0.2396 - val_accuracy: 0.8896\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2493 - accuracy: 0.8848 - val_loss: 0.2359 - val_accuracy: 0.8930\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2485 - accuracy: 0.8848 - val_loss: 0.2355 - val_accuracy: 0.8902\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2479 - accuracy: 0.8849 - val_loss: 0.2384 - val_accuracy: 0.8924\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2484 - accuracy: 0.8842 - val_loss: 0.2403 - val_accuracy: 0.8874\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2486 - accuracy: 0.8843 - val_loss: 0.2432 - val_accuracy: 0.8900\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2488 - accuracy: 0.8844 - val_loss: 0.2383 - val_accuracy: 0.8881\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2482 - accuracy: 0.8849 - val_loss: 0.2361 - val_accuracy: 0.8908\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2478 - accuracy: 0.8851 - val_loss: 0.2369 - val_accuracy: 0.8869\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2493 - accuracy: 0.8847 - val_loss: 0.2425 - val_accuracy: 0.8888\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2488 - accuracy: 0.8847 - val_loss: 0.2414 - val_accuracy: 0.8899\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2476 - accuracy: 0.8852 - val_loss: 0.2396 - val_accuracy: 0.8870\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2477 - accuracy: 0.8850 - val_loss: 0.2434 - val_accuracy: 0.8859\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2484 - accuracy: 0.8849 - val_loss: 0.2429 - val_accuracy: 0.8866\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2469 - accuracy: 0.8847 - val_loss: 0.2427 - val_accuracy: 0.8934\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2480 - accuracy: 0.8851 - val_loss: 0.2374 - val_accuracy: 0.8896\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2472 - accuracy: 0.8845 - val_loss: 0.2348 - val_accuracy: 0.8910\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2477 - accuracy: 0.8851 - val_loss: 0.2403 - val_accuracy: 0.8852\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2481 - accuracy: 0.8847 - val_loss: 0.2402 - val_accuracy: 0.8917\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2477 - accuracy: 0.8853 - val_loss: 0.2383 - val_accuracy: 0.8901\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2484 - accuracy: 0.8847 - val_loss: 0.2386 - val_accuracy: 0.8890\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2481 - accuracy: 0.8853 - val_loss: 0.2365 - val_accuracy: 0.8910\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2476 - accuracy: 0.8852 - val_loss: 0.2366 - val_accuracy: 0.8912\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2479 - accuracy: 0.8849 - val_loss: 0.2371 - val_accuracy: 0.8924\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2481 - accuracy: 0.8848 - val_loss: 0.2352 - val_accuracy: 0.8927\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2483 - accuracy: 0.8843 - val_loss: 0.2408 - val_accuracy: 0.8875\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2474 - accuracy: 0.8854 - val_loss: 0.2436 - val_accuracy: 0.8867\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2482 - accuracy: 0.8844 - val_loss: 0.2430 - val_accuracy: 0.8903\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2492 - accuracy: 0.8845 - val_loss: 0.2412 - val_accuracy: 0.8887\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2474 - accuracy: 0.8857 - val_loss: 0.2486 - val_accuracy: 0.8845\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2486 - accuracy: 0.8849 - val_loss: 0.2345 - val_accuracy: 0.8918\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2478 - accuracy: 0.8846 - val_loss: 0.2473 - val_accuracy: 0.8877\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2475 - accuracy: 0.8853 - val_loss: 0.2354 - val_accuracy: 0.8913\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2470 - accuracy: 0.8850 - val_loss: 0.2350 - val_accuracy: 0.8897\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2479 - accuracy: 0.8856 - val_loss: 0.2396 - val_accuracy: 0.8859\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2481 - accuracy: 0.8845 - val_loss: 0.2509 - val_accuracy: 0.8815\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2483 - accuracy: 0.8843 - val_loss: 0.2432 - val_accuracy: 0.8858\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2471 - accuracy: 0.8855 - val_loss: 0.2392 - val_accuracy: 0.8892\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2479 - accuracy: 0.8849 - val_loss: 0.2397 - val_accuracy: 0.8881\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2473 - accuracy: 0.8856 - val_loss: 0.2375 - val_accuracy: 0.8923\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2477 - accuracy: 0.8856 - val_loss: 0.2400 - val_accuracy: 0.8900\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2476 - accuracy: 0.8846 - val_loss: 0.2363 - val_accuracy: 0.8910\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2475 - accuracy: 0.8846 - val_loss: 0.2498 - val_accuracy: 0.8814\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 0.2350 - val_accuracy: 0.8894\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2467 - accuracy: 0.8855 - val_loss: 0.2428 - val_accuracy: 0.8856\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2477 - accuracy: 0.8854 - val_loss: 0.2390 - val_accuracy: 0.8883\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2474 - accuracy: 0.8858 - val_loss: 0.2369 - val_accuracy: 0.8910\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2477 - accuracy: 0.8851 - val_loss: 0.2394 - val_accuracy: 0.8892\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2475 - accuracy: 0.8854 - val_loss: 0.2374 - val_accuracy: 0.8897\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2476 - accuracy: 0.8852 - val_loss: 0.2498 - val_accuracy: 0.8798\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2475 - accuracy: 0.8854 - val_loss: 0.2370 - val_accuracy: 0.8910\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2482 - accuracy: 0.8851 - val_loss: 0.2373 - val_accuracy: 0.8903\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2477 - accuracy: 0.8856 - val_loss: 0.2376 - val_accuracy: 0.8888\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2482 - accuracy: 0.8845 - val_loss: 0.2396 - val_accuracy: 0.8911\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2473 - accuracy: 0.8848 - val_loss: 0.2424 - val_accuracy: 0.8929\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2469 - accuracy: 0.8859 - val_loss: 0.2348 - val_accuracy: 0.8926\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2479 - accuracy: 0.8851 - val_loss: 0.2361 - val_accuracy: 0.8912\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2469 - accuracy: 0.8856 - val_loss: 0.2409 - val_accuracy: 0.8877\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2482 - accuracy: 0.8851 - val_loss: 0.2362 - val_accuracy: 0.8904\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2478 - accuracy: 0.8853 - val_loss: 0.2375 - val_accuracy: 0.8897\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2477 - accuracy: 0.8848 - val_loss: 0.2385 - val_accuracy: 0.8906\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2468 - accuracy: 0.8857 - val_loss: 0.2421 - val_accuracy: 0.8817\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2480 - accuracy: 0.8849 - val_loss: 0.2387 - val_accuracy: 0.8926\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2471 - accuracy: 0.8855 - val_loss: 0.2415 - val_accuracy: 0.8851\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2483 - accuracy: 0.8848 - val_loss: 0.2369 - val_accuracy: 0.8922\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2475 - accuracy: 0.8849 - val_loss: 0.2368 - val_accuracy: 0.8898\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2474 - accuracy: 0.8853 - val_loss: 0.2361 - val_accuracy: 0.8922\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2480 - accuracy: 0.8848 - val_loss: 0.2435 - val_accuracy: 0.8847\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2480 - accuracy: 0.8854 - val_loss: 0.2351 - val_accuracy: 0.8940\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2472 - accuracy: 0.8851 - val_loss: 0.2379 - val_accuracy: 0.8880\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2475 - accuracy: 0.8852 - val_loss: 0.2362 - val_accuracy: 0.8908\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2479 - accuracy: 0.8855 - val_loss: 0.2368 - val_accuracy: 0.8883\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2475 - accuracy: 0.8859 - val_loss: 0.2425 - val_accuracy: 0.8862\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2469 - accuracy: 0.8857 - val_loss: 0.2321 - val_accuracy: 0.8931\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2469 - accuracy: 0.8860 - val_loss: 0.2349 - val_accuracy: 0.8904\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2477 - accuracy: 0.8860 - val_loss: 0.2446 - val_accuracy: 0.8859\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2478 - accuracy: 0.8843 - val_loss: 0.2360 - val_accuracy: 0.8916\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2476 - accuracy: 0.8852 - val_loss: 0.2405 - val_accuracy: 0.8885\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2474 - accuracy: 0.8853 - val_loss: 0.2335 - val_accuracy: 0.8942\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2471 - accuracy: 0.8855 - val_loss: 0.2353 - val_accuracy: 0.8899\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2474 - accuracy: 0.8855 - val_loss: 0.2375 - val_accuracy: 0.8895\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2482 - accuracy: 0.8852 - val_loss: 0.2338 - val_accuracy: 0.8934\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2480 - accuracy: 0.8853 - val_loss: 0.2358 - val_accuracy: 0.8892\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2477 - accuracy: 0.8857 - val_loss: 0.2370 - val_accuracy: 0.8922\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2468 - accuracy: 0.8853 - val_loss: 0.2409 - val_accuracy: 0.8922\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2480 - accuracy: 0.8855 - val_loss: 0.2376 - val_accuracy: 0.8904\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2476 - accuracy: 0.8854 - val_loss: 0.2368 - val_accuracy: 0.8908\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2485 - accuracy: 0.8856 - val_loss: 0.2421 - val_accuracy: 0.8851\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2468 - accuracy: 0.8857 - val_loss: 0.2386 - val_accuracy: 0.8916\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2470 - accuracy: 0.8854 - val_loss: 0.2341 - val_accuracy: 0.8896\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2476 - accuracy: 0.8846 - val_loss: 0.2420 - val_accuracy: 0.8875\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2469 - accuracy: 0.8855 - val_loss: 0.2397 - val_accuracy: 0.8882\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2473 - accuracy: 0.8855 - val_loss: 0.2458 - val_accuracy: 0.8811\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2486 - accuracy: 0.8850 - val_loss: 0.2441 - val_accuracy: 0.8879\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2475 - accuracy: 0.8855 - val_loss: 0.2348 - val_accuracy: 0.8914\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2469 - accuracy: 0.8853 - val_loss: 0.2440 - val_accuracy: 0.8877\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2473 - accuracy: 0.8856 - val_loss: 0.2407 - val_accuracy: 0.8854\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2481 - accuracy: 0.8856 - val_loss: 0.2355 - val_accuracy: 0.8902\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2470 - accuracy: 0.8857 - val_loss: 0.2339 - val_accuracy: 0.8917\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2488 - accuracy: 0.8848 - val_loss: 0.2389 - val_accuracy: 0.8857\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2475 - accuracy: 0.8853 - val_loss: 0.2400 - val_accuracy: 0.8872\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2480 - accuracy: 0.8850 - val_loss: 0.2486 - val_accuracy: 0.8826\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2474 - accuracy: 0.8855 - val_loss: 0.2355 - val_accuracy: 0.8903\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2477 - accuracy: 0.8849 - val_loss: 0.2349 - val_accuracy: 0.8895\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2473 - accuracy: 0.8853 - val_loss: 0.2333 - val_accuracy: 0.8934\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2471 - accuracy: 0.8855 - val_loss: 0.2366 - val_accuracy: 0.8897\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2466 - accuracy: 0.8857 - val_loss: 0.2358 - val_accuracy: 0.8906\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2477 - accuracy: 0.8860 - val_loss: 0.2373 - val_accuracy: 0.8893\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2471 - accuracy: 0.8852 - val_loss: 0.2366 - val_accuracy: 0.8884\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2466 - accuracy: 0.8855 - val_loss: 0.2433 - val_accuracy: 0.8853\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2474 - accuracy: 0.8857 - val_loss: 0.2326 - val_accuracy: 0.8905\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2479 - accuracy: 0.8854 - val_loss: 0.2400 - val_accuracy: 0.8859\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2479 - accuracy: 0.8860 - val_loss: 0.2363 - val_accuracy: 0.8929\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2480 - accuracy: 0.8856 - val_loss: 0.2383 - val_accuracy: 0.8893\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2478 - accuracy: 0.8857 - val_loss: 0.2370 - val_accuracy: 0.8871\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2468 - accuracy: 0.8859 - val_loss: 0.2337 - val_accuracy: 0.8934\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2470 - accuracy: 0.8855 - val_loss: 0.2380 - val_accuracy: 0.8891\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2474 - accuracy: 0.8858 - val_loss: 0.2365 - val_accuracy: 0.8893\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2471 - accuracy: 0.8852 - val_loss: 0.2360 - val_accuracy: 0.8910\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2473 - accuracy: 0.8853 - val_loss: 0.2357 - val_accuracy: 0.8907\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 0.2392 - val_accuracy: 0.8863\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2469 - accuracy: 0.8850 - val_loss: 0.2336 - val_accuracy: 0.8908\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2474 - accuracy: 0.8859 - val_loss: 0.2395 - val_accuracy: 0.8891\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2465 - accuracy: 0.8855 - val_loss: 0.2356 - val_accuracy: 0.8904\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2472 - accuracy: 0.8854 - val_loss: 0.2324 - val_accuracy: 0.8920\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2471 - accuracy: 0.8853 - val_loss: 0.2353 - val_accuracy: 0.8924\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2471 - accuracy: 0.8857 - val_loss: 0.2401 - val_accuracy: 0.8873\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2475 - accuracy: 0.8846 - val_loss: 0.2461 - val_accuracy: 0.8817\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2475 - accuracy: 0.8848 - val_loss: 0.2371 - val_accuracy: 0.8911\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2474 - accuracy: 0.8859 - val_loss: 0.2369 - val_accuracy: 0.8877\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2470 - accuracy: 0.8860 - val_loss: 0.2369 - val_accuracy: 0.8897\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2479 - accuracy: 0.8854 - val_loss: 0.2393 - val_accuracy: 0.8905\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2464 - accuracy: 0.8857 - val_loss: 0.2362 - val_accuracy: 0.8934\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2471 - accuracy: 0.8856 - val_loss: 0.2356 - val_accuracy: 0.8920\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2471 - accuracy: 0.8856 - val_loss: 0.2353 - val_accuracy: 0.8908\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2464 - accuracy: 0.8858 - val_loss: 0.2402 - val_accuracy: 0.8886\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2472 - accuracy: 0.8859 - val_loss: 0.2372 - val_accuracy: 0.8925\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2479 - accuracy: 0.8848 - val_loss: 0.2380 - val_accuracy: 0.8884\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2469 - accuracy: 0.8849 - val_loss: 0.2322 - val_accuracy: 0.8942\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2474 - accuracy: 0.8859 - val_loss: 0.2356 - val_accuracy: 0.8909\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2473 - accuracy: 0.8854 - val_loss: 0.2362 - val_accuracy: 0.8926\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2468 - accuracy: 0.8860 - val_loss: 0.2517 - val_accuracy: 0.8898\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2476 - accuracy: 0.8853 - val_loss: 0.2349 - val_accuracy: 0.8903\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2472 - accuracy: 0.8857 - val_loss: 0.2369 - val_accuracy: 0.8917\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2470 - accuracy: 0.8858 - val_loss: 0.2366 - val_accuracy: 0.8911\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2468 - accuracy: 0.8858 - val_loss: 0.2366 - val_accuracy: 0.8894\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 0.2424 - val_accuracy: 0.8914\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2466 - accuracy: 0.8860 - val_loss: 0.2350 - val_accuracy: 0.8936\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2473 - accuracy: 0.8855 - val_loss: 0.2466 - val_accuracy: 0.8842\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2477 - accuracy: 0.8857 - val_loss: 0.2360 - val_accuracy: 0.8905\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2472 - accuracy: 0.8851 - val_loss: 0.2353 - val_accuracy: 0.8917\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2477 - accuracy: 0.8858 - val_loss: 0.2374 - val_accuracy: 0.8887\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2473 - accuracy: 0.8853 - val_loss: 0.2351 - val_accuracy: 0.8906\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2472 - accuracy: 0.8857 - val_loss: 0.2368 - val_accuracy: 0.8909\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2470 - accuracy: 0.8854 - val_loss: 0.2383 - val_accuracy: 0.8930\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2459 - accuracy: 0.8855 - val_loss: 0.2419 - val_accuracy: 0.8882\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2474 - accuracy: 0.8857 - val_loss: 0.2347 - val_accuracy: 0.8911\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2465 - accuracy: 0.8855 - val_loss: 0.2316 - val_accuracy: 0.8943\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2472 - accuracy: 0.8851 - val_loss: 0.2355 - val_accuracy: 0.8908\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2480 - accuracy: 0.8857 - val_loss: 0.2429 - val_accuracy: 0.8931\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2473 - accuracy: 0.8852 - val_loss: 0.2391 - val_accuracy: 0.8870\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2477 - accuracy: 0.8850 - val_loss: 0.2356 - val_accuracy: 0.8933\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2464 - accuracy: 0.8861 - val_loss: 0.2441 - val_accuracy: 0.8822\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2473 - accuracy: 0.8847 - val_loss: 0.2407 - val_accuracy: 0.8895\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2469 - accuracy: 0.8856 - val_loss: 0.2348 - val_accuracy: 0.8893\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2476 - accuracy: 0.8854 - val_loss: 0.2323 - val_accuracy: 0.8949\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2470 - accuracy: 0.8858 - val_loss: 0.2355 - val_accuracy: 0.8891\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2473 - accuracy: 0.8851 - val_loss: 0.2364 - val_accuracy: 0.8916\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2464 - accuracy: 0.8860 - val_loss: 0.2380 - val_accuracy: 0.8879\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2478 - accuracy: 0.8848 - val_loss: 0.2330 - val_accuracy: 0.8934\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2479 - accuracy: 0.8856 - val_loss: 0.2475 - val_accuracy: 0.8834\n",
      "accuracy: 88.34%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2480 - accuracy: 0.8856 - val_loss: 0.2383 - val_accuracy: 0.8908\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2473 - accuracy: 0.8856 - val_loss: 0.2356 - val_accuracy: 0.8900\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2465 - accuracy: 0.8863 - val_loss: 0.2377 - val_accuracy: 0.8877\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2471 - accuracy: 0.8857 - val_loss: 0.2375 - val_accuracy: 0.8862\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 0.2431 - val_accuracy: 0.8881\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2454 - accuracy: 0.8868 - val_loss: 0.2357 - val_accuracy: 0.8900\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2470 - accuracy: 0.8855 - val_loss: 0.2344 - val_accuracy: 0.8932\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2467 - accuracy: 0.8858 - val_loss: 0.2363 - val_accuracy: 0.8929\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2467 - accuracy: 0.8853 - val_loss: 0.2393 - val_accuracy: 0.8884\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2478 - accuracy: 0.8853 - val_loss: 0.2371 - val_accuracy: 0.8897\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2461 - accuracy: 0.8859 - val_loss: 0.2387 - val_accuracy: 0.8917\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2467 - accuracy: 0.8857 - val_loss: 0.2393 - val_accuracy: 0.8894\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2472 - accuracy: 0.8858 - val_loss: 0.2352 - val_accuracy: 0.8916\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2462 - accuracy: 0.8861 - val_loss: 0.2391 - val_accuracy: 0.8940\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2468 - accuracy: 0.8857 - val_loss: 0.2372 - val_accuracy: 0.8935\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2473 - accuracy: 0.8858 - val_loss: 0.2387 - val_accuracy: 0.8890\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2476 - accuracy: 0.8858 - val_loss: 0.2373 - val_accuracy: 0.8903\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2470 - accuracy: 0.8854 - val_loss: 0.2379 - val_accuracy: 0.8895\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2474 - accuracy: 0.8857 - val_loss: 0.2340 - val_accuracy: 0.8899\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2466 - accuracy: 0.8860 - val_loss: 0.2377 - val_accuracy: 0.8880\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2466 - accuracy: 0.8854 - val_loss: 0.2341 - val_accuracy: 0.8927\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2466 - accuracy: 0.8865 - val_loss: 0.2386 - val_accuracy: 0.8912\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2467 - accuracy: 0.8857 - val_loss: 0.2363 - val_accuracy: 0.8909\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2467 - accuracy: 0.8856 - val_loss: 0.2399 - val_accuracy: 0.8894\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2477 - accuracy: 0.8856 - val_loss: 0.2439 - val_accuracy: 0.8858\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2478 - accuracy: 0.8854 - val_loss: 0.2371 - val_accuracy: 0.8921\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2471 - accuracy: 0.8861 - val_loss: 0.2353 - val_accuracy: 0.8903\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2468 - accuracy: 0.8858 - val_loss: 0.2381 - val_accuracy: 0.8877\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2475 - accuracy: 0.8854 - val_loss: 0.2378 - val_accuracy: 0.8892\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2461 - accuracy: 0.8855 - val_loss: 0.2435 - val_accuracy: 0.8917\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2465 - accuracy: 0.8861 - val_loss: 0.2494 - val_accuracy: 0.8798\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2474 - accuracy: 0.8853 - val_loss: 0.2402 - val_accuracy: 0.8869\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2464 - accuracy: 0.8859 - val_loss: 0.2318 - val_accuracy: 0.8943\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2469 - accuracy: 0.8854 - val_loss: 0.2364 - val_accuracy: 0.8897\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2461 - accuracy: 0.8862 - val_loss: 0.2380 - val_accuracy: 0.8934\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2471 - accuracy: 0.8862 - val_loss: 0.2398 - val_accuracy: 0.8896\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2471 - accuracy: 0.8857 - val_loss: 0.2361 - val_accuracy: 0.8928\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2464 - accuracy: 0.8855 - val_loss: 0.2447 - val_accuracy: 0.8880\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2474 - accuracy: 0.8854 - val_loss: 0.2398 - val_accuracy: 0.8897\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2467 - accuracy: 0.8857 - val_loss: 0.2344 - val_accuracy: 0.8932\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2472 - accuracy: 0.8857 - val_loss: 0.2439 - val_accuracy: 0.8875\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2474 - accuracy: 0.8854 - val_loss: 0.2434 - val_accuracy: 0.8839\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2467 - accuracy: 0.8859 - val_loss: 0.2319 - val_accuracy: 0.8932\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2463 - accuracy: 0.8860 - val_loss: 0.2396 - val_accuracy: 0.8881\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2466 - accuracy: 0.8862 - val_loss: 0.2410 - val_accuracy: 0.8905\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2464 - accuracy: 0.8859 - val_loss: 0.2380 - val_accuracy: 0.8928\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2467 - accuracy: 0.8857 - val_loss: 0.2451 - val_accuracy: 0.8911\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2462 - accuracy: 0.8855 - val_loss: 0.2425 - val_accuracy: 0.8903\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2466 - accuracy: 0.8855 - val_loss: 0.2368 - val_accuracy: 0.8889\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2475 - accuracy: 0.8856 - val_loss: 0.2333 - val_accuracy: 0.8931\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2468 - accuracy: 0.8856 - val_loss: 0.2382 - val_accuracy: 0.8915\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2472 - accuracy: 0.8853 - val_loss: 0.2418 - val_accuracy: 0.8906\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2475 - accuracy: 0.8851 - val_loss: 0.2361 - val_accuracy: 0.8909\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2456 - accuracy: 0.8862 - val_loss: 0.2387 - val_accuracy: 0.8896\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2473 - accuracy: 0.8856 - val_loss: 0.2347 - val_accuracy: 0.8935\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2469 - accuracy: 0.8863 - val_loss: 0.2331 - val_accuracy: 0.8936\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2474 - accuracy: 0.8857 - val_loss: 0.2378 - val_accuracy: 0.8913\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2473 - accuracy: 0.8857 - val_loss: 0.2369 - val_accuracy: 0.8902\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2475 - accuracy: 0.8855 - val_loss: 0.2365 - val_accuracy: 0.8913\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2473 - accuracy: 0.8858 - val_loss: 0.2380 - val_accuracy: 0.8887\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2466 - accuracy: 0.8852 - val_loss: 0.2408 - val_accuracy: 0.8920\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2468 - accuracy: 0.8854 - val_loss: 0.2403 - val_accuracy: 0.8855\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2469 - accuracy: 0.8861 - val_loss: 0.2356 - val_accuracy: 0.8886\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2468 - accuracy: 0.8857 - val_loss: 0.2373 - val_accuracy: 0.8946\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2475 - accuracy: 0.8851 - val_loss: 0.2376 - val_accuracy: 0.8919\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2463 - accuracy: 0.8860 - val_loss: 0.2374 - val_accuracy: 0.8906\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2466 - accuracy: 0.8858 - val_loss: 0.2408 - val_accuracy: 0.8872\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2468 - accuracy: 0.8858 - val_loss: 0.2360 - val_accuracy: 0.8903\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 43s 306us/step - loss: 0.2472 - accuracy: 0.8855 - val_loss: 0.2448 - val_accuracy: 0.8847\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 42s 301us/step - loss: 0.2478 - accuracy: 0.8849 - val_loss: 0.2395 - val_accuracy: 0.8877\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2468 - accuracy: 0.8857 - val_loss: 0.2528 - val_accuracy: 0.8820\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2468 - accuracy: 0.8856 - val_loss: 0.2400 - val_accuracy: 0.8914\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2468 - accuracy: 0.8860 - val_loss: 0.2380 - val_accuracy: 0.8912\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2477 - accuracy: 0.8853 - val_loss: 0.2432 - val_accuracy: 0.8837\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2473 - accuracy: 0.8862 - val_loss: 0.2339 - val_accuracy: 0.8923\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2466 - accuracy: 0.8860 - val_loss: 0.2359 - val_accuracy: 0.8916\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2469 - accuracy: 0.8862 - val_loss: 0.2379 - val_accuracy: 0.8884\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2468 - accuracy: 0.8858 - val_loss: 0.2357 - val_accuracy: 0.8922\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2469 - accuracy: 0.8859 - val_loss: 0.2346 - val_accuracy: 0.8953\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2474 - accuracy: 0.8855 - val_loss: 0.2372 - val_accuracy: 0.8907\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2470 - accuracy: 0.8854 - val_loss: 0.2383 - val_accuracy: 0.8892\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2465 - accuracy: 0.8861 - val_loss: 0.2403 - val_accuracy: 0.8859\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2472 - accuracy: 0.8850 - val_loss: 0.2402 - val_accuracy: 0.8847\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2463 - accuracy: 0.8857 - val_loss: 0.2361 - val_accuracy: 0.8913\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 42s 299us/step - loss: 0.2466 - accuracy: 0.8867 - val_loss: 0.2381 - val_accuracy: 0.8871\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2479 - accuracy: 0.8858 - val_loss: 0.2340 - val_accuracy: 0.8912\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2465 - accuracy: 0.8862 - val_loss: 0.2443 - val_accuracy: 0.8873\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2463 - accuracy: 0.8864 - val_loss: 0.2372 - val_accuracy: 0.8919\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2462 - accuracy: 0.8861 - val_loss: 0.2319 - val_accuracy: 0.8942\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2467 - accuracy: 0.8853 - val_loss: 0.2400 - val_accuracy: 0.8891\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2465 - accuracy: 0.8863 - val_loss: 0.2379 - val_accuracy: 0.8930\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2473 - accuracy: 0.8857 - val_loss: 0.2370 - val_accuracy: 0.8913\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2460 - accuracy: 0.8865 - val_loss: 0.2396 - val_accuracy: 0.8897\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2466 - accuracy: 0.8856 - val_loss: 0.2414 - val_accuracy: 0.8878\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2473 - accuracy: 0.8854 - val_loss: 0.2347 - val_accuracy: 0.8890\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2469 - accuracy: 0.8863 - val_loss: 0.2370 - val_accuracy: 0.8901\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2477 - accuracy: 0.8852 - val_loss: 0.2356 - val_accuracy: 0.8909\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2472 - accuracy: 0.8858 - val_loss: 0.2361 - val_accuracy: 0.8908\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2471 - accuracy: 0.8859 - val_loss: 0.2408 - val_accuracy: 0.8903\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2466 - accuracy: 0.8859 - val_loss: 0.2407 - val_accuracy: 0.8875\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2462 - accuracy: 0.8863 - val_loss: 0.2373 - val_accuracy: 0.8913\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2462 - accuracy: 0.8855 - val_loss: 0.2413 - val_accuracy: 0.8860\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2471 - accuracy: 0.8856 - val_loss: 0.2385 - val_accuracy: 0.8835\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2466 - accuracy: 0.8861 - val_loss: 0.2393 - val_accuracy: 0.8905\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2479 - accuracy: 0.8853 - val_loss: 0.2416 - val_accuracy: 0.8938\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2469 - accuracy: 0.8854 - val_loss: 0.2339 - val_accuracy: 0.8922\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2464 - accuracy: 0.8857 - val_loss: 0.2378 - val_accuracy: 0.8907\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2458 - accuracy: 0.8856 - val_loss: 0.2461 - val_accuracy: 0.8936\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2467 - accuracy: 0.8852 - val_loss: 0.2366 - val_accuracy: 0.8902\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2463 - accuracy: 0.8860 - val_loss: 0.2348 - val_accuracy: 0.8884\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2469 - accuracy: 0.8858 - val_loss: 0.2366 - val_accuracy: 0.8884\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2474 - accuracy: 0.8855 - val_loss: 0.2332 - val_accuracy: 0.8938\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2462 - accuracy: 0.8860 - val_loss: 0.2427 - val_accuracy: 0.8890\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2476 - accuracy: 0.8856 - val_loss: 0.2396 - val_accuracy: 0.8918\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2471 - accuracy: 0.8857 - val_loss: 0.2428 - val_accuracy: 0.8945\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2461 - accuracy: 0.8857 - val_loss: 0.2407 - val_accuracy: 0.8933\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2462 - accuracy: 0.8858 - val_loss: 0.2336 - val_accuracy: 0.8953\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2468 - accuracy: 0.8855 - val_loss: 0.2384 - val_accuracy: 0.8904\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2471 - accuracy: 0.8855 - val_loss: 0.2343 - val_accuracy: 0.8906\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2465 - accuracy: 0.8856 - val_loss: 0.2383 - val_accuracy: 0.8871\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2463 - accuracy: 0.8858 - val_loss: 0.2349 - val_accuracy: 0.8932\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2467 - accuracy: 0.8861 - val_loss: 0.2378 - val_accuracy: 0.8923\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2465 - accuracy: 0.8859 - val_loss: 0.2402 - val_accuracy: 0.8850\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2459 - accuracy: 0.8865 - val_loss: 0.2387 - val_accuracy: 0.8951\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2463 - accuracy: 0.8859 - val_loss: 0.2358 - val_accuracy: 0.8921\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2461 - accuracy: 0.8854 - val_loss: 0.2381 - val_accuracy: 0.8879\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2461 - accuracy: 0.8857 - val_loss: 0.2370 - val_accuracy: 0.8910\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2471 - accuracy: 0.8857 - val_loss: 0.2358 - val_accuracy: 0.8926\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2466 - accuracy: 0.8862 - val_loss: 0.2357 - val_accuracy: 0.8917\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2457 - accuracy: 0.8860 - val_loss: 0.2400 - val_accuracy: 0.8919\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2467 - accuracy: 0.8861 - val_loss: 0.2374 - val_accuracy: 0.8907\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2471 - accuracy: 0.8859 - val_loss: 0.2364 - val_accuracy: 0.8881\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2468 - accuracy: 0.8857 - val_loss: 0.2384 - val_accuracy: 0.8898\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2463 - accuracy: 0.8852 - val_loss: 0.2346 - val_accuracy: 0.8918\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2457 - accuracy: 0.8863 - val_loss: 0.2367 - val_accuracy: 0.8902\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2469 - accuracy: 0.8861 - val_loss: 0.2341 - val_accuracy: 0.8909\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2466 - accuracy: 0.8857 - val_loss: 0.2387 - val_accuracy: 0.8882\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2468 - accuracy: 0.8863 - val_loss: 0.2389 - val_accuracy: 0.8915\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2458 - accuracy: 0.8859 - val_loss: 0.2376 - val_accuracy: 0.8882\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2464 - accuracy: 0.8860 - val_loss: 0.2476 - val_accuracy: 0.8795\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.2466 - accuracy: 0.8864 - val_loss: 0.2353 - val_accuracy: 0.8914\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2467 - accuracy: 0.8859 - val_loss: 0.2348 - val_accuracy: 0.8940\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2457 - accuracy: 0.8866 - val_loss: 0.2351 - val_accuracy: 0.8936\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2473 - accuracy: 0.8859 - val_loss: 0.2346 - val_accuracy: 0.8900\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2458 - accuracy: 0.8865 - val_loss: 0.2390 - val_accuracy: 0.8899\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2479 - accuracy: 0.8856 - val_loss: 0.2395 - val_accuracy: 0.8826\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2467 - accuracy: 0.8857 - val_loss: 0.2427 - val_accuracy: 0.8847\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2482 - accuracy: 0.8851 - val_loss: 0.2376 - val_accuracy: 0.8935\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2467 - accuracy: 0.8858 - val_loss: 0.2358 - val_accuracy: 0.8929\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2459 - accuracy: 0.8862 - val_loss: 0.2369 - val_accuracy: 0.8918\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2476 - accuracy: 0.8855 - val_loss: 0.2396 - val_accuracy: 0.8916\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2467 - accuracy: 0.8861 - val_loss: 0.2377 - val_accuracy: 0.8888\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2478 - accuracy: 0.8859 - val_loss: 0.2415 - val_accuracy: 0.8896\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2473 - accuracy: 0.8858 - val_loss: 0.2397 - val_accuracy: 0.8891\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2470 - accuracy: 0.8857 - val_loss: 0.2426 - val_accuracy: 0.8888\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2480 - accuracy: 0.8853 - val_loss: 0.2364 - val_accuracy: 0.8909\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2484 - accuracy: 0.8853 - val_loss: 0.2391 - val_accuracy: 0.8895\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2473 - accuracy: 0.8851 - val_loss: 0.2407 - val_accuracy: 0.8849\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2478 - accuracy: 0.8855 - val_loss: 0.2412 - val_accuracy: 0.8883\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2463 - accuracy: 0.8853 - val_loss: 0.2381 - val_accuracy: 0.8877\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2472 - accuracy: 0.8851 - val_loss: 0.2398 - val_accuracy: 0.8893\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2466 - accuracy: 0.8857 - val_loss: 0.2380 - val_accuracy: 0.8912\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2468 - accuracy: 0.8858 - val_loss: 0.2397 - val_accuracy: 0.8864\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2466 - accuracy: 0.8862 - val_loss: 0.2452 - val_accuracy: 0.8901\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2466 - accuracy: 0.8858 - val_loss: 0.2421 - val_accuracy: 0.8908\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2473 - accuracy: 0.8853 - val_loss: 0.2367 - val_accuracy: 0.8910\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2468 - accuracy: 0.8855 - val_loss: 0.2344 - val_accuracy: 0.8915\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 45s 324us/step - loss: 0.2469 - accuracy: 0.8860 - val_loss: 0.2393 - val_accuracy: 0.8866\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2471 - accuracy: 0.8858 - val_loss: 0.2363 - val_accuracy: 0.8911\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2467 - accuracy: 0.8853 - val_loss: 0.2465 - val_accuracy: 0.8929\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 42s 299us/step - loss: 0.2473 - accuracy: 0.8855 - val_loss: 0.2419 - val_accuracy: 0.8861\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2462 - accuracy: 0.8860 - val_loss: 0.2402 - val_accuracy: 0.8873\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2475 - accuracy: 0.8858 - val_loss: 0.2336 - val_accuracy: 0.8928\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2481 - accuracy: 0.8855 - val_loss: 0.2461 - val_accuracy: 0.8872\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2476 - accuracy: 0.8858 - val_loss: 0.2382 - val_accuracy: 0.8902\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2470 - accuracy: 0.8857 - val_loss: 0.2381 - val_accuracy: 0.8921\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2487 - accuracy: 0.8851 - val_loss: 0.2542 - val_accuracy: 0.8774\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2481 - accuracy: 0.8847 - val_loss: 0.2385 - val_accuracy: 0.8888\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2471 - accuracy: 0.8858 - val_loss: 0.2371 - val_accuracy: 0.8877\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2465 - accuracy: 0.8869 - val_loss: 0.2370 - val_accuracy: 0.8914\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2465 - accuracy: 0.8857 - val_loss: 0.2457 - val_accuracy: 0.8843\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 0.2353 - val_accuracy: 0.8922\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2470 - accuracy: 0.8859 - val_loss: 0.2352 - val_accuracy: 0.8922\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2472 - accuracy: 0.8858 - val_loss: 0.2357 - val_accuracy: 0.8923\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2469 - accuracy: 0.8855 - val_loss: 0.2345 - val_accuracy: 0.8946\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2466 - accuracy: 0.8856 - val_loss: 0.2380 - val_accuracy: 0.8917\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2474 - accuracy: 0.8853 - val_loss: 0.2346 - val_accuracy: 0.8924\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2464 - accuracy: 0.8862 - val_loss: 0.2399 - val_accuracy: 0.8874\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 49s 352us/step - loss: 0.2464 - accuracy: 0.8857 - val_loss: 0.2371 - val_accuracy: 0.8896\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 46s 330us/step - loss: 0.2458 - accuracy: 0.8858 - val_loss: 0.2358 - val_accuracy: 0.8925\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2470 - accuracy: 0.8855 - val_loss: 0.2338 - val_accuracy: 0.8917\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2472 - accuracy: 0.8853 - val_loss: 0.2354 - val_accuracy: 0.8927\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2460 - accuracy: 0.8861 - val_loss: 0.2464 - val_accuracy: 0.8899\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2471 - accuracy: 0.8857 - val_loss: 0.2330 - val_accuracy: 0.8930\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2452 - accuracy: 0.8862 - val_loss: 0.2375 - val_accuracy: 0.8890\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2464 - accuracy: 0.8863 - val_loss: 0.2368 - val_accuracy: 0.8916\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2472 - accuracy: 0.8849 - val_loss: 0.2394 - val_accuracy: 0.8865\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2469 - accuracy: 0.8853 - val_loss: 0.2393 - val_accuracy: 0.8908\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2473 - accuracy: 0.8853 - val_loss: 0.2426 - val_accuracy: 0.8892\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2470 - accuracy: 0.8858 - val_loss: 0.2393 - val_accuracy: 0.8917\n",
      "accuracy: 89.17%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2454 - accuracy: 0.8871 - val_loss: 0.2393 - val_accuracy: 0.8899\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2451 - accuracy: 0.8864 - val_loss: 0.2489 - val_accuracy: 0.8904\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2465 - accuracy: 0.8863 - val_loss: 0.2419 - val_accuracy: 0.8850\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2463 - accuracy: 0.8867 - val_loss: 0.2402 - val_accuracy: 0.8880\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2460 - accuracy: 0.8866 - val_loss: 0.2412 - val_accuracy: 0.8882\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2458 - accuracy: 0.8865 - val_loss: 0.2473 - val_accuracy: 0.8846\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2457 - accuracy: 0.8866 - val_loss: 0.2437 - val_accuracy: 0.8837\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2456 - accuracy: 0.8863 - val_loss: 0.2432 - val_accuracy: 0.8877\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2458 - accuracy: 0.8863 - val_loss: 0.2403 - val_accuracy: 0.8845\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.2455 - accuracy: 0.8865 - val_loss: 0.2411 - val_accuracy: 0.8908\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2455 - accuracy: 0.8866 - val_loss: 0.2459 - val_accuracy: 0.8890\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2457 - accuracy: 0.8863 - val_loss: 0.2442 - val_accuracy: 0.8823\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2464 - accuracy: 0.8859 - val_loss: 0.2388 - val_accuracy: 0.8891\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2461 - accuracy: 0.8862 - val_loss: 0.2398 - val_accuracy: 0.8863\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2458 - accuracy: 0.8860 - val_loss: 0.2513 - val_accuracy: 0.8772\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2461 - accuracy: 0.8871 - val_loss: 0.2418 - val_accuracy: 0.8910\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2466 - accuracy: 0.8864 - val_loss: 0.2431 - val_accuracy: 0.8858\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2462 - accuracy: 0.8859 - val_loss: 0.2439 - val_accuracy: 0.8855\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2461 - accuracy: 0.8862 - val_loss: 0.2436 - val_accuracy: 0.8868\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2462 - accuracy: 0.8867 - val_loss: 0.2427 - val_accuracy: 0.8859\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2456 - accuracy: 0.8866 - val_loss: 0.2433 - val_accuracy: 0.8837\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2468 - accuracy: 0.8859 - val_loss: 0.2447 - val_accuracy: 0.8860\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2460 - accuracy: 0.8863 - val_loss: 0.2427 - val_accuracy: 0.8860\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2461 - accuracy: 0.8868 - val_loss: 0.2430 - val_accuracy: 0.8862\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2449 - accuracy: 0.8868 - val_loss: 0.2443 - val_accuracy: 0.8865\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2452 - accuracy: 0.8865 - val_loss: 0.2456 - val_accuracy: 0.8830\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2457 - accuracy: 0.8866 - val_loss: 0.2418 - val_accuracy: 0.8853\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2454 - accuracy: 0.8873 - val_loss: 0.2418 - val_accuracy: 0.8871\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2461 - accuracy: 0.8861 - val_loss: 0.2402 - val_accuracy: 0.8899\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2463 - accuracy: 0.8861 - val_loss: 0.2421 - val_accuracy: 0.8867\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2445 - accuracy: 0.8869 - val_loss: 0.2468 - val_accuracy: 0.8852\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2468 - accuracy: 0.8862 - val_loss: 0.2417 - val_accuracy: 0.8870\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2459 - accuracy: 0.8868 - val_loss: 0.2440 - val_accuracy: 0.8849\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2461 - accuracy: 0.8866 - val_loss: 0.2435 - val_accuracy: 0.8831\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2453 - accuracy: 0.8868 - val_loss: 0.2448 - val_accuracy: 0.8829\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2458 - accuracy: 0.8861 - val_loss: 0.2417 - val_accuracy: 0.8865\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2452 - accuracy: 0.8868 - val_loss: 0.2482 - val_accuracy: 0.8811\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2461 - accuracy: 0.8863 - val_loss: 0.2416 - val_accuracy: 0.8880\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2460 - accuracy: 0.8862 - val_loss: 0.2441 - val_accuracy: 0.8862\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2455 - accuracy: 0.8865 - val_loss: 0.2429 - val_accuracy: 0.8845\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2458 - accuracy: 0.8862 - val_loss: 0.2411 - val_accuracy: 0.8888\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2452 - accuracy: 0.8870 - val_loss: 0.2407 - val_accuracy: 0.8845\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2457 - accuracy: 0.8865 - val_loss: 0.2423 - val_accuracy: 0.8856\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2454 - accuracy: 0.8868 - val_loss: 0.2395 - val_accuracy: 0.8861\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2455 - accuracy: 0.8865 - val_loss: 0.2479 - val_accuracy: 0.8842\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2459 - accuracy: 0.8868 - val_loss: 0.2404 - val_accuracy: 0.8874\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2461 - accuracy: 0.8859 - val_loss: 0.2415 - val_accuracy: 0.8851\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2455 - accuracy: 0.8865 - val_loss: 0.2398 - val_accuracy: 0.8885\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2450 - accuracy: 0.8872 - val_loss: 0.2451 - val_accuracy: 0.8844\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2452 - accuracy: 0.8863 - val_loss: 0.2409 - val_accuracy: 0.8868\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2450 - accuracy: 0.8867 - val_loss: 0.2410 - val_accuracy: 0.8853\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2471 - accuracy: 0.8854 - val_loss: 0.2453 - val_accuracy: 0.8818\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2455 - accuracy: 0.8861 - val_loss: 0.2404 - val_accuracy: 0.8896\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2462 - accuracy: 0.8861 - val_loss: 0.2420 - val_accuracy: 0.8843\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2467 - accuracy: 0.8853 - val_loss: 0.2491 - val_accuracy: 0.8884\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2453 - accuracy: 0.8869 - val_loss: 0.2404 - val_accuracy: 0.8865\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2465 - accuracy: 0.8861 - val_loss: 0.2445 - val_accuracy: 0.8843\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2461 - accuracy: 0.8866 - val_loss: 0.2545 - val_accuracy: 0.8771\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2460 - accuracy: 0.8862 - val_loss: 0.2394 - val_accuracy: 0.8878\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2454 - accuracy: 0.8868 - val_loss: 0.2428 - val_accuracy: 0.8896\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2457 - accuracy: 0.8863 - val_loss: 0.2475 - val_accuracy: 0.8848\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2464 - accuracy: 0.8869 - val_loss: 0.2406 - val_accuracy: 0.8891\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2452 - accuracy: 0.8866 - val_loss: 0.2448 - val_accuracy: 0.8863\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2448 - accuracy: 0.8864 - val_loss: 0.2436 - val_accuracy: 0.8876\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2468 - accuracy: 0.8862 - val_loss: 0.2570 - val_accuracy: 0.8792\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2452 - accuracy: 0.8869 - val_loss: 0.2381 - val_accuracy: 0.8863\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2455 - accuracy: 0.8863 - val_loss: 0.2405 - val_accuracy: 0.8890\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2449 - accuracy: 0.8868 - val_loss: 0.2422 - val_accuracy: 0.8857\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2462 - accuracy: 0.8860 - val_loss: 0.2400 - val_accuracy: 0.8890\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2457 - accuracy: 0.8862 - val_loss: 0.2494 - val_accuracy: 0.8817\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2459 - accuracy: 0.8862 - val_loss: 0.2390 - val_accuracy: 0.8913\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2458 - accuracy: 0.8864 - val_loss: 0.2485 - val_accuracy: 0.8824\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2454 - accuracy: 0.8868 - val_loss: 0.2424 - val_accuracy: 0.8887\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2465 - accuracy: 0.8858 - val_loss: 0.2415 - val_accuracy: 0.8880\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2463 - accuracy: 0.8869 - val_loss: 0.2460 - val_accuracy: 0.8825\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2468 - accuracy: 0.8863 - val_loss: 0.2431 - val_accuracy: 0.8853\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2461 - accuracy: 0.8859 - val_loss: 0.2437 - val_accuracy: 0.8894\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2469 - accuracy: 0.8859 - val_loss: 0.2412 - val_accuracy: 0.8877\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2459 - accuracy: 0.8868 - val_loss: 0.2415 - val_accuracy: 0.8880\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2456 - accuracy: 0.8862 - val_loss: 0.2428 - val_accuracy: 0.8887\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2454 - accuracy: 0.8863 - val_loss: 0.2441 - val_accuracy: 0.8877\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2453 - accuracy: 0.8868 - val_loss: 0.2443 - val_accuracy: 0.8851\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2450 - accuracy: 0.8863 - val_loss: 0.2416 - val_accuracy: 0.8855\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2453 - accuracy: 0.8866 - val_loss: 0.2399 - val_accuracy: 0.8905\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2452 - accuracy: 0.8862 - val_loss: 0.2416 - val_accuracy: 0.8854\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2460 - accuracy: 0.8865 - val_loss: 0.2395 - val_accuracy: 0.8884\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2461 - accuracy: 0.8866 - val_loss: 0.2501 - val_accuracy: 0.8877\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2451 - accuracy: 0.8868 - val_loss: 0.2508 - val_accuracy: 0.8821\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2455 - accuracy: 0.8860 - val_loss: 0.2413 - val_accuracy: 0.8852\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 42s 299us/step - loss: 0.2454 - accuracy: 0.8867 - val_loss: 0.2409 - val_accuracy: 0.8891\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2455 - accuracy: 0.8869 - val_loss: 0.2452 - val_accuracy: 0.8827\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2460 - accuracy: 0.8864 - val_loss: 0.2575 - val_accuracy: 0.8738\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2451 - accuracy: 0.8868 - val_loss: 0.2417 - val_accuracy: 0.8871\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2446 - accuracy: 0.8871 - val_loss: 0.2416 - val_accuracy: 0.8896\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2476 - accuracy: 0.8866 - val_loss: 0.2459 - val_accuracy: 0.8829\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2451 - accuracy: 0.8869 - val_loss: 0.2435 - val_accuracy: 0.8855\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2457 - accuracy: 0.8865 - val_loss: 0.2423 - val_accuracy: 0.8856\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2465 - accuracy: 0.8864 - val_loss: 0.2400 - val_accuracy: 0.8875\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2468 - accuracy: 0.8852 - val_loss: 0.2428 - val_accuracy: 0.8871\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2453 - accuracy: 0.8864 - val_loss: 0.2429 - val_accuracy: 0.8858\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2447 - accuracy: 0.8863 - val_loss: 0.2451 - val_accuracy: 0.8824\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2458 - accuracy: 0.8863 - val_loss: 0.2483 - val_accuracy: 0.8847\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2456 - accuracy: 0.8866 - val_loss: 0.2477 - val_accuracy: 0.8811\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2466 - accuracy: 0.8860 - val_loss: 0.2433 - val_accuracy: 0.8888\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2460 - accuracy: 0.8867 - val_loss: 0.2469 - val_accuracy: 0.8833\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2475 - accuracy: 0.8861 - val_loss: 0.2428 - val_accuracy: 0.8869\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2461 - accuracy: 0.8866 - val_loss: 0.2408 - val_accuracy: 0.8901\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2472 - accuracy: 0.8856 - val_loss: 0.2405 - val_accuracy: 0.8882\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2460 - accuracy: 0.8861 - val_loss: 0.2401 - val_accuracy: 0.8876\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2465 - accuracy: 0.8862 - val_loss: 0.2449 - val_accuracy: 0.8844\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2450 - accuracy: 0.8866 - val_loss: 0.2459 - val_accuracy: 0.8880\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2455 - accuracy: 0.8867 - val_loss: 0.2408 - val_accuracy: 0.8859\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2460 - accuracy: 0.8862 - val_loss: 0.2425 - val_accuracy: 0.8897\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2455 - accuracy: 0.8869 - val_loss: 0.2455 - val_accuracy: 0.8830\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2455 - accuracy: 0.8869 - val_loss: 0.2427 - val_accuracy: 0.8886\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2458 - accuracy: 0.8868 - val_loss: 0.2397 - val_accuracy: 0.8885\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2460 - accuracy: 0.8861 - val_loss: 0.2424 - val_accuracy: 0.8845\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2447 - accuracy: 0.8864 - val_loss: 0.2500 - val_accuracy: 0.8809\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2454 - accuracy: 0.8862 - val_loss: 0.2434 - val_accuracy: 0.8877\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2462 - accuracy: 0.8857 - val_loss: 0.2463 - val_accuracy: 0.8907\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2468 - accuracy: 0.8858 - val_loss: 0.2461 - val_accuracy: 0.8820\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2464 - accuracy: 0.8865 - val_loss: 0.2476 - val_accuracy: 0.8808\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2460 - accuracy: 0.8867 - val_loss: 0.2454 - val_accuracy: 0.8834\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2459 - accuracy: 0.8860 - val_loss: 0.2423 - val_accuracy: 0.8880\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2458 - accuracy: 0.8867 - val_loss: 0.2488 - val_accuracy: 0.8806\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2461 - accuracy: 0.8861 - val_loss: 0.2490 - val_accuracy: 0.8805\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2460 - accuracy: 0.8858 - val_loss: 0.2404 - val_accuracy: 0.8860\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2453 - accuracy: 0.8868 - val_loss: 0.2483 - val_accuracy: 0.8812\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2466 - accuracy: 0.8862 - val_loss: 0.2436 - val_accuracy: 0.8856\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2470 - accuracy: 0.8865 - val_loss: 0.2499 - val_accuracy: 0.8809\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2480 - accuracy: 0.8856 - val_loss: 0.2459 - val_accuracy: 0.8886\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2457 - accuracy: 0.8868 - val_loss: 0.2407 - val_accuracy: 0.8891\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2457 - accuracy: 0.8865 - val_loss: 0.2418 - val_accuracy: 0.8878\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2462 - accuracy: 0.8864 - val_loss: 0.2523 - val_accuracy: 0.8860\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2463 - accuracy: 0.8863 - val_loss: 0.2390 - val_accuracy: 0.8889\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2476 - accuracy: 0.8857 - val_loss: 0.2452 - val_accuracy: 0.8846\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2458 - accuracy: 0.8868 - val_loss: 0.2459 - val_accuracy: 0.8873\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2459 - accuracy: 0.8861 - val_loss: 0.2424 - val_accuracy: 0.8884\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2461 - accuracy: 0.8866 - val_loss: 0.2453 - val_accuracy: 0.8833\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2457 - accuracy: 0.8865 - val_loss: 0.2464 - val_accuracy: 0.8858\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2454 - accuracy: 0.8866 - val_loss: 0.2452 - val_accuracy: 0.8855\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2457 - accuracy: 0.8866 - val_loss: 0.2435 - val_accuracy: 0.8877\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2467 - accuracy: 0.8863 - val_loss: 0.2429 - val_accuracy: 0.8857\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2464 - accuracy: 0.8862 - val_loss: 0.2400 - val_accuracy: 0.8878\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2463 - accuracy: 0.8863 - val_loss: 0.2410 - val_accuracy: 0.8879\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2457 - accuracy: 0.8858 - val_loss: 0.2417 - val_accuracy: 0.8891\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2468 - accuracy: 0.8861 - val_loss: 0.2471 - val_accuracy: 0.8821\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2466 - accuracy: 0.8866 - val_loss: 0.2441 - val_accuracy: 0.8888\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2464 - accuracy: 0.8856 - val_loss: 0.2451 - val_accuracy: 0.8855\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2456 - accuracy: 0.8865 - val_loss: 0.2437 - val_accuracy: 0.8836\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2528 - accuracy: 0.8809 - val_loss: 0.2573 - val_accuracy: 0.8736\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2664 - accuracy: 0.8704 - val_loss: 0.2534 - val_accuracy: 0.8739\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2636 - accuracy: 0.8724 - val_loss: 0.2606 - val_accuracy: 0.8663\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2614 - accuracy: 0.8730 - val_loss: 0.2591 - val_accuracy: 0.8676\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2635 - accuracy: 0.8717 - val_loss: 0.2626 - val_accuracy: 0.8640\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2640 - accuracy: 0.8715 - val_loss: 0.2541 - val_accuracy: 0.8778\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2633 - accuracy: 0.8724 - val_loss: 0.2562 - val_accuracy: 0.8720\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2630 - accuracy: 0.8716 - val_loss: 0.2565 - val_accuracy: 0.8760\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2613 - accuracy: 0.8739 - val_loss: 0.2604 - val_accuracy: 0.8738\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2637 - accuracy: 0.8718 - val_loss: 0.2705 - val_accuracy: 0.8598\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2629 - accuracy: 0.8719 - val_loss: 0.2655 - val_accuracy: 0.8599\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2624 - accuracy: 0.8729 - val_loss: 0.2591 - val_accuracy: 0.8673\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2618 - accuracy: 0.8731 - val_loss: 0.2531 - val_accuracy: 0.8773\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2615 - accuracy: 0.8737 - val_loss: 0.2647 - val_accuracy: 0.8679\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2613 - accuracy: 0.8736 - val_loss: 0.2652 - val_accuracy: 0.8643\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2613 - accuracy: 0.8732 - val_loss: 0.2614 - val_accuracy: 0.8657\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2610 - accuracy: 0.8732 - val_loss: 0.2556 - val_accuracy: 0.8751\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2591 - accuracy: 0.8742 - val_loss: 0.2607 - val_accuracy: 0.8703\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2602 - accuracy: 0.8741 - val_loss: 0.2560 - val_accuracy: 0.8750\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2603 - accuracy: 0.8743 - val_loss: 0.2578 - val_accuracy: 0.8709\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2596 - accuracy: 0.8749 - val_loss: 0.2598 - val_accuracy: 0.8661\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2594 - accuracy: 0.8744 - val_loss: 0.2557 - val_accuracy: 0.8716\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2587 - accuracy: 0.8753 - val_loss: 0.2564 - val_accuracy: 0.8762\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2598 - accuracy: 0.8751 - val_loss: 0.2540 - val_accuracy: 0.8771\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2600 - accuracy: 0.8743 - val_loss: 0.2545 - val_accuracy: 0.8725\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2598 - accuracy: 0.8756 - val_loss: 0.2693 - val_accuracy: 0.8712\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2589 - accuracy: 0.8748 - val_loss: 0.2566 - val_accuracy: 0.8754\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2604 - accuracy: 0.8734 - val_loss: 0.2534 - val_accuracy: 0.8803\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2598 - accuracy: 0.8747 - val_loss: 0.2603 - val_accuracy: 0.8732\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2611 - accuracy: 0.8737 - val_loss: 0.2710 - val_accuracy: 0.8620\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2596 - accuracy: 0.8746 - val_loss: 0.2524 - val_accuracy: 0.8763\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2599 - accuracy: 0.8743 - val_loss: 0.2607 - val_accuracy: 0.8696\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2597 - accuracy: 0.8748 - val_loss: 0.2513 - val_accuracy: 0.8810\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2591 - accuracy: 0.8745 - val_loss: 0.2529 - val_accuracy: 0.8766\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2593 - accuracy: 0.8745 - val_loss: 0.2526 - val_accuracy: 0.8772\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2587 - accuracy: 0.8747 - val_loss: 0.2563 - val_accuracy: 0.8707\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2600 - accuracy: 0.8744 - val_loss: 0.2568 - val_accuracy: 0.8726\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2591 - accuracy: 0.8748 - val_loss: 0.2543 - val_accuracy: 0.8739\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2579 - accuracy: 0.8754 - val_loss: 0.2584 - val_accuracy: 0.8701\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2590 - accuracy: 0.8745 - val_loss: 0.2503 - val_accuracy: 0.8772\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2591 - accuracy: 0.8746 - val_loss: 0.2561 - val_accuracy: 0.8751\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2570 - accuracy: 0.8758 - val_loss: 0.2516 - val_accuracy: 0.8752\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2574 - accuracy: 0.8760 - val_loss: 0.2526 - val_accuracy: 0.8771\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 42s 298us/step - loss: 0.2580 - accuracy: 0.8752 - val_loss: 0.2499 - val_accuracy: 0.8785\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2584 - accuracy: 0.8752 - val_loss: 0.2523 - val_accuracy: 0.8758\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2587 - accuracy: 0.8746 - val_loss: 0.2530 - val_accuracy: 0.8764\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2571 - accuracy: 0.8756 - val_loss: 0.2531 - val_accuracy: 0.8746\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2586 - accuracy: 0.8748 - val_loss: 0.2525 - val_accuracy: 0.8766\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2586 - accuracy: 0.8753 - val_loss: 0.2512 - val_accuracy: 0.8768\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2575 - accuracy: 0.8760 - val_loss: 0.2527 - val_accuracy: 0.8758\n",
      "accuracy: 87.58%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2591 - accuracy: 0.8754 - val_loss: 0.2486 - val_accuracy: 0.8769\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2584 - accuracy: 0.8753 - val_loss: 0.2511 - val_accuracy: 0.8715\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2593 - accuracy: 0.8755 - val_loss: 0.2488 - val_accuracy: 0.8740\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2594 - accuracy: 0.8757 - val_loss: 0.2489 - val_accuracy: 0.8780\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2594 - accuracy: 0.8757 - val_loss: 0.2432 - val_accuracy: 0.8793\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2592 - accuracy: 0.8756 - val_loss: 0.2598 - val_accuracy: 0.8637\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.2581 - accuracy: 0.8760 - val_loss: 0.2497 - val_accuracy: 0.8799\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2593 - accuracy: 0.8753 - val_loss: 0.2465 - val_accuracy: 0.8777\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2590 - accuracy: 0.8759 - val_loss: 0.2552 - val_accuracy: 0.8730\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2591 - accuracy: 0.8752 - val_loss: 0.2464 - val_accuracy: 0.8780\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2587 - accuracy: 0.8758 - val_loss: 0.2518 - val_accuracy: 0.8740\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2581 - accuracy: 0.8757 - val_loss: 0.2499 - val_accuracy: 0.8753\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2570 - accuracy: 0.8767 - val_loss: 0.2500 - val_accuracy: 0.8754\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2588 - accuracy: 0.8754 - val_loss: 0.2478 - val_accuracy: 0.8780\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2579 - accuracy: 0.8762 - val_loss: 0.2508 - val_accuracy: 0.8735\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2580 - accuracy: 0.8762 - val_loss: 0.2587 - val_accuracy: 0.8646\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2583 - accuracy: 0.8765 - val_loss: 0.2511 - val_accuracy: 0.8729\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2595 - accuracy: 0.8752 - val_loss: 0.2472 - val_accuracy: 0.8793\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2577 - accuracy: 0.8770 - val_loss: 0.2523 - val_accuracy: 0.8749\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2594 - accuracy: 0.8753 - val_loss: 0.2454 - val_accuracy: 0.8774\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2572 - accuracy: 0.8771 - val_loss: 0.2547 - val_accuracy: 0.8730\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2580 - accuracy: 0.8777 - val_loss: 0.2443 - val_accuracy: 0.8805\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2582 - accuracy: 0.8770 - val_loss: 0.2484 - val_accuracy: 0.8757\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2583 - accuracy: 0.8768 - val_loss: 0.2483 - val_accuracy: 0.8776\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2578 - accuracy: 0.8764 - val_loss: 0.2596 - val_accuracy: 0.8700\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2579 - accuracy: 0.8772 - val_loss: 0.2475 - val_accuracy: 0.8808\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2569 - accuracy: 0.8771 - val_loss: 0.2502 - val_accuracy: 0.8781\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2579 - accuracy: 0.8771 - val_loss: 0.2507 - val_accuracy: 0.8733\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2575 - accuracy: 0.8770 - val_loss: 0.2574 - val_accuracy: 0.8706\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2578 - accuracy: 0.8773 - val_loss: 0.2488 - val_accuracy: 0.8746\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2590 - accuracy: 0.8761 - val_loss: 0.2645 - val_accuracy: 0.8631\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2572 - accuracy: 0.8773 - val_loss: 0.2536 - val_accuracy: 0.8744\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2595 - accuracy: 0.8761 - val_loss: 0.2585 - val_accuracy: 0.8676\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2587 - accuracy: 0.8766 - val_loss: 0.2461 - val_accuracy: 0.8809\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2581 - accuracy: 0.8763 - val_loss: 0.2617 - val_accuracy: 0.8780\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 42s 300us/step - loss: 0.2575 - accuracy: 0.8769 - val_loss: 0.2523 - val_accuracy: 0.8737\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2587 - accuracy: 0.8768 - val_loss: 0.2471 - val_accuracy: 0.8766\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2586 - accuracy: 0.8765 - val_loss: 0.2530 - val_accuracy: 0.8713\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2574 - accuracy: 0.8773 - val_loss: 0.2549 - val_accuracy: 0.8759\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2579 - accuracy: 0.8770 - val_loss: 0.2473 - val_accuracy: 0.8789\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2579 - accuracy: 0.8769 - val_loss: 0.2477 - val_accuracy: 0.8776\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2577 - accuracy: 0.8772 - val_loss: 0.2490 - val_accuracy: 0.8774\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2577 - accuracy: 0.8761 - val_loss: 0.2476 - val_accuracy: 0.8800\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2576 - accuracy: 0.8773 - val_loss: 0.2462 - val_accuracy: 0.8788\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2574 - accuracy: 0.8769 - val_loss: 0.2486 - val_accuracy: 0.8788\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2577 - accuracy: 0.8770 - val_loss: 0.2495 - val_accuracy: 0.8744\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2575 - accuracy: 0.8770 - val_loss: 0.2503 - val_accuracy: 0.8753\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2570 - accuracy: 0.8771 - val_loss: 0.2452 - val_accuracy: 0.8777\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2563 - accuracy: 0.8774 - val_loss: 0.2645 - val_accuracy: 0.8672\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2558 - accuracy: 0.8782 - val_loss: 0.2477 - val_accuracy: 0.8791\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2577 - accuracy: 0.8765 - val_loss: 0.2491 - val_accuracy: 0.8770\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2578 - accuracy: 0.8777 - val_loss: 0.2516 - val_accuracy: 0.8738\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2571 - accuracy: 0.8763 - val_loss: 0.2600 - val_accuracy: 0.8644\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2570 - accuracy: 0.8774 - val_loss: 0.2482 - val_accuracy: 0.8798\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2557 - accuracy: 0.8783 - val_loss: 0.2492 - val_accuracy: 0.8791\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2567 - accuracy: 0.8774 - val_loss: 0.2490 - val_accuracy: 0.8772\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2568 - accuracy: 0.8771 - val_loss: 0.2464 - val_accuracy: 0.8802\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2576 - accuracy: 0.8770 - val_loss: 0.2568 - val_accuracy: 0.8662\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2563 - accuracy: 0.8782 - val_loss: 0.2469 - val_accuracy: 0.8779\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2568 - accuracy: 0.8771 - val_loss: 0.2567 - val_accuracy: 0.8728\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2562 - accuracy: 0.8773 - val_loss: 0.2475 - val_accuracy: 0.8797\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2563 - accuracy: 0.8772 - val_loss: 0.2491 - val_accuracy: 0.8766\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2563 - accuracy: 0.8779 - val_loss: 0.2494 - val_accuracy: 0.8769\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2568 - accuracy: 0.8765 - val_loss: 0.2526 - val_accuracy: 0.8772\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2575 - accuracy: 0.8769 - val_loss: 0.2462 - val_accuracy: 0.8778\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2558 - accuracy: 0.8780 - val_loss: 0.2498 - val_accuracy: 0.8728\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2580 - accuracy: 0.8764 - val_loss: 0.2504 - val_accuracy: 0.8715\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2569 - accuracy: 0.8776 - val_loss: 0.2475 - val_accuracy: 0.8827\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2562 - accuracy: 0.8781 - val_loss: 0.2447 - val_accuracy: 0.8795\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2558 - accuracy: 0.8783 - val_loss: 0.2499 - val_accuracy: 0.8749\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2564 - accuracy: 0.8777 - val_loss: 0.2506 - val_accuracy: 0.8734\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2555 - accuracy: 0.8778 - val_loss: 0.2457 - val_accuracy: 0.8798\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2567 - accuracy: 0.8773 - val_loss: 0.2536 - val_accuracy: 0.8736\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2558 - accuracy: 0.8783 - val_loss: 0.2512 - val_accuracy: 0.8703\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2561 - accuracy: 0.8780 - val_loss: 0.2487 - val_accuracy: 0.8785\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2562 - accuracy: 0.8780 - val_loss: 0.2461 - val_accuracy: 0.8789\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2560 - accuracy: 0.8779 - val_loss: 0.2497 - val_accuracy: 0.8726\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2555 - accuracy: 0.8778 - val_loss: 0.2511 - val_accuracy: 0.8770\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2562 - accuracy: 0.8776 - val_loss: 0.2582 - val_accuracy: 0.8693\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2568 - accuracy: 0.8779 - val_loss: 0.2577 - val_accuracy: 0.8671\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2566 - accuracy: 0.8779 - val_loss: 0.2470 - val_accuracy: 0.8774\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2576 - accuracy: 0.8771 - val_loss: 0.2506 - val_accuracy: 0.8768\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2557 - accuracy: 0.8780 - val_loss: 0.2496 - val_accuracy: 0.8731\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2559 - accuracy: 0.8786 - val_loss: 0.2531 - val_accuracy: 0.8692\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2566 - accuracy: 0.8770 - val_loss: 0.2494 - val_accuracy: 0.8775\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2561 - accuracy: 0.8778 - val_loss: 0.2512 - val_accuracy: 0.8758\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2563 - accuracy: 0.8776 - val_loss: 0.2488 - val_accuracy: 0.8815\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2556 - accuracy: 0.8783 - val_loss: 0.2489 - val_accuracy: 0.8789\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2552 - accuracy: 0.8786 - val_loss: 0.2534 - val_accuracy: 0.8724\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2572 - accuracy: 0.8773 - val_loss: 0.2506 - val_accuracy: 0.8748\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2555 - accuracy: 0.8776 - val_loss: 0.2474 - val_accuracy: 0.8794\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2558 - accuracy: 0.8780 - val_loss: 0.2484 - val_accuracy: 0.8796\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2559 - accuracy: 0.8787 - val_loss: 0.2449 - val_accuracy: 0.8802\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2563 - accuracy: 0.8782 - val_loss: 0.2443 - val_accuracy: 0.8808\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2562 - accuracy: 0.8778 - val_loss: 0.2529 - val_accuracy: 0.8755\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2562 - accuracy: 0.8772 - val_loss: 0.2468 - val_accuracy: 0.8802\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2561 - accuracy: 0.8778 - val_loss: 0.2454 - val_accuracy: 0.8782\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2558 - accuracy: 0.8780 - val_loss: 0.2457 - val_accuracy: 0.8775\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2566 - accuracy: 0.8776 - val_loss: 0.2516 - val_accuracy: 0.8740\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2556 - accuracy: 0.8777 - val_loss: 0.2462 - val_accuracy: 0.8782\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2554 - accuracy: 0.8788 - val_loss: 0.2435 - val_accuracy: 0.8804\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2561 - accuracy: 0.8777 - val_loss: 0.2478 - val_accuracy: 0.8783\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2555 - accuracy: 0.8781 - val_loss: 0.2499 - val_accuracy: 0.8727\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2561 - accuracy: 0.8783 - val_loss: 0.2485 - val_accuracy: 0.8758\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2550 - accuracy: 0.8786 - val_loss: 0.2509 - val_accuracy: 0.8735\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2556 - accuracy: 0.8782 - val_loss: 0.2477 - val_accuracy: 0.8743\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2558 - accuracy: 0.8786 - val_loss: 0.2504 - val_accuracy: 0.8790\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2548 - accuracy: 0.8785 - val_loss: 0.2487 - val_accuracy: 0.8755\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2561 - accuracy: 0.8777 - val_loss: 0.2472 - val_accuracy: 0.8803\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2560 - accuracy: 0.8783 - val_loss: 0.2440 - val_accuracy: 0.8816\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2551 - accuracy: 0.8787 - val_loss: 0.2662 - val_accuracy: 0.8668\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2555 - accuracy: 0.8786 - val_loss: 0.2490 - val_accuracy: 0.8791\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 40s 289us/step - loss: 0.2554 - accuracy: 0.8785 - val_loss: 0.2466 - val_accuracy: 0.8790\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2550 - accuracy: 0.8782 - val_loss: 0.2473 - val_accuracy: 0.8766\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2550 - accuracy: 0.8786 - val_loss: 0.2485 - val_accuracy: 0.8757\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2550 - accuracy: 0.8790 - val_loss: 0.2531 - val_accuracy: 0.8718\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2548 - accuracy: 0.8789 - val_loss: 0.2465 - val_accuracy: 0.8778\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2549 - accuracy: 0.8785 - val_loss: 0.2515 - val_accuracy: 0.8746\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2546 - accuracy: 0.8787 - val_loss: 0.2459 - val_accuracy: 0.8809\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2551 - accuracy: 0.8789 - val_loss: 0.2503 - val_accuracy: 0.8751\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2556 - accuracy: 0.8782 - val_loss: 0.2513 - val_accuracy: 0.8770\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2559 - accuracy: 0.8787 - val_loss: 0.2459 - val_accuracy: 0.8792\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2554 - accuracy: 0.8784 - val_loss: 0.2478 - val_accuracy: 0.8789\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2548 - accuracy: 0.8789 - val_loss: 0.2449 - val_accuracy: 0.8785\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2548 - accuracy: 0.8791 - val_loss: 0.2676 - val_accuracy: 0.8732\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2559 - accuracy: 0.8787 - val_loss: 0.2515 - val_accuracy: 0.8741\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2553 - accuracy: 0.8782 - val_loss: 0.2487 - val_accuracy: 0.8779\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2552 - accuracy: 0.8791 - val_loss: 0.2474 - val_accuracy: 0.8790\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2548 - accuracy: 0.8791 - val_loss: 0.2476 - val_accuracy: 0.8782\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2557 - accuracy: 0.8783 - val_loss: 0.2503 - val_accuracy: 0.8746\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2556 - accuracy: 0.8784 - val_loss: 0.2504 - val_accuracy: 0.8759\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2558 - accuracy: 0.8785 - val_loss: 0.2539 - val_accuracy: 0.8701\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2542 - accuracy: 0.8788 - val_loss: 0.2440 - val_accuracy: 0.8819\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2559 - accuracy: 0.8782 - val_loss: 0.2525 - val_accuracy: 0.8810\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2557 - accuracy: 0.8788 - val_loss: 0.2571 - val_accuracy: 0.8772\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2553 - accuracy: 0.8783 - val_loss: 0.2596 - val_accuracy: 0.8694\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2551 - accuracy: 0.8790 - val_loss: 0.2474 - val_accuracy: 0.8785\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2566 - accuracy: 0.8776 - val_loss: 0.2526 - val_accuracy: 0.8727\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2559 - accuracy: 0.8785 - val_loss: 0.2467 - val_accuracy: 0.8771\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2568 - accuracy: 0.8778 - val_loss: 0.2460 - val_accuracy: 0.8810\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2546 - accuracy: 0.8791 - val_loss: 0.2510 - val_accuracy: 0.8750\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2549 - accuracy: 0.8789 - val_loss: 0.2481 - val_accuracy: 0.8755\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2550 - accuracy: 0.8792 - val_loss: 0.2475 - val_accuracy: 0.8788\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2547 - accuracy: 0.8788 - val_loss: 0.2448 - val_accuracy: 0.8783\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2549 - accuracy: 0.8792 - val_loss: 0.2467 - val_accuracy: 0.8765\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 41s 296us/step - loss: 0.2551 - accuracy: 0.8789 - val_loss: 0.2466 - val_accuracy: 0.8808\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2549 - accuracy: 0.8793 - val_loss: 0.2457 - val_accuracy: 0.8801\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 42s 297us/step - loss: 0.2546 - accuracy: 0.8788 - val_loss: 0.2485 - val_accuracy: 0.8757\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 42s 299us/step - loss: 0.2549 - accuracy: 0.8784 - val_loss: 0.2495 - val_accuracy: 0.8816\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2551 - accuracy: 0.8786 - val_loss: 0.2467 - val_accuracy: 0.8797\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 42s 296us/step - loss: 0.2550 - accuracy: 0.8783 - val_loss: 0.2478 - val_accuracy: 0.8758\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2556 - accuracy: 0.8780 - val_loss: 0.2446 - val_accuracy: 0.8821\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2560 - accuracy: 0.8787 - val_loss: 0.2494 - val_accuracy: 0.8770\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 42s 300us/step - loss: 0.2556 - accuracy: 0.8785 - val_loss: 0.2463 - val_accuracy: 0.8811\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2552 - accuracy: 0.8788 - val_loss: 0.2470 - val_accuracy: 0.8766\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 40s 287us/step - loss: 0.2542 - accuracy: 0.8783 - val_loss: 0.2469 - val_accuracy: 0.8783\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2553 - accuracy: 0.8785 - val_loss: 0.2447 - val_accuracy: 0.8789\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2556 - accuracy: 0.8777 - val_loss: 0.2534 - val_accuracy: 0.8742\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 40s 286us/step - loss: 0.2558 - accuracy: 0.8785 - val_loss: 0.2549 - val_accuracy: 0.8682\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2538 - accuracy: 0.8789 - val_loss: 0.2535 - val_accuracy: 0.8764\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2557 - accuracy: 0.8785 - val_loss: 0.2501 - val_accuracy: 0.8761\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2555 - accuracy: 0.8790 - val_loss: 0.2526 - val_accuracy: 0.8705\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2543 - accuracy: 0.8794 - val_loss: 0.2489 - val_accuracy: 0.8744\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2544 - accuracy: 0.8794 - val_loss: 0.2455 - val_accuracy: 0.8819\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.2550 - accuracy: 0.8784 - val_loss: 0.2834 - val_accuracy: 0.8760\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2544 - accuracy: 0.8788 - val_loss: 0.2471 - val_accuracy: 0.8775\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2544 - accuracy: 0.8787 - val_loss: 0.2592 - val_accuracy: 0.8665\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2553 - accuracy: 0.8785 - val_loss: 0.2460 - val_accuracy: 0.8815\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2551 - accuracy: 0.8784 - val_loss: 0.2496 - val_accuracy: 0.8800\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2534 - accuracy: 0.8792 - val_loss: 0.2453 - val_accuracy: 0.8803\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 41s 289us/step - loss: 0.2543 - accuracy: 0.8791 - val_loss: 0.2453 - val_accuracy: 0.8821\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2544 - accuracy: 0.8790 - val_loss: 0.2455 - val_accuracy: 0.8796\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2552 - accuracy: 0.8787 - val_loss: 0.2511 - val_accuracy: 0.8791\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2542 - accuracy: 0.8791 - val_loss: 0.2641 - val_accuracy: 0.8650\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2554 - accuracy: 0.8781 - val_loss: 0.2493 - val_accuracy: 0.8736\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2543 - accuracy: 0.8786 - val_loss: 0.2501 - val_accuracy: 0.8735\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 41s 290us/step - loss: 0.2554 - accuracy: 0.8787 - val_loss: 0.2467 - val_accuracy: 0.8808\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2551 - accuracy: 0.8786 - val_loss: 0.2539 - val_accuracy: 0.8737\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2548 - accuracy: 0.8785 - val_loss: 0.2521 - val_accuracy: 0.8719\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2552 - accuracy: 0.8789 - val_loss: 0.2450 - val_accuracy: 0.8805\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2556 - accuracy: 0.8785 - val_loss: 0.2441 - val_accuracy: 0.8792\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2548 - accuracy: 0.8784 - val_loss: 0.2477 - val_accuracy: 0.8804\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 41s 295us/step - loss: 0.2546 - accuracy: 0.8791 - val_loss: 0.2469 - val_accuracy: 0.8774\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 41s 291us/step - loss: 0.2546 - accuracy: 0.8790 - val_loss: 0.2486 - val_accuracy: 0.8771\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2552 - accuracy: 0.8783 - val_loss: 0.2494 - val_accuracy: 0.8733\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.2545 - accuracy: 0.8787 - val_loss: 0.2480 - val_accuracy: 0.8754\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2546 - accuracy: 0.8792 - val_loss: 0.2537 - val_accuracy: 0.8698\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 41s 293us/step - loss: 0.2555 - accuracy: 0.8785 - val_loss: 0.2466 - val_accuracy: 0.8796\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 41s 294us/step - loss: 0.2540 - accuracy: 0.8793 - val_loss: 0.2620 - val_accuracy: 0.8681\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 48s 339us/step - loss: 0.2543 - accuracy: 0.8792 - val_loss: 0.2492 - val_accuracy: 0.8767\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 0.2547 - accuracy: 0.8792 - val_loss: 0.2465 - val_accuracy: 0.8775\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 0.2553 - accuracy: 0.8785 - val_loss: 0.2492 - val_accuracy: 0.8757\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 43s 310us/step - loss: 0.2546 - accuracy: 0.8797 - val_loss: 0.2488 - val_accuracy: 0.8816\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 43s 308us/step - loss: 0.2549 - accuracy: 0.8789 - val_loss: 0.2590 - val_accuracy: 0.8661\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 44s 312us/step - loss: 0.2540 - accuracy: 0.8792 - val_loss: 0.2543 - val_accuracy: 0.8786\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 44s 312us/step - loss: 0.2540 - accuracy: 0.8795 - val_loss: 0.2694 - val_accuracy: 0.8675\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 44s 316us/step - loss: 0.2546 - accuracy: 0.8788 - val_loss: 0.2576 - val_accuracy: 0.8693\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 44s 315us/step - loss: 0.2555 - accuracy: 0.8787 - val_loss: 0.2512 - val_accuracy: 0.8779\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 44s 311us/step - loss: 0.2540 - accuracy: 0.8796 - val_loss: 0.2594 - val_accuracy: 0.8660\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 43s 309us/step - loss: 0.2542 - accuracy: 0.8791 - val_loss: 0.2543 - val_accuracy: 0.8688\n",
      "accuracy: 86.88%\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    XTrain, XVal, yTrain, yVal = train_test_split(X, Y, test_size=0.2, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    cnn.fit(XTrain, yTrain, nb_epoch=200, validation_data=(XVal, yVal))\n",
    "    scores = cnn.evaluate(XVal, yVal, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (cnn.metrics_names[1], scores[1]*100))\n",
    "    a.append(scores[1] * 100)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88.97316455841064, 88.34012746810913, 89.16707038879395, 87.58447766304016, 86.87729835510254]\n"
     ]
    }
   ],
   "source": [
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
