{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-1]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-1]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],1,X.shape[1]))\n",
    "x = np.reshape(x, (x.shape[0],1,x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, input_shape=(None, 41))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4,input_dim=41))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "a=[]\n",
    "folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 19s 134us/step - loss: 0.4500 - accuracy: 0.7464 - val_loss: 0.4091 - val_accuracy: 0.8075\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4074 - accuracy: 0.7681 - val_loss: 0.4060 - val_accuracy: 0.7632\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4044 - accuracy: 0.7695 - val_loss: 0.4028 - val_accuracy: 0.7679\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4026 - accuracy: 0.7685 - val_loss: 0.4021 - val_accuracy: 0.7944\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4011 - accuracy: 0.7712 - val_loss: 0.4003 - val_accuracy: 0.7641\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3999 - accuracy: 0.7703 - val_loss: 0.3991 - val_accuracy: 0.7592\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3991 - accuracy: 0.7722 - val_loss: 0.3986 - val_accuracy: 0.7821\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3986 - accuracy: 0.7713 - val_loss: 0.3978 - val_accuracy: 0.7743\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3975 - accuracy: 0.7709 - val_loss: 0.3971 - val_accuracy: 0.7793\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 18s 125us/step - loss: 0.3974 - accuracy: 0.7727 - val_loss: 0.3965 - val_accuracy: 0.7687\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3962 - accuracy: 0.7745 - val_loss: 0.3956 - val_accuracy: 0.7707\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 0.3951 - accuracy: 0.7760 - val_loss: 0.3939 - val_accuracy: 0.7707\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3933 - accuracy: 0.7803 - val_loss: 0.3954 - val_accuracy: 0.7715\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3905 - accuracy: 0.7856 - val_loss: 0.3890 - val_accuracy: 0.7924\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3876 - accuracy: 0.7943 - val_loss: 0.3876 - val_accuracy: 0.7947\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 0.3834 - accuracy: 0.8020 - val_loss: 0.3808 - val_accuracy: 0.8191\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3784 - accuracy: 0.8106 - val_loss: 0.3757 - val_accuracy: 0.8185\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 0.3726 - accuracy: 0.8186 - val_loss: 0.3711 - val_accuracy: 0.8204\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 0.3671 - accuracy: 0.8253 - val_loss: 0.3648 - val_accuracy: 0.8279\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 17s 125us/step - loss: 0.3625 - accuracy: 0.8292 - val_loss: 0.3583 - val_accuracy: 0.8460\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 18s 125us/step - loss: 0.3577 - accuracy: 0.8336 - val_loss: 0.3550 - val_accuracy: 0.8347\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3539 - accuracy: 0.8346 - val_loss: 0.3501 - val_accuracy: 0.8393\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 18s 128us/step - loss: 0.3503 - accuracy: 0.8371 - val_loss: 0.3467 - val_accuracy: 0.8386\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3476 - accuracy: 0.8380 - val_loss: 0.3443 - val_accuracy: 0.8518\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3452 - accuracy: 0.8384 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 0.3426 - accuracy: 0.8397 - val_loss: 0.3379 - val_accuracy: 0.8494\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3410 - accuracy: 0.8408 - val_loss: 0.3364 - val_accuracy: 0.8486\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3397 - accuracy: 0.8417 - val_loss: 0.3366 - val_accuracy: 0.8420\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 18s 125us/step - loss: 0.3388 - accuracy: 0.8421 - val_loss: 0.3328 - val_accuracy: 0.8499\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 0.3379 - accuracy: 0.8425 - val_loss: 0.3321 - val_accuracy: 0.8529\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 18s 125us/step - loss: 0.3371 - accuracy: 0.8435 - val_loss: 0.3315 - val_accuracy: 0.8510\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3356 - accuracy: 0.8440 - val_loss: 0.3300 - val_accuracy: 0.8508\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3350 - accuracy: 0.8447 - val_loss: 0.3340 - val_accuracy: 0.8615\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3350 - accuracy: 0.8443 - val_loss: 0.3302 - val_accuracy: 0.8549\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3337 - accuracy: 0.8455 - val_loss: 0.3281 - val_accuracy: 0.8510\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3336 - accuracy: 0.8454 - val_loss: 0.3287 - val_accuracy: 0.8477\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3333 - accuracy: 0.8457 - val_loss: 0.3294 - val_accuracy: 0.8503\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3327 - accuracy: 0.8462 - val_loss: 0.3274 - val_accuracy: 0.8544\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3322 - accuracy: 0.8462 - val_loss: 0.3269 - val_accuracy: 0.8495\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3326 - accuracy: 0.8469 - val_loss: 0.3257 - val_accuracy: 0.8533\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3323 - accuracy: 0.8468 - val_loss: 0.3267 - val_accuracy: 0.8496\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3317 - accuracy: 0.8472 - val_loss: 0.3296 - val_accuracy: 0.8584\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3315 - accuracy: 0.8477 - val_loss: 0.3263 - val_accuracy: 0.8502\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3311 - accuracy: 0.8482 - val_loss: 0.3294 - val_accuracy: 0.8562\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3315 - accuracy: 0.8478 - val_loss: 0.3256 - val_accuracy: 0.8510\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3306 - accuracy: 0.8484 - val_loss: 0.3270 - val_accuracy: 0.8509\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3310 - accuracy: 0.8491 - val_loss: 0.3252 - val_accuracy: 0.8512\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3302 - accuracy: 0.8490 - val_loss: 0.3243 - val_accuracy: 0.8529\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3309 - accuracy: 0.8478 - val_loss: 0.3239 - val_accuracy: 0.8531\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3302 - accuracy: 0.8491 - val_loss: 0.3253 - val_accuracy: 0.8507\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.3294 - accuracy: 0.8491 - val_loss: 0.3240 - val_accuracy: 0.8527\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3294 - accuracy: 0.8492 - val_loss: 0.3239 - val_accuracy: 0.8557\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3298 - accuracy: 0.8492 - val_loss: 0.3236 - val_accuracy: 0.8538\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3301 - accuracy: 0.8492 - val_loss: 0.3236 - val_accuracy: 0.8530\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3291 - accuracy: 0.8502 - val_loss: 0.3239 - val_accuracy: 0.8532\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3292 - accuracy: 0.8498 - val_loss: 0.3250 - val_accuracy: 0.8531\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3288 - accuracy: 0.8505 - val_loss: 0.3239 - val_accuracy: 0.8533\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3292 - accuracy: 0.8504 - val_loss: 0.3259 - val_accuracy: 0.8506\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3287 - accuracy: 0.8500 - val_loss: 0.3251 - val_accuracy: 0.8570\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3290 - accuracy: 0.8506 - val_loss: 0.3239 - val_accuracy: 0.8560\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3292 - accuracy: 0.8508 - val_loss: 0.3235 - val_accuracy: 0.8561\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3288 - accuracy: 0.8508 - val_loss: 0.3261 - val_accuracy: 0.8579\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3280 - accuracy: 0.8508 - val_loss: 0.3236 - val_accuracy: 0.8559\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3288 - accuracy: 0.8507 - val_loss: 0.3224 - val_accuracy: 0.8549\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3278 - accuracy: 0.8516 - val_loss: 0.3234 - val_accuracy: 0.8529\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3287 - accuracy: 0.8512 - val_loss: 0.3241 - val_accuracy: 0.8562\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3280 - accuracy: 0.8516 - val_loss: 0.3242 - val_accuracy: 0.8523\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3279 - accuracy: 0.8514 - val_loss: 0.3223 - val_accuracy: 0.8553\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3274 - accuracy: 0.8517 - val_loss: 0.3224 - val_accuracy: 0.8539\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3279 - accuracy: 0.8516 - val_loss: 0.3266 - val_accuracy: 0.8507\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3277 - accuracy: 0.8518 - val_loss: 0.3253 - val_accuracy: 0.8574\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3278 - accuracy: 0.8515 - val_loss: 0.3220 - val_accuracy: 0.8540\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3277 - accuracy: 0.8516 - val_loss: 0.3222 - val_accuracy: 0.8562\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3271 - accuracy: 0.8525 - val_loss: 0.3218 - val_accuracy: 0.8548\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3272 - accuracy: 0.8520 - val_loss: 0.3285 - val_accuracy: 0.8612\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3265 - accuracy: 0.8527 - val_loss: 0.3214 - val_accuracy: 0.8558\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3272 - accuracy: 0.8524 - val_loss: 0.3229 - val_accuracy: 0.8532\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3275 - accuracy: 0.8514 - val_loss: 0.3214 - val_accuracy: 0.8561\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3270 - accuracy: 0.8523 - val_loss: 0.3282 - val_accuracy: 0.8506\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3267 - accuracy: 0.8523 - val_loss: 0.3250 - val_accuracy: 0.8588\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3263 - accuracy: 0.8525 - val_loss: 0.3224 - val_accuracy: 0.8534\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 118us/step - loss: 0.3267 - accuracy: 0.8527 - val_loss: 0.3214 - val_accuracy: 0.8563\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3258 - accuracy: 0.8529 - val_loss: 0.3244 - val_accuracy: 0.8580\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3268 - accuracy: 0.8530 - val_loss: 0.3218 - val_accuracy: 0.8566\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3266 - accuracy: 0.8529 - val_loss: 0.3235 - val_accuracy: 0.8573\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3264 - accuracy: 0.8530 - val_loss: 0.3257 - val_accuracy: 0.8520\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3256 - accuracy: 0.8530 - val_loss: 0.3255 - val_accuracy: 0.8519\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3257 - accuracy: 0.8533 - val_loss: 0.3218 - val_accuracy: 0.8563\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3259 - accuracy: 0.8530 - val_loss: 0.3213 - val_accuracy: 0.8564\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3262 - accuracy: 0.8534 - val_loss: 0.3211 - val_accuracy: 0.8554\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3258 - accuracy: 0.8531 - val_loss: 0.3209 - val_accuracy: 0.8563\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3262 - accuracy: 0.8531 - val_loss: 0.3218 - val_accuracy: 0.8563\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3260 - accuracy: 0.8532 - val_loss: 0.3217 - val_accuracy: 0.8565\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3260 - accuracy: 0.8534 - val_loss: 0.3213 - val_accuracy: 0.8547\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3258 - accuracy: 0.8532 - val_loss: 0.3220 - val_accuracy: 0.8549\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3261 - accuracy: 0.8528 - val_loss: 0.3208 - val_accuracy: 0.8562\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3258 - accuracy: 0.8541 - val_loss: 0.3209 - val_accuracy: 0.8565\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3250 - accuracy: 0.8536 - val_loss: 0.3235 - val_accuracy: 0.8585\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3253 - accuracy: 0.8539 - val_loss: 0.3213 - val_accuracy: 0.8565\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3253 - accuracy: 0.8534 - val_loss: 0.3205 - val_accuracy: 0.8567\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3252 - accuracy: 0.8538 - val_loss: 0.3242 - val_accuracy: 0.8599\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3244 - accuracy: 0.8536 - val_loss: 0.3219 - val_accuracy: 0.8537\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3254 - accuracy: 0.8541 - val_loss: 0.3226 - val_accuracy: 0.8524\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3253 - accuracy: 0.8541 - val_loss: 0.3233 - val_accuracy: 0.8591\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3253 - accuracy: 0.8536 - val_loss: 0.3216 - val_accuracy: 0.8569\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3253 - accuracy: 0.8540 - val_loss: 0.3210 - val_accuracy: 0.8563\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3248 - accuracy: 0.8541 - val_loss: 0.3208 - val_accuracy: 0.8554\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3250 - accuracy: 0.8540 - val_loss: 0.3221 - val_accuracy: 0.8565\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3250 - accuracy: 0.8547 - val_loss: 0.3263 - val_accuracy: 0.8508\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3248 - accuracy: 0.8542 - val_loss: 0.3235 - val_accuracy: 0.8529\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3247 - accuracy: 0.8541 - val_loss: 0.3209 - val_accuracy: 0.8569\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3243 - accuracy: 0.8546 - val_loss: 0.3217 - val_accuracy: 0.8537\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3247 - accuracy: 0.8539 - val_loss: 0.3250 - val_accuracy: 0.8511\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3245 - accuracy: 0.8549 - val_loss: 0.3206 - val_accuracy: 0.8565\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3247 - accuracy: 0.8544 - val_loss: 0.3229 - val_accuracy: 0.8533\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3240 - accuracy: 0.8540 - val_loss: 0.3214 - val_accuracy: 0.8574\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3237 - accuracy: 0.8552 - val_loss: 0.3240 - val_accuracy: 0.8529\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3243 - accuracy: 0.8546 - val_loss: 0.3206 - val_accuracy: 0.8547\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3243 - accuracy: 0.8541 - val_loss: 0.3205 - val_accuracy: 0.8564\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3241 - accuracy: 0.8548 - val_loss: 0.3213 - val_accuracy: 0.8569\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3244 - accuracy: 0.8545 - val_loss: 0.3205 - val_accuracy: 0.8555\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3241 - accuracy: 0.8548 - val_loss: 0.3213 - val_accuracy: 0.8549\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3237 - accuracy: 0.8556 - val_loss: 0.3232 - val_accuracy: 0.8589\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3239 - accuracy: 0.8549 - val_loss: 0.3212 - val_accuracy: 0.8573\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3238 - accuracy: 0.8549 - val_loss: 0.3209 - val_accuracy: 0.8549\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3238 - accuracy: 0.8548 - val_loss: 0.3202 - val_accuracy: 0.8567\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3234 - accuracy: 0.8549 - val_loss: 0.3208 - val_accuracy: 0.8569\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3237 - accuracy: 0.8549 - val_loss: 0.3206 - val_accuracy: 0.8568\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3241 - accuracy: 0.8552 - val_loss: 0.3217 - val_accuracy: 0.8535\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3234 - accuracy: 0.8550 - val_loss: 0.3208 - val_accuracy: 0.8542\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3231 - accuracy: 0.8551 - val_loss: 0.3223 - val_accuracy: 0.8571\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3240 - accuracy: 0.8556 - val_loss: 0.3248 - val_accuracy: 0.8516\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3236 - accuracy: 0.8549 - val_loss: 0.3222 - val_accuracy: 0.8587\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3241 - accuracy: 0.8547 - val_loss: 0.3229 - val_accuracy: 0.8527\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3234 - accuracy: 0.8552 - val_loss: 0.3278 - val_accuracy: 0.8509\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3237 - accuracy: 0.8547 - val_loss: 0.3201 - val_accuracy: 0.8566\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3231 - accuracy: 0.8552 - val_loss: 0.3204 - val_accuracy: 0.8570\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3243 - accuracy: 0.8553 - val_loss: 0.3197 - val_accuracy: 0.8571\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3233 - accuracy: 0.8549 - val_loss: 0.3218 - val_accuracy: 0.8540\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3235 - accuracy: 0.8553 - val_loss: 0.3228 - val_accuracy: 0.8597\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3232 - accuracy: 0.8553 - val_loss: 0.3222 - val_accuracy: 0.8531\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3233 - accuracy: 0.8551 - val_loss: 0.3197 - val_accuracy: 0.8566\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3230 - accuracy: 0.8555 - val_loss: 0.3203 - val_accuracy: 0.8572\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3231 - accuracy: 0.8557 - val_loss: 0.3216 - val_accuracy: 0.8581\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3232 - accuracy: 0.8552 - val_loss: 0.3245 - val_accuracy: 0.8615\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3238 - accuracy: 0.8553 - val_loss: 0.3201 - val_accuracy: 0.8549\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3230 - accuracy: 0.8557 - val_loss: 0.3210 - val_accuracy: 0.8563\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3231 - accuracy: 0.8556 - val_loss: 0.3203 - val_accuracy: 0.8571\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3228 - accuracy: 0.8556 - val_loss: 0.3206 - val_accuracy: 0.8561\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3225 - accuracy: 0.8558 - val_loss: 0.3216 - val_accuracy: 0.8531\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3229 - accuracy: 0.8558 - val_loss: 0.3217 - val_accuracy: 0.8578\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3223 - accuracy: 0.8554 - val_loss: 0.3220 - val_accuracy: 0.8579\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3227 - accuracy: 0.8556 - val_loss: 0.3303 - val_accuracy: 0.8502\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3227 - accuracy: 0.8558 - val_loss: 0.3201 - val_accuracy: 0.8548\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3227 - accuracy: 0.8551 - val_loss: 0.3238 - val_accuracy: 0.8582\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3229 - accuracy: 0.8551 - val_loss: 0.3198 - val_accuracy: 0.8573\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3224 - accuracy: 0.8560 - val_loss: 0.3196 - val_accuracy: 0.8571\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3231 - accuracy: 0.8555 - val_loss: 0.3195 - val_accuracy: 0.8572\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3223 - accuracy: 0.8555 - val_loss: 0.3220 - val_accuracy: 0.8531\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3231 - accuracy: 0.8553 - val_loss: 0.3202 - val_accuracy: 0.8572\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3226 - accuracy: 0.8555 - val_loss: 0.3208 - val_accuracy: 0.8538\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3222 - accuracy: 0.8560 - val_loss: 0.3230 - val_accuracy: 0.8524\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3220 - accuracy: 0.8561 - val_loss: 0.3217 - val_accuracy: 0.8577\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3227 - accuracy: 0.8557 - val_loss: 0.3199 - val_accuracy: 0.8575\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3223 - accuracy: 0.8557 - val_loss: 0.3210 - val_accuracy: 0.8569\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3220 - accuracy: 0.8560 - val_loss: 0.3194 - val_accuracy: 0.8574\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3226 - accuracy: 0.8549 - val_loss: 0.3235 - val_accuracy: 0.8528\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3222 - accuracy: 0.8560 - val_loss: 0.3198 - val_accuracy: 0.8572\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3226 - accuracy: 0.8557 - val_loss: 0.3196 - val_accuracy: 0.8573\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3220 - accuracy: 0.8558 - val_loss: 0.3214 - val_accuracy: 0.8540\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3216 - accuracy: 0.8560 - val_loss: 0.3206 - val_accuracy: 0.8553\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3223 - accuracy: 0.8563 - val_loss: 0.3198 - val_accuracy: 0.8563\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3220 - accuracy: 0.8557 - val_loss: 0.3245 - val_accuracy: 0.8522\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3221 - accuracy: 0.8559 - val_loss: 0.3195 - val_accuracy: 0.8573\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3227 - accuracy: 0.8560 - val_loss: 0.3192 - val_accuracy: 0.8576\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3222 - accuracy: 0.8551 - val_loss: 0.3201 - val_accuracy: 0.8573\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3222 - accuracy: 0.8553 - val_loss: 0.3207 - val_accuracy: 0.8575\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3214 - accuracy: 0.8557 - val_loss: 0.3191 - val_accuracy: 0.8564\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3227 - accuracy: 0.8562 - val_loss: 0.3205 - val_accuracy: 0.8575\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3216 - accuracy: 0.8565 - val_loss: 0.3194 - val_accuracy: 0.8575\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3220 - accuracy: 0.8557 - val_loss: 0.3201 - val_accuracy: 0.8575\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3220 - accuracy: 0.8554 - val_loss: 0.3193 - val_accuracy: 0.8576\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3221 - accuracy: 0.8558 - val_loss: 0.3210 - val_accuracy: 0.8537\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3223 - accuracy: 0.8561 - val_loss: 0.3199 - val_accuracy: 0.8548\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3215 - accuracy: 0.8556 - val_loss: 0.3187 - val_accuracy: 0.8577\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3215 - accuracy: 0.8561 - val_loss: 0.3196 - val_accuracy: 0.8574\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3215 - accuracy: 0.8562 - val_loss: 0.3219 - val_accuracy: 0.8532\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3217 - accuracy: 0.8563 - val_loss: 0.3228 - val_accuracy: 0.8611\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3221 - accuracy: 0.8561 - val_loss: 0.3194 - val_accuracy: 0.8571\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3212 - accuracy: 0.8563 - val_loss: 0.3192 - val_accuracy: 0.8574\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3217 - accuracy: 0.8562 - val_loss: 0.3206 - val_accuracy: 0.8543\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3211 - accuracy: 0.8559 - val_loss: 0.3197 - val_accuracy: 0.8550\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3217 - accuracy: 0.8559 - val_loss: 0.3267 - val_accuracy: 0.8510\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3220 - accuracy: 0.8555 - val_loss: 0.3192 - val_accuracy: 0.8560\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3222 - accuracy: 0.8560 - val_loss: 0.3197 - val_accuracy: 0.8553\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3217 - accuracy: 0.8558 - val_loss: 0.3191 - val_accuracy: 0.8575\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3216 - accuracy: 0.8565 - val_loss: 0.3212 - val_accuracy: 0.8539\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3213 - accuracy: 0.8562 - val_loss: 0.3188 - val_accuracy: 0.8577\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3214 - accuracy: 0.8563 - val_loss: 0.3197 - val_accuracy: 0.8562\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3219 - accuracy: 0.8562 - val_loss: 0.3206 - val_accuracy: 0.8582\n",
      "accuracy: 85.82%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3229 - accuracy: 0.8554 - val_loss: 0.3173 - val_accuracy: 0.8659\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3229 - accuracy: 0.8550 - val_loss: 0.3124 - val_accuracy: 0.8603\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3230 - accuracy: 0.8548 - val_loss: 0.3118 - val_accuracy: 0.8613\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3229 - accuracy: 0.8554 - val_loss: 0.3146 - val_accuracy: 0.8631\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3230 - accuracy: 0.8552 - val_loss: 0.3134 - val_accuracy: 0.8590\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3229 - accuracy: 0.8552 - val_loss: 0.3123 - val_accuracy: 0.8620\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3238 - accuracy: 0.8549 - val_loss: 0.3118 - val_accuracy: 0.8622\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3227 - accuracy: 0.8556 - val_loss: 0.3151 - val_accuracy: 0.8639\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3227 - accuracy: 0.8552 - val_loss: 0.3118 - val_accuracy: 0.8619\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3232 - accuracy: 0.8548 - val_loss: 0.3122 - val_accuracy: 0.8623\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3227 - accuracy: 0.8556 - val_loss: 0.3132 - val_accuracy: 0.8595\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3224 - accuracy: 0.8551 - val_loss: 0.3120 - val_accuracy: 0.8622\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3227 - accuracy: 0.8554 - val_loss: 0.3144 - val_accuracy: 0.8631\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3228 - accuracy: 0.8550 - val_loss: 0.3121 - val_accuracy: 0.8608\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3229 - accuracy: 0.8555 - val_loss: 0.3130 - val_accuracy: 0.8599\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3227 - accuracy: 0.8558 - val_loss: 0.3127 - val_accuracy: 0.8617\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3223 - accuracy: 0.8554 - val_loss: 0.3211 - val_accuracy: 0.8551\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3220 - accuracy: 0.8558 - val_loss: 0.3156 - val_accuracy: 0.8645\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3219 - accuracy: 0.8558 - val_loss: 0.3125 - val_accuracy: 0.8600\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3223 - accuracy: 0.8554 - val_loss: 0.3122 - val_accuracy: 0.8608\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3226 - accuracy: 0.8557 - val_loss: 0.3123 - val_accuracy: 0.8620\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3222 - accuracy: 0.8554 - val_loss: 0.3121 - val_accuracy: 0.8624\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3228 - accuracy: 0.8553 - val_loss: 0.3124 - val_accuracy: 0.8628\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3223 - accuracy: 0.8558 - val_loss: 0.3119 - val_accuracy: 0.8619\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3228 - accuracy: 0.8556 - val_loss: 0.3124 - val_accuracy: 0.8622\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3229 - accuracy: 0.8551 - val_loss: 0.3161 - val_accuracy: 0.8652\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3225 - accuracy: 0.8553 - val_loss: 0.3136 - val_accuracy: 0.8632\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3223 - accuracy: 0.8554 - val_loss: 0.3124 - val_accuracy: 0.8629\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3224 - accuracy: 0.8553 - val_loss: 0.3142 - val_accuracy: 0.8584\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3227 - accuracy: 0.8553 - val_loss: 0.3123 - val_accuracy: 0.8630\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3227 - accuracy: 0.8553 - val_loss: 0.3153 - val_accuracy: 0.8646\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3228 - accuracy: 0.8558 - val_loss: 0.3119 - val_accuracy: 0.8601\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3225 - accuracy: 0.8550 - val_loss: 0.3132 - val_accuracy: 0.8631\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3222 - accuracy: 0.8557 - val_loss: 0.3130 - val_accuracy: 0.8599\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3214 - accuracy: 0.8561 - val_loss: 0.3175 - val_accuracy: 0.8650\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3224 - accuracy: 0.8552 - val_loss: 0.3132 - val_accuracy: 0.8628\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3220 - accuracy: 0.8554 - val_loss: 0.3162 - val_accuracy: 0.8570\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3223 - accuracy: 0.8554 - val_loss: 0.3121 - val_accuracy: 0.8627\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3223 - accuracy: 0.8556 - val_loss: 0.3116 - val_accuracy: 0.8616\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3223 - accuracy: 0.8553 - val_loss: 0.3126 - val_accuracy: 0.8624\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3221 - accuracy: 0.8557 - val_loss: 0.3114 - val_accuracy: 0.8617\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3222 - accuracy: 0.8555 - val_loss: 0.3132 - val_accuracy: 0.8590\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3218 - accuracy: 0.8552 - val_loss: 0.3113 - val_accuracy: 0.8623\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3222 - accuracy: 0.8557 - val_loss: 0.3157 - val_accuracy: 0.8582\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3217 - accuracy: 0.8555 - val_loss: 0.3127 - val_accuracy: 0.8631\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3220 - accuracy: 0.8560 - val_loss: 0.3130 - val_accuracy: 0.8624\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3218 - accuracy: 0.8560 - val_loss: 0.3118 - val_accuracy: 0.8602\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3215 - accuracy: 0.8560 - val_loss: 0.3142 - val_accuracy: 0.8628\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3220 - accuracy: 0.8556 - val_loss: 0.3115 - val_accuracy: 0.8620\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3209 - accuracy: 0.8560 - val_loss: 0.3149 - val_accuracy: 0.8642\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3219 - accuracy: 0.8559 - val_loss: 0.3155 - val_accuracy: 0.8646\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3224 - accuracy: 0.8558 - val_loss: 0.3118 - val_accuracy: 0.8628\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3223 - accuracy: 0.8557 - val_loss: 0.3135 - val_accuracy: 0.8636\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3216 - accuracy: 0.8555 - val_loss: 0.3112 - val_accuracy: 0.8620\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3225 - accuracy: 0.8557 - val_loss: 0.3114 - val_accuracy: 0.8621\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3223 - accuracy: 0.8552 - val_loss: 0.3129 - val_accuracy: 0.8601\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3217 - accuracy: 0.8556 - val_loss: 0.3117 - val_accuracy: 0.8621\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3213 - accuracy: 0.8559 - val_loss: 0.3126 - val_accuracy: 0.8600\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3218 - accuracy: 0.8556 - val_loss: 0.3120 - val_accuracy: 0.8618\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3221 - accuracy: 0.8558 - val_loss: 0.3152 - val_accuracy: 0.8646\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3214 - accuracy: 0.8554 - val_loss: 0.3123 - val_accuracy: 0.8622\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3224 - accuracy: 0.8558 - val_loss: 0.3122 - val_accuracy: 0.8601\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3224 - accuracy: 0.8558 - val_loss: 0.3116 - val_accuracy: 0.8623\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3213 - accuracy: 0.8558 - val_loss: 0.3146 - val_accuracy: 0.8581\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3221 - accuracy: 0.8555 - val_loss: 0.3130 - val_accuracy: 0.8594\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3214 - accuracy: 0.8556 - val_loss: 0.3140 - val_accuracy: 0.8641\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3220 - accuracy: 0.8553 - val_loss: 0.3113 - val_accuracy: 0.8622\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3218 - accuracy: 0.8557 - val_loss: 0.3192 - val_accuracy: 0.8676\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3210 - accuracy: 0.8561 - val_loss: 0.3117 - val_accuracy: 0.8624\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3224 - accuracy: 0.8555 - val_loss: 0.3128 - val_accuracy: 0.8630\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3222 - accuracy: 0.8556 - val_loss: 0.3148 - val_accuracy: 0.8634\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3215 - accuracy: 0.8557 - val_loss: 0.3112 - val_accuracy: 0.8623\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3225 - accuracy: 0.8556 - val_loss: 0.3131 - val_accuracy: 0.8632\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3209 - accuracy: 0.8560 - val_loss: 0.3129 - val_accuracy: 0.8593\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3221 - accuracy: 0.8551 - val_loss: 0.3116 - val_accuracy: 0.8622\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3213 - accuracy: 0.8561 - val_loss: 0.3116 - val_accuracy: 0.8629\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3214 - accuracy: 0.8557 - val_loss: 0.3113 - val_accuracy: 0.8617\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3223 - accuracy: 0.8559 - val_loss: 0.3112 - val_accuracy: 0.8620\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3212 - accuracy: 0.8558 - val_loss: 0.3114 - val_accuracy: 0.8614\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3216 - accuracy: 0.8562 - val_loss: 0.3111 - val_accuracy: 0.8623\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3215 - accuracy: 0.8563 - val_loss: 0.3122 - val_accuracy: 0.8628\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3214 - accuracy: 0.8560 - val_loss: 0.3114 - val_accuracy: 0.8615\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3212 - accuracy: 0.8556 - val_loss: 0.3134 - val_accuracy: 0.8633\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3215 - accuracy: 0.8559 - val_loss: 0.3115 - val_accuracy: 0.8617\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3215 - accuracy: 0.8556 - val_loss: 0.3121 - val_accuracy: 0.8630\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3217 - accuracy: 0.8557 - val_loss: 0.3115 - val_accuracy: 0.8630\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3209 - accuracy: 0.8563 - val_loss: 0.3111 - val_accuracy: 0.8623\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3218 - accuracy: 0.8556 - val_loss: 0.3125 - val_accuracy: 0.8596\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3212 - accuracy: 0.8560 - val_loss: 0.3125 - val_accuracy: 0.8601\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3216 - accuracy: 0.8561 - val_loss: 0.3165 - val_accuracy: 0.8641\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3208 - accuracy: 0.8563 - val_loss: 0.3110 - val_accuracy: 0.8620\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3205 - accuracy: 0.8559 - val_loss: 0.3145 - val_accuracy: 0.8650\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3213 - accuracy: 0.8558 - val_loss: 0.3128 - val_accuracy: 0.8637\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3210 - accuracy: 0.8560 - val_loss: 0.3119 - val_accuracy: 0.8611\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3212 - accuracy: 0.8559 - val_loss: 0.3110 - val_accuracy: 0.8621\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3213 - accuracy: 0.8557 - val_loss: 0.3114 - val_accuracy: 0.8625\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3211 - accuracy: 0.8557 - val_loss: 0.3137 - val_accuracy: 0.8582\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3212 - accuracy: 0.8560 - val_loss: 0.3115 - val_accuracy: 0.8624\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3211 - accuracy: 0.8559 - val_loss: 0.3123 - val_accuracy: 0.8624\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3211 - accuracy: 0.8560 - val_loss: 0.3118 - val_accuracy: 0.8607\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3207 - accuracy: 0.8563 - val_loss: 0.3112 - val_accuracy: 0.8628\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3203 - accuracy: 0.8568 - val_loss: 0.3119 - val_accuracy: 0.8619\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3212 - accuracy: 0.8562 - val_loss: 0.3112 - val_accuracy: 0.8623\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3214 - accuracy: 0.8557 - val_loss: 0.3114 - val_accuracy: 0.8627\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3209 - accuracy: 0.8566 - val_loss: 0.3122 - val_accuracy: 0.8624\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3211 - accuracy: 0.8559 - val_loss: 0.3140 - val_accuracy: 0.8588\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3205 - accuracy: 0.8561 - val_loss: 0.3108 - val_accuracy: 0.8624\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3212 - accuracy: 0.8560 - val_loss: 0.3129 - val_accuracy: 0.8621\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3208 - accuracy: 0.8559 - val_loss: 0.3113 - val_accuracy: 0.8616\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3204 - accuracy: 0.8560 - val_loss: 0.3123 - val_accuracy: 0.8606\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3206 - accuracy: 0.8565 - val_loss: 0.3113 - val_accuracy: 0.8623\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3211 - accuracy: 0.8559 - val_loss: 0.3110 - val_accuracy: 0.8624\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3207 - accuracy: 0.8563 - val_loss: 0.3129 - val_accuracy: 0.8587\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3209 - accuracy: 0.8563 - val_loss: 0.3114 - val_accuracy: 0.8625\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3211 - accuracy: 0.8561 - val_loss: 0.3167 - val_accuracy: 0.8575\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3211 - accuracy: 0.8556 - val_loss: 0.3121 - val_accuracy: 0.8632\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3205 - accuracy: 0.8565 - val_loss: 0.3120 - val_accuracy: 0.8609\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3207 - accuracy: 0.8560 - val_loss: 0.3208 - val_accuracy: 0.8554\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3213 - accuracy: 0.8565 - val_loss: 0.3121 - val_accuracy: 0.8627\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3210 - accuracy: 0.8562 - val_loss: 0.3147 - val_accuracy: 0.8582\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3212 - accuracy: 0.8560 - val_loss: 0.3116 - val_accuracy: 0.8613\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3205 - accuracy: 0.8559 - val_loss: 0.3108 - val_accuracy: 0.8624\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3206 - accuracy: 0.8562 - val_loss: 0.3106 - val_accuracy: 0.8620\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3203 - accuracy: 0.8561 - val_loss: 0.3119 - val_accuracy: 0.8629\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.3211 - accuracy: 0.8565 - val_loss: 0.3124 - val_accuracy: 0.8630\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3209 - accuracy: 0.8567 - val_loss: 0.3148 - val_accuracy: 0.8580\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3202 - accuracy: 0.8560 - val_loss: 0.3117 - val_accuracy: 0.8601\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3209 - accuracy: 0.8561 - val_loss: 0.3110 - val_accuracy: 0.8627\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3205 - accuracy: 0.8562 - val_loss: 0.3157 - val_accuracy: 0.8644\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3201 - accuracy: 0.8559 - val_loss: 0.3112 - val_accuracy: 0.8631\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3210 - accuracy: 0.8561 - val_loss: 0.3118 - val_accuracy: 0.8632\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3210 - accuracy: 0.8560 - val_loss: 0.3109 - val_accuracy: 0.8619\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3202 - accuracy: 0.8564 - val_loss: 0.3164 - val_accuracy: 0.8659\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3205 - accuracy: 0.8567 - val_loss: 0.3105 - val_accuracy: 0.8623\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3208 - accuracy: 0.8559 - val_loss: 0.3111 - val_accuracy: 0.8617\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3204 - accuracy: 0.8561 - val_loss: 0.3125 - val_accuracy: 0.8591\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3205 - accuracy: 0.8563 - val_loss: 0.3119 - val_accuracy: 0.8630\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3208 - accuracy: 0.8559 - val_loss: 0.3110 - val_accuracy: 0.8621\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3204 - accuracy: 0.8560 - val_loss: 0.3152 - val_accuracy: 0.8577\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3203 - accuracy: 0.8563 - val_loss: 0.3118 - val_accuracy: 0.8602\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3209 - accuracy: 0.8561 - val_loss: 0.3161 - val_accuracy: 0.8571\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3205 - accuracy: 0.8565 - val_loss: 0.3115 - val_accuracy: 0.8622\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3205 - accuracy: 0.8562 - val_loss: 0.3126 - val_accuracy: 0.8636\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3204 - accuracy: 0.8563 - val_loss: 0.3112 - val_accuracy: 0.8627\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3201 - accuracy: 0.8566 - val_loss: 0.3124 - val_accuracy: 0.8636\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3201 - accuracy: 0.8560 - val_loss: 0.3118 - val_accuracy: 0.8631\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3203 - accuracy: 0.8563 - val_loss: 0.3110 - val_accuracy: 0.8620\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3199 - accuracy: 0.8565 - val_loss: 0.3114 - val_accuracy: 0.8622\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3207 - accuracy: 0.8561 - val_loss: 0.3108 - val_accuracy: 0.8623\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3205 - accuracy: 0.8563 - val_loss: 0.3136 - val_accuracy: 0.8594\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3208 - accuracy: 0.8560 - val_loss: 0.3108 - val_accuracy: 0.8626\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3209 - accuracy: 0.8565 - val_loss: 0.3111 - val_accuracy: 0.8632\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3203 - accuracy: 0.8565 - val_loss: 0.3110 - val_accuracy: 0.8622\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3207 - accuracy: 0.8562 - val_loss: 0.3109 - val_accuracy: 0.8618\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3200 - accuracy: 0.8564 - val_loss: 0.3146 - val_accuracy: 0.8642\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3205 - accuracy: 0.8567 - val_loss: 0.3138 - val_accuracy: 0.8638\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3201 - accuracy: 0.8564 - val_loss: 0.3108 - val_accuracy: 0.8621\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3203 - accuracy: 0.8565 - val_loss: 0.3118 - val_accuracy: 0.8627\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3204 - accuracy: 0.8564 - val_loss: 0.3116 - val_accuracy: 0.8607\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3205 - accuracy: 0.8559 - val_loss: 0.3113 - val_accuracy: 0.8633\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3203 - accuracy: 0.8564 - val_loss: 0.3141 - val_accuracy: 0.8592\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3201 - accuracy: 0.8563 - val_loss: 0.3107 - val_accuracy: 0.8623\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3202 - accuracy: 0.8564 - val_loss: 0.3154 - val_accuracy: 0.8651\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3200 - accuracy: 0.8564 - val_loss: 0.3108 - val_accuracy: 0.8624\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3202 - accuracy: 0.8565 - val_loss: 0.3114 - val_accuracy: 0.8628\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3199 - accuracy: 0.8564 - val_loss: 0.3108 - val_accuracy: 0.8623\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3203 - accuracy: 0.8565 - val_loss: 0.3119 - val_accuracy: 0.8599\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3198 - accuracy: 0.8561 - val_loss: 0.3124 - val_accuracy: 0.8594\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3204 - accuracy: 0.8564 - val_loss: 0.3114 - val_accuracy: 0.8616\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3197 - accuracy: 0.8568 - val_loss: 0.3110 - val_accuracy: 0.8625\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3200 - accuracy: 0.8564 - val_loss: 0.3158 - val_accuracy: 0.8581\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3202 - accuracy: 0.8566 - val_loss: 0.3153 - val_accuracy: 0.8653\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3199 - accuracy: 0.8559 - val_loss: 0.3126 - val_accuracy: 0.8596\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3201 - accuracy: 0.8560 - val_loss: 0.3155 - val_accuracy: 0.8578\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3196 - accuracy: 0.8565 - val_loss: 0.3103 - val_accuracy: 0.8627\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3205 - accuracy: 0.8563 - val_loss: 0.3155 - val_accuracy: 0.8646\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3201 - accuracy: 0.8563 - val_loss: 0.3106 - val_accuracy: 0.8613\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3197 - accuracy: 0.8564 - val_loss: 0.3106 - val_accuracy: 0.8625\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3199 - accuracy: 0.8566 - val_loss: 0.3105 - val_accuracy: 0.8627\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3198 - accuracy: 0.8568 - val_loss: 0.3121 - val_accuracy: 0.8634\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3195 - accuracy: 0.8563 - val_loss: 0.3103 - val_accuracy: 0.8624\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3198 - accuracy: 0.8563 - val_loss: 0.3116 - val_accuracy: 0.8632\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3200 - accuracy: 0.8565 - val_loss: 0.3113 - val_accuracy: 0.8610\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3198 - accuracy: 0.8566 - val_loss: 0.3137 - val_accuracy: 0.8640\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3195 - accuracy: 0.8564 - val_loss: 0.3108 - val_accuracy: 0.8631\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3200 - accuracy: 0.8562 - val_loss: 0.3103 - val_accuracy: 0.8628\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3202 - accuracy: 0.8569 - val_loss: 0.3116 - val_accuracy: 0.8601\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3200 - accuracy: 0.8566 - val_loss: 0.3125 - val_accuracy: 0.8637\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3194 - accuracy: 0.8566 - val_loss: 0.3155 - val_accuracy: 0.8579\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3199 - accuracy: 0.8561 - val_loss: 0.3108 - val_accuracy: 0.8632\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3196 - accuracy: 0.8561 - val_loss: 0.3124 - val_accuracy: 0.8597\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3200 - accuracy: 0.8564 - val_loss: 0.3103 - val_accuracy: 0.8623\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3196 - accuracy: 0.8568 - val_loss: 0.3113 - val_accuracy: 0.8633\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3195 - accuracy: 0.8563 - val_loss: 0.3114 - val_accuracy: 0.8613\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3206 - accuracy: 0.8561 - val_loss: 0.3116 - val_accuracy: 0.8600\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3202 - accuracy: 0.8562 - val_loss: 0.3107 - val_accuracy: 0.8628\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3196 - accuracy: 0.8568 - val_loss: 0.3112 - val_accuracy: 0.8602\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3195 - accuracy: 0.8567 - val_loss: 0.3106 - val_accuracy: 0.8625\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3196 - accuracy: 0.8564 - val_loss: 0.3108 - val_accuracy: 0.8611\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3202 - accuracy: 0.8564 - val_loss: 0.3103 - val_accuracy: 0.8630\n",
      "accuracy: 86.30%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3201 - accuracy: 0.8564 - val_loss: 0.3092 - val_accuracy: 0.8613\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3200 - accuracy: 0.8566 - val_loss: 0.3090 - val_accuracy: 0.8628\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3198 - accuracy: 0.8566 - val_loss: 0.3087 - val_accuracy: 0.8622\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3202 - accuracy: 0.8568 - val_loss: 0.3098 - val_accuracy: 0.8604\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3200 - accuracy: 0.8567 - val_loss: 0.3093 - val_accuracy: 0.8618\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3197 - accuracy: 0.8563 - val_loss: 0.3107 - val_accuracy: 0.8591\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3202 - accuracy: 0.8564 - val_loss: 0.3090 - val_accuracy: 0.8622\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3206 - accuracy: 0.8564 - val_loss: 0.3093 - val_accuracy: 0.8615\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3196 - accuracy: 0.8568 - val_loss: 0.3103 - val_accuracy: 0.8605\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3196 - accuracy: 0.8565 - val_loss: 0.3132 - val_accuracy: 0.8575\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3199 - accuracy: 0.8566 - val_loss: 0.3085 - val_accuracy: 0.8626\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3201 - accuracy: 0.8565 - val_loss: 0.3097 - val_accuracy: 0.8630\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3196 - accuracy: 0.8563 - val_loss: 0.3096 - val_accuracy: 0.8624\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3198 - accuracy: 0.8564 - val_loss: 0.3122 - val_accuracy: 0.8642\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3198 - accuracy: 0.8564 - val_loss: 0.3111 - val_accuracy: 0.8638\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3199 - accuracy: 0.8563 - val_loss: 0.3092 - val_accuracy: 0.8617\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3200 - accuracy: 0.8565 - val_loss: 0.3111 - val_accuracy: 0.8591\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3199 - accuracy: 0.8563 - val_loss: 0.3108 - val_accuracy: 0.8588\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3198 - accuracy: 0.8563 - val_loss: 0.3093 - val_accuracy: 0.8612\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3198 - accuracy: 0.8565 - val_loss: 0.3086 - val_accuracy: 0.8628\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3198 - accuracy: 0.8562 - val_loss: 0.3091 - val_accuracy: 0.8619\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.3205 - accuracy: 0.8563 - val_loss: 0.3099 - val_accuracy: 0.8630\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3203 - accuracy: 0.8564 - val_loss: 0.3136 - val_accuracy: 0.8654\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3200 - accuracy: 0.8566 - val_loss: 0.3090 - val_accuracy: 0.8623\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3197 - accuracy: 0.8566 - val_loss: 0.3102 - val_accuracy: 0.8603\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3199 - accuracy: 0.8565 - val_loss: 0.3182 - val_accuracy: 0.8558\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3196 - accuracy: 0.8566 - val_loss: 0.3094 - val_accuracy: 0.8612\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3199 - accuracy: 0.8565 - val_loss: 0.3089 - val_accuracy: 0.8629\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3194 - accuracy: 0.8565 - val_loss: 0.3109 - val_accuracy: 0.8592\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3199 - accuracy: 0.8568 - val_loss: 0.3103 - val_accuracy: 0.8631\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3196 - accuracy: 0.8571 - val_loss: 0.3093 - val_accuracy: 0.8617\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3202 - accuracy: 0.8563 - val_loss: 0.3146 - val_accuracy: 0.8663\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3196 - accuracy: 0.8566 - val_loss: 0.3090 - val_accuracy: 0.8617\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3193 - accuracy: 0.8565 - val_loss: 0.3102 - val_accuracy: 0.8597\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3195 - accuracy: 0.8570 - val_loss: 0.3111 - val_accuracy: 0.8642\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3192 - accuracy: 0.8568 - val_loss: 0.3097 - val_accuracy: 0.8608\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3196 - accuracy: 0.8569 - val_loss: 0.3095 - val_accuracy: 0.8615\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3197 - accuracy: 0.8563 - val_loss: 0.3085 - val_accuracy: 0.8622\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3197 - accuracy: 0.8565 - val_loss: 0.3085 - val_accuracy: 0.8628\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3193 - accuracy: 0.8567 - val_loss: 0.3097 - val_accuracy: 0.8627\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3197 - accuracy: 0.8568 - val_loss: 0.3083 - val_accuracy: 0.8625\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3192 - accuracy: 0.8569 - val_loss: 0.3110 - val_accuracy: 0.8592\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3199 - accuracy: 0.8568 - val_loss: 0.3092 - val_accuracy: 0.8616\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3201 - accuracy: 0.8563 - val_loss: 0.3085 - val_accuracy: 0.8623\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3192 - accuracy: 0.8568 - val_loss: 0.3097 - val_accuracy: 0.8632\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3195 - accuracy: 0.8567 - val_loss: 0.3095 - val_accuracy: 0.8608\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3192 - accuracy: 0.8565 - val_loss: 0.3145 - val_accuracy: 0.8571\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3196 - accuracy: 0.8560 - val_loss: 0.3089 - val_accuracy: 0.8629\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3196 - accuracy: 0.8566 - val_loss: 0.3093 - val_accuracy: 0.8630\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3198 - accuracy: 0.8566 - val_loss: 0.3095 - val_accuracy: 0.8630\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3196 - accuracy: 0.8563 - val_loss: 0.3102 - val_accuracy: 0.8632\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3195 - accuracy: 0.8567 - val_loss: 0.3125 - val_accuracy: 0.8646\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3197 - accuracy: 0.8566 - val_loss: 0.3085 - val_accuracy: 0.8626\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3199 - accuracy: 0.8566 - val_loss: 0.3086 - val_accuracy: 0.8627\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3193 - accuracy: 0.8565 - val_loss: 0.3082 - val_accuracy: 0.8628\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3195 - accuracy: 0.8567 - val_loss: 0.3090 - val_accuracy: 0.8628\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3194 - accuracy: 0.8564 - val_loss: 0.3086 - val_accuracy: 0.8627\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3195 - accuracy: 0.8564 - val_loss: 0.3088 - val_accuracy: 0.8618\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3196 - accuracy: 0.8566 - val_loss: 0.3093 - val_accuracy: 0.8612\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3197 - accuracy: 0.8562 - val_loss: 0.3093 - val_accuracy: 0.8628\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3195 - accuracy: 0.8566 - val_loss: 0.3094 - val_accuracy: 0.8630\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3191 - accuracy: 0.8568 - val_loss: 0.3099 - val_accuracy: 0.8632\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3197 - accuracy: 0.8566 - val_loss: 0.3110 - val_accuracy: 0.8628\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3194 - accuracy: 0.8563 - val_loss: 0.3090 - val_accuracy: 0.8612\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3187 - accuracy: 0.8571 - val_loss: 0.3091 - val_accuracy: 0.8628\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3195 - accuracy: 0.8565 - val_loss: 0.3088 - val_accuracy: 0.8620\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3188 - accuracy: 0.8568 - val_loss: 0.3086 - val_accuracy: 0.8621\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3187 - accuracy: 0.8568 - val_loss: 0.3093 - val_accuracy: 0.8631\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3190 - accuracy: 0.8568 - val_loss: 0.3126 - val_accuracy: 0.8581\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3194 - accuracy: 0.8568 - val_loss: 0.3086 - val_accuracy: 0.8619\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3194 - accuracy: 0.8563 - val_loss: 0.3108 - val_accuracy: 0.8632\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3192 - accuracy: 0.8567 - val_loss: 0.3102 - val_accuracy: 0.8636\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3190 - accuracy: 0.8566 - val_loss: 0.3086 - val_accuracy: 0.8624\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3195 - accuracy: 0.8566 - val_loss: 0.3113 - val_accuracy: 0.8582\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3196 - accuracy: 0.8565 - val_loss: 0.3085 - val_accuracy: 0.8631\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3190 - accuracy: 0.8570 - val_loss: 0.3086 - val_accuracy: 0.8627\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3194 - accuracy: 0.8568 - val_loss: 0.3084 - val_accuracy: 0.8624\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3192 - accuracy: 0.8569 - val_loss: 0.3086 - val_accuracy: 0.8623\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.3191 - accuracy: 0.8567 - val_loss: 0.3099 - val_accuracy: 0.8611\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3190 - accuracy: 0.8571 - val_loss: 0.3112 - val_accuracy: 0.8643\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3192 - accuracy: 0.8568 - val_loss: 0.3086 - val_accuracy: 0.8624\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3189 - accuracy: 0.8566 - val_loss: 0.3091 - val_accuracy: 0.8629\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3193 - accuracy: 0.8569 - val_loss: 0.3089 - val_accuracy: 0.8626\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3189 - accuracy: 0.8566 - val_loss: 0.3090 - val_accuracy: 0.8631\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3189 - accuracy: 0.8568 - val_loss: 0.3103 - val_accuracy: 0.8595\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3196 - accuracy: 0.8564 - val_loss: 0.3089 - val_accuracy: 0.8629\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3193 - accuracy: 0.8565 - val_loss: 0.3104 - val_accuracy: 0.8641\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3189 - accuracy: 0.8567 - val_loss: 0.3084 - val_accuracy: 0.8623\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3188 - accuracy: 0.8568 - val_loss: 0.3079 - val_accuracy: 0.8624\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3194 - accuracy: 0.8566 - val_loss: 0.3082 - val_accuracy: 0.8630\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3189 - accuracy: 0.8565 - val_loss: 0.3097 - val_accuracy: 0.8617\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3188 - accuracy: 0.8568 - val_loss: 0.3113 - val_accuracy: 0.8587\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3191 - accuracy: 0.8566 - val_loss: 0.3098 - val_accuracy: 0.8629\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3190 - accuracy: 0.8570 - val_loss: 0.3120 - val_accuracy: 0.8647\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3191 - accuracy: 0.8567 - val_loss: 0.3095 - val_accuracy: 0.8633\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3190 - accuracy: 0.8569 - val_loss: 0.3098 - val_accuracy: 0.8631\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3189 - accuracy: 0.8566 - val_loss: 0.3083 - val_accuracy: 0.8624\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3193 - accuracy: 0.8565 - val_loss: 0.3093 - val_accuracy: 0.8617\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3189 - accuracy: 0.8566 - val_loss: 0.3107 - val_accuracy: 0.8638\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3187 - accuracy: 0.8568 - val_loss: 0.3105 - val_accuracy: 0.8628\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3188 - accuracy: 0.8570 - val_loss: 0.3097 - val_accuracy: 0.8622\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3189 - accuracy: 0.8567 - val_loss: 0.3096 - val_accuracy: 0.8604\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3181 - accuracy: 0.8574 - val_loss: 0.3112 - val_accuracy: 0.8645\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3190 - accuracy: 0.8567 - val_loss: 0.3083 - val_accuracy: 0.8630\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3188 - accuracy: 0.8566 - val_loss: 0.3080 - val_accuracy: 0.8627\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3186 - accuracy: 0.8568 - val_loss: 0.3083 - val_accuracy: 0.8629\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3187 - accuracy: 0.8566 - val_loss: 0.3082 - val_accuracy: 0.8619\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3190 - accuracy: 0.8570 - val_loss: 0.3081 - val_accuracy: 0.8627\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3192 - accuracy: 0.8565 - val_loss: 0.3087 - val_accuracy: 0.8608\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3185 - accuracy: 0.8570 - val_loss: 0.3088 - val_accuracy: 0.8631\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3193 - accuracy: 0.8563 - val_loss: 0.3090 - val_accuracy: 0.8611\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3186 - accuracy: 0.8574 - val_loss: 0.3094 - val_accuracy: 0.8631\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3187 - accuracy: 0.8564 - val_loss: 0.3129 - val_accuracy: 0.8650\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3191 - accuracy: 0.8568 - val_loss: 0.3115 - val_accuracy: 0.8641\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3188 - accuracy: 0.8569 - val_loss: 0.3102 - val_accuracy: 0.8627\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3189 - accuracy: 0.8564 - val_loss: 0.3108 - val_accuracy: 0.8591\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3186 - accuracy: 0.8570 - val_loss: 0.3101 - val_accuracy: 0.8600\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3190 - accuracy: 0.8567 - val_loss: 0.3084 - val_accuracy: 0.8615\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3188 - accuracy: 0.8569 - val_loss: 0.3080 - val_accuracy: 0.8620\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3188 - accuracy: 0.8568 - val_loss: 0.3092 - val_accuracy: 0.8608\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3187 - accuracy: 0.8568 - val_loss: 0.3080 - val_accuracy: 0.8623\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3181 - accuracy: 0.8571 - val_loss: 0.3093 - val_accuracy: 0.8630\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3184 - accuracy: 0.8570 - val_loss: 0.3092 - val_accuracy: 0.8630\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3185 - accuracy: 0.8571 - val_loss: 0.3080 - val_accuracy: 0.8629\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3185 - accuracy: 0.8571 - val_loss: 0.3080 - val_accuracy: 0.8622\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3190 - accuracy: 0.8565 - val_loss: 0.3080 - val_accuracy: 0.8626\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3190 - accuracy: 0.8568 - val_loss: 0.3078 - val_accuracy: 0.8623\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3185 - accuracy: 0.8566 - val_loss: 0.3085 - val_accuracy: 0.8618\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3182 - accuracy: 0.8568 - val_loss: 0.3083 - val_accuracy: 0.8628\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3187 - accuracy: 0.8570 - val_loss: 0.3078 - val_accuracy: 0.8625\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3187 - accuracy: 0.8568 - val_loss: 0.3075 - val_accuracy: 0.8630\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3185 - accuracy: 0.8567 - val_loss: 0.3080 - val_accuracy: 0.8628\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3183 - accuracy: 0.8570 - val_loss: 0.3105 - val_accuracy: 0.8590\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3184 - accuracy: 0.8563 - val_loss: 0.3077 - val_accuracy: 0.8629\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3187 - accuracy: 0.8567 - val_loss: 0.3148 - val_accuracy: 0.8652\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3189 - accuracy: 0.8568 - val_loss: 0.3079 - val_accuracy: 0.8627\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3190 - accuracy: 0.8569 - val_loss: 0.3101 - val_accuracy: 0.8629\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3190 - accuracy: 0.8569 - val_loss: 0.3087 - val_accuracy: 0.8610\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3185 - accuracy: 0.8566 - val_loss: 0.3134 - val_accuracy: 0.8577\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3181 - accuracy: 0.8573 - val_loss: 0.3090 - val_accuracy: 0.8632\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3186 - accuracy: 0.8571 - val_loss: 0.3080 - val_accuracy: 0.8622\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3185 - accuracy: 0.8568 - val_loss: 0.3079 - val_accuracy: 0.8627\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3178 - accuracy: 0.8571 - val_loss: 0.3085 - val_accuracy: 0.8621\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3180 - accuracy: 0.8568 - val_loss: 0.3076 - val_accuracy: 0.8622\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3183 - accuracy: 0.8568 - val_loss: 0.3078 - val_accuracy: 0.8630\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3183 - accuracy: 0.8569 - val_loss: 0.3074 - val_accuracy: 0.8625\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3182 - accuracy: 0.8569 - val_loss: 0.3076 - val_accuracy: 0.8628\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3182 - accuracy: 0.8569 - val_loss: 0.3080 - val_accuracy: 0.8630\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3190 - accuracy: 0.8567 - val_loss: 0.3125 - val_accuracy: 0.8650\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3184 - accuracy: 0.8571 - val_loss: 0.3122 - val_accuracy: 0.8581\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3186 - accuracy: 0.8569 - val_loss: 0.3090 - val_accuracy: 0.8632\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3182 - accuracy: 0.8570 - val_loss: 0.3084 - val_accuracy: 0.8628\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3180 - accuracy: 0.8572 - val_loss: 0.3085 - val_accuracy: 0.8631\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3179 - accuracy: 0.8568 - val_loss: 0.3085 - val_accuracy: 0.8625\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3184 - accuracy: 0.8566 - val_loss: 0.3083 - val_accuracy: 0.8629\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3184 - accuracy: 0.8567 - val_loss: 0.3085 - val_accuracy: 0.8630\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3178 - accuracy: 0.8572 - val_loss: 0.3077 - val_accuracy: 0.8626\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3188 - accuracy: 0.8567 - val_loss: 0.3093 - val_accuracy: 0.8628\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3183 - accuracy: 0.8569 - val_loss: 0.3083 - val_accuracy: 0.8618\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3182 - accuracy: 0.8568 - val_loss: 0.3119 - val_accuracy: 0.8645\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3181 - accuracy: 0.8567 - val_loss: 0.3080 - val_accuracy: 0.8625\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3178 - accuracy: 0.8568 - val_loss: 0.3078 - val_accuracy: 0.8624\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3179 - accuracy: 0.8573 - val_loss: 0.3095 - val_accuracy: 0.8594\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3181 - accuracy: 0.8568 - val_loss: 0.3072 - val_accuracy: 0.8623\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3176 - accuracy: 0.8566 - val_loss: 0.3076 - val_accuracy: 0.8630\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3182 - accuracy: 0.8571 - val_loss: 0.3077 - val_accuracy: 0.8629\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3181 - accuracy: 0.8570 - val_loss: 0.3075 - val_accuracy: 0.8626\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3176 - accuracy: 0.8570 - val_loss: 0.3084 - val_accuracy: 0.8631\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3177 - accuracy: 0.8572 - val_loss: 0.3075 - val_accuracy: 0.8618\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3181 - accuracy: 0.8569 - val_loss: 0.3093 - val_accuracy: 0.8632\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3175 - accuracy: 0.8568 - val_loss: 0.3076 - val_accuracy: 0.8627\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3181 - accuracy: 0.8565 - val_loss: 0.3073 - val_accuracy: 0.8628\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3180 - accuracy: 0.8570 - val_loss: 0.3089 - val_accuracy: 0.8628\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3179 - accuracy: 0.8568 - val_loss: 0.3091 - val_accuracy: 0.8636\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3172 - accuracy: 0.8569 - val_loss: 0.3074 - val_accuracy: 0.8629\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3178 - accuracy: 0.8572 - val_loss: 0.3070 - val_accuracy: 0.8624\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3174 - accuracy: 0.8572 - val_loss: 0.3074 - val_accuracy: 0.8628\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3177 - accuracy: 0.8569 - val_loss: 0.3078 - val_accuracy: 0.8614\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3174 - accuracy: 0.8570 - val_loss: 0.3092 - val_accuracy: 0.8634\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3178 - accuracy: 0.8572 - val_loss: 0.3068 - val_accuracy: 0.8629\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3176 - accuracy: 0.8572 - val_loss: 0.3091 - val_accuracy: 0.8636\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3172 - accuracy: 0.8566 - val_loss: 0.3106 - val_accuracy: 0.8588\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3170 - accuracy: 0.8572 - val_loss: 0.3066 - val_accuracy: 0.8624\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3171 - accuracy: 0.8570 - val_loss: 0.3073 - val_accuracy: 0.8628\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3173 - accuracy: 0.8568 - val_loss: 0.3073 - val_accuracy: 0.8614\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3172 - accuracy: 0.8575 - val_loss: 0.3075 - val_accuracy: 0.8628\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3175 - accuracy: 0.8568 - val_loss: 0.3068 - val_accuracy: 0.8629\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3169 - accuracy: 0.8570 - val_loss: 0.3076 - val_accuracy: 0.8629\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3171 - accuracy: 0.8575 - val_loss: 0.3072 - val_accuracy: 0.8628\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3173 - accuracy: 0.8571 - val_loss: 0.3102 - val_accuracy: 0.8631\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3175 - accuracy: 0.8566 - val_loss: 0.3066 - val_accuracy: 0.8627\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3174 - accuracy: 0.8569 - val_loss: 0.3099 - val_accuracy: 0.8638\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3171 - accuracy: 0.8572 - val_loss: 0.3081 - val_accuracy: 0.8602\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3173 - accuracy: 0.8571 - val_loss: 0.3072 - val_accuracy: 0.8628\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3173 - accuracy: 0.8565 - val_loss: 0.3072 - val_accuracy: 0.8612\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3174 - accuracy: 0.8569 - val_loss: 0.3082 - val_accuracy: 0.8634\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3170 - accuracy: 0.8572 - val_loss: 0.3071 - val_accuracy: 0.8621\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3166 - accuracy: 0.8571 - val_loss: 0.3062 - val_accuracy: 0.8629\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3171 - accuracy: 0.8568 - val_loss: 0.3062 - val_accuracy: 0.8625\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3171 - accuracy: 0.8570 - val_loss: 0.3071 - val_accuracy: 0.8628\n",
      "accuracy: 86.28%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3146 - accuracy: 0.8584 - val_loss: 0.3148 - val_accuracy: 0.8562\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3148 - accuracy: 0.8587 - val_loss: 0.3146 - val_accuracy: 0.8561\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3142 - accuracy: 0.8587 - val_loss: 0.3166 - val_accuracy: 0.8569\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3156 - accuracy: 0.8585 - val_loss: 0.3169 - val_accuracy: 0.8580\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3147 - accuracy: 0.8591 - val_loss: 0.3145 - val_accuracy: 0.8568\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3141 - accuracy: 0.8589 - val_loss: 0.3144 - val_accuracy: 0.8564\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3146 - accuracy: 0.8591 - val_loss: 0.3143 - val_accuracy: 0.8565\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3144 - accuracy: 0.8587 - val_loss: 0.3144 - val_accuracy: 0.8565\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3148 - accuracy: 0.8585 - val_loss: 0.3149 - val_accuracy: 0.8557\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3142 - accuracy: 0.8584 - val_loss: 0.3189 - val_accuracy: 0.8598\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3145 - accuracy: 0.8584 - val_loss: 0.3143 - val_accuracy: 0.8564\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3147 - accuracy: 0.8589 - val_loss: 0.3194 - val_accuracy: 0.8519\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3145 - accuracy: 0.8586 - val_loss: 0.3141 - val_accuracy: 0.8569\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3136 - accuracy: 0.8589 - val_loss: 0.3153 - val_accuracy: 0.8567\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3142 - accuracy: 0.8585 - val_loss: 0.3177 - val_accuracy: 0.8527\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3143 - accuracy: 0.8587 - val_loss: 0.3139 - val_accuracy: 0.8564\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3144 - accuracy: 0.8584 - val_loss: 0.3144 - val_accuracy: 0.8563\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3140 - accuracy: 0.8588 - val_loss: 0.3152 - val_accuracy: 0.8546\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3141 - accuracy: 0.8584 - val_loss: 0.3150 - val_accuracy: 0.8557\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3142 - accuracy: 0.8585 - val_loss: 0.3145 - val_accuracy: 0.8563\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3137 - accuracy: 0.8586 - val_loss: 0.3140 - val_accuracy: 0.8563\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3136 - accuracy: 0.8585 - val_loss: 0.3144 - val_accuracy: 0.8547\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3137 - accuracy: 0.8586 - val_loss: 0.3143 - val_accuracy: 0.8549\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3138 - accuracy: 0.8586 - val_loss: 0.3158 - val_accuracy: 0.8538\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3138 - accuracy: 0.8588 - val_loss: 0.3159 - val_accuracy: 0.8542\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3138 - accuracy: 0.8581 - val_loss: 0.3148 - val_accuracy: 0.8550\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3140 - accuracy: 0.8585 - val_loss: 0.3136 - val_accuracy: 0.8564\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3139 - accuracy: 0.8585 - val_loss: 0.3136 - val_accuracy: 0.8560\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3140 - accuracy: 0.8585 - val_loss: 0.3138 - val_accuracy: 0.8562\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3133 - accuracy: 0.8594 - val_loss: 0.3134 - val_accuracy: 0.8559\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3132 - accuracy: 0.8589 - val_loss: 0.3131 - val_accuracy: 0.8562\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3137 - accuracy: 0.8590 - val_loss: 0.3135 - val_accuracy: 0.8565\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3143 - accuracy: 0.8587 - val_loss: 0.3156 - val_accuracy: 0.8581\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3135 - accuracy: 0.8587 - val_loss: 0.3131 - val_accuracy: 0.8565\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3130 - accuracy: 0.8587 - val_loss: 0.3132 - val_accuracy: 0.8563\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3134 - accuracy: 0.8586 - val_loss: 0.3137 - val_accuracy: 0.8557\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3128 - accuracy: 0.8590 - val_loss: 0.3163 - val_accuracy: 0.8547\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3132 - accuracy: 0.8586 - val_loss: 0.3135 - val_accuracy: 0.8558\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3134 - accuracy: 0.8585 - val_loss: 0.3161 - val_accuracy: 0.8560\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3132 - accuracy: 0.8584 - val_loss: 0.3128 - val_accuracy: 0.8569\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3128 - accuracy: 0.8587 - val_loss: 0.3125 - val_accuracy: 0.8563\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3133 - accuracy: 0.8584 - val_loss: 0.3127 - val_accuracy: 0.8568\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3133 - accuracy: 0.8590 - val_loss: 0.3124 - val_accuracy: 0.8566\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3127 - accuracy: 0.8588 - val_loss: 0.3122 - val_accuracy: 0.8565\n",
      "Epoch 45/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3126 - accuracy: 0.8585 - val_loss: 0.3133 - val_accuracy: 0.8572\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3129 - accuracy: 0.8584 - val_loss: 0.3124 - val_accuracy: 0.8565\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3130 - accuracy: 0.8587 - val_loss: 0.3124 - val_accuracy: 0.8562\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3128 - accuracy: 0.8586 - val_loss: 0.3140 - val_accuracy: 0.8559\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3125 - accuracy: 0.8584 - val_loss: 0.3154 - val_accuracy: 0.8541\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3123 - accuracy: 0.8586 - val_loss: 0.3137 - val_accuracy: 0.8541\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3121 - accuracy: 0.8588 - val_loss: 0.3126 - val_accuracy: 0.8573\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3124 - accuracy: 0.8583 - val_loss: 0.3148 - val_accuracy: 0.8540\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3123 - accuracy: 0.8586 - val_loss: 0.3120 - val_accuracy: 0.8560\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3121 - accuracy: 0.8590 - val_loss: 0.3120 - val_accuracy: 0.8567\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3123 - accuracy: 0.8590 - val_loss: 0.3137 - val_accuracy: 0.8578\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3124 - accuracy: 0.8589 - val_loss: 0.3138 - val_accuracy: 0.8543\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3117 - accuracy: 0.8588 - val_loss: 0.3124 - val_accuracy: 0.8563\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3122 - accuracy: 0.8589 - val_loss: 0.3150 - val_accuracy: 0.8530\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3125 - accuracy: 0.8587 - val_loss: 0.3119 - val_accuracy: 0.8563\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3120 - accuracy: 0.8584 - val_loss: 0.3139 - val_accuracy: 0.8546\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3112 - accuracy: 0.8588 - val_loss: 0.3150 - val_accuracy: 0.8527\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3116 - accuracy: 0.8589 - val_loss: 0.3111 - val_accuracy: 0.8564\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3115 - accuracy: 0.8582 - val_loss: 0.3114 - val_accuracy: 0.8562\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3120 - accuracy: 0.8585 - val_loss: 0.3137 - val_accuracy: 0.8541\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3114 - accuracy: 0.8585 - val_loss: 0.3132 - val_accuracy: 0.8564\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3116 - accuracy: 0.8590 - val_loss: 0.3113 - val_accuracy: 0.8563\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3118 - accuracy: 0.8584 - val_loss: 0.3114 - val_accuracy: 0.8559\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3117 - accuracy: 0.8590 - val_loss: 0.3115 - val_accuracy: 0.8569\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3117 - accuracy: 0.8589 - val_loss: 0.3115 - val_accuracy: 0.8563\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3113 - accuracy: 0.8589 - val_loss: 0.3122 - val_accuracy: 0.8561\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3113 - accuracy: 0.8585 - val_loss: 0.3108 - val_accuracy: 0.8569\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3111 - accuracy: 0.8589 - val_loss: 0.3112 - val_accuracy: 0.8569\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3112 - accuracy: 0.8585 - val_loss: 0.3105 - val_accuracy: 0.8563\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3112 - accuracy: 0.8587 - val_loss: 0.3109 - val_accuracy: 0.8561\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3116 - accuracy: 0.8587 - val_loss: 0.3110 - val_accuracy: 0.8569\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3109 - accuracy: 0.8588 - val_loss: 0.3115 - val_accuracy: 0.8570\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3112 - accuracy: 0.8588 - val_loss: 0.3102 - val_accuracy: 0.8561\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3113 - accuracy: 0.8586 - val_loss: 0.3103 - val_accuracy: 0.8563\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3113 - accuracy: 0.8590 - val_loss: 0.3103 - val_accuracy: 0.8563\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3107 - accuracy: 0.8586 - val_loss: 0.3109 - val_accuracy: 0.8567\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3105 - accuracy: 0.8587 - val_loss: 0.3119 - val_accuracy: 0.8579\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3107 - accuracy: 0.8586 - val_loss: 0.3100 - val_accuracy: 0.8558\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3110 - accuracy: 0.8588 - val_loss: 0.3105 - val_accuracy: 0.8569\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3106 - accuracy: 0.8593 - val_loss: 0.3121 - val_accuracy: 0.8579\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3103 - accuracy: 0.8587 - val_loss: 0.3107 - val_accuracy: 0.8553\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3109 - accuracy: 0.8584 - val_loss: 0.3111 - val_accuracy: 0.8552\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3102 - accuracy: 0.8585 - val_loss: 0.3109 - val_accuracy: 0.8547\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3104 - accuracy: 0.8587 - val_loss: 0.3103 - val_accuracy: 0.8563\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3100 - accuracy: 0.8585 - val_loss: 0.3096 - val_accuracy: 0.8560\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3099 - accuracy: 0.8586 - val_loss: 0.3094 - val_accuracy: 0.8568\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3106 - accuracy: 0.8589 - val_loss: 0.3113 - val_accuracy: 0.8579\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3100 - accuracy: 0.8588 - val_loss: 0.3101 - val_accuracy: 0.8552\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3102 - accuracy: 0.8585 - val_loss: 0.3090 - val_accuracy: 0.8566\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3098 - accuracy: 0.8588 - val_loss: 0.3092 - val_accuracy: 0.8560\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3097 - accuracy: 0.8590 - val_loss: 0.3121 - val_accuracy: 0.8543\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3097 - accuracy: 0.8585 - val_loss: 0.3120 - val_accuracy: 0.8533\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3098 - accuracy: 0.8589 - val_loss: 0.3094 - val_accuracy: 0.8559\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3093 - accuracy: 0.8584 - val_loss: 0.3134 - val_accuracy: 0.8529\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3096 - accuracy: 0.8587 - val_loss: 0.3113 - val_accuracy: 0.8546\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3096 - accuracy: 0.8588 - val_loss: 0.3106 - val_accuracy: 0.8537\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3087 - accuracy: 0.8588 - val_loss: 0.3082 - val_accuracy: 0.8561\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3102 - accuracy: 0.8586 - val_loss: 0.3097 - val_accuracy: 0.8579\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3092 - accuracy: 0.8586 - val_loss: 0.3082 - val_accuracy: 0.8563\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3088 - accuracy: 0.8586 - val_loss: 0.3089 - val_accuracy: 0.8562\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3089 - accuracy: 0.8591 - val_loss: 0.3100 - val_accuracy: 0.8580\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3089 - accuracy: 0.8587 - val_loss: 0.3093 - val_accuracy: 0.8560\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3093 - accuracy: 0.8583 - val_loss: 0.3084 - val_accuracy: 0.8560\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3087 - accuracy: 0.8591 - val_loss: 0.3099 - val_accuracy: 0.8575\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3090 - accuracy: 0.8586 - val_loss: 0.3077 - val_accuracy: 0.8569\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3080 - accuracy: 0.8591 - val_loss: 0.3083 - val_accuracy: 0.8569\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3085 - accuracy: 0.8587 - val_loss: 0.3096 - val_accuracy: 0.8544\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3089 - accuracy: 0.8588 - val_loss: 0.3076 - val_accuracy: 0.8569\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3080 - accuracy: 0.8588 - val_loss: 0.3072 - val_accuracy: 0.8563\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3083 - accuracy: 0.8588 - val_loss: 0.3125 - val_accuracy: 0.8527\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3082 - accuracy: 0.8587 - val_loss: 0.3071 - val_accuracy: 0.8569\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3084 - accuracy: 0.8587 - val_loss: 0.3109 - val_accuracy: 0.8587\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3084 - accuracy: 0.8584 - val_loss: 0.3083 - val_accuracy: 0.8557\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3077 - accuracy: 0.8586 - val_loss: 0.3082 - val_accuracy: 0.8565\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3077 - accuracy: 0.8583 - val_loss: 0.3069 - val_accuracy: 0.8569\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3080 - accuracy: 0.8585 - val_loss: 0.3068 - val_accuracy: 0.8561\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3072 - accuracy: 0.8582 - val_loss: 0.3095 - val_accuracy: 0.8536\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3075 - accuracy: 0.8589 - val_loss: 0.3062 - val_accuracy: 0.8563\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3071 - accuracy: 0.8588 - val_loss: 0.3062 - val_accuracy: 0.8566\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3087 - accuracy: 0.8588 - val_loss: 0.3064 - val_accuracy: 0.8564\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3077 - accuracy: 0.8585 - val_loss: 0.3070 - val_accuracy: 0.8558\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3070 - accuracy: 0.8585 - val_loss: 0.3073 - val_accuracy: 0.8565\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3065 - accuracy: 0.8587 - val_loss: 0.3065 - val_accuracy: 0.8559\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3077 - accuracy: 0.8585 - val_loss: 0.3092 - val_accuracy: 0.8566\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3077 - accuracy: 0.8581 - val_loss: 0.3056 - val_accuracy: 0.8565\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3068 - accuracy: 0.8588 - val_loss: 0.3055 - val_accuracy: 0.8566\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3072 - accuracy: 0.8588 - val_loss: 0.3054 - val_accuracy: 0.8565\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3070 - accuracy: 0.8584 - val_loss: 0.3053 - val_accuracy: 0.8562\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3062 - accuracy: 0.8589 - val_loss: 0.3057 - val_accuracy: 0.8565\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3079 - accuracy: 0.8584 - val_loss: 0.3058 - val_accuracy: 0.8569\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3064 - accuracy: 0.8586 - val_loss: 0.3053 - val_accuracy: 0.8569\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3059 - accuracy: 0.8585 - val_loss: 0.3053 - val_accuracy: 0.8559\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3062 - accuracy: 0.8590 - val_loss: 0.3073 - val_accuracy: 0.8546\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3059 - accuracy: 0.8587 - val_loss: 0.3051 - val_accuracy: 0.8574\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3066 - accuracy: 0.8584 - val_loss: 0.3104 - val_accuracy: 0.8524\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.3062 - accuracy: 0.8584 - val_loss: 0.3093 - val_accuracy: 0.8564\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3063 - accuracy: 0.8584 - val_loss: 0.3046 - val_accuracy: 0.8563\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3057 - accuracy: 0.8580 - val_loss: 0.3055 - val_accuracy: 0.8574\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3063 - accuracy: 0.8586 - val_loss: 0.3057 - val_accuracy: 0.8569\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3054 - accuracy: 0.8587 - val_loss: 0.3048 - val_accuracy: 0.8564\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3053 - accuracy: 0.8587 - val_loss: 0.3054 - val_accuracy: 0.8570\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3056 - accuracy: 0.8586 - val_loss: 0.3047 - val_accuracy: 0.8564\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3058 - accuracy: 0.8585 - val_loss: 0.3058 - val_accuracy: 0.8581\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3056 - accuracy: 0.8582 - val_loss: 0.3049 - val_accuracy: 0.8557\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3057 - accuracy: 0.8583 - val_loss: 0.3037 - val_accuracy: 0.8562\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3054 - accuracy: 0.8582 - val_loss: 0.3044 - val_accuracy: 0.8558\n",
      "Epoch 151/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3049 - accuracy: 0.8581 - val_loss: 0.3038 - val_accuracy: 0.8560\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3054 - accuracy: 0.8580 - val_loss: 0.3042 - val_accuracy: 0.8557\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3049 - accuracy: 0.8586 - val_loss: 0.3030 - val_accuracy: 0.8564\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3057 - accuracy: 0.8582 - val_loss: 0.3037 - val_accuracy: 0.8569\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3047 - accuracy: 0.8581 - val_loss: 0.3026 - val_accuracy: 0.8564\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3045 - accuracy: 0.8587 - val_loss: 0.3033 - val_accuracy: 0.8574\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3042 - accuracy: 0.8585 - val_loss: 0.3026 - val_accuracy: 0.8564\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3048 - accuracy: 0.8585 - val_loss: 0.3057 - val_accuracy: 0.8552\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3048 - accuracy: 0.8581 - val_loss: 0.3027 - val_accuracy: 0.8565\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3036 - accuracy: 0.8584 - val_loss: 0.3046 - val_accuracy: 0.8544\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3042 - accuracy: 0.8584 - val_loss: 0.3024 - val_accuracy: 0.8569\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3048 - accuracy: 0.8577 - val_loss: 0.3039 - val_accuracy: 0.8543\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3043 - accuracy: 0.8586 - val_loss: 0.3024 - val_accuracy: 0.8569\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3039 - accuracy: 0.8582 - val_loss: 0.3018 - val_accuracy: 0.8565\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3038 - accuracy: 0.8583 - val_loss: 0.3064 - val_accuracy: 0.8598\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3035 - accuracy: 0.8584 - val_loss: 0.3016 - val_accuracy: 0.8564\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3042 - accuracy: 0.8580 - val_loss: 0.3057 - val_accuracy: 0.8594\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3040 - accuracy: 0.8582 - val_loss: 0.3065 - val_accuracy: 0.8546\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3036 - accuracy: 0.8584 - val_loss: 0.3046 - val_accuracy: 0.8577\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3039 - accuracy: 0.8585 - val_loss: 0.3014 - val_accuracy: 0.8563\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3036 - accuracy: 0.8586 - val_loss: 0.3063 - val_accuracy: 0.8531\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3035 - accuracy: 0.8583 - val_loss: 0.3047 - val_accuracy: 0.8538\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3026 - accuracy: 0.8588 - val_loss: 0.3007 - val_accuracy: 0.8566\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3030 - accuracy: 0.8582 - val_loss: 0.3019 - val_accuracy: 0.8561\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3039 - accuracy: 0.8583 - val_loss: 0.3014 - val_accuracy: 0.8562\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3038 - accuracy: 0.8582 - val_loss: 0.3061 - val_accuracy: 0.8528\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3028 - accuracy: 0.8582 - val_loss: 0.3024 - val_accuracy: 0.8560\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3029 - accuracy: 0.8582 - val_loss: 0.3031 - val_accuracy: 0.8574\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3029 - accuracy: 0.8583 - val_loss: 0.3021 - val_accuracy: 0.8571\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3024 - accuracy: 0.8581 - val_loss: 0.3011 - val_accuracy: 0.8558\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3027 - accuracy: 0.8581 - val_loss: 0.3005 - val_accuracy: 0.8562\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3026 - accuracy: 0.8582 - val_loss: 0.3014 - val_accuracy: 0.8575\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3028 - accuracy: 0.8583 - val_loss: 0.3022 - val_accuracy: 0.8548\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3027 - accuracy: 0.8579 - val_loss: 0.3004 - val_accuracy: 0.8562\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3027 - accuracy: 0.8583 - val_loss: 0.3000 - val_accuracy: 0.8570\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3028 - accuracy: 0.8581 - val_loss: 0.3012 - val_accuracy: 0.8566\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3020 - accuracy: 0.8586 - val_loss: 0.3014 - val_accuracy: 0.8550\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3030 - accuracy: 0.8581 - val_loss: 0.3018 - val_accuracy: 0.8578\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3022 - accuracy: 0.8585 - val_loss: 0.3014 - val_accuracy: 0.8579\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3024 - accuracy: 0.8583 - val_loss: 0.3005 - val_accuracy: 0.8557\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3019 - accuracy: 0.8585 - val_loss: 0.3006 - val_accuracy: 0.8557\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.3025 - accuracy: 0.8580 - val_loss: 0.2998 - val_accuracy: 0.8562\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3018 - accuracy: 0.8584 - val_loss: 0.3021 - val_accuracy: 0.8549\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3008 - accuracy: 0.8591 - val_loss: 0.3002 - val_accuracy: 0.8571\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3018 - accuracy: 0.8586 - val_loss: 0.2991 - val_accuracy: 0.8566\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3021 - accuracy: 0.8584 - val_loss: 0.3006 - val_accuracy: 0.8554\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3015 - accuracy: 0.8582 - val_loss: 0.3033 - val_accuracy: 0.8545\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3021 - accuracy: 0.8581 - val_loss: 0.2990 - val_accuracy: 0.8570\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3018 - accuracy: 0.8584 - val_loss: 0.2995 - val_accuracy: 0.8568\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3011 - accuracy: 0.8586 - val_loss: 0.3008 - val_accuracy: 0.8550\n",
      "accuracy: 85.50%\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3017 - accuracy: 0.8581 - val_loss: 0.2991 - val_accuracy: 0.8567\n",
      "Epoch 2/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3018 - accuracy: 0.8583 - val_loss: 0.2991 - val_accuracy: 0.8571\n",
      "Epoch 3/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3014 - accuracy: 0.8579 - val_loss: 0.2983 - val_accuracy: 0.8571\n",
      "Epoch 4/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3016 - accuracy: 0.8582 - val_loss: 0.2986 - val_accuracy: 0.8575\n",
      "Epoch 5/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3011 - accuracy: 0.8588 - val_loss: 0.3022 - val_accuracy: 0.8610\n",
      "Epoch 6/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3019 - accuracy: 0.8583 - val_loss: 0.3043 - val_accuracy: 0.8528\n",
      "Epoch 7/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3007 - accuracy: 0.8588 - val_loss: 0.3011 - val_accuracy: 0.8563\n",
      "Epoch 8/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3015 - accuracy: 0.8581 - val_loss: 0.3021 - val_accuracy: 0.8594\n",
      "Epoch 9/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3011 - accuracy: 0.8579 - val_loss: 0.3009 - val_accuracy: 0.8563\n",
      "Epoch 10/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3011 - accuracy: 0.8576 - val_loss: 0.2979 - val_accuracy: 0.8572\n",
      "Epoch 11/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3020 - accuracy: 0.8580 - val_loss: 0.2981 - val_accuracy: 0.8571\n",
      "Epoch 12/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3010 - accuracy: 0.8585 - val_loss: 0.3046 - val_accuracy: 0.8527\n",
      "Epoch 13/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3012 - accuracy: 0.8580 - val_loss: 0.2987 - val_accuracy: 0.8571\n",
      "Epoch 14/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3007 - accuracy: 0.8580 - val_loss: 0.2974 - val_accuracy: 0.8571\n",
      "Epoch 15/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3010 - accuracy: 0.8582 - val_loss: 0.2993 - val_accuracy: 0.8575\n",
      "Epoch 16/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3008 - accuracy: 0.8583 - val_loss: 0.2977 - val_accuracy: 0.8573\n",
      "Epoch 17/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3006 - accuracy: 0.8585 - val_loss: 0.3009 - val_accuracy: 0.8557\n",
      "Epoch 18/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3008 - accuracy: 0.8580 - val_loss: 0.2966 - val_accuracy: 0.8572\n",
      "Epoch 19/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3001 - accuracy: 0.8582 - val_loss: 0.2993 - val_accuracy: 0.8567\n",
      "Epoch 20/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3006 - accuracy: 0.8582 - val_loss: 0.3015 - val_accuracy: 0.8591\n",
      "Epoch 21/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3011 - accuracy: 0.8578 - val_loss: 0.2996 - val_accuracy: 0.8581\n",
      "Epoch 22/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3012 - accuracy: 0.8584 - val_loss: 0.2967 - val_accuracy: 0.8572\n",
      "Epoch 23/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3008 - accuracy: 0.8581 - val_loss: 0.2981 - val_accuracy: 0.8572\n",
      "Epoch 24/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3003 - accuracy: 0.8578 - val_loss: 0.2986 - val_accuracy: 0.8569\n",
      "Epoch 25/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2998 - accuracy: 0.8581 - val_loss: 0.2962 - val_accuracy: 0.8571\n",
      "Epoch 26/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3001 - accuracy: 0.8580 - val_loss: 0.2990 - val_accuracy: 0.8573\n",
      "Epoch 27/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2997 - accuracy: 0.8581 - val_loss: 0.2979 - val_accuracy: 0.8571\n",
      "Epoch 28/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3001 - accuracy: 0.8579 - val_loss: 0.3035 - val_accuracy: 0.8549\n",
      "Epoch 29/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3002 - accuracy: 0.8580 - val_loss: 0.2972 - val_accuracy: 0.8577\n",
      "Epoch 30/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2993 - accuracy: 0.8582 - val_loss: 0.2971 - val_accuracy: 0.8573\n",
      "Epoch 31/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3004 - accuracy: 0.8576 - val_loss: 0.3022 - val_accuracy: 0.8542\n",
      "Epoch 32/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2995 - accuracy: 0.8583 - val_loss: 0.2990 - val_accuracy: 0.8557\n",
      "Epoch 33/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2997 - accuracy: 0.8583 - val_loss: 0.2982 - val_accuracy: 0.8561\n",
      "Epoch 34/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2996 - accuracy: 0.8582 - val_loss: 0.2970 - val_accuracy: 0.8567\n",
      "Epoch 35/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3000 - accuracy: 0.8581 - val_loss: 0.2958 - val_accuracy: 0.8572\n",
      "Epoch 36/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3002 - accuracy: 0.8579 - val_loss: 0.2987 - val_accuracy: 0.8573\n",
      "Epoch 37/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3000 - accuracy: 0.8583 - val_loss: 0.2974 - val_accuracy: 0.8570\n",
      "Epoch 38/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3012 - accuracy: 0.8576 - val_loss: 0.2961 - val_accuracy: 0.8573\n",
      "Epoch 39/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.3000 - accuracy: 0.8575 - val_loss: 0.2955 - val_accuracy: 0.8571\n",
      "Epoch 40/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3001 - accuracy: 0.8580 - val_loss: 0.2959 - val_accuracy: 0.8572\n",
      "Epoch 41/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2989 - accuracy: 0.8584 - val_loss: 0.2960 - val_accuracy: 0.8573\n",
      "Epoch 42/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3001 - accuracy: 0.8581 - val_loss: 0.2955 - val_accuracy: 0.8573\n",
      "Epoch 43/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2994 - accuracy: 0.8582 - val_loss: 0.2979 - val_accuracy: 0.8573\n",
      "Epoch 44/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2992 - accuracy: 0.8579 - val_loss: 0.2963 - val_accuracy: 0.8570\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2994 - accuracy: 0.8581 - val_loss: 0.2967 - val_accuracy: 0.8570\n",
      "Epoch 46/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2998 - accuracy: 0.8581 - val_loss: 0.3005 - val_accuracy: 0.8576\n",
      "Epoch 47/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2987 - accuracy: 0.8581 - val_loss: 0.2978 - val_accuracy: 0.8570\n",
      "Epoch 48/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2991 - accuracy: 0.8579 - val_loss: 0.2962 - val_accuracy: 0.8571\n",
      "Epoch 49/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2991 - accuracy: 0.8582 - val_loss: 0.2958 - val_accuracy: 0.8572\n",
      "Epoch 50/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2991 - accuracy: 0.8584 - val_loss: 0.2982 - val_accuracy: 0.8573\n",
      "Epoch 51/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2992 - accuracy: 0.8585 - val_loss: 0.2959 - val_accuracy: 0.8571\n",
      "Epoch 52/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2989 - accuracy: 0.8582 - val_loss: 0.2962 - val_accuracy: 0.8575\n",
      "Epoch 53/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2996 - accuracy: 0.8578 - val_loss: 0.2997 - val_accuracy: 0.8543\n",
      "Epoch 54/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2991 - accuracy: 0.8575 - val_loss: 0.2971 - val_accuracy: 0.8562\n",
      "Epoch 55/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2990 - accuracy: 0.8581 - val_loss: 0.2945 - val_accuracy: 0.8571\n",
      "Epoch 56/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2993 - accuracy: 0.8577 - val_loss: 0.2961 - val_accuracy: 0.8570\n",
      "Epoch 57/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2987 - accuracy: 0.8577 - val_loss: 0.2976 - val_accuracy: 0.8572\n",
      "Epoch 58/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2996 - accuracy: 0.8576 - val_loss: 0.2954 - val_accuracy: 0.8573\n",
      "Epoch 59/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2991 - accuracy: 0.8584 - val_loss: 0.2989 - val_accuracy: 0.8559\n",
      "Epoch 60/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2993 - accuracy: 0.8580 - val_loss: 0.2966 - val_accuracy: 0.8574\n",
      "Epoch 61/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2975 - accuracy: 0.8583 - val_loss: 0.2949 - val_accuracy: 0.8572\n",
      "Epoch 62/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2987 - accuracy: 0.8583 - val_loss: 0.2962 - val_accuracy: 0.8573\n",
      "Epoch 63/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2990 - accuracy: 0.8583 - val_loss: 0.2954 - val_accuracy: 0.8569\n",
      "Epoch 64/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2993 - accuracy: 0.8582 - val_loss: 0.2958 - val_accuracy: 0.8573\n",
      "Epoch 65/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2998 - accuracy: 0.8578 - val_loss: 0.2981 - val_accuracy: 0.8573\n",
      "Epoch 66/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2991 - accuracy: 0.8582 - val_loss: 0.2948 - val_accuracy: 0.8571\n",
      "Epoch 67/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2983 - accuracy: 0.8581 - val_loss: 0.2950 - val_accuracy: 0.8574\n",
      "Epoch 68/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2984 - accuracy: 0.8581 - val_loss: 0.2966 - val_accuracy: 0.8571\n",
      "Epoch 69/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2983 - accuracy: 0.8582 - val_loss: 0.2947 - val_accuracy: 0.8573\n",
      "Epoch 70/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2993 - accuracy: 0.8582 - val_loss: 0.2946 - val_accuracy: 0.8570\n",
      "Epoch 71/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2986 - accuracy: 0.8577 - val_loss: 0.2941 - val_accuracy: 0.8572\n",
      "Epoch 72/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2982 - accuracy: 0.8579 - val_loss: 0.2965 - val_accuracy: 0.8572\n",
      "Epoch 73/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2981 - accuracy: 0.8583 - val_loss: 0.2946 - val_accuracy: 0.8571\n",
      "Epoch 74/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2991 - accuracy: 0.8578 - val_loss: 0.2947 - val_accuracy: 0.8571\n",
      "Epoch 75/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2992 - accuracy: 0.8580 - val_loss: 0.2957 - val_accuracy: 0.8573\n",
      "Epoch 76/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2983 - accuracy: 0.8583 - val_loss: 0.2951 - val_accuracy: 0.8577\n",
      "Epoch 77/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2981 - accuracy: 0.8580 - val_loss: 0.2948 - val_accuracy: 0.8565\n",
      "Epoch 78/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2988 - accuracy: 0.8576 - val_loss: 0.2997 - val_accuracy: 0.8552\n",
      "Epoch 79/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2990 - accuracy: 0.8577 - val_loss: 0.2942 - val_accuracy: 0.8572\n",
      "Epoch 80/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2981 - accuracy: 0.8581 - val_loss: 0.2944 - val_accuracy: 0.8572\n",
      "Epoch 81/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2984 - accuracy: 0.8580 - val_loss: 0.2947 - val_accuracy: 0.8573\n",
      "Epoch 82/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2985 - accuracy: 0.8581 - val_loss: 0.2945 - val_accuracy: 0.8573\n",
      "Epoch 83/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2976 - accuracy: 0.8580 - val_loss: 0.2968 - val_accuracy: 0.8572\n",
      "Epoch 84/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2983 - accuracy: 0.8586 - val_loss: 0.2960 - val_accuracy: 0.8568\n",
      "Epoch 85/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2983 - accuracy: 0.8580 - val_loss: 0.2944 - val_accuracy: 0.8573\n",
      "Epoch 86/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2977 - accuracy: 0.8581 - val_loss: 0.2970 - val_accuracy: 0.8589\n",
      "Epoch 87/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.2986 - accuracy: 0.8583 - val_loss: 0.3054 - val_accuracy: 0.8508\n",
      "Epoch 88/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2989 - accuracy: 0.8582 - val_loss: 0.2966 - val_accuracy: 0.8565\n",
      "Epoch 89/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2984 - accuracy: 0.8585 - val_loss: 0.2955 - val_accuracy: 0.8573\n",
      "Epoch 90/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2980 - accuracy: 0.8579 - val_loss: 0.2941 - val_accuracy: 0.8575\n",
      "Epoch 91/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2975 - accuracy: 0.8581 - val_loss: 0.2971 - val_accuracy: 0.8560\n",
      "Epoch 92/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2982 - accuracy: 0.8581 - val_loss: 0.2934 - val_accuracy: 0.8573\n",
      "Epoch 93/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2984 - accuracy: 0.8580 - val_loss: 0.2954 - val_accuracy: 0.8561\n",
      "Epoch 94/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2983 - accuracy: 0.8581 - val_loss: 0.2945 - val_accuracy: 0.8576\n",
      "Epoch 95/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2982 - accuracy: 0.8580 - val_loss: 0.2957 - val_accuracy: 0.8571\n",
      "Epoch 96/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2976 - accuracy: 0.8582 - val_loss: 0.2938 - val_accuracy: 0.8574\n",
      "Epoch 97/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2975 - accuracy: 0.8585 - val_loss: 0.2935 - val_accuracy: 0.8570\n",
      "Epoch 98/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2980 - accuracy: 0.8580 - val_loss: 0.2938 - val_accuracy: 0.8577\n",
      "Epoch 99/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2982 - accuracy: 0.8578 - val_loss: 0.2943 - val_accuracy: 0.8569\n",
      "Epoch 100/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2978 - accuracy: 0.8576 - val_loss: 0.2934 - val_accuracy: 0.8573\n",
      "Epoch 101/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2980 - accuracy: 0.8581 - val_loss: 0.2943 - val_accuracy: 0.8571\n",
      "Epoch 102/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2977 - accuracy: 0.8580 - val_loss: 0.2943 - val_accuracy: 0.8571\n",
      "Epoch 103/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2985 - accuracy: 0.8578 - val_loss: 0.2942 - val_accuracy: 0.8578\n",
      "Epoch 104/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2978 - accuracy: 0.8584 - val_loss: 0.2942 - val_accuracy: 0.8574\n",
      "Epoch 105/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2976 - accuracy: 0.8584 - val_loss: 0.2943 - val_accuracy: 0.8577\n",
      "Epoch 106/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2975 - accuracy: 0.8579 - val_loss: 0.2953 - val_accuracy: 0.8578\n",
      "Epoch 107/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2977 - accuracy: 0.8582 - val_loss: 0.2962 - val_accuracy: 0.8556\n",
      "Epoch 108/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2981 - accuracy: 0.8586 - val_loss: 0.2940 - val_accuracy: 0.8571\n",
      "Epoch 109/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2979 - accuracy: 0.8579 - val_loss: 0.2971 - val_accuracy: 0.8562\n",
      "Epoch 110/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2978 - accuracy: 0.8581 - val_loss: 0.2943 - val_accuracy: 0.8573\n",
      "Epoch 111/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2979 - accuracy: 0.8584 - val_loss: 0.3039 - val_accuracy: 0.8521\n",
      "Epoch 112/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2975 - accuracy: 0.8580 - val_loss: 0.2935 - val_accuracy: 0.8576\n",
      "Epoch 113/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2973 - accuracy: 0.8579 - val_loss: 0.2936 - val_accuracy: 0.8574\n",
      "Epoch 114/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2971 - accuracy: 0.8585 - val_loss: 0.2935 - val_accuracy: 0.8570\n",
      "Epoch 115/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2978 - accuracy: 0.8582 - val_loss: 0.2934 - val_accuracy: 0.8571\n",
      "Epoch 116/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2975 - accuracy: 0.8585 - val_loss: 0.2941 - val_accuracy: 0.8573\n",
      "Epoch 117/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2975 - accuracy: 0.8583 - val_loss: 0.2936 - val_accuracy: 0.8569\n",
      "Epoch 118/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2974 - accuracy: 0.8578 - val_loss: 0.2938 - val_accuracy: 0.8572\n",
      "Epoch 119/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2974 - accuracy: 0.8587 - val_loss: 0.2939 - val_accuracy: 0.8571\n",
      "Epoch 120/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2974 - accuracy: 0.8582 - val_loss: 0.2934 - val_accuracy: 0.8570\n",
      "Epoch 121/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2974 - accuracy: 0.8583 - val_loss: 0.2955 - val_accuracy: 0.8572\n",
      "Epoch 122/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2976 - accuracy: 0.8580 - val_loss: 0.2950 - val_accuracy: 0.8573\n",
      "Epoch 123/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2980 - accuracy: 0.8582 - val_loss: 0.2972 - val_accuracy: 0.8564\n",
      "Epoch 124/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2971 - accuracy: 0.8585 - val_loss: 0.2939 - val_accuracy: 0.8578\n",
      "Epoch 125/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2972 - accuracy: 0.8583 - val_loss: 0.2936 - val_accuracy: 0.8574\n",
      "Epoch 126/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2971 - accuracy: 0.8583 - val_loss: 0.2963 - val_accuracy: 0.8559\n",
      "Epoch 127/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2979 - accuracy: 0.8576 - val_loss: 0.2937 - val_accuracy: 0.8577\n",
      "Epoch 128/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2964 - accuracy: 0.8583 - val_loss: 0.2935 - val_accuracy: 0.8572\n",
      "Epoch 129/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2970 - accuracy: 0.8576 - val_loss: 0.2931 - val_accuracy: 0.8571\n",
      "Epoch 130/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2973 - accuracy: 0.8580 - val_loss: 0.2951 - val_accuracy: 0.8561\n",
      "Epoch 131/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2980 - accuracy: 0.8581 - val_loss: 0.2931 - val_accuracy: 0.8571\n",
      "Epoch 132/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2974 - accuracy: 0.8582 - val_loss: 0.2931 - val_accuracy: 0.8574\n",
      "Epoch 133/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2971 - accuracy: 0.8583 - val_loss: 0.2943 - val_accuracy: 0.8572\n",
      "Epoch 134/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2971 - accuracy: 0.8580 - val_loss: 0.2936 - val_accuracy: 0.8571\n",
      "Epoch 135/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2977 - accuracy: 0.8583 - val_loss: 0.2928 - val_accuracy: 0.8572\n",
      "Epoch 136/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2971 - accuracy: 0.8584 - val_loss: 0.2933 - val_accuracy: 0.8578\n",
      "Epoch 137/200\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.2965 - accuracy: 0.8584 - val_loss: 0.2940 - val_accuracy: 0.8573\n",
      "Epoch 138/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2974 - accuracy: 0.8584 - val_loss: 0.2936 - val_accuracy: 0.8571\n",
      "Epoch 139/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.2969 - accuracy: 0.8583 - val_loss: 0.2932 - val_accuracy: 0.8576\n",
      "Epoch 140/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2970 - accuracy: 0.8581 - val_loss: 0.2946 - val_accuracy: 0.8570\n",
      "Epoch 141/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2972 - accuracy: 0.8582 - val_loss: 0.2926 - val_accuracy: 0.8575\n",
      "Epoch 142/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2976 - accuracy: 0.8582 - val_loss: 0.2945 - val_accuracy: 0.8579\n",
      "Epoch 143/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2974 - accuracy: 0.8581 - val_loss: 0.2952 - val_accuracy: 0.8558\n",
      "Epoch 144/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2976 - accuracy: 0.8580 - val_loss: 0.2938 - val_accuracy: 0.8569\n",
      "Epoch 145/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2968 - accuracy: 0.8581 - val_loss: 0.2947 - val_accuracy: 0.8571\n",
      "Epoch 146/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2975 - accuracy: 0.8582 - val_loss: 0.2930 - val_accuracy: 0.8572\n",
      "Epoch 147/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2965 - accuracy: 0.8584 - val_loss: 0.2941 - val_accuracy: 0.8574\n",
      "Epoch 148/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2970 - accuracy: 0.8582 - val_loss: 0.2983 - val_accuracy: 0.8574\n",
      "Epoch 149/200\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.2968 - accuracy: 0.8579 - val_loss: 0.2932 - val_accuracy: 0.8573\n",
      "Epoch 150/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2975 - accuracy: 0.8579 - val_loss: 0.2981 - val_accuracy: 0.8543\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2968 - accuracy: 0.8578 - val_loss: 0.2952 - val_accuracy: 0.8574\n",
      "Epoch 152/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2968 - accuracy: 0.8578 - val_loss: 0.2937 - val_accuracy: 0.8573\n",
      "Epoch 153/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2974 - accuracy: 0.8580 - val_loss: 0.2927 - val_accuracy: 0.8575\n",
      "Epoch 154/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2970 - accuracy: 0.8584 - val_loss: 0.2926 - val_accuracy: 0.8575\n",
      "Epoch 155/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2967 - accuracy: 0.8581 - val_loss: 0.2929 - val_accuracy: 0.8572\n",
      "Epoch 156/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2968 - accuracy: 0.8580 - val_loss: 0.2941 - val_accuracy: 0.8567\n",
      "Epoch 157/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2969 - accuracy: 0.8582 - val_loss: 0.2927 - val_accuracy: 0.8573\n",
      "Epoch 158/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2962 - accuracy: 0.8584 - val_loss: 0.2952 - val_accuracy: 0.8569\n",
      "Epoch 159/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2963 - accuracy: 0.8580 - val_loss: 0.2955 - val_accuracy: 0.8572\n",
      "Epoch 160/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2959 - accuracy: 0.8585 - val_loss: 0.2982 - val_accuracy: 0.8632\n",
      "Epoch 161/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2969 - accuracy: 0.8579 - val_loss: 0.2927 - val_accuracy: 0.8573\n",
      "Epoch 162/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2972 - accuracy: 0.8585 - val_loss: 0.2927 - val_accuracy: 0.8574\n",
      "Epoch 163/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2966 - accuracy: 0.8582 - val_loss: 0.2959 - val_accuracy: 0.8572\n",
      "Epoch 164/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2966 - accuracy: 0.8582 - val_loss: 0.2927 - val_accuracy: 0.8577\n",
      "Epoch 165/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2968 - accuracy: 0.8582 - val_loss: 0.2928 - val_accuracy: 0.8575\n",
      "Epoch 166/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2965 - accuracy: 0.8581 - val_loss: 0.2979 - val_accuracy: 0.8569\n",
      "Epoch 167/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2959 - accuracy: 0.8579 - val_loss: 0.2948 - val_accuracy: 0.8573\n",
      "Epoch 168/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2969 - accuracy: 0.8579 - val_loss: 0.2951 - val_accuracy: 0.8573\n",
      "Epoch 169/200\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.2959 - accuracy: 0.8583 - val_loss: 0.2947 - val_accuracy: 0.8566\n",
      "Epoch 170/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2967 - accuracy: 0.8581 - val_loss: 0.2924 - val_accuracy: 0.8574\n",
      "Epoch 171/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2972 - accuracy: 0.8578 - val_loss: 0.2940 - val_accuracy: 0.8563\n",
      "Epoch 172/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2965 - accuracy: 0.8580 - val_loss: 0.2934 - val_accuracy: 0.8569\n",
      "Epoch 173/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2966 - accuracy: 0.8582 - val_loss: 0.2924 - val_accuracy: 0.8575\n",
      "Epoch 174/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2962 - accuracy: 0.8579 - val_loss: 0.2938 - val_accuracy: 0.8572\n",
      "Epoch 175/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2967 - accuracy: 0.8584 - val_loss: 0.2938 - val_accuracy: 0.8573\n",
      "Epoch 176/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2970 - accuracy: 0.8581 - val_loss: 0.2921 - val_accuracy: 0.8574\n",
      "Epoch 177/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2961 - accuracy: 0.8582 - val_loss: 0.2934 - val_accuracy: 0.8571\n",
      "Epoch 178/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2965 - accuracy: 0.8580 - val_loss: 0.2989 - val_accuracy: 0.8532\n",
      "Epoch 179/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2968 - accuracy: 0.8583 - val_loss: 0.2926 - val_accuracy: 0.8575\n",
      "Epoch 180/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2966 - accuracy: 0.8582 - val_loss: 0.2924 - val_accuracy: 0.8573\n",
      "Epoch 181/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2964 - accuracy: 0.8585 - val_loss: 0.2939 - val_accuracy: 0.8573\n",
      "Epoch 182/200\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.2963 - accuracy: 0.8581 - val_loss: 0.2923 - val_accuracy: 0.8575\n",
      "Epoch 183/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2965 - accuracy: 0.8583 - val_loss: 0.2928 - val_accuracy: 0.8573\n",
      "Epoch 184/200\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.2962 - accuracy: 0.8582 - val_loss: 0.2938 - val_accuracy: 0.8570\n",
      "Epoch 185/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2966 - accuracy: 0.8583 - val_loss: 0.2919 - val_accuracy: 0.8575\n",
      "Epoch 186/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2968 - accuracy: 0.8583 - val_loss: 0.2959 - val_accuracy: 0.8586\n",
      "Epoch 187/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2967 - accuracy: 0.8586 - val_loss: 0.2939 - val_accuracy: 0.8571\n",
      "Epoch 188/200\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.2966 - accuracy: 0.8579 - val_loss: 0.2928 - val_accuracy: 0.8577\n",
      "Epoch 189/200\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.2958 - accuracy: 0.8583 - val_loss: 0.2922 - val_accuracy: 0.8576\n",
      "Epoch 190/200\n",
      "140272/140272 [==============================] - 10s 68us/step - loss: 0.2960 - accuracy: 0.8580 - val_loss: 0.2986 - val_accuracy: 0.8544\n",
      "Epoch 191/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2960 - accuracy: 0.8585 - val_loss: 0.2932 - val_accuracy: 0.8572\n",
      "Epoch 192/200\n",
      "140272/140272 [==============================] - 9s 65us/step - loss: 0.2961 - accuracy: 0.8583 - val_loss: 0.2931 - val_accuracy: 0.8580\n",
      "Epoch 193/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2959 - accuracy: 0.8587 - val_loss: 0.2932 - val_accuracy: 0.8574\n",
      "Epoch 194/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2968 - accuracy: 0.8587 - val_loss: 0.2941 - val_accuracy: 0.8569\n",
      "Epoch 195/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2961 - accuracy: 0.8585 - val_loss: 0.2934 - val_accuracy: 0.8577\n",
      "Epoch 196/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2965 - accuracy: 0.8585 - val_loss: 0.2936 - val_accuracy: 0.8571\n",
      "Epoch 197/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2959 - accuracy: 0.8585 - val_loss: 0.2928 - val_accuracy: 0.8574\n",
      "Epoch 198/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2961 - accuracy: 0.8585 - val_loss: 0.2934 - val_accuracy: 0.8570\n",
      "Epoch 199/200\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.2970 - accuracy: 0.8583 - val_loss: 0.2943 - val_accuracy: 0.8563\n",
      "Epoch 200/200\n",
      "140272/140272 [==============================] - 9s 67us/step - loss: 0.2965 - accuracy: 0.8580 - val_loss: 0.2932 - val_accuracy: 0.8573\n",
      "accuracy: 85.73%\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    XTrain, XVal, yTrain, yVal = train_test_split(X, Y, test_size=0.2, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    model.fit(XTrain, yTrain, nb_epoch=200, validation_data=(XVal, yVal))\n",
    "    scores = model.evaluate(XVal, yVal, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    a.append(scores[1] * 100)\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85.81938743591309, 86.30129098892212, 86.28418445587158, 85.50286293029785, 85.7252836227417]\n"
     ]
    }
   ],
   "source": [
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175341, 1, 41)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
