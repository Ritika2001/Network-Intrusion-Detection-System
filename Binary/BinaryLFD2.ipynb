{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-1]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr = X.values\n",
    "arr = x.values\n",
    "\n",
    "import librosa\n",
    "Arr1 = librosa.feature.delta(Arr)\n",
    "arr1 = librosa.feature.delta(arr)\n",
    "\n",
    "Delta1 = pd.DataFrame(Arr1)\n",
    "delta1 = pd.DataFrame(arr1)\n",
    "\n",
    "Arr2 = librosa.feature.delta(Arr1)\n",
    "arr2 = librosa.feature.delta(arr1)\n",
    "\n",
    "Delta2 = pd.DataFrame(Arr2)\n",
    "delta2 = pd.DataFrame(arr2)\n",
    "\n",
    "scaler = Normalizer().fit(Delta1)\n",
    "Delta1 = scaler.transform(Delta1)\n",
    "scaler = Normalizer().fit(delta1)\n",
    "delta1 = scaler.transform(delta1)\n",
    "\n",
    "Delta1 = np.reshape(Delta1, (Delta1.shape[0],Delta1.shape[1],1))\n",
    "delta1 = np.reshape(delta1, (delta1.shape[0],delta1.shape[1],1))\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],X.shape[1],1))\n",
    "x = np.reshape(x, (x.shape[0],x.shape[1],1))\n",
    "\n",
    "scaler = Normalizer().fit(Delta2)\n",
    "Delta2 = scaler.transform(Delta2)\n",
    "scaler = Normalizer().fit(delta2)\n",
    "delta2 = scaler.transform(delta2)\n",
    "\n",
    "Delta2 = np.reshape(Delta2, (Delta2.shape[0],Delta2.shape[1],1))\n",
    "delta2 = np.reshape(delta2, (delta2.shape[0],delta2.shape[1],1))\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "lstm_output_size = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 41, 64)       256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 41, 64)       256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 41, 64)       256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 20, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 20, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 20, 64)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 64)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 64)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 20, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 192)      0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 140)          147280      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 140)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            141         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 148,189\n",
      "Trainable params: 148,189\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Convolution1D, Dense, Dropout, Flatten, MaxPooling1D, concatenate, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "lstm_output_size=70\n",
    "Xshape = Input(shape=(41, 1))\n",
    "Delta1shape = Input(shape=(41, 1))\n",
    "Delta2shape = Input(shape=(41, 1))\n",
    "\n",
    "x1 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Xshape)\n",
    "x1 = MaxPooling1D(pool_length=(2))(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "   \n",
    "x2 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Delta1shape)\n",
    "x2 = MaxPooling1D(pool_length=(2))(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "\n",
    "x3 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Delta2shape)\n",
    "x3 = MaxPooling1D(pool_length=(2))(x3)\n",
    "x3 = Dropout(0.5)(x3)\n",
    "\n",
    "output = concatenate([x1, x2, x3])\n",
    "\n",
    "x4 = Bidirectional(LSTM(lstm_output_size))(output)\n",
    "x4 = Dropout(0.1)(x4)\n",
    "x4 = Dense(1, activation=\"sigmoid\")(x4)\n",
    "\n",
    "model = Model([Xshape, Delta1shape, Delta2shape],x4)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/200\n",
      "175341/175341 [==============================] - 423s 2ms/step - loss: 0.4159 - accuracy: 0.7674 - val_loss: 0.5503 - val_accuracy: 0.6870\n",
      "Epoch 2/200\n",
      "175341/175341 [==============================] - 414s 2ms/step - loss: 0.3763 - accuracy: 0.8125 - val_loss: 0.5570 - val_accuracy: 0.6867\n",
      "Epoch 3/200\n",
      "175341/175341 [==============================] - 412s 2ms/step - loss: 0.3665 - accuracy: 0.8192 - val_loss: 0.5342 - val_accuracy: 0.7219\n",
      "Epoch 4/200\n",
      "175341/175341 [==============================] - 413s 2ms/step - loss: 0.3622 - accuracy: 0.8223 - val_loss: 0.5716 - val_accuracy: 0.6945\n",
      "Epoch 5/200\n",
      "175341/175341 [==============================] - 418s 2ms/step - loss: 0.3598 - accuracy: 0.8247 - val_loss: 0.5468 - val_accuracy: 0.7059\n",
      "Epoch 6/200\n",
      "175341/175341 [==============================] - 418s 2ms/step - loss: 0.3576 - accuracy: 0.8263 - val_loss: 0.5407 - val_accuracy: 0.7141\n",
      "Epoch 7/200\n",
      "175341/175341 [==============================] - 415s 2ms/step - loss: 0.3563 - accuracy: 0.8258 - val_loss: 0.5439 - val_accuracy: 0.6992\n",
      "Epoch 8/200\n",
      "175341/175341 [==============================] - 418s 2ms/step - loss: 0.3547 - accuracy: 0.8278 - val_loss: 0.5475 - val_accuracy: 0.7206\n",
      "Epoch 9/200\n",
      "175341/175341 [==============================] - 417s 2ms/step - loss: 0.3529 - accuracy: 0.8282 - val_loss: 0.5253 - val_accuracy: 0.7252\n",
      "Epoch 10/200\n",
      "175341/175341 [==============================] - 416s 2ms/step - loss: 0.3517 - accuracy: 0.8308 - val_loss: 0.5282 - val_accuracy: 0.7309\n",
      "Epoch 11/200\n",
      "175341/175341 [==============================] - 416s 2ms/step - loss: 0.3302 - accuracy: 0.8508 - val_loss: 0.5074 - val_accuracy: 0.7352\n",
      "Epoch 12/200\n",
      "175341/175341 [==============================] - 417s 2ms/step - loss: 0.3188 - accuracy: 0.8596 - val_loss: 0.5443 - val_accuracy: 0.7302\n",
      "Epoch 13/200\n",
      "175341/175341 [==============================] - 419s 2ms/step - loss: 0.3147 - accuracy: 0.8625 - val_loss: 0.5621 - val_accuracy: 0.7249\n",
      "Epoch 14/200\n",
      "175341/175341 [==============================] - 417s 2ms/step - loss: 0.3120 - accuracy: 0.8640 - val_loss: 0.5393 - val_accuracy: 0.7273\n",
      "Epoch 15/200\n",
      "175341/175341 [==============================] - 420s 2ms/step - loss: 0.3078 - accuracy: 0.8658 - val_loss: 0.5361 - val_accuracy: 0.7247\n",
      "Epoch 16/200\n",
      "175341/175341 [==============================] - 420s 2ms/step - loss: 0.3030 - accuracy: 0.8674 - val_loss: 0.5067 - val_accuracy: 0.7300\n",
      "Epoch 17/200\n",
      "175341/175341 [==============================] - 419s 2ms/step - loss: 0.3004 - accuracy: 0.8677 - val_loss: 0.5357 - val_accuracy: 0.7297\n",
      "Epoch 18/200\n",
      "175341/175341 [==============================] - 420s 2ms/step - loss: 0.2984 - accuracy: 0.8679 - val_loss: 0.5319 - val_accuracy: 0.7288\n",
      "Epoch 19/200\n",
      "175341/175341 [==============================] - 421s 2ms/step - loss: 0.2963 - accuracy: 0.8689 - val_loss: 0.5075 - val_accuracy: 0.7297\n",
      "Epoch 20/200\n",
      "175341/175341 [==============================] - 424s 2ms/step - loss: 0.2949 - accuracy: 0.8693 - val_loss: 0.4981 - val_accuracy: 0.7350\n",
      "Epoch 21/200\n",
      "175341/175341 [==============================] - 423s 2ms/step - loss: 0.2940 - accuracy: 0.8694 - val_loss: 0.5059 - val_accuracy: 0.7281\n",
      "Epoch 22/200\n",
      "175341/175341 [==============================] - 423s 2ms/step - loss: 0.2928 - accuracy: 0.8696 - val_loss: 0.5075 - val_accuracy: 0.7349\n",
      "Epoch 23/200\n",
      "175341/175341 [==============================] - 416s 2ms/step - loss: 0.2916 - accuracy: 0.8702 - val_loss: 0.5018 - val_accuracy: 0.7303\n",
      "Epoch 24/200\n",
      "175341/175341 [==============================] - 416s 2ms/step - loss: 0.2905 - accuracy: 0.8710 - val_loss: 0.4951 - val_accuracy: 0.7290\n",
      "Epoch 25/200\n",
      "175341/175341 [==============================] - 412s 2ms/step - loss: 0.2904 - accuracy: 0.8710 - val_loss: 0.5039 - val_accuracy: 0.7346\n",
      "Epoch 26/200\n",
      "175341/175341 [==============================] - 412s 2ms/step - loss: 0.2893 - accuracy: 0.8715 - val_loss: 0.5035 - val_accuracy: 0.7318\n",
      "Epoch 27/200\n",
      "175341/175341 [==============================] - 416s 2ms/step - loss: 0.2881 - accuracy: 0.8714 - val_loss: 0.5046 - val_accuracy: 0.7303\n",
      "Epoch 28/200\n",
      "175341/175341 [==============================] - 417s 2ms/step - loss: 0.2874 - accuracy: 0.8716 - val_loss: 0.5174 - val_accuracy: 0.7283\n",
      "Epoch 29/200\n",
      "175341/175341 [==============================] - 411s 2ms/step - loss: 0.2872 - accuracy: 0.8715 - val_loss: 0.5027 - val_accuracy: 0.7339\n",
      "Epoch 30/200\n",
      "175341/175341 [==============================] - 419s 2ms/step - loss: 0.2871 - accuracy: 0.8718 - val_loss: 0.5326 - val_accuracy: 0.7258\n",
      "Epoch 31/200\n",
      "175341/175341 [==============================] - 418s 2ms/step - loss: 0.2865 - accuracy: 0.8725 - val_loss: 0.5074 - val_accuracy: 0.7304\n",
      "Epoch 32/200\n",
      "175341/175341 [==============================] - 413s 2ms/step - loss: 0.2864 - accuracy: 0.8718 - val_loss: 0.5287 - val_accuracy: 0.7294\n",
      "Epoch 33/200\n",
      "175341/175341 [==============================] - 418s 2ms/step - loss: 0.2852 - accuracy: 0.8721 - val_loss: 0.5101 - val_accuracy: 0.7337\n",
      "Epoch 34/200\n",
      "175341/175341 [==============================] - 418s 2ms/step - loss: 0.2853 - accuracy: 0.8725 - val_loss: 0.5080 - val_accuracy: 0.7339\n",
      "Epoch 35/200\n",
      "175341/175341 [==============================] - 419s 2ms/step - loss: 0.2843 - accuracy: 0.8728 - val_loss: 0.5208 - val_accuracy: 0.7341\n",
      "Epoch 36/200\n",
      "175341/175341 [==============================] - 407s 2ms/step - loss: 0.2848 - accuracy: 0.8730 - val_loss: 0.5221 - val_accuracy: 0.7289\n",
      "Epoch 37/200\n",
      "175341/175341 [==============================] - 411s 2ms/step - loss: 0.2850 - accuracy: 0.8723 - val_loss: 0.5132 - val_accuracy: 0.7330\n",
      "Epoch 38/200\n",
      "175341/175341 [==============================] - 412s 2ms/step - loss: 0.2835 - accuracy: 0.8731 - val_loss: 0.5084 - val_accuracy: 0.7347\n",
      "Epoch 39/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2830 - accuracy: 0.8735 - val_loss: 0.5079 - val_accuracy: 0.7342\n",
      "Epoch 40/200\n",
      "175341/175341 [==============================] - 392s 2ms/step - loss: 0.2829 - accuracy: 0.8736 - val_loss: 0.5165 - val_accuracy: 0.7346\n",
      "Epoch 41/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2825 - accuracy: 0.8737 - val_loss: 0.5146 - val_accuracy: 0.7340\n",
      "Epoch 42/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2827 - accuracy: 0.8733 - val_loss: 0.5167 - val_accuracy: 0.7349\n",
      "Epoch 43/200\n",
      "175341/175341 [==============================] - 392s 2ms/step - loss: 0.2814 - accuracy: 0.8738 - val_loss: 0.5205 - val_accuracy: 0.7351\n",
      "Epoch 44/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2809 - accuracy: 0.8742 - val_loss: 0.5333 - val_accuracy: 0.7345\n",
      "Epoch 45/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2810 - accuracy: 0.8744 - val_loss: 0.5163 - val_accuracy: 0.7354\n",
      "Epoch 46/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2809 - accuracy: 0.8740 - val_loss: 0.5173 - val_accuracy: 0.7355\n",
      "Epoch 47/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2812 - accuracy: 0.8740 - val_loss: 0.5306 - val_accuracy: 0.7321\n",
      "Epoch 48/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2808 - accuracy: 0.8746 - val_loss: 0.5155 - val_accuracy: 0.7350\n",
      "Epoch 49/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2801 - accuracy: 0.8742 - val_loss: 0.5262 - val_accuracy: 0.7360\n",
      "Epoch 50/200\n",
      "175341/175341 [==============================] - 393s 2ms/step - loss: 0.2803 - accuracy: 0.8741 - val_loss: 0.5084 - val_accuracy: 0.7358\n",
      "Epoch 51/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2798 - accuracy: 0.8745 - val_loss: 0.5343 - val_accuracy: 0.7343\n",
      "Epoch 52/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2801 - accuracy: 0.8744 - val_loss: 0.5415 - val_accuracy: 0.7285\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2788 - accuracy: 0.8753 - val_loss: 0.5257 - val_accuracy: 0.7351\n",
      "Epoch 54/200\n",
      "175341/175341 [==============================] - 392s 2ms/step - loss: 0.2790 - accuracy: 0.8746 - val_loss: 0.5538 - val_accuracy: 0.7321\n",
      "Epoch 55/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2792 - accuracy: 0.8747 - val_loss: 0.5438 - val_accuracy: 0.7339\n",
      "Epoch 56/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2781 - accuracy: 0.8748 - val_loss: 0.5373 - val_accuracy: 0.7359\n",
      "Epoch 57/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2782 - accuracy: 0.8746 - val_loss: 0.5378 - val_accuracy: 0.7307\n",
      "Epoch 58/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2786 - accuracy: 0.8747 - val_loss: 0.5225 - val_accuracy: 0.7310\n",
      "Epoch 59/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2777 - accuracy: 0.8746 - val_loss: 0.5310 - val_accuracy: 0.7354\n",
      "Epoch 60/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2775 - accuracy: 0.8748 - val_loss: 0.5348 - val_accuracy: 0.7353\n",
      "Epoch 61/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2769 - accuracy: 0.8755 - val_loss: 0.5263 - val_accuracy: 0.7356\n",
      "Epoch 62/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2774 - accuracy: 0.8749 - val_loss: 0.5388 - val_accuracy: 0.7365\n",
      "Epoch 63/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2767 - accuracy: 0.8753 - val_loss: 0.5292 - val_accuracy: 0.7368\n",
      "Epoch 64/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2769 - accuracy: 0.8751 - val_loss: 0.5430 - val_accuracy: 0.7355\n",
      "Epoch 65/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2756 - accuracy: 0.8755 - val_loss: 0.5337 - val_accuracy: 0.7358\n",
      "Epoch 66/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2768 - accuracy: 0.8752 - val_loss: 0.5330 - val_accuracy: 0.7334\n",
      "Epoch 67/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2758 - accuracy: 0.8753 - val_loss: 0.5426 - val_accuracy: 0.7342\n",
      "Epoch 68/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2757 - accuracy: 0.8748 - val_loss: 0.5505 - val_accuracy: 0.7357\n",
      "Epoch 69/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2751 - accuracy: 0.8755 - val_loss: 0.5366 - val_accuracy: 0.7350\n",
      "Epoch 70/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2749 - accuracy: 0.8756 - val_loss: 0.5497 - val_accuracy: 0.7353\n",
      "Epoch 71/200\n",
      "175341/175341 [==============================] - 400s 2ms/step - loss: 0.2747 - accuracy: 0.8760 - val_loss: 0.5357 - val_accuracy: 0.7353\n",
      "Epoch 72/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2750 - accuracy: 0.8757 - val_loss: 0.5562 - val_accuracy: 0.7351\n",
      "Epoch 73/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2742 - accuracy: 0.8757 - val_loss: 0.5437 - val_accuracy: 0.7359\n",
      "Epoch 74/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2731 - accuracy: 0.8757 - val_loss: 0.5512 - val_accuracy: 0.7356\n",
      "Epoch 75/200\n",
      "175341/175341 [==============================] - 400s 2ms/step - loss: 0.2722 - accuracy: 0.8761 - val_loss: 0.5808 - val_accuracy: 0.7347\n",
      "Epoch 76/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2723 - accuracy: 0.8756 - val_loss: 0.5553 - val_accuracy: 0.7354\n",
      "Epoch 77/200\n",
      "175341/175341 [==============================] - 402s 2ms/step - loss: 0.2712 - accuracy: 0.8764 - val_loss: 0.5346 - val_accuracy: 0.7366\n",
      "Epoch 78/200\n",
      "175341/175341 [==============================] - 403s 2ms/step - loss: 0.2726 - accuracy: 0.8756 - val_loss: 0.5692 - val_accuracy: 0.7352\n",
      "Epoch 79/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2708 - accuracy: 0.8757 - val_loss: 0.5501 - val_accuracy: 0.7357\n",
      "Epoch 80/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2698 - accuracy: 0.8767 - val_loss: 0.5757 - val_accuracy: 0.7354\n",
      "Epoch 81/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2680 - accuracy: 0.8761 - val_loss: 0.5720 - val_accuracy: 0.7361\n",
      "Epoch 82/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2674 - accuracy: 0.8766 - val_loss: 0.5917 - val_accuracy: 0.7353\n",
      "Epoch 83/200\n",
      "175341/175341 [==============================] - 391s 2ms/step - loss: 0.2671 - accuracy: 0.8769 - val_loss: 0.5754 - val_accuracy: 0.7325\n",
      "Epoch 84/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2671 - accuracy: 0.8763 - val_loss: 0.5811 - val_accuracy: 0.7369\n",
      "Epoch 85/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2670 - accuracy: 0.8762 - val_loss: 0.5872 - val_accuracy: 0.7369\n",
      "Epoch 86/200\n",
      "175341/175341 [==============================] - 393s 2ms/step - loss: 0.2673 - accuracy: 0.8769 - val_loss: 0.5952 - val_accuracy: 0.7364\n",
      "Epoch 87/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2668 - accuracy: 0.8763 - val_loss: 0.6037 - val_accuracy: 0.7343\n",
      "Epoch 88/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2661 - accuracy: 0.8769 - val_loss: 0.5981 - val_accuracy: 0.7371\n",
      "Epoch 89/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2651 - accuracy: 0.8770 - val_loss: 0.6025 - val_accuracy: 0.7352\n",
      "Epoch 90/200\n",
      "175341/175341 [==============================] - 393s 2ms/step - loss: 0.2662 - accuracy: 0.8766 - val_loss: 0.6055 - val_accuracy: 0.7359\n",
      "Epoch 91/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2649 - accuracy: 0.8770 - val_loss: 0.6169 - val_accuracy: 0.7350\n",
      "Epoch 92/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2650 - accuracy: 0.8773 - val_loss: 0.6017 - val_accuracy: 0.7358\n",
      "Epoch 93/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2645 - accuracy: 0.8773 - val_loss: 0.6211 - val_accuracy: 0.7352\n",
      "Epoch 94/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2664 - accuracy: 0.8769 - val_loss: 0.6342 - val_accuracy: 0.7352\n",
      "Epoch 95/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2642 - accuracy: 0.8776 - val_loss: 0.6167 - val_accuracy: 0.7363\n",
      "Epoch 96/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2637 - accuracy: 0.8775 - val_loss: 0.5915 - val_accuracy: 0.7370\n",
      "Epoch 97/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2646 - accuracy: 0.8774 - val_loss: 0.5943 - val_accuracy: 0.7313\n",
      "Epoch 98/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2649 - accuracy: 0.8776 - val_loss: 0.6121 - val_accuracy: 0.7348\n",
      "Epoch 99/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2647 - accuracy: 0.8767 - val_loss: 0.6249 - val_accuracy: 0.7368\n",
      "Epoch 100/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2643 - accuracy: 0.8773 - val_loss: 0.5974 - val_accuracy: 0.7382\n",
      "Epoch 101/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2637 - accuracy: 0.8774 - val_loss: 0.6166 - val_accuracy: 0.7359\n",
      "Epoch 102/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2643 - accuracy: 0.8771 - val_loss: 0.5916 - val_accuracy: 0.7373\n",
      "Epoch 103/200\n",
      "175341/175341 [==============================] - 400s 2ms/step - loss: 0.2635 - accuracy: 0.8779 - val_loss: 0.5990 - val_accuracy: 0.7367\n",
      "Epoch 104/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2627 - accuracy: 0.8774 - val_loss: 0.6052 - val_accuracy: 0.7364\n",
      "Epoch 105/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2637 - accuracy: 0.8773 - val_loss: 0.5987 - val_accuracy: 0.7350\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2642 - accuracy: 0.8774 - val_loss: 0.5939 - val_accuracy: 0.7353\n",
      "Epoch 107/200\n",
      "175341/175341 [==============================] - 400s 2ms/step - loss: 0.2627 - accuracy: 0.8781 - val_loss: 0.6126 - val_accuracy: 0.7352\n",
      "Epoch 108/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2638 - accuracy: 0.8776 - val_loss: 0.6116 - val_accuracy: 0.7363\n",
      "Epoch 109/200\n",
      "175341/175341 [==============================] - 404s 2ms/step - loss: 0.2641 - accuracy: 0.8772 - val_loss: 0.5871 - val_accuracy: 0.7353\n",
      "Epoch 110/200\n",
      "175341/175341 [==============================] - 400s 2ms/step - loss: 0.2628 - accuracy: 0.8777 - val_loss: 0.6023 - val_accuracy: 0.7358\n",
      "Epoch 111/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2653 - accuracy: 0.8767 - val_loss: 0.6075 - val_accuracy: 0.7367\n",
      "Epoch 112/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2630 - accuracy: 0.8773 - val_loss: 0.6129 - val_accuracy: 0.7404\n",
      "Epoch 113/200\n",
      "175341/175341 [==============================] - 402s 2ms/step - loss: 0.2630 - accuracy: 0.8778 - val_loss: 0.5946 - val_accuracy: 0.7345\n",
      "Epoch 114/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2615 - accuracy: 0.8784 - val_loss: 0.6258 - val_accuracy: 0.7338\n",
      "Epoch 115/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2629 - accuracy: 0.8779 - val_loss: 0.6169 - val_accuracy: 0.7367\n",
      "Epoch 116/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2621 - accuracy: 0.8773 - val_loss: 0.5995 - val_accuracy: 0.7371\n",
      "Epoch 117/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2626 - accuracy: 0.8779 - val_loss: 0.5919 - val_accuracy: 0.7345\n",
      "Epoch 118/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2628 - accuracy: 0.8779 - val_loss: 0.5900 - val_accuracy: 0.7354\n",
      "Epoch 119/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2620 - accuracy: 0.8778 - val_loss: 0.5902 - val_accuracy: 0.7360\n",
      "Epoch 120/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2617 - accuracy: 0.8779 - val_loss: 0.6184 - val_accuracy: 0.7367\n",
      "Epoch 121/200\n",
      "175341/175341 [==============================] - 404s 2ms/step - loss: 0.2617 - accuracy: 0.8779 - val_loss: 0.6030 - val_accuracy: 0.7378\n",
      "Epoch 122/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2619 - accuracy: 0.8781 - val_loss: 0.6146 - val_accuracy: 0.7362\n",
      "Epoch 123/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2628 - accuracy: 0.8778 - val_loss: 0.6316 - val_accuracy: 0.7371\n",
      "Epoch 124/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2616 - accuracy: 0.8786 - val_loss: 0.6124 - val_accuracy: 0.7361\n",
      "Epoch 125/200\n",
      "175341/175341 [==============================] - 395s 2ms/step - loss: 0.2622 - accuracy: 0.8776 - val_loss: 0.6077 - val_accuracy: 0.7370\n",
      "Epoch 126/200\n",
      "175341/175341 [==============================] - 392s 2ms/step - loss: 0.2610 - accuracy: 0.8784 - val_loss: 0.5966 - val_accuracy: 0.7354\n",
      "Epoch 127/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2617 - accuracy: 0.8783 - val_loss: 0.6157 - val_accuracy: 0.7364\n",
      "Epoch 128/200\n",
      "175341/175341 [==============================] - 400s 2ms/step - loss: 0.2606 - accuracy: 0.8786 - val_loss: 0.6057 - val_accuracy: 0.7386\n",
      "Epoch 129/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2610 - accuracy: 0.8789 - val_loss: 0.6086 - val_accuracy: 0.7351\n",
      "Epoch 130/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2619 - accuracy: 0.8786 - val_loss: 0.6564 - val_accuracy: 0.7363\n",
      "Epoch 131/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2598 - accuracy: 0.8794 - val_loss: 0.6061 - val_accuracy: 0.7364\n",
      "Epoch 132/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2616 - accuracy: 0.8780 - val_loss: 0.6022 - val_accuracy: 0.7351\n",
      "Epoch 133/200\n",
      "175341/175341 [==============================] - 393s 2ms/step - loss: 0.2611 - accuracy: 0.8786 - val_loss: 0.6129 - val_accuracy: 0.7353\n",
      "Epoch 134/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2594 - accuracy: 0.8789 - val_loss: 0.6325 - val_accuracy: 0.7358\n",
      "Epoch 135/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2599 - accuracy: 0.8787 - val_loss: 0.6209 - val_accuracy: 0.7364\n",
      "Epoch 136/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2593 - accuracy: 0.8789 - val_loss: 0.6475 - val_accuracy: 0.7368\n",
      "Epoch 137/200\n",
      "175341/175341 [==============================] - 394s 2ms/step - loss: 0.2596 - accuracy: 0.8789 - val_loss: 0.6289 - val_accuracy: 0.7362\n",
      "Epoch 138/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2593 - accuracy: 0.8787 - val_loss: 0.6372 - val_accuracy: 0.7356\n",
      "Epoch 139/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2592 - accuracy: 0.8787 - val_loss: 0.6354 - val_accuracy: 0.7374\n",
      "Epoch 140/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2585 - accuracy: 0.8792 - val_loss: 0.6121 - val_accuracy: 0.7384\n",
      "Epoch 141/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2604 - accuracy: 0.8789 - val_loss: 0.6153 - val_accuracy: 0.7357\n",
      "Epoch 142/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2611 - accuracy: 0.8782 - val_loss: 0.6023 - val_accuracy: 0.7344\n",
      "Epoch 143/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2596 - accuracy: 0.8795 - val_loss: 0.6262 - val_accuracy: 0.7362\n",
      "Epoch 144/200\n",
      "175341/175341 [==============================] - 396s 2ms/step - loss: 0.2592 - accuracy: 0.8789 - val_loss: 0.5949 - val_accuracy: 0.7334\n",
      "Epoch 145/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2584 - accuracy: 0.8793 - val_loss: 0.6165 - val_accuracy: 0.7383\n",
      "Epoch 146/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2596 - accuracy: 0.8795 - val_loss: 0.6224 - val_accuracy: 0.7371\n",
      "Epoch 147/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2573 - accuracy: 0.8793 - val_loss: 0.6070 - val_accuracy: 0.7366\n",
      "Epoch 148/200\n",
      "175341/175341 [==============================] - 398s 2ms/step - loss: 0.2609 - accuracy: 0.8785 - val_loss: 0.6300 - val_accuracy: 0.7362\n",
      "Epoch 149/200\n",
      "175341/175341 [==============================] - 399s 2ms/step - loss: 0.2586 - accuracy: 0.8796 - val_loss: 0.6297 - val_accuracy: 0.7376\n",
      "Epoch 150/200\n",
      "175341/175341 [==============================] - 402s 2ms/step - loss: 0.2583 - accuracy: 0.8803 - val_loss: 0.6239 - val_accuracy: 0.7397\n",
      "Epoch 151/200\n",
      "175341/175341 [==============================] - 397s 2ms/step - loss: 0.2600 - accuracy: 0.8789 - val_loss: 0.6139 - val_accuracy: 0.7346\n",
      "Epoch 152/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2595 - accuracy: 0.8791 - val_loss: 0.6247 - val_accuracy: 0.7384\n",
      "Epoch 153/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2573 - accuracy: 0.8799 - val_loss: 0.6231 - val_accuracy: 0.7372\n",
      "Epoch 154/200\n",
      "175341/175341 [==============================] - 401s 2ms/step - loss: 0.2584 - accuracy: 0.8794 - val_loss: 0.6161 - val_accuracy: 0.7369\n",
      "Epoch 155/200\n",
      "175341/175341 [==============================] - 236s 1ms/step - loss: 0.2595 - accuracy: 0.8798 - val_loss: 0.6007 - val_accuracy: 0.7404\n",
      "Epoch 156/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2577 - accuracy: 0.8800 - val_loss: 0.6419 - val_accuracy: 0.7379\n",
      "Epoch 157/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2589 - accuracy: 0.8795 - val_loss: 0.6229 - val_accuracy: 0.7402\n",
      "Epoch 158/200\n",
      "175341/175341 [==============================] - 207s 1ms/step - loss: 0.2597 - accuracy: 0.8791 - val_loss: 0.6439 - val_accuracy: 0.7337\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2574 - accuracy: 0.8802 - val_loss: 0.6096 - val_accuracy: 0.7353\n",
      "Epoch 160/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2602 - accuracy: 0.8785 - val_loss: 0.6027 - val_accuracy: 0.7347\n",
      "Epoch 161/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2586 - accuracy: 0.8795 - val_loss: 0.6219 - val_accuracy: 0.7369\n",
      "Epoch 162/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2561 - accuracy: 0.8803 - val_loss: 0.6405 - val_accuracy: 0.7375\n",
      "Epoch 163/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2567 - accuracy: 0.8801 - val_loss: 0.6175 - val_accuracy: 0.7346\n",
      "Epoch 164/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2555 - accuracy: 0.8806 - val_loss: 0.6343 - val_accuracy: 0.7386\n",
      "Epoch 165/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2579 - accuracy: 0.8800 - val_loss: 0.5790 - val_accuracy: 0.7294\n",
      "Epoch 166/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2689 - accuracy: 0.8760 - val_loss: 0.6172 - val_accuracy: 0.7383\n",
      "Epoch 167/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2586 - accuracy: 0.8791 - val_loss: 0.6003 - val_accuracy: 0.7377\n",
      "Epoch 168/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2561 - accuracy: 0.8807 - val_loss: 0.6180 - val_accuracy: 0.7371\n",
      "Epoch 169/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2574 - accuracy: 0.8796 - val_loss: 0.6280 - val_accuracy: 0.7388\n",
      "Epoch 170/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2552 - accuracy: 0.8809 - val_loss: 0.6090 - val_accuracy: 0.7359\n",
      "Epoch 171/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2558 - accuracy: 0.8802 - val_loss: 0.6201 - val_accuracy: 0.7291\n",
      "Epoch 172/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2569 - accuracy: 0.8800 - val_loss: 0.6351 - val_accuracy: 0.7355\n",
      "Epoch 173/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2554 - accuracy: 0.8811 - val_loss: 0.6328 - val_accuracy: 0.7374\n",
      "Epoch 174/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2553 - accuracy: 0.8799 - val_loss: 0.5883 - val_accuracy: 0.7342\n",
      "Epoch 175/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2538 - accuracy: 0.8808 - val_loss: 0.6217 - val_accuracy: 0.7289\n",
      "Epoch 176/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2553 - accuracy: 0.8807 - val_loss: 0.6219 - val_accuracy: 0.7348\n",
      "Epoch 177/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2540 - accuracy: 0.8814 - val_loss: 0.6341 - val_accuracy: 0.7361\n",
      "Epoch 178/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2539 - accuracy: 0.8815 - val_loss: 0.6323 - val_accuracy: 0.7355\n",
      "Epoch 179/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2549 - accuracy: 0.8808 - val_loss: 0.6385 - val_accuracy: 0.7377\n",
      "Epoch 180/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2550 - accuracy: 0.8812 - val_loss: 0.6211 - val_accuracy: 0.7343\n",
      "Epoch 181/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2535 - accuracy: 0.8819 - val_loss: 0.6276 - val_accuracy: 0.7366\n",
      "Epoch 182/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2555 - accuracy: 0.8811 - val_loss: 0.6212 - val_accuracy: 0.7376\n",
      "Epoch 183/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2540 - accuracy: 0.8817 - val_loss: 0.6307 - val_accuracy: 0.7380\n",
      "Epoch 184/200\n",
      "175341/175341 [==============================] - 207s 1ms/step - loss: 0.2555 - accuracy: 0.8811 - val_loss: 0.6299 - val_accuracy: 0.7379\n",
      "Epoch 185/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2549 - accuracy: 0.8814 - val_loss: 0.6188 - val_accuracy: 0.7379\n",
      "Epoch 186/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2537 - accuracy: 0.8816 - val_loss: 0.5937 - val_accuracy: 0.7359\n",
      "Epoch 187/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2544 - accuracy: 0.8809 - val_loss: 0.6179 - val_accuracy: 0.7387\n",
      "Epoch 188/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2533 - accuracy: 0.8820 - val_loss: 0.5837 - val_accuracy: 0.7356\n",
      "Epoch 189/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2534 - accuracy: 0.8823 - val_loss: 0.6156 - val_accuracy: 0.7412\n",
      "Epoch 190/200\n",
      "175341/175341 [==============================] - 207s 1ms/step - loss: 0.2523 - accuracy: 0.8819 - val_loss: 0.6130 - val_accuracy: 0.7313\n",
      "Epoch 191/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2547 - accuracy: 0.8810 - val_loss: 0.5988 - val_accuracy: 0.7386\n",
      "Epoch 192/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2518 - accuracy: 0.8831 - val_loss: 0.6186 - val_accuracy: 0.7400\n",
      "Epoch 193/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2527 - accuracy: 0.8820 - val_loss: 0.6493 - val_accuracy: 0.7353\n",
      "Epoch 194/200\n",
      "175341/175341 [==============================] - 207s 1ms/step - loss: 0.2527 - accuracy: 0.8820 - val_loss: 0.6248 - val_accuracy: 0.7396\n",
      "Epoch 195/200\n",
      "175341/175341 [==============================] - 207s 1ms/step - loss: 0.2521 - accuracy: 0.8821 - val_loss: 0.6197 - val_accuracy: 0.7387\n",
      "Epoch 196/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2527 - accuracy: 0.8818 - val_loss: 0.6236 - val_accuracy: 0.7377\n",
      "Epoch 197/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2543 - accuracy: 0.8807 - val_loss: 0.6743 - val_accuracy: 0.7383\n",
      "Epoch 198/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2522 - accuracy: 0.8826 - val_loss: 0.6456 - val_accuracy: 0.7387\n",
      "Epoch 199/200\n",
      "175341/175341 [==============================] - 206s 1ms/step - loss: 0.2519 - accuracy: 0.8828 - val_loss: 0.6232 - val_accuracy: 0.7384\n",
      "Epoch 200/200\n",
      "175341/175341 [==============================] - 207s 1ms/step - loss: 0.2517 - accuracy: 0.8823 - val_loss: 0.6140 - val_accuracy: 0.7378\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X,Delta1,Delta2], Y, epochs=200, validation_data=([x,delta1,delta2], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7377568867512024\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.45      0.60     37000\n",
      "           1       0.68      0.98      0.80     45332\n",
      "\n",
      "    accuracy                           0.74     82332\n",
      "   macro avg       0.81      0.71      0.70     82332\n",
      "weighted avg       0.80      0.74      0.71     82332\n",
      "\n",
      "          predicted_negative  predicted_positive\n",
      "negative               16469               20531\n",
      "positive                1060               44272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "predictions = model.predict([x,delta1,delta2])\n",
    "predictions = [0 if i<0.5 else 1 for i in predictions]\n",
    "print(\"Accuracy: \",accuracy_score(y,predictions))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Classification Report: \\n\",classification_report(y,predictions))\n",
    "conmat = np.array(confusion_matrix(y, predictions, labels=[0,1]))\n",
    "confusion = pd.DataFrame(conmat, index=['negative', 'positive'],\n",
    "                         columns=['predicted_negative','predicted_positive'])\n",
    "print (confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
