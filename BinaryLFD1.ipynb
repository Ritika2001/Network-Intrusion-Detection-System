{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-1]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr = X.values\n",
    "arr = x.values\n",
    "\n",
    "import librosa\n",
    "Arr_Delta = librosa.feature.delta(Arr)\n",
    "arr_delta = librosa.feature.delta(arr)\n",
    "\n",
    "Delta1 = pd.DataFrame(Arr_Delta)\n",
    "delta1 = pd.DataFrame(arr_delta)\n",
    "\n",
    "scaler = Normalizer().fit(Delta1)\n",
    "Delta1 = scaler.transform(Delta1)\n",
    "scaler = Normalizer().fit(delta1)\n",
    "delta1 = scaler.transform(delta1)\n",
    "\n",
    "Delta1 = np.reshape(Delta1, (Delta1.shape[0],Delta1.shape[1],1))\n",
    "delta1 = np.reshape(delta1, (delta1.shape[0],delta1.shape[1],1))\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],X.shape[1],1))\n",
    "x = np.reshape(x, (x.shape[0],x.shape[1],1))\n",
    "\n",
    "lstm_output_size = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 41, 64)       256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 41, 64)       256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 20, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 20, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 64)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 64)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 128)      0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 140)          111440      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 140)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            141         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 112,093\n",
      "Trainable params: 112,093\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Convolution1D, Dense, Dropout, Flatten, MaxPooling1D, concatenate, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "lstm_output_size=70\n",
    "Xshape = Input(shape=(41, 1))\n",
    "Delta1shape = Input(shape=(41, 1))\n",
    "\n",
    "x1 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Xshape)\n",
    "x1 = MaxPooling1D(pool_length=(2))(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "   \n",
    "x2 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Delta1shape)\n",
    "x2 = MaxPooling1D(pool_length=(2))(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "\n",
    "output = concatenate([x1, x2])\n",
    "\n",
    "x3 = Bidirectional(LSTM(lstm_output_size))(output)\n",
    "x3 = Dropout(0.1)(x3)\n",
    "x3 = Dense(1, activation=\"sigmoid\")(x3)\n",
    "\n",
    "model = Model([Xshape, Delta1shape],x3)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/200\n",
      "175341/175341 [==============================] - 173s 986us/step - loss: 0.4132 - accuracy: 0.7683 - val_loss: 0.5572 - val_accuracy: 0.6862\n",
      "Epoch 2/200\n",
      "175341/175341 [==============================] - 171s 977us/step - loss: 0.3736 - accuracy: 0.8153 - val_loss: 0.5397 - val_accuracy: 0.6890\n",
      "Epoch 3/200\n",
      "175341/175341 [==============================] - 169s 962us/step - loss: 0.3643 - accuracy: 0.8196 - val_loss: 0.5604 - val_accuracy: 0.6893\n",
      "Epoch 4/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.3611 - accuracy: 0.8234 - val_loss: 0.5556 - val_accuracy: 0.6954\n",
      "Epoch 5/200\n",
      "175341/175341 [==============================] - 322s 2ms/step - loss: 0.3600 - accuracy: 0.8235 - val_loss: 0.5442 - val_accuracy: 0.7231\n",
      "Epoch 6/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.3572 - accuracy: 0.8260 - val_loss: 0.5511 - val_accuracy: 0.7275\n",
      "Epoch 7/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.3545 - accuracy: 0.8270 - val_loss: 0.5397 - val_accuracy: 0.7233\n",
      "Epoch 8/200\n",
      "175341/175341 [==============================] - 328s 2ms/step - loss: 0.3518 - accuracy: 0.8311 - val_loss: 0.5326 - val_accuracy: 0.7257\n",
      "Epoch 9/200\n",
      "175341/175341 [==============================] - 324s 2ms/step - loss: 0.3359 - accuracy: 0.8464 - val_loss: 0.5287 - val_accuracy: 0.7278\n",
      "Epoch 10/200\n",
      "175341/175341 [==============================] - 324s 2ms/step - loss: 0.3197 - accuracy: 0.8586 - val_loss: 0.5364 - val_accuracy: 0.7023\n",
      "Epoch 11/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.3159 - accuracy: 0.8612 - val_loss: 0.5193 - val_accuracy: 0.7350\n",
      "Epoch 12/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.3113 - accuracy: 0.8641 - val_loss: 0.5245 - val_accuracy: 0.7281\n",
      "Epoch 13/200\n",
      "175341/175341 [==============================] - 331s 2ms/step - loss: 0.3083 - accuracy: 0.8650 - val_loss: 0.5300 - val_accuracy: 0.7245\n",
      "Epoch 14/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.3018 - accuracy: 0.8664 - val_loss: 0.4976 - val_accuracy: 0.7294\n",
      "Epoch 15/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.3004 - accuracy: 0.8673 - val_loss: 0.5278 - val_accuracy: 0.7284\n",
      "Epoch 16/200\n",
      "175341/175341 [==============================] - 324s 2ms/step - loss: 0.2976 - accuracy: 0.8680 - val_loss: 0.5007 - val_accuracy: 0.7288\n",
      "Epoch 17/200\n",
      "175341/175341 [==============================] - 331s 2ms/step - loss: 0.2960 - accuracy: 0.8680 - val_loss: 0.5127 - val_accuracy: 0.7274\n",
      "Epoch 18/200\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 0.2941 - accuracy: 0.8680 - val_loss: 0.5022 - val_accuracy: 0.7269\n",
      "Epoch 19/200\n",
      "175341/175341 [==============================] - 324s 2ms/step - loss: 0.2929 - accuracy: 0.8689 - val_loss: 0.5068 - val_accuracy: 0.7321\n",
      "Epoch 20/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2913 - accuracy: 0.8690 - val_loss: 0.5307 - val_accuracy: 0.7282\n",
      "Epoch 21/200\n",
      "175341/175341 [==============================] - 328s 2ms/step - loss: 0.2901 - accuracy: 0.8696 - val_loss: 0.5148 - val_accuracy: 0.7264\n",
      "Epoch 22/200\n",
      "175341/175341 [==============================] - 332s 2ms/step - loss: 0.2894 - accuracy: 0.8701 - val_loss: 0.5016 - val_accuracy: 0.7301\n",
      "Epoch 23/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2883 - accuracy: 0.8705 - val_loss: 0.5341 - val_accuracy: 0.7253\n",
      "Epoch 24/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2875 - accuracy: 0.8705 - val_loss: 0.5168 - val_accuracy: 0.7271\n",
      "Epoch 25/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2862 - accuracy: 0.8712 - val_loss: 0.4995 - val_accuracy: 0.7328\n",
      "Epoch 26/200\n",
      "175341/175341 [==============================] - 336s 2ms/step - loss: 0.2867 - accuracy: 0.8710 - val_loss: 0.5155 - val_accuracy: 0.7345\n",
      "Epoch 27/200\n",
      "175341/175341 [==============================] - 329s 2ms/step - loss: 0.2864 - accuracy: 0.8707 - val_loss: 0.5208 - val_accuracy: 0.7337\n",
      "Epoch 28/200\n",
      "175341/175341 [==============================] - 329s 2ms/step - loss: 0.2858 - accuracy: 0.8720 - val_loss: 0.5117 - val_accuracy: 0.7284\n",
      "Epoch 29/200\n",
      "175341/175341 [==============================] - 330s 2ms/step - loss: 0.2852 - accuracy: 0.8720 - val_loss: 0.4981 - val_accuracy: 0.7343\n",
      "Epoch 30/200\n",
      "175341/175341 [==============================] - 329s 2ms/step - loss: 0.2841 - accuracy: 0.8718 - val_loss: 0.5097 - val_accuracy: 0.7294\n",
      "Epoch 31/200\n",
      "175341/175341 [==============================] - 336s 2ms/step - loss: 0.2838 - accuracy: 0.8722 - val_loss: 0.4999 - val_accuracy: 0.7345\n",
      "Epoch 32/200\n",
      "175341/175341 [==============================] - 327s 2ms/step - loss: 0.2836 - accuracy: 0.8725 - val_loss: 0.5037 - val_accuracy: 0.7329\n",
      "Epoch 33/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.2831 - accuracy: 0.8727 - val_loss: 0.5262 - val_accuracy: 0.7350\n",
      "Epoch 34/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.2833 - accuracy: 0.8726 - val_loss: 0.5155 - val_accuracy: 0.7331\n",
      "Epoch 35/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2823 - accuracy: 0.8729 - val_loss: 0.5173 - val_accuracy: 0.7315\n",
      "Epoch 36/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2830 - accuracy: 0.8725 - val_loss: 0.5016 - val_accuracy: 0.7290\n",
      "Epoch 37/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 0.2821 - accuracy: 0.8732 - val_loss: 0.5145 - val_accuracy: 0.7280\n",
      "Epoch 38/200\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 0.2821 - accuracy: 0.8729 - val_loss: 0.5102 - val_accuracy: 0.7324\n",
      "Epoch 39/200\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 0.2814 - accuracy: 0.8727 - val_loss: 0.5003 - val_accuracy: 0.7347\n",
      "Epoch 40/200\n",
      "175341/175341 [==============================] - 328s 2ms/step - loss: 0.2819 - accuracy: 0.8729 - val_loss: 0.5068 - val_accuracy: 0.7343\n",
      "Epoch 41/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2811 - accuracy: 0.8733 - val_loss: 0.5135 - val_accuracy: 0.7301\n",
      "Epoch 42/200\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 0.2817 - accuracy: 0.8734 - val_loss: 0.4934 - val_accuracy: 0.7310\n",
      "Epoch 43/200\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 0.2799 - accuracy: 0.8736 - val_loss: 0.4882 - val_accuracy: 0.7349\n",
      "Epoch 44/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2807 - accuracy: 0.8736 - val_loss: 0.5145 - val_accuracy: 0.7341\n",
      "Epoch 45/200\n",
      "175341/175341 [==============================] - 328s 2ms/step - loss: 0.2807 - accuracy: 0.8738 - val_loss: 0.5006 - val_accuracy: 0.7348\n",
      "Epoch 46/200\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 0.2802 - accuracy: 0.8739 - val_loss: 0.4889 - val_accuracy: 0.7291\n",
      "Epoch 47/200\n",
      "175341/175341 [==============================] - 324s 2ms/step - loss: 0.2798 - accuracy: 0.8736 - val_loss: 0.5090 - val_accuracy: 0.7343\n",
      "Epoch 48/200\n",
      "175341/175341 [==============================] - 326s 2ms/step - loss: 0.2799 - accuracy: 0.8735 - val_loss: 0.5061 - val_accuracy: 0.7328\n",
      "Epoch 49/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.2798 - accuracy: 0.8736 - val_loss: 0.4951 - val_accuracy: 0.7354\n",
      "Epoch 50/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.2794 - accuracy: 0.8741 - val_loss: 0.5167 - val_accuracy: 0.7342\n",
      "Epoch 51/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.2792 - accuracy: 0.8741 - val_loss: 0.5223 - val_accuracy: 0.7333\n",
      "Epoch 52/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.2787 - accuracy: 0.8740 - val_loss: 0.5127 - val_accuracy: 0.7359\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2794 - accuracy: 0.8740 - val_loss: 0.4992 - val_accuracy: 0.7351\n",
      "Epoch 54/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2790 - accuracy: 0.8740 - val_loss: 0.4994 - val_accuracy: 0.7351\n",
      "Epoch 55/200\n",
      "175341/175341 [==============================] - 306s 2ms/step - loss: 0.2785 - accuracy: 0.8746 - val_loss: 0.5030 - val_accuracy: 0.7347\n",
      "Epoch 56/200\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 0.2784 - accuracy: 0.8745 - val_loss: 0.5012 - val_accuracy: 0.7337\n",
      "Epoch 57/200\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 0.2772 - accuracy: 0.8748 - val_loss: 0.5235 - val_accuracy: 0.7356\n",
      "Epoch 58/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2784 - accuracy: 0.8739 - val_loss: 0.5091 - val_accuracy: 0.7349\n",
      "Epoch 59/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2778 - accuracy: 0.8744 - val_loss: 0.4922 - val_accuracy: 0.7316\n",
      "Epoch 60/200\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 0.2767 - accuracy: 0.8751 - val_loss: 0.5214 - val_accuracy: 0.7349\n",
      "Epoch 61/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2783 - accuracy: 0.8744 - val_loss: 0.5026 - val_accuracy: 0.7272\n",
      "Epoch 62/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2779 - accuracy: 0.8745 - val_loss: 0.5241 - val_accuracy: 0.7303\n",
      "Epoch 63/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2768 - accuracy: 0.8754 - val_loss: 0.5177 - val_accuracy: 0.7281\n",
      "Epoch 64/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2768 - accuracy: 0.8748 - val_loss: 0.4937 - val_accuracy: 0.7355\n",
      "Epoch 65/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2766 - accuracy: 0.8752 - val_loss: 0.5125 - val_accuracy: 0.7339\n",
      "Epoch 66/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2762 - accuracy: 0.8745 - val_loss: 0.5039 - val_accuracy: 0.7342\n",
      "Epoch 67/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2769 - accuracy: 0.8746 - val_loss: 0.5085 - val_accuracy: 0.7348\n",
      "Epoch 68/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2763 - accuracy: 0.8752 - val_loss: 0.5175 - val_accuracy: 0.7350\n",
      "Epoch 69/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2761 - accuracy: 0.8751 - val_loss: 0.4895 - val_accuracy: 0.7353\n",
      "Epoch 70/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2755 - accuracy: 0.8754 - val_loss: 0.5038 - val_accuracy: 0.7348\n",
      "Epoch 71/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2750 - accuracy: 0.8756 - val_loss: 0.4982 - val_accuracy: 0.7296\n",
      "Epoch 72/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2755 - accuracy: 0.8749 - val_loss: 0.4987 - val_accuracy: 0.7354\n",
      "Epoch 73/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2753 - accuracy: 0.8754 - val_loss: 0.4933 - val_accuracy: 0.7354\n",
      "Epoch 74/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2752 - accuracy: 0.8755 - val_loss: 0.4837 - val_accuracy: 0.7356\n",
      "Epoch 75/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2746 - accuracy: 0.8755 - val_loss: 0.4854 - val_accuracy: 0.7351\n",
      "Epoch 76/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2745 - accuracy: 0.8756 - val_loss: 0.4936 - val_accuracy: 0.7353\n",
      "Epoch 77/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2737 - accuracy: 0.8757 - val_loss: 0.5103 - val_accuracy: 0.7298\n",
      "Epoch 78/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2738 - accuracy: 0.8755 - val_loss: 0.5063 - val_accuracy: 0.7355\n",
      "Epoch 79/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2732 - accuracy: 0.8761 - val_loss: 0.4773 - val_accuracy: 0.7346\n",
      "Epoch 80/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2729 - accuracy: 0.8761 - val_loss: 0.4883 - val_accuracy: 0.7342\n",
      "Epoch 81/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2728 - accuracy: 0.8760 - val_loss: 0.4983 - val_accuracy: 0.7291\n",
      "Epoch 82/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2723 - accuracy: 0.8761 - val_loss: 0.4750 - val_accuracy: 0.7346\n",
      "Epoch 83/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2730 - accuracy: 0.8757 - val_loss: 0.4602 - val_accuracy: 0.7360\n",
      "Epoch 84/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2724 - accuracy: 0.8764 - val_loss: 0.4779 - val_accuracy: 0.7350\n",
      "Epoch 85/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2718 - accuracy: 0.8761 - val_loss: 0.4756 - val_accuracy: 0.7366\n",
      "Epoch 86/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.2710 - accuracy: 0.8759 - val_loss: 0.4557 - val_accuracy: 0.7341\n",
      "Epoch 87/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2704 - accuracy: 0.8767 - val_loss: 0.5054 - val_accuracy: 0.7314\n",
      "Epoch 88/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2700 - accuracy: 0.8768 - val_loss: 0.4762 - val_accuracy: 0.7351\n",
      "Epoch 89/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2703 - accuracy: 0.8762 - val_loss: 0.4652 - val_accuracy: 0.7317\n",
      "Epoch 90/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2698 - accuracy: 0.8766 - val_loss: 0.4758 - val_accuracy: 0.7350\n",
      "Epoch 91/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.2699 - accuracy: 0.8765 - val_loss: 0.4979 - val_accuracy: 0.7323\n",
      "Epoch 92/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2702 - accuracy: 0.8771 - val_loss: 0.4696 - val_accuracy: 0.7355\n",
      "Epoch 93/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2694 - accuracy: 0.8765 - val_loss: 0.4824 - val_accuracy: 0.7341\n",
      "Epoch 94/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2681 - accuracy: 0.8770 - val_loss: 0.4503 - val_accuracy: 0.7365\n",
      "Epoch 95/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.2687 - accuracy: 0.8765 - val_loss: 0.4626 - val_accuracy: 0.7356\n",
      "Epoch 96/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.2691 - accuracy: 0.8768 - val_loss: 0.4797 - val_accuracy: 0.7358\n",
      "Epoch 97/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2690 - accuracy: 0.8768 - val_loss: 0.5251 - val_accuracy: 0.7328\n",
      "Epoch 98/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2682 - accuracy: 0.8770 - val_loss: 0.4340 - val_accuracy: 0.7348\n",
      "Epoch 99/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2683 - accuracy: 0.8768 - val_loss: 0.4664 - val_accuracy: 0.7365\n",
      "Epoch 100/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.2676 - accuracy: 0.8772 - val_loss: 0.4697 - val_accuracy: 0.7353\n",
      "Epoch 101/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2671 - accuracy: 0.8773 - val_loss: 0.4684 - val_accuracy: 0.7353\n",
      "Epoch 102/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2662 - accuracy: 0.8771 - val_loss: 0.4542 - val_accuracy: 0.7356\n",
      "Epoch 103/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2674 - accuracy: 0.8773 - val_loss: 0.4465 - val_accuracy: 0.7356\n",
      "Epoch 104/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.2668 - accuracy: 0.8775 - val_loss: 0.4480 - val_accuracy: 0.7349\n",
      "Epoch 105/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.2672 - accuracy: 0.8768 - val_loss: 0.5231 - val_accuracy: 0.7345\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2667 - accuracy: 0.8770 - val_loss: 0.4621 - val_accuracy: 0.7364\n",
      "Epoch 107/200\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 0.2668 - accuracy: 0.8768 - val_loss: 0.4526 - val_accuracy: 0.7348\n",
      "Epoch 108/200\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 0.2652 - accuracy: 0.8770 - val_loss: 0.4528 - val_accuracy: 0.7350\n",
      "Epoch 109/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2661 - accuracy: 0.8777 - val_loss: 0.4681 - val_accuracy: 0.7355\n",
      "Epoch 110/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2648 - accuracy: 0.8774 - val_loss: 0.4806 - val_accuracy: 0.7345\n",
      "Epoch 111/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2655 - accuracy: 0.8778 - val_loss: 0.4712 - val_accuracy: 0.7346\n",
      "Epoch 112/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2650 - accuracy: 0.8774 - val_loss: 0.4293 - val_accuracy: 0.7349\n",
      "Epoch 113/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2656 - accuracy: 0.8773 - val_loss: 0.4562 - val_accuracy: 0.7339\n",
      "Epoch 114/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2645 - accuracy: 0.8779 - val_loss: 0.4524 - val_accuracy: 0.7352\n",
      "Epoch 115/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2642 - accuracy: 0.8777 - val_loss: 0.4616 - val_accuracy: 0.7339\n",
      "Epoch 116/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2641 - accuracy: 0.8771 - val_loss: 0.4608 - val_accuracy: 0.7360\n",
      "Epoch 117/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2640 - accuracy: 0.8774 - val_loss: 0.4469 - val_accuracy: 0.7464\n",
      "Epoch 118/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2638 - accuracy: 0.8778 - val_loss: 0.4431 - val_accuracy: 0.7463\n",
      "Epoch 119/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2671 - accuracy: 0.8774 - val_loss: 0.5080 - val_accuracy: 0.7402\n",
      "Epoch 120/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2658 - accuracy: 0.8776 - val_loss: 0.5493 - val_accuracy: 0.7338\n",
      "Epoch 121/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2651 - accuracy: 0.8781 - val_loss: 0.5452 - val_accuracy: 0.7390\n",
      "Epoch 122/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2641 - accuracy: 0.8785 - val_loss: 0.5553 - val_accuracy: 0.7361\n",
      "Epoch 123/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2638 - accuracy: 0.8783 - val_loss: 0.5639 - val_accuracy: 0.7339\n",
      "Epoch 124/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2634 - accuracy: 0.8783 - val_loss: 0.5455 - val_accuracy: 0.7375\n",
      "Epoch 125/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2631 - accuracy: 0.8781 - val_loss: 0.5823 - val_accuracy: 0.7340\n",
      "Epoch 126/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2625 - accuracy: 0.8786 - val_loss: 0.5657 - val_accuracy: 0.7376\n",
      "Epoch 127/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2630 - accuracy: 0.8788 - val_loss: 0.5523 - val_accuracy: 0.7415\n",
      "Epoch 128/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.2620 - accuracy: 0.8784 - val_loss: 0.5522 - val_accuracy: 0.7342\n",
      "Epoch 129/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2627 - accuracy: 0.8783 - val_loss: 0.5403 - val_accuracy: 0.7356\n",
      "Epoch 130/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2623 - accuracy: 0.8786 - val_loss: 0.5782 - val_accuracy: 0.7341\n",
      "Epoch 131/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2632 - accuracy: 0.8785 - val_loss: 0.5451 - val_accuracy: 0.7363\n",
      "Epoch 132/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2623 - accuracy: 0.8781 - val_loss: 0.5550 - val_accuracy: 0.7419\n",
      "Epoch 133/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2617 - accuracy: 0.8788 - val_loss: 0.5667 - val_accuracy: 0.7395\n",
      "Epoch 134/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2616 - accuracy: 0.8784 - val_loss: 0.5439 - val_accuracy: 0.7432\n",
      "Epoch 135/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2607 - accuracy: 0.8784 - val_loss: 0.5628 - val_accuracy: 0.7378\n",
      "Epoch 136/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2603 - accuracy: 0.8785 - val_loss: 0.5409 - val_accuracy: 0.7357\n",
      "Epoch 137/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.2606 - accuracy: 0.8785 - val_loss: 0.5557 - val_accuracy: 0.7374\n",
      "Epoch 138/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2611 - accuracy: 0.8786 - val_loss: 0.5565 - val_accuracy: 0.7358\n",
      "Epoch 139/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2614 - accuracy: 0.8786 - val_loss: 0.5575 - val_accuracy: 0.7412\n",
      "Epoch 140/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2606 - accuracy: 0.8784 - val_loss: 0.5374 - val_accuracy: 0.7363\n",
      "Epoch 141/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2608 - accuracy: 0.8788 - val_loss: 0.5554 - val_accuracy: 0.7356\n",
      "Epoch 142/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.2610 - accuracy: 0.8782 - val_loss: 0.5608 - val_accuracy: 0.7342\n",
      "Epoch 143/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2605 - accuracy: 0.8795 - val_loss: 0.5499 - val_accuracy: 0.7309\n",
      "Epoch 144/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2608 - accuracy: 0.8789 - val_loss: 0.5510 - val_accuracy: 0.7364\n",
      "Epoch 145/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2592 - accuracy: 0.8792 - val_loss: 0.5503 - val_accuracy: 0.7414\n",
      "Epoch 146/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.2606 - accuracy: 0.8786 - val_loss: 0.5499 - val_accuracy: 0.7343\n",
      "Epoch 147/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2600 - accuracy: 0.8786 - val_loss: 0.5312 - val_accuracy: 0.7484\n",
      "Epoch 148/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2600 - accuracy: 0.8786 - val_loss: 0.5310 - val_accuracy: 0.7424\n",
      "Epoch 149/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2602 - accuracy: 0.8790 - val_loss: 0.5636 - val_accuracy: 0.7360\n",
      "Epoch 150/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2602 - accuracy: 0.8787 - val_loss: 0.5387 - val_accuracy: 0.7351\n",
      "Epoch 151/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.2596 - accuracy: 0.8797 - val_loss: 0.5493 - val_accuracy: 0.7374\n",
      "Epoch 152/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2597 - accuracy: 0.8791 - val_loss: 0.5529 - val_accuracy: 0.7366\n",
      "Epoch 153/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2594 - accuracy: 0.8791 - val_loss: 0.5447 - val_accuracy: 0.7276\n",
      "Epoch 154/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2598 - accuracy: 0.8789 - val_loss: 0.5386 - val_accuracy: 0.7359\n",
      "Epoch 155/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.2593 - accuracy: 0.8789 - val_loss: 0.5565 - val_accuracy: 0.7364\n",
      "Epoch 156/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.2580 - accuracy: 0.8801 - val_loss: 0.5501 - val_accuracy: 0.7355\n",
      "Epoch 157/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2582 - accuracy: 0.8787 - val_loss: 0.5532 - val_accuracy: 0.7359\n",
      "Epoch 158/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2589 - accuracy: 0.8796 - val_loss: 0.5483 - val_accuracy: 0.7356\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2592 - accuracy: 0.8796 - val_loss: 0.5553 - val_accuracy: 0.7336\n",
      "Epoch 160/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2585 - accuracy: 0.8790 - val_loss: 0.5318 - val_accuracy: 0.7420\n",
      "Epoch 161/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2591 - accuracy: 0.8792 - val_loss: 0.5627 - val_accuracy: 0.7302\n",
      "Epoch 162/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2576 - accuracy: 0.8793 - val_loss: 0.5423 - val_accuracy: 0.7349\n",
      "Epoch 163/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2575 - accuracy: 0.8802 - val_loss: 0.5717 - val_accuracy: 0.7352\n",
      "Epoch 164/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2572 - accuracy: 0.8799 - val_loss: 0.5568 - val_accuracy: 0.7389\n",
      "Epoch 165/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2574 - accuracy: 0.8792 - val_loss: 0.5335 - val_accuracy: 0.7429\n",
      "Epoch 166/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2581 - accuracy: 0.8799 - val_loss: 0.5429 - val_accuracy: 0.7365\n",
      "Epoch 167/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2582 - accuracy: 0.8797 - val_loss: 0.5570 - val_accuracy: 0.7342\n",
      "Epoch 168/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2570 - accuracy: 0.8798 - val_loss: 0.5488 - val_accuracy: 0.7366\n",
      "Epoch 169/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2556 - accuracy: 0.8806 - val_loss: 0.5618 - val_accuracy: 0.7343\n",
      "Epoch 170/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2581 - accuracy: 0.8790 - val_loss: 0.5523 - val_accuracy: 0.7347\n",
      "Epoch 171/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2572 - accuracy: 0.8793 - val_loss: 0.5615 - val_accuracy: 0.7379\n",
      "Epoch 172/200\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 0.2556 - accuracy: 0.8807 - val_loss: 0.5267 - val_accuracy: 0.7418\n",
      "Epoch 173/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2566 - accuracy: 0.8798 - val_loss: 0.5691 - val_accuracy: 0.7348\n",
      "Epoch 174/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2566 - accuracy: 0.8800 - val_loss: 0.5439 - val_accuracy: 0.7373\n",
      "Epoch 175/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2566 - accuracy: 0.8805 - val_loss: 0.5425 - val_accuracy: 0.7388\n",
      "Epoch 176/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2568 - accuracy: 0.8805 - val_loss: 0.5717 - val_accuracy: 0.7351\n",
      "Epoch 177/200\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 0.2574 - accuracy: 0.8798 - val_loss: 0.5444 - val_accuracy: 0.7357\n",
      "Epoch 178/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2570 - accuracy: 0.8793 - val_loss: 0.5323 - val_accuracy: 0.7371\n",
      "Epoch 179/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2551 - accuracy: 0.8802 - val_loss: 0.5403 - val_accuracy: 0.7377\n",
      "Epoch 180/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2568 - accuracy: 0.8792 - val_loss: 0.5555 - val_accuracy: 0.7421\n",
      "Epoch 181/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2559 - accuracy: 0.8803 - val_loss: 0.5381 - val_accuracy: 0.7381\n",
      "Epoch 182/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2560 - accuracy: 0.8802 - val_loss: 0.5357 - val_accuracy: 0.7344\n",
      "Epoch 183/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.2560 - accuracy: 0.8803 - val_loss: 0.5388 - val_accuracy: 0.7335\n",
      "Epoch 184/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2564 - accuracy: 0.8801 - val_loss: 0.5591 - val_accuracy: 0.7344\n",
      "Epoch 185/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2568 - accuracy: 0.8801 - val_loss: 0.5374 - val_accuracy: 0.7434\n",
      "Epoch 186/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2547 - accuracy: 0.8806 - val_loss: 0.5447 - val_accuracy: 0.7358\n",
      "Epoch 187/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2556 - accuracy: 0.8803 - val_loss: 0.5362 - val_accuracy: 0.7359\n",
      "Epoch 188/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2558 - accuracy: 0.8800 - val_loss: 0.5281 - val_accuracy: 0.7326\n",
      "Epoch 189/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2560 - accuracy: 0.8798 - val_loss: 0.5535 - val_accuracy: 0.7341\n",
      "Epoch 190/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.2553 - accuracy: 0.8807 - val_loss: 0.5113 - val_accuracy: 0.7419\n",
      "Epoch 191/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2546 - accuracy: 0.8806 - val_loss: 0.5308 - val_accuracy: 0.7445\n",
      "Epoch 192/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.2565 - accuracy: 0.8798 - val_loss: 0.5513 - val_accuracy: 0.7363\n",
      "Epoch 193/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2548 - accuracy: 0.8811 - val_loss: 0.5394 - val_accuracy: 0.7356\n",
      "Epoch 194/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2542 - accuracy: 0.8814 - val_loss: 0.5376 - val_accuracy: 0.7347\n",
      "Epoch 195/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.2553 - accuracy: 0.8801 - val_loss: 0.5268 - val_accuracy: 0.7362\n",
      "Epoch 196/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2550 - accuracy: 0.8807 - val_loss: 0.5052 - val_accuracy: 0.7428\n",
      "Epoch 197/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.2553 - accuracy: 0.8801 - val_loss: 0.5401 - val_accuracy: 0.7309\n",
      "Epoch 198/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.2550 - accuracy: 0.8807 - val_loss: 0.5161 - val_accuracy: 0.7359\n",
      "Epoch 199/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2553 - accuracy: 0.8806 - val_loss: 0.5333 - val_accuracy: 0.7441\n",
      "Epoch 200/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.2546 - accuracy: 0.8802 - val_loss: 0.5397 - val_accuracy: 0.7431\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X,Delta1], Y, epochs=200, validation_data=([x,delta1], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7430768109605014\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.46      0.62     37000\n",
      "           1       0.69      0.97      0.81     45332\n",
      "\n",
      "    accuracy                           0.74     82332\n",
      "   macro avg       0.81      0.72      0.71     82332\n",
      "weighted avg       0.80      0.74      0.72     82332\n",
      "\n",
      "          predicted_negative  predicted_positive\n",
      "negative               17073               19927\n",
      "positive                1226               44106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "predictions = model.predict([x,delta1])\n",
    "predictions = [0 if i<0.5 else 1 for i in predictions]\n",
    "print(\"Accuracy: \",accuracy_score(y,predictions))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Classification Report: \\n\",classification_report(y,predictions))\n",
    "conmat = np.array(confusion_matrix(y, predictions, labels=[0,1]))\n",
    "confusion = pd.DataFrame(conmat, index=['negative', 'positive'],\n",
    "                         columns=['predicted_negative','predicted_positive'])\n",
    "print (confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
