{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "traindata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv')\n",
    "testdata = pd.read_csv('/home/ritika/NetworkIntrusionDetection/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "traindata=traindata.drop('id',axis=1)\n",
    "testdata=testdata.drop('id',axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "traindata['proto'] = lb_make.fit_transform(traindata['proto'])\n",
    "traindata['service'] = lb_make.fit_transform(traindata['service'])\n",
    "traindata['state'] = lb_make.fit_transform(traindata['state'])\n",
    "traindata['attack_cat'] = lb_make.fit_transform(traindata['attack_cat'])\n",
    "\n",
    "testdata['proto'] = lb_make.fit_transform(testdata['proto'])\n",
    "testdata['service'] = lb_make.fit_transform(testdata['service'])\n",
    "testdata['state'] = lb_make.fit_transform(testdata['state'])\n",
    "testdata['attack_cat'] = lb_make.fit_transform(testdata['attack_cat'])\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,-2]\n",
    "x = testdata.iloc[:,1:42]\n",
    "y = testdata.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr = X.values\n",
    "arr = x.values\n",
    "\n",
    "import librosa\n",
    "Arr_Delta = librosa.feature.delta(Arr)\n",
    "arr_delta = librosa.feature.delta(arr)\n",
    "\n",
    "Delta1 = pd.DataFrame(Arr_Delta)\n",
    "delta1 = pd.DataFrame(arr_delta)\n",
    "\n",
    "scaler = Normalizer().fit(Delta1)\n",
    "Delta1 = scaler.transform(Delta1)\n",
    "scaler = Normalizer().fit(delta1)\n",
    "delta1 = scaler.transform(delta1)\n",
    "\n",
    "Delta1 = np.reshape(Delta1, (Delta1.shape[0],Delta1.shape[1],1))\n",
    "delta1 = np.reshape(delta1, (delta1.shape[0],delta1.shape[1],1))\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "X = scaler.transform(X)\n",
    "scaler = Normalizer().fit(x)\n",
    "x = scaler.transform(x)\n",
    "\n",
    "Y = np.array(Y)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0],X.shape[1],1))\n",
    "x = np.reshape(x, (x.shape[0],x.shape[1],1))\n",
    "lstm_output_size = 70\n",
    "\n",
    "Y = to_categorical(Y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 41, 64)       256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 41, 64)       256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 20, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 20, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 64)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 64)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 128)      0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 140)          111440      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 140)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1410        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 113,362\n",
      "Trainable params: 113,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Convolution1D, Dense, Dropout, Flatten, MaxPooling1D, concatenate, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "lstm_output_size=70\n",
    "Xshape = Input(shape=(41, 1))\n",
    "Delta1shape = Input(shape=(41, 1))\n",
    "\n",
    "x1 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Xshape)\n",
    "x1 = MaxPooling1D(pool_length=(2))(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "   \n",
    "x2 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Delta1shape)\n",
    "x2 = MaxPooling1D(pool_length=(2))(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "\n",
    "output = concatenate([x1, x2])\n",
    "\n",
    "x3 = Bidirectional(LSTM(lstm_output_size))(output)\n",
    "x3 = Dropout(0.1)(x3)\n",
    "x3 = Dense(10, activation=\"softmax\")(x3)\n",
    "\n",
    "model = Model([Xshape, Delta1shape],x3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\")`\n",
      "  \n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 41, 64)       256         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 41, 64)       256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 20, 64)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 20, 64)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 20, 64)       0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 20, 64)       0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 20, 128)      0           dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 140)          111440      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 140)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           1410        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 113,362\n",
      "Trainable params: 113,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/200\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 1.3999 - accuracy: 0.5265 - val_loss: 1.3141 - val_accuracy: 0.6172\n",
      "Epoch 2/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 1.3519 - accuracy: 0.5355 - val_loss: 1.2690 - val_accuracy: 0.5967\n",
      "Epoch 3/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 1.3301 - accuracy: 0.5422 - val_loss: 1.2920 - val_accuracy: 0.5922\n",
      "Epoch 4/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 1.3243 - accuracy: 0.5456 - val_loss: 1.2769 - val_accuracy: 0.5974\n",
      "Epoch 5/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 1.3206 - accuracy: 0.5471 - val_loss: 1.2895 - val_accuracy: 0.5835\n",
      "Epoch 6/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.3173 - accuracy: 0.5485 - val_loss: 1.2831 - val_accuracy: 0.5912\n",
      "Epoch 7/200\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 1.3159 - accuracy: 0.5494 - val_loss: 1.2765 - val_accuracy: 0.5911\n",
      "Epoch 8/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 1.3141 - accuracy: 0.5503 - val_loss: 1.2611 - val_accuracy: 0.5926\n",
      "Epoch 9/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.3118 - accuracy: 0.5507 - val_loss: 1.2747 - val_accuracy: 0.5888\n",
      "Epoch 10/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 1.3095 - accuracy: 0.5515 - val_loss: 1.2721 - val_accuracy: 0.5851\n",
      "Epoch 11/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 1.2919 - accuracy: 0.5518 - val_loss: 1.2158 - val_accuracy: 0.5850\n",
      "Epoch 12/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 1.1410 - accuracy: 0.5847 - val_loss: 1.0799 - val_accuracy: 0.6072\n",
      "Epoch 13/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.0997 - accuracy: 0.5970 - val_loss: 1.0272 - val_accuracy: 0.6275\n",
      "Epoch 14/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 1.0976 - accuracy: 0.5949 - val_loss: 1.0565 - val_accuracy: 0.6155\n",
      "Epoch 15/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 1.1103 - accuracy: 0.5836 - val_loss: 1.1248 - val_accuracy: 0.6154\n",
      "Epoch 16/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 1.1252 - accuracy: 0.5786 - val_loss: 1.5366 - val_accuracy: 0.3997\n",
      "Epoch 17/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 1.0502 - accuracy: 0.6115 - val_loss: 1.9384 - val_accuracy: 0.3988\n",
      "Epoch 18/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 1.0426 - accuracy: 0.6136 - val_loss: 2.0026 - val_accuracy: 0.4006\n",
      "Epoch 19/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 1.0378 - accuracy: 0.6148 - val_loss: 2.1118 - val_accuracy: 0.3971\n",
      "Epoch 20/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 1.0300 - accuracy: 0.6170 - val_loss: 2.3694 - val_accuracy: 0.3969\n",
      "Epoch 21/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 1.0098 - accuracy: 0.6225 - val_loss: 2.2699 - val_accuracy: 0.3626\n",
      "Epoch 22/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 1.0015 - accuracy: 0.6247 - val_loss: 2.2482 - val_accuracy: 0.4007\n",
      "Epoch 23/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9982 - accuracy: 0.6254 - val_loss: 2.2707 - val_accuracy: 0.3936\n",
      "Epoch 24/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9953 - accuracy: 0.6270 - val_loss: 2.3324 - val_accuracy: 0.3578\n",
      "Epoch 25/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9934 - accuracy: 0.6264 - val_loss: 2.2093 - val_accuracy: 0.3857\n",
      "Epoch 26/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9897 - accuracy: 0.6274 - val_loss: 2.2293 - val_accuracy: 0.3523\n",
      "Epoch 27/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9892 - accuracy: 0.6280 - val_loss: 2.1425 - val_accuracy: 0.3787\n",
      "Epoch 28/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9859 - accuracy: 0.6284 - val_loss: 2.1941 - val_accuracy: 0.3811\n",
      "Epoch 29/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9817 - accuracy: 0.6294 - val_loss: 2.1859 - val_accuracy: 0.3855\n",
      "Epoch 30/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9835 - accuracy: 0.6290 - val_loss: 2.2017 - val_accuracy: 0.3783\n",
      "Epoch 31/200\n",
      "175341/175341 [==============================] - 323s 2ms/step - loss: 0.9796 - accuracy: 0.6295 - val_loss: 2.1968 - val_accuracy: 0.3863\n",
      "Epoch 32/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9806 - accuracy: 0.6297 - val_loss: 2.1947 - val_accuracy: 0.3786\n",
      "Epoch 33/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9764 - accuracy: 0.6313 - val_loss: 2.1515 - val_accuracy: 0.3706\n",
      "Epoch 34/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9757 - accuracy: 0.6308 - val_loss: 2.1690 - val_accuracy: 0.3777\n",
      "Epoch 35/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9767 - accuracy: 0.6304 - val_loss: 2.1539 - val_accuracy: 0.3808\n",
      "Epoch 36/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9731 - accuracy: 0.6316 - val_loss: 2.2540 - val_accuracy: 0.3790\n",
      "Epoch 37/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.9753 - accuracy: 0.6305 - val_loss: 2.1218 - val_accuracy: 0.3854\n",
      "Epoch 38/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.9724 - accuracy: 0.6316 - val_loss: 2.1659 - val_accuracy: 0.3700\n",
      "Epoch 39/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9738 - accuracy: 0.6313 - val_loss: 2.0764 - val_accuracy: 0.3776\n",
      "Epoch 40/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9705 - accuracy: 0.6323 - val_loss: 2.1274 - val_accuracy: 0.3666\n",
      "Epoch 41/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9734 - accuracy: 0.6312 - val_loss: 2.0772 - val_accuracy: 0.3529\n",
      "Epoch 42/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9719 - accuracy: 0.6315 - val_loss: 2.1788 - val_accuracy: 0.3705\n",
      "Epoch 43/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9690 - accuracy: 0.6329 - val_loss: 2.1422 - val_accuracy: 0.3709\n",
      "Epoch 44/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9721 - accuracy: 0.6326 - val_loss: 2.1968 - val_accuracy: 0.3767\n",
      "Epoch 45/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.9682 - accuracy: 0.6331 - val_loss: 2.2094 - val_accuracy: 0.3473\n",
      "Epoch 46/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9685 - accuracy: 0.6331 - val_loss: 2.1961 - val_accuracy: 0.3825\n",
      "Epoch 47/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9702 - accuracy: 0.6312 - val_loss: 2.1270 - val_accuracy: 0.3719\n",
      "Epoch 48/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9677 - accuracy: 0.6328 - val_loss: 2.0753 - val_accuracy: 0.3714\n",
      "Epoch 49/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9707 - accuracy: 0.6325 - val_loss: 2.1050 - val_accuracy: 0.3821\n",
      "Epoch 50/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9615 - accuracy: 0.6344 - val_loss: 2.1371 - val_accuracy: 0.3526\n",
      "Epoch 51/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9673 - accuracy: 0.6331 - val_loss: 1.9945 - val_accuracy: 0.3782\n",
      "Epoch 52/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9667 - accuracy: 0.6329 - val_loss: 2.1470 - val_accuracy: 0.3537\n",
      "Epoch 53/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9664 - accuracy: 0.6330 - val_loss: 2.2049 - val_accuracy: 0.3686\n",
      "Epoch 54/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9683 - accuracy: 0.6325 - val_loss: 2.0874 - val_accuracy: 0.3828\n",
      "Epoch 55/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.9636 - accuracy: 0.6334 - val_loss: 2.1302 - val_accuracy: 0.3853\n",
      "Epoch 56/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9650 - accuracy: 0.6341 - val_loss: 2.0171 - val_accuracy: 0.3786\n",
      "Epoch 57/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.9653 - accuracy: 0.6342 - val_loss: 2.1084 - val_accuracy: 0.3677\n",
      "Epoch 58/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 1.0205 - accuracy: 0.6203 - val_loss: 1.2625 - val_accuracy: 0.5864\n",
      "Epoch 59/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 1.1780 - accuracy: 0.5707 - val_loss: 2.3552 - val_accuracy: 0.3970\n",
      "Epoch 60/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 1.0157 - accuracy: 0.6198 - val_loss: 2.3510 - val_accuracy: 0.3471\n",
      "Epoch 61/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9882 - accuracy: 0.6283 - val_loss: 2.1445 - val_accuracy: 0.3384\n",
      "Epoch 62/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9880 - accuracy: 0.6286 - val_loss: 1.2715 - val_accuracy: 0.5889\n",
      "Epoch 63/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 1.0924 - accuracy: 0.5953 - val_loss: 2.2986 - val_accuracy: 0.3949\n",
      "Epoch 64/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 1.0104 - accuracy: 0.6224 - val_loss: 2.1749 - val_accuracy: 0.3834\n",
      "Epoch 65/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 1.1346 - accuracy: 0.5744 - val_loss: 2.0433 - val_accuracy: 0.3977\n",
      "Epoch 66/200\n",
      "175341/175341 [==============================] - 322s 2ms/step - loss: 1.0080 - accuracy: 0.6191 - val_loss: 2.5154 - val_accuracy: 0.4006\n",
      "Epoch 67/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9844 - accuracy: 0.6302 - val_loss: 2.3734 - val_accuracy: 0.3558\n",
      "Epoch 68/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 0.9798 - accuracy: 0.6310 - val_loss: 2.2916 - val_accuracy: 0.3544\n",
      "Epoch 69/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 0.9756 - accuracy: 0.6323 - val_loss: 2.2797 - val_accuracy: 0.3739\n",
      "Epoch 70/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 0.9706 - accuracy: 0.6330 - val_loss: 2.1997 - val_accuracy: 0.3754\n",
      "Epoch 71/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9700 - accuracy: 0.6329 - val_loss: 2.1938 - val_accuracy: 0.3525\n",
      "Epoch 72/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9670 - accuracy: 0.6332 - val_loss: 2.1916 - val_accuracy: 0.3372\n",
      "Epoch 73/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 0.9639 - accuracy: 0.6335 - val_loss: 2.1289 - val_accuracy: 0.3369\n",
      "Epoch 74/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9617 - accuracy: 0.6335 - val_loss: 2.2062 - val_accuracy: 0.3396\n",
      "Epoch 75/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9602 - accuracy: 0.6341 - val_loss: 2.1982 - val_accuracy: 0.3454\n",
      "Epoch 76/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 0.9655 - accuracy: 0.6334 - val_loss: 2.2508 - val_accuracy: 0.3430\n",
      "Epoch 77/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9594 - accuracy: 0.6348 - val_loss: 2.2599 - val_accuracy: 0.3879\n",
      "Epoch 78/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9576 - accuracy: 0.6336 - val_loss: 2.0063 - val_accuracy: 0.3673\n",
      "Epoch 79/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9545 - accuracy: 0.6360 - val_loss: 2.0755 - val_accuracy: 0.3661\n",
      "Epoch 80/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9545 - accuracy: 0.6357 - val_loss: 0.8775 - val_accuracy: 0.6338\n",
      "Epoch 81/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.9090 - accuracy: 0.6476 - val_loss: 0.8728 - val_accuracy: 0.6320\n",
      "Epoch 82/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.9044 - accuracy: 0.6473 - val_loss: 0.8669 - val_accuracy: 0.6399\n",
      "Epoch 83/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.9015 - accuracy: 0.6482 - val_loss: 0.8653 - val_accuracy: 0.6295\n",
      "Epoch 84/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.9001 - accuracy: 0.6495 - val_loss: 0.8911 - val_accuracy: 0.6300\n",
      "Epoch 85/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.8966 - accuracy: 0.6490 - val_loss: 0.8985 - val_accuracy: 0.6223\n",
      "Epoch 86/200\n",
      "175341/175341 [==============================] - 321s 2ms/step - loss: 0.8992 - accuracy: 0.6495 - val_loss: 0.8939 - val_accuracy: 0.6261\n",
      "Epoch 87/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.8977 - accuracy: 0.6501 - val_loss: 0.9347 - val_accuracy: 0.6200\n",
      "Epoch 88/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.8995 - accuracy: 0.6488 - val_loss: 0.8795 - val_accuracy: 0.6240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.8954 - accuracy: 0.6504 - val_loss: 0.8708 - val_accuracy: 0.6509\n",
      "Epoch 90/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.8956 - accuracy: 0.6498 - val_loss: 0.8712 - val_accuracy: 0.6287\n",
      "Epoch 91/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.8921 - accuracy: 0.6512 - val_loss: 0.8675 - val_accuracy: 0.6213\n",
      "Epoch 92/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.8935 - accuracy: 0.6505 - val_loss: 0.8910 - val_accuracy: 0.6388\n",
      "Epoch 93/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.8943 - accuracy: 0.6508 - val_loss: 0.8822 - val_accuracy: 0.6078\n",
      "Epoch 94/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.8923 - accuracy: 0.6508 - val_loss: 0.8817 - val_accuracy: 0.6375\n",
      "Epoch 95/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.8901 - accuracy: 0.6508 - val_loss: 0.8845 - val_accuracy: 0.6118\n",
      "Epoch 96/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.8928 - accuracy: 0.6508 - val_loss: 0.8705 - val_accuracy: 0.6215\n",
      "Epoch 97/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.8928 - accuracy: 0.6509 - val_loss: 0.9124 - val_accuracy: 0.6150\n",
      "Epoch 98/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.8863 - accuracy: 0.6526 - val_loss: 0.8770 - val_accuracy: 0.6255\n",
      "Epoch 99/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.8883 - accuracy: 0.6520 - val_loss: 0.8541 - val_accuracy: 0.6647\n",
      "Epoch 100/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.8902 - accuracy: 0.6500 - val_loss: 0.8727 - val_accuracy: 0.6400\n",
      "Epoch 101/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.8877 - accuracy: 0.6518 - val_loss: 0.8877 - val_accuracy: 0.6229\n",
      "Epoch 102/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.8898 - accuracy: 0.6518 - val_loss: 0.8795 - val_accuracy: 0.6249\n",
      "Epoch 103/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.8885 - accuracy: 0.6525 - val_loss: 0.8831 - val_accuracy: 0.6100\n",
      "Epoch 104/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.8888 - accuracy: 0.6518 - val_loss: 0.9385 - val_accuracy: 0.6060\n",
      "Epoch 105/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.8898 - accuracy: 0.6519 - val_loss: 0.8608 - val_accuracy: 0.6339\n",
      "Epoch 106/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.8880 - accuracy: 0.6520 - val_loss: 0.8955 - val_accuracy: 0.6128\n",
      "Epoch 107/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.8884 - accuracy: 0.6519 - val_loss: 0.8553 - val_accuracy: 0.6519\n",
      "Epoch 108/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.8908 - accuracy: 0.6509 - val_loss: 0.8851 - val_accuracy: 0.6181\n",
      "Epoch 109/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.8846 - accuracy: 0.6527 - val_loss: 0.8592 - val_accuracy: 0.6331\n",
      "Epoch 110/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.8861 - accuracy: 0.6531 - val_loss: 0.8636 - val_accuracy: 0.6312\n",
      "Epoch 111/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.8866 - accuracy: 0.6524 - val_loss: 0.9019 - val_accuracy: 0.6175\n",
      "Epoch 112/200\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 0.8863 - accuracy: 0.6526 - val_loss: 0.8909 - val_accuracy: 0.6241\n",
      "Epoch 113/200\n",
      "175341/175341 [==============================] - 318s 2ms/step - loss: 0.8857 - accuracy: 0.6524 - val_loss: 0.8872 - val_accuracy: 0.6231\n",
      "Epoch 114/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.8867 - accuracy: 0.6526 - val_loss: 0.8915 - val_accuracy: 0.6108\n",
      "Epoch 115/200\n",
      "175341/175341 [==============================] - 319s 2ms/step - loss: 0.8848 - accuracy: 0.6533 - val_loss: 0.8671 - val_accuracy: 0.6265\n",
      "Epoch 116/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.8856 - accuracy: 0.6527 - val_loss: 0.8699 - val_accuracy: 0.6331\n",
      "Epoch 117/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.8835 - accuracy: 0.6536 - val_loss: 0.8683 - val_accuracy: 0.6480\n",
      "Epoch 118/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.8838 - accuracy: 0.6536 - val_loss: 0.8808 - val_accuracy: 0.6078\n",
      "Epoch 119/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.8834 - accuracy: 0.6527 - val_loss: 0.9591 - val_accuracy: 0.6191\n",
      "Epoch 120/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.8836 - accuracy: 0.6533 - val_loss: 0.8858 - val_accuracy: 0.6096\n",
      "Epoch 121/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.8821 - accuracy: 0.6529 - val_loss: 0.8909 - val_accuracy: 0.6095\n",
      "Epoch 122/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.8800 - accuracy: 0.6536 - val_loss: 0.9288 - val_accuracy: 0.6130\n",
      "Epoch 123/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.8843 - accuracy: 0.6534 - val_loss: 0.8712 - val_accuracy: 0.6394\n",
      "Epoch 124/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.8836 - accuracy: 0.6536 - val_loss: 0.9240 - val_accuracy: 0.6021\n",
      "Epoch 125/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9320 - accuracy: 0.6401 - val_loss: 2.2808 - val_accuracy: 0.3708\n",
      "Epoch 126/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9896 - accuracy: 0.6235 - val_loss: 2.4574 - val_accuracy: 0.3290\n",
      "Epoch 127/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.9550 - accuracy: 0.6357 - val_loss: 2.2167 - val_accuracy: 0.3430\n",
      "Epoch 128/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9491 - accuracy: 0.6373 - val_loss: 2.0952 - val_accuracy: 0.3339\n",
      "Epoch 129/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.9463 - accuracy: 0.6373 - val_loss: 2.3325 - val_accuracy: 0.3192\n",
      "Epoch 130/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.9421 - accuracy: 0.6397 - val_loss: 2.3909 - val_accuracy: 0.3614\n",
      "Epoch 131/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9421 - accuracy: 0.6381 - val_loss: 2.2331 - val_accuracy: 0.3859\n",
      "Epoch 132/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.9388 - accuracy: 0.6395 - val_loss: 2.4010 - val_accuracy: 0.3407\n",
      "Epoch 133/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9369 - accuracy: 0.6392 - val_loss: 2.4099 - val_accuracy: 0.3307\n",
      "Epoch 134/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9383 - accuracy: 0.6402 - val_loss: 2.5762 - val_accuracy: 0.3184\n",
      "Epoch 135/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.9374 - accuracy: 0.6403 - val_loss: 2.6257 - val_accuracy: 0.3186\n",
      "Epoch 136/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9342 - accuracy: 0.6402 - val_loss: 2.6499 - val_accuracy: 0.3714\n",
      "Epoch 137/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.9358 - accuracy: 0.6398 - val_loss: 2.1974 - val_accuracy: 0.3348\n",
      "Epoch 138/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.9399 - accuracy: 0.6394 - val_loss: 2.3243 - val_accuracy: 0.3687\n",
      "Epoch 139/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9353 - accuracy: 0.6402 - val_loss: 2.5227 - val_accuracy: 0.3308\n",
      "Epoch 140/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.9363 - accuracy: 0.6403 - val_loss: 2.5553 - val_accuracy: 0.3021\n",
      "Epoch 141/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.9334 - accuracy: 0.6412 - val_loss: 2.5183 - val_accuracy: 0.3103\n",
      "Epoch 142/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.9319 - accuracy: 0.6422 - val_loss: 2.5543 - val_accuracy: 0.3278\n",
      "Epoch 143/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9324 - accuracy: 0.6419 - val_loss: 2.4657 - val_accuracy: 0.3509\n",
      "Epoch 144/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.9309 - accuracy: 0.6416 - val_loss: 2.6023 - val_accuracy: 0.3815\n",
      "Epoch 145/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.9304 - accuracy: 0.6418 - val_loss: 2.6191 - val_accuracy: 0.3116\n",
      "Epoch 146/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.9328 - accuracy: 0.6413 - val_loss: 2.4947 - val_accuracy: 0.3407\n",
      "Epoch 147/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9290 - accuracy: 0.6434 - val_loss: 2.5309 - val_accuracy: 0.3456\n",
      "Epoch 148/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.9307 - accuracy: 0.6425 - val_loss: 2.5431 - val_accuracy: 0.3313\n",
      "Epoch 149/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9305 - accuracy: 0.6424 - val_loss: 2.4840 - val_accuracy: 0.3761\n",
      "Epoch 150/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9294 - accuracy: 0.6424 - val_loss: 2.6290 - val_accuracy: 0.3129\n",
      "Epoch 151/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9266 - accuracy: 0.6431 - val_loss: 2.5632 - val_accuracy: 0.3991\n",
      "Epoch 152/200\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 0.9284 - accuracy: 0.6430 - val_loss: 2.1566 - val_accuracy: 0.3189\n",
      "Epoch 153/200\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 0.9287 - accuracy: 0.6429 - val_loss: 2.7261 - val_accuracy: 0.3414\n",
      "Epoch 154/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9304 - accuracy: 0.6417 - val_loss: 2.5696 - val_accuracy: 0.3390\n",
      "Epoch 155/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9277 - accuracy: 0.6428 - val_loss: 2.6108 - val_accuracy: 0.3211\n",
      "Epoch 156/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9270 - accuracy: 0.6432 - val_loss: 2.5283 - val_accuracy: 0.3900\n",
      "Epoch 157/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9264 - accuracy: 0.6441 - val_loss: 2.6457 - val_accuracy: 0.3566\n",
      "Epoch 158/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9280 - accuracy: 0.6434 - val_loss: 2.5189 - val_accuracy: 0.3677\n",
      "Epoch 159/200\n",
      "175341/175341 [==============================] - 316s 2ms/step - loss: 0.9294 - accuracy: 0.6429 - val_loss: 2.4332 - val_accuracy: 0.3231\n",
      "Epoch 160/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.9282 - accuracy: 0.6432 - val_loss: 2.5231 - val_accuracy: 0.3303\n",
      "Epoch 161/200\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 0.9271 - accuracy: 0.6423 - val_loss: 2.6133 - val_accuracy: 0.3119\n",
      "Epoch 162/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9282 - accuracy: 0.6424 - val_loss: 2.5053 - val_accuracy: 0.3669\n",
      "Epoch 163/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9263 - accuracy: 0.6438 - val_loss: 2.6045 - val_accuracy: 0.3322\n",
      "Epoch 164/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9302 - accuracy: 0.6430 - val_loss: 2.4558 - val_accuracy: 0.3342\n",
      "Epoch 165/200\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 0.9260 - accuracy: 0.6438 - val_loss: 2.5233 - val_accuracy: 0.3169\n",
      "Epoch 166/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9258 - accuracy: 0.6436 - val_loss: 2.4667 - val_accuracy: 0.3270\n",
      "Epoch 167/200\n",
      "175341/175341 [==============================] - 314s 2ms/step - loss: 0.9321 - accuracy: 0.6427 - val_loss: 2.4367 - val_accuracy: 0.3559\n",
      "Epoch 168/200\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 0.9252 - accuracy: 0.6441 - val_loss: 2.4555 - val_accuracy: 0.3338\n",
      "Epoch 169/200\n",
      "175341/175341 [==============================] - 330s 2ms/step - loss: 0.9262 - accuracy: 0.6448 - val_loss: 2.5531 - val_accuracy: 0.3465\n",
      "Epoch 170/200\n",
      "175341/175341 [==============================] - 330s 2ms/step - loss: 0.9255 - accuracy: 0.6444 - val_loss: 2.6282 - val_accuracy: 0.3475\n",
      "Epoch 171/200\n",
      "175341/175341 [==============================] - 336s 2ms/step - loss: 0.9281 - accuracy: 0.6430 - val_loss: 2.5021 - val_accuracy: 0.3392\n",
      "Epoch 172/200\n",
      "175341/175341 [==============================] - 337s 2ms/step - loss: 0.9245 - accuracy: 0.6444 - val_loss: 2.4832 - val_accuracy: 0.3579\n",
      "Epoch 173/200\n",
      "175341/175341 [==============================] - 337s 2ms/step - loss: 0.9236 - accuracy: 0.6443 - val_loss: 2.6470 - val_accuracy: 0.3741\n",
      "Epoch 174/200\n",
      "175341/175341 [==============================] - 334s 2ms/step - loss: 0.9369 - accuracy: 0.6414 - val_loss: 2.2271 - val_accuracy: 0.3401\n",
      "Epoch 175/200\n",
      "175341/175341 [==============================] - 336s 2ms/step - loss: 0.9251 - accuracy: 0.6448 - val_loss: 2.4740 - val_accuracy: 0.3143\n",
      "Epoch 176/200\n",
      "175341/175341 [==============================] - 339s 2ms/step - loss: 0.9225 - accuracy: 0.6440 - val_loss: 2.4304 - val_accuracy: 0.3347\n",
      "Epoch 177/200\n",
      "175341/175341 [==============================] - 315s 2ms/step - loss: 0.9250 - accuracy: 0.6450 - val_loss: 2.4727 - val_accuracy: 0.3321\n",
      "Epoch 178/200\n",
      " 30048/175341 [====>.........................] - ETA: 3:59 - loss: 0.9160 - accuracy: 0.6455"
     ]
    }
   ],
   "source": [
    "model.fit([X,Delta1], Y, epochs=200, validation_data=([x,delta1], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict([x,delta1])\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pred = np.zeros((82332,1), dtype=int)\n",
    "for i in range(0, predictions.shape[0]):\n",
    "    pred[i] = np.where(predictions[i] == np.amax(predictions[i]))\n",
    "\n",
    "pred = to_categorical(pred)\n",
    "z = np.zeros((82332,3), dtype=int)\n",
    "pred = np.append(pred, z, axis=1)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \",accuracy_score(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,classification_report,confusion_matrix\n",
    "print(\"Classification Report: \\n\",classification_report(y,pred))\n",
    "conmat = np.array(confusion_matrix(y.argmax(axis=1), pred.argmax(axis=1)))\n",
    "confusion = pd.DataFrame(conmat, index=['0','1','2','3','4','5','6','7','8','9'],\n",
    "                        columns=[['0','1','2','3','4','5','6','7','8','9']])\n",
    "print (conmat)\n",
    "conmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 41, 64)       256         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 41, 64)       256         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 20, 64)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 20, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 20, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 20, 64)       0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 20, 128)      0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 140)          111440      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 140)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1410        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 113,362\n",
      "Trainable params: 113,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/100\n",
      "175341/175341 [==============================] - 333s 2ms/step - loss: 1.6887 - accuracy: 0.5076 - val_loss: 1.3955 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "175341/175341 [==============================] - 328s 2ms/step - loss: 1.4884 - accuracy: 0.5192 - val_loss: 1.3630 - val_accuracy: 0.6155\n",
      "Epoch 3/100\n",
      "175341/175341 [==============================] - 324s 2ms/step - loss: 1.4753 - accuracy: 0.5212 - val_loss: 1.3456 - val_accuracy: 0.6143\n",
      "Epoch 4/100\n",
      "175341/175341 [==============================] - 340s 2ms/step - loss: 1.4689 - accuracy: 0.5221 - val_loss: 1.3670 - val_accuracy: 0.6144\n",
      "Epoch 5/100\n",
      "175341/175341 [==============================] - 363s 2ms/step - loss: 1.4633 - accuracy: 0.5240 - val_loss: 1.4003 - val_accuracy: 0.6147\n",
      "Epoch 6/100\n",
      "175341/175341 [==============================] - 333s 2ms/step - loss: 1.4597 - accuracy: 0.5251 - val_loss: 1.3583 - val_accuracy: 0.6154\n",
      "Epoch 7/100\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 1.4561 - accuracy: 0.5261 - val_loss: 1.3791 - val_accuracy: 0.6158\n",
      "Epoch 8/100\n",
      "175341/175341 [==============================] - 346s 2ms/step - loss: 1.4531 - accuracy: 0.5265 - val_loss: 1.3385 - val_accuracy: 0.6160\n",
      "Epoch 9/100\n",
      "175341/175341 [==============================] - 345s 2ms/step - loss: 1.4511 - accuracy: 0.5279 - val_loss: 1.3742 - val_accuracy: 0.6160\n",
      "Epoch 10/100\n",
      "175341/175341 [==============================] - 346s 2ms/step - loss: 1.4473 - accuracy: 0.5286 - val_loss: 1.3424 - val_accuracy: 0.6161\n",
      "Epoch 11/100\n",
      "175341/175341 [==============================] - 353s 2ms/step - loss: 1.4449 - accuracy: 0.5289 - val_loss: 1.3574 - val_accuracy: 0.6160\n",
      "Epoch 12/100\n",
      "175341/175341 [==============================] - 325s 2ms/step - loss: 1.4443 - accuracy: 0.5289 - val_loss: 1.3366 - val_accuracy: 0.6168\n",
      "Epoch 13/100\n",
      "175341/175341 [==============================] - 324s 2ms/step - loss: 1.4420 - accuracy: 0.5292 - val_loss: 1.3687 - val_accuracy: 0.6160\n",
      "Epoch 14/100\n",
      "175341/175341 [==============================] - 423s 2ms/step - loss: 1.4418 - accuracy: 0.5292 - val_loss: 1.3223 - val_accuracy: 0.6163\n",
      "Epoch 15/100\n",
      "175341/175341 [==============================] - 411s 2ms/step - loss: 1.4409 - accuracy: 0.5292 - val_loss: 1.3275 - val_accuracy: 0.6165\n",
      "Epoch 16/100\n",
      "175341/175341 [==============================] - 391s 2ms/step - loss: 1.4403 - accuracy: 0.5291 - val_loss: 1.3432 - val_accuracy: 0.6164\n",
      "Epoch 17/100\n",
      "175341/175341 [==============================] - 361s 2ms/step - loss: 1.4399 - accuracy: 0.5295 - val_loss: 1.3478 - val_accuracy: 0.6165\n",
      "Epoch 18/100\n",
      "175341/175341 [==============================] - 340s 2ms/step - loss: 1.4390 - accuracy: 0.5292 - val_loss: 1.3962 - val_accuracy: 0.6161\n",
      "Epoch 19/100\n",
      "175341/175341 [==============================] - 341s 2ms/step - loss: 1.4382 - accuracy: 0.5295 - val_loss: 1.3324 - val_accuracy: 0.6166\n",
      "Epoch 20/100\n",
      "175341/175341 [==============================] - 331s 2ms/step - loss: 1.4375 - accuracy: 0.5296 - val_loss: 1.3460 - val_accuracy: 0.6158\n",
      "Epoch 21/100\n",
      "175341/175341 [==============================] - 387s 2ms/step - loss: 1.4373 - accuracy: 0.5292 - val_loss: 1.3409 - val_accuracy: 0.6165\n",
      "Epoch 22/100\n",
      "175341/175341 [==============================] - 364s 2ms/step - loss: 1.4376 - accuracy: 0.5294 - val_loss: 1.4035 - val_accuracy: 0.6152\n",
      "Epoch 23/100\n",
      "175341/175341 [==============================] - 385s 2ms/step - loss: 1.4370 - accuracy: 0.5298 - val_loss: 1.3531 - val_accuracy: 0.6158\n",
      "Epoch 24/100\n",
      "175341/175341 [==============================] - 349s 2ms/step - loss: 1.4363 - accuracy: 0.5296 - val_loss: 1.3472 - val_accuracy: 0.6162\n",
      "Epoch 25/100\n",
      "175341/175341 [==============================] - 317s 2ms/step - loss: 1.4367 - accuracy: 0.5298 - val_loss: 1.3446 - val_accuracy: 0.6159\n",
      "Epoch 26/100\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 1.4353 - accuracy: 0.5298 - val_loss: 1.3793 - val_accuracy: 0.6163\n",
      "Epoch 27/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4349 - accuracy: 0.5300 - val_loss: 1.3306 - val_accuracy: 0.6160\n",
      "Epoch 28/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4357 - accuracy: 0.5300 - val_loss: 1.3418 - val_accuracy: 0.6162\n",
      "Epoch 29/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4354 - accuracy: 0.5297 - val_loss: 1.3349 - val_accuracy: 0.6164\n",
      "Epoch 30/100\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 1.4353 - accuracy: 0.5293 - val_loss: 1.3441 - val_accuracy: 0.6158\n",
      "Epoch 31/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4346 - accuracy: 0.5299 - val_loss: 1.3237 - val_accuracy: 0.6164\n",
      "Epoch 32/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4347 - accuracy: 0.5299 - val_loss: 1.3425 - val_accuracy: 0.6161\n",
      "Epoch 33/100\n",
      "175341/175341 [==============================] - 313s 2ms/step - loss: 1.4346 - accuracy: 0.5304 - val_loss: 1.3304 - val_accuracy: 0.6161\n",
      "Epoch 34/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4338 - accuracy: 0.5296 - val_loss: 1.3666 - val_accuracy: 0.6162\n",
      "Epoch 35/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4339 - accuracy: 0.5299 - val_loss: 1.3796 - val_accuracy: 0.6161\n",
      "Epoch 36/100\n",
      "175341/175341 [==============================] - 312s 2ms/step - loss: 1.4338 - accuracy: 0.5296 - val_loss: 1.3625 - val_accuracy: 0.6167\n",
      "Epoch 37/100\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 1.4347 - accuracy: 0.5296 - val_loss: 1.3460 - val_accuracy: 0.6168\n",
      "Epoch 38/100\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 1.4343 - accuracy: 0.5301 - val_loss: 1.3319 - val_accuracy: 0.6165\n",
      "Epoch 39/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4347 - accuracy: 0.5299 - val_loss: 1.3722 - val_accuracy: 0.6158\n",
      "Epoch 40/100\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 1.4345 - accuracy: 0.5298 - val_loss: 1.3538 - val_accuracy: 0.6157\n",
      "Epoch 41/100\n",
      "175341/175341 [==============================] - 306s 2ms/step - loss: 1.4347 - accuracy: 0.5296 - val_loss: 1.3146 - val_accuracy: 0.6168\n",
      "Epoch 42/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4344 - accuracy: 0.5298 - val_loss: 1.3830 - val_accuracy: 0.6162\n",
      "Epoch 43/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4341 - accuracy: 0.5299 - val_loss: 1.3366 - val_accuracy: 0.6160\n",
      "Epoch 44/100\n",
      "175341/175341 [==============================] - 306s 2ms/step - loss: 1.4343 - accuracy: 0.5296 - val_loss: 1.3427 - val_accuracy: 0.6162\n",
      "Epoch 45/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4338 - accuracy: 0.5296 - val_loss: 1.3770 - val_accuracy: 0.6159\n",
      "Epoch 46/100\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 1.4340 - accuracy: 0.5298 - val_loss: 1.3581 - val_accuracy: 0.6178\n",
      "Epoch 47/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4339 - accuracy: 0.5301 - val_loss: 1.3533 - val_accuracy: 0.6169\n",
      "Epoch 48/100\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 1.4338 - accuracy: 0.5298 - val_loss: 1.3420 - val_accuracy: 0.6158\n",
      "Epoch 49/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4332 - accuracy: 0.5304 - val_loss: 1.3081 - val_accuracy: 0.6176\n",
      "Epoch 50/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4324 - accuracy: 0.5302 - val_loss: 1.3248 - val_accuracy: 0.6170\n",
      "Epoch 51/100\n",
      "175341/175341 [==============================] - 307s 2ms/step - loss: 1.4321 - accuracy: 0.5302 - val_loss: 1.3840 - val_accuracy: 0.6176\n",
      "Epoch 52/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4325 - accuracy: 0.5300 - val_loss: 1.3290 - val_accuracy: 0.6158\n",
      "Epoch 53/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4320 - accuracy: 0.5301 - val_loss: 1.3873 - val_accuracy: 0.6172\n",
      "Epoch 54/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4328 - accuracy: 0.5303 - val_loss: 1.3207 - val_accuracy: 0.6175\n",
      "Epoch 55/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4326 - accuracy: 0.5303 - val_loss: 1.3857 - val_accuracy: 0.6165\n",
      "Epoch 56/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4321 - accuracy: 0.5303 - val_loss: 1.4208 - val_accuracy: 0.6070\n",
      "Epoch 57/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4317 - accuracy: 0.5302 - val_loss: 1.3731 - val_accuracy: 0.6174\n",
      "Epoch 58/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4313 - accuracy: 0.5305 - val_loss: 1.3410 - val_accuracy: 0.6171\n",
      "Epoch 59/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4319 - accuracy: 0.5300 - val_loss: 1.3959 - val_accuracy: 0.6169\n",
      "Epoch 60/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4320 - accuracy: 0.5306 - val_loss: 1.3404 - val_accuracy: 0.6168\n",
      "Epoch 61/100\n",
      "175341/175341 [==============================] - 308s 2ms/step - loss: 1.4316 - accuracy: 0.5302 - val_loss: 1.3643 - val_accuracy: 0.6181\n",
      "Epoch 62/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4310 - accuracy: 0.5305 - val_loss: 1.3350 - val_accuracy: 0.6162\n",
      "Epoch 63/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4298 - accuracy: 0.5308 - val_loss: 1.3443 - val_accuracy: 0.6171\n",
      "Epoch 64/100\n",
      "175341/175341 [==============================] - 309s 2ms/step - loss: 1.4316 - accuracy: 0.5301 - val_loss: 1.3122 - val_accuracy: 0.6180\n",
      "Epoch 65/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4281 - accuracy: 0.5304 - val_loss: 1.3145 - val_accuracy: 0.6164\n",
      "Epoch 66/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4225 - accuracy: 0.5308 - val_loss: 1.3248 - val_accuracy: 0.6173\n",
      "Epoch 67/100\n",
      "175341/175341 [==============================] - 311s 2ms/step - loss: 1.4187 - accuracy: 0.5315 - val_loss: 1.3461 - val_accuracy: 0.6162\n",
      "Epoch 68/100\n",
      "175341/175341 [==============================] - 310s 2ms/step - loss: 1.4149 - accuracy: 0.5312 - val_loss: 1.3203 - val_accuracy: 0.6169\n",
      "Epoch 69/100\n",
      "175341/175341 [==============================] - 320s 2ms/step - loss: 1.4137 - accuracy: 0.5318 - val_loss: 1.3462 - val_accuracy: 0.6178\n",
      "Epoch 70/100\n",
      "175341/175341 [==============================] - 338s 2ms/step - loss: 1.4132 - accuracy: 0.5316 - val_loss: 1.3194 - val_accuracy: 0.6184\n",
      "Epoch 71/100\n",
      " 59264/175341 [=========>....................] - ETA: 3:24 - loss: 1.4135 - accuracy: 0.5318"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7cb12588dc85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDelta1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/project/lib/python3.5/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Convolution1D, Dense, Dropout, Flatten, MaxPooling1D, concatenate, Reshape\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "lstm_output_size=70\n",
    "Xshape = Input(shape=(41, 1))\n",
    "Delta1shape = Input(shape=(41, 1))\n",
    "\n",
    "x1 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Xshape)\n",
    "x1 = MaxPooling1D(pool_length=(2))(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "   \n",
    "x2 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Delta1shape)\n",
    "x2 = MaxPooling1D(pool_length=(2))(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "\n",
    "output = concatenate([x1, x2])\n",
    "\n",
    "x3 = Bidirectional(LSTM(lstm_output_size, kernel_regularizer = l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer = l2(0.01)))(output)\n",
    "x3 = Dropout(0.1)(x3)\n",
    "x3 = Dense(10, activation=\"softmax\")(x3)\n",
    "\n",
    "model = Model([Xshape, Delta1shape],x3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit([X,Delta1], Y, epochs=100, validation_data=([x,delta1], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 41, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 41, 64)       256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 41, 64)       256         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 20, 64)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 20, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 20, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 20, 64)       0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 20, 128)      0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 140)          111440      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 140)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1410        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 113,362\n",
      "Trainable params: 113,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/100\n",
      "175341/175341 [==============================] - 305s 2ms/step - loss: 1.4000 - accuracy: 0.5269 - val_loss: 1.2912 - val_accuracy: 0.6165\n",
      "Epoch 2/100\n",
      "175341/175341 [==============================] - 303s 2ms/step - loss: 1.3669 - accuracy: 0.5344 - val_loss: 1.2698 - val_accuracy: 0.6194\n",
      "Epoch 3/100\n",
      "175341/175341 [==============================] - 304s 2ms/step - loss: 1.3359 - accuracy: 0.5397 - val_loss: 1.2910 - val_accuracy: 0.5820\n",
      "Epoch 4/100\n",
      "175341/175341 [==============================] - 306s 2ms/step - loss: 1.3233 - accuracy: 0.5439 - val_loss: 1.2598 - val_accuracy: 0.5930\n",
      "Epoch 5/100\n",
      "175341/175341 [==============================] - 304s 2ms/step - loss: 1.3017 - accuracy: 0.5469 - val_loss: 1.2249 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "175341/175341 [==============================] - 305s 2ms/step - loss: 1.1731 - accuracy: 0.5762 - val_loss: 1.0751 - val_accuracy: 0.6179\n",
      "Epoch 7/100\n",
      "175341/175341 [==============================] - 303s 2ms/step - loss: 1.1158 - accuracy: 0.5933 - val_loss: 1.0619 - val_accuracy: 0.6180\n",
      "Epoch 8/100\n",
      "175341/175341 [==============================] - 304s 2ms/step - loss: 1.1046 - accuracy: 0.5947 - val_loss: 1.0762 - val_accuracy: 0.6196\n",
      "Epoch 9/100\n",
      "175341/175341 [==============================] - 305s 2ms/step - loss: 1.0941 - accuracy: 0.5982 - val_loss: 1.0450 - val_accuracy: 0.6239\n",
      "Epoch 10/100\n",
      "175341/175341 [==============================] - 305s 2ms/step - loss: 1.1120 - accuracy: 0.5868 - val_loss: 1.1369 - val_accuracy: 0.5772\n",
      "Epoch 11/100\n",
      "175341/175341 [==============================] - 306s 2ms/step - loss: 1.0769 - accuracy: 0.6006 - val_loss: 1.9979 - val_accuracy: 0.4224\n",
      "Epoch 12/100\n",
      "175341/175341 [==============================] - 306s 2ms/step - loss: 1.0537 - accuracy: 0.6063 - val_loss: 2.5233 - val_accuracy: 0.3944\n",
      "Epoch 13/100\n",
      "175341/175341 [==============================] - 302s 2ms/step - loss: 1.0264 - accuracy: 0.6180 - val_loss: 2.2301 - val_accuracy: 0.4073\n",
      "Epoch 14/100\n",
      "175341/175341 [==============================] - 298s 2ms/step - loss: 1.0143 - accuracy: 0.6210 - val_loss: 2.1383 - val_accuracy: 0.4005\n",
      "Epoch 15/100\n",
      "175341/175341 [==============================] - 299s 2ms/step - loss: 1.0087 - accuracy: 0.6238 - val_loss: 2.2058 - val_accuracy: 0.3864\n",
      "Epoch 16/100\n",
      "175341/175341 [==============================] - 301s 2ms/step - loss: 1.0055 - accuracy: 0.6226 - val_loss: 2.2078 - val_accuracy: 0.3769\n",
      "Epoch 17/100\n",
      "175341/175341 [==============================] - 302s 2ms/step - loss: 1.0016 - accuracy: 0.6240 - val_loss: 2.2561 - val_accuracy: 0.3849\n",
      "Epoch 18/100\n",
      "175341/175341 [==============================] - 304s 2ms/step - loss: 0.9947 - accuracy: 0.6262 - val_loss: 2.2244 - val_accuracy: 0.3826\n",
      "Epoch 19/100\n",
      "175341/175341 [==============================] - 304s 2ms/step - loss: 0.9940 - accuracy: 0.6269 - val_loss: 2.1999 - val_accuracy: 0.3884\n",
      "Epoch 20/100\n",
      "175341/175341 [==============================] - 296s 2ms/step - loss: 0.9910 - accuracy: 0.6257 - val_loss: 2.1941 - val_accuracy: 0.3912\n",
      "Epoch 21/100\n",
      "175341/175341 [==============================] - 296s 2ms/step - loss: 0.9880 - accuracy: 0.6278 - val_loss: 2.1156 - val_accuracy: 0.3845\n",
      "Epoch 22/100\n",
      "175341/175341 [==============================] - 297s 2ms/step - loss: 0.9877 - accuracy: 0.6273 - val_loss: 2.1094 - val_accuracy: 0.3773\n",
      "Epoch 23/100\n",
      "175341/175341 [==============================] - 297s 2ms/step - loss: 0.9887 - accuracy: 0.6271 - val_loss: 2.0672 - val_accuracy: 0.3847\n",
      "Epoch 24/100\n",
      "175341/175341 [==============================] - 297s 2ms/step - loss: 0.9871 - accuracy: 0.6277 - val_loss: 2.0647 - val_accuracy: 0.3853\n",
      "Epoch 25/100\n",
      "175341/175341 [==============================] - 296s 2ms/step - loss: 0.9821 - accuracy: 0.6288 - val_loss: 2.1074 - val_accuracy: 0.3863\n",
      "Epoch 26/100\n",
      "175341/175341 [==============================] - 298s 2ms/step - loss: 0.9835 - accuracy: 0.6279 - val_loss: 2.1332 - val_accuracy: 0.3888\n",
      "Epoch 27/100\n",
      "175341/175341 [==============================] - 298s 2ms/step - loss: 0.9839 - accuracy: 0.6293 - val_loss: 2.1199 - val_accuracy: 0.3913\n",
      "Epoch 28/100\n",
      "175341/175341 [==============================] - 297s 2ms/step - loss: 0.9796 - accuracy: 0.6294 - val_loss: 2.2476 - val_accuracy: 0.3565\n",
      "Epoch 29/100\n",
      "175341/175341 [==============================] - 296s 2ms/step - loss: 0.9825 - accuracy: 0.6280 - val_loss: 2.2345 - val_accuracy: 0.3725\n",
      "Epoch 30/100\n",
      "175341/175341 [==============================] - 296s 2ms/step - loss: 0.9780 - accuracy: 0.6300 - val_loss: 2.1742 - val_accuracy: 0.3699\n",
      "Epoch 31/100\n",
      "175341/175341 [==============================] - 297s 2ms/step - loss: 0.9924 - accuracy: 0.6267 - val_loss: 1.2755 - val_accuracy: 0.5853\n",
      "Epoch 32/100\n",
      "175341/175341 [==============================] - 297s 2ms/step - loss: 1.1499 - accuracy: 0.5616 - val_loss: 1.2523 - val_accuracy: 0.5837\n",
      "Epoch 33/100\n",
      "175341/175341 [==============================] - 298s 2ms/step - loss: 1.1307 - accuracy: 0.5898 - val_loss: 2.2967 - val_accuracy: 0.4043\n",
      "Epoch 34/100\n",
      "175341/175341 [==============================] - 298s 2ms/step - loss: 0.9964 - accuracy: 0.6261 - val_loss: 2.1388 - val_accuracy: 0.3653\n",
      "Epoch 35/100\n",
      "175341/175341 [==============================] - 286s 2ms/step - loss: 0.9841 - accuracy: 0.6288 - val_loss: 2.1372 - val_accuracy: 0.3781\n",
      "Epoch 36/100\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 0.9830 - accuracy: 0.6293 - val_loss: 2.1853 - val_accuracy: 0.3375\n",
      "Epoch 37/100\n",
      "175341/175341 [==============================] - 287s 2ms/step - loss: 0.9790 - accuracy: 0.6305 - val_loss: 2.0650 - val_accuracy: 0.3695\n",
      "Epoch 38/100\n",
      "175341/175341 [==============================] - 287s 2ms/step - loss: 0.9746 - accuracy: 0.6315 - val_loss: 2.0509 - val_accuracy: 0.3845\n",
      "Epoch 39/100\n",
      "175341/175341 [==============================] - 287s 2ms/step - loss: 0.9754 - accuracy: 0.6316 - val_loss: 2.1630 - val_accuracy: 0.3667\n",
      "Epoch 40/100\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 0.9700 - accuracy: 0.6324 - val_loss: 2.1281 - val_accuracy: 0.3526\n",
      "Epoch 41/100\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 0.9723 - accuracy: 0.6331 - val_loss: 2.2755 - val_accuracy: 0.3460\n",
      "Epoch 42/100\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 0.9683 - accuracy: 0.6331 - val_loss: 2.1143 - val_accuracy: 0.3508\n",
      "Epoch 43/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.9702 - accuracy: 0.6325 - val_loss: 2.1628 - val_accuracy: 0.3395\n",
      "Epoch 44/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 0.9676 - accuracy: 0.6335 - val_loss: 2.0755 - val_accuracy: 0.3494\n",
      "Epoch 45/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.9633 - accuracy: 0.6344 - val_loss: 2.0136 - val_accuracy: 0.3402\n",
      "Epoch 46/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.9640 - accuracy: 0.6351 - val_loss: 2.1357 - val_accuracy: 0.3323\n",
      "Epoch 47/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9621 - accuracy: 0.6341 - val_loss: 2.0965 - val_accuracy: 0.3862\n",
      "Epoch 48/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.9660 - accuracy: 0.6338 - val_loss: 2.1664 - val_accuracy: 0.3464\n",
      "Epoch 49/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 0.9617 - accuracy: 0.6339 - val_loss: 2.1626 - val_accuracy: 0.3490\n",
      "Epoch 50/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.9655 - accuracy: 0.6336 - val_loss: 2.1796 - val_accuracy: 0.3495\n",
      "Epoch 51/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.9563 - accuracy: 0.6357 - val_loss: 2.1277 - val_accuracy: 0.3514\n",
      "Epoch 52/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.9589 - accuracy: 0.6349 - val_loss: 2.1530 - val_accuracy: 0.3515\n",
      "Epoch 53/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.9675 - accuracy: 0.6322 - val_loss: 2.1401 - val_accuracy: 0.3478\n",
      "Epoch 54/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 0.9558 - accuracy: 0.6345 - val_loss: 2.1192 - val_accuracy: 0.3408\n",
      "Epoch 55/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 1.0800 - accuracy: 0.6022 - val_loss: 1.0290 - val_accuracy: 0.6261\n",
      "Epoch 56/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 1.0631 - accuracy: 0.6013 - val_loss: 2.4801 - val_accuracy: 0.3936\n",
      "Epoch 57/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 1.0096 - accuracy: 0.6216 - val_loss: 2.2518 - val_accuracy: 0.3800\n",
      "Epoch 58/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.9645 - accuracy: 0.6343 - val_loss: 1.8947 - val_accuracy: 0.3507\n",
      "Epoch 59/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9602 - accuracy: 0.6347 - val_loss: 1.8808 - val_accuracy: 0.3806\n",
      "Epoch 60/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.9578 - accuracy: 0.6355 - val_loss: 1.9431 - val_accuracy: 0.3424\n",
      "Epoch 61/100\n",
      "175341/175341 [==============================] - 293s 2ms/step - loss: 0.9758 - accuracy: 0.6306 - val_loss: 1.2627 - val_accuracy: 0.5775\n",
      "Epoch 62/100\n",
      "175341/175341 [==============================] - 293s 2ms/step - loss: 1.0007 - accuracy: 0.6174 - val_loss: 2.2404 - val_accuracy: 0.3471\n",
      "Epoch 63/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 0.9585 - accuracy: 0.6341 - val_loss: 2.0669 - val_accuracy: 0.3576\n",
      "Epoch 64/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9578 - accuracy: 0.6346 - val_loss: 2.1980 - val_accuracy: 0.3536\n",
      "Epoch 65/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9603 - accuracy: 0.6339 - val_loss: 0.9546 - val_accuracy: 0.5944\n",
      "Epoch 66/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9329 - accuracy: 0.6403 - val_loss: 0.8941 - val_accuracy: 0.6123\n",
      "Epoch 67/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 0.9088 - accuracy: 0.6461 - val_loss: 0.8857 - val_accuracy: 0.6292\n",
      "Epoch 68/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9022 - accuracy: 0.6483 - val_loss: 0.8771 - val_accuracy: 0.6312\n",
      "Epoch 69/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9037 - accuracy: 0.6481 - val_loss: 0.8714 - val_accuracy: 0.6169\n",
      "Epoch 70/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.9003 - accuracy: 0.6492 - val_loss: 0.8735 - val_accuracy: 0.6235\n",
      "Epoch 71/100\n",
      "175341/175341 [==============================] - 291s 2ms/step - loss: 0.8990 - accuracy: 0.6491 - val_loss: 0.8669 - val_accuracy: 0.6258\n",
      "Epoch 72/100\n",
      "175341/175341 [==============================] - 293s 2ms/step - loss: 0.8956 - accuracy: 0.6497 - val_loss: 0.8723 - val_accuracy: 0.6205\n",
      "Epoch 73/100\n",
      "175341/175341 [==============================] - 293s 2ms/step - loss: 0.8942 - accuracy: 0.6495 - val_loss: 0.8383 - val_accuracy: 0.6515\n",
      "Epoch 74/100\n",
      "175341/175341 [==============================] - 293s 2ms/step - loss: 0.8930 - accuracy: 0.6504 - val_loss: 0.8685 - val_accuracy: 0.6230\n",
      "Epoch 75/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.8944 - accuracy: 0.6509 - val_loss: 0.8598 - val_accuracy: 0.6237\n",
      "Epoch 76/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8935 - accuracy: 0.6509 - val_loss: 0.8624 - val_accuracy: 0.6139\n",
      "Epoch 77/100\n",
      "175341/175341 [==============================] - 295s 2ms/step - loss: 0.8927 - accuracy: 0.6498 - val_loss: 0.8642 - val_accuracy: 0.6231\n",
      "Epoch 78/100\n",
      "175341/175341 [==============================] - 292s 2ms/step - loss: 0.8913 - accuracy: 0.6507 - val_loss: 0.8448 - val_accuracy: 0.6444\n",
      "Epoch 79/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8927 - accuracy: 0.6502 - val_loss: 0.8613 - val_accuracy: 0.6376\n",
      "Epoch 80/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8891 - accuracy: 0.6512 - val_loss: 0.8631 - val_accuracy: 0.6211\n",
      "Epoch 81/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8897 - accuracy: 0.6516 - val_loss: 0.8502 - val_accuracy: 0.6324\n",
      "Epoch 82/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8905 - accuracy: 0.6508 - val_loss: 0.8623 - val_accuracy: 0.6200\n",
      "Epoch 83/100\n",
      "175341/175341 [==============================] - 295s 2ms/step - loss: 0.8899 - accuracy: 0.6505 - val_loss: 0.8995 - val_accuracy: 0.6264\n",
      "Epoch 84/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8880 - accuracy: 0.6516 - val_loss: 0.8740 - val_accuracy: 0.6116\n",
      "Epoch 85/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8879 - accuracy: 0.6511 - val_loss: 0.9013 - val_accuracy: 0.6031\n",
      "Epoch 86/100\n",
      "175341/175341 [==============================] - 295s 2ms/step - loss: 0.8879 - accuracy: 0.6527 - val_loss: 0.8511 - val_accuracy: 0.6286\n",
      "Epoch 87/100\n",
      "175341/175341 [==============================] - 294s 2ms/step - loss: 0.8886 - accuracy: 0.6510 - val_loss: 0.8544 - val_accuracy: 0.6244\n",
      "Epoch 88/100\n",
      "175341/175341 [==============================] - 295s 2ms/step - loss: 0.8885 - accuracy: 0.6519 - val_loss: 0.8656 - val_accuracy: 0.6193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.8875 - accuracy: 0.6515 - val_loss: 0.8605 - val_accuracy: 0.6087\n",
      "Epoch 90/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.8890 - accuracy: 0.6517 - val_loss: 0.8452 - val_accuracy: 0.6369\n",
      "Epoch 91/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.8857 - accuracy: 0.6522 - val_loss: 0.8849 - val_accuracy: 0.6210\n",
      "Epoch 92/100\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 0.8874 - accuracy: 0.6515 - val_loss: 0.8720 - val_accuracy: 0.6237\n",
      "Epoch 93/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.8861 - accuracy: 0.6528 - val_loss: 0.8712 - val_accuracy: 0.6250\n",
      "Epoch 94/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.8899 - accuracy: 0.6521 - val_loss: 0.8638 - val_accuracy: 0.6258\n",
      "Epoch 95/100\n",
      "175341/175341 [==============================] - 290s 2ms/step - loss: 0.8878 - accuracy: 0.6524 - val_loss: 0.8808 - val_accuracy: 0.6271\n",
      "Epoch 96/100\n",
      "175341/175341 [==============================] - 288s 2ms/step - loss: 0.8882 - accuracy: 0.6505 - val_loss: 0.8689 - val_accuracy: 0.6163\n",
      "Epoch 97/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.8864 - accuracy: 0.6523 - val_loss: 0.8726 - val_accuracy: 0.6192\n",
      "Epoch 98/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.8872 - accuracy: 0.6520 - val_loss: 0.8801 - val_accuracy: 0.6293\n",
      "Epoch 99/100\n",
      "175341/175341 [==============================] - 289s 2ms/step - loss: 0.8933 - accuracy: 0.6499 - val_loss: 0.8620 - val_accuracy: 0.6226\n",
      "Epoch 100/100\n",
      "175341/175341 [==============================] - 293s 2ms/step - loss: 0.8839 - accuracy: 0.6525 - val_loss: 0.8607 - val_accuracy: 0.6210\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Convolution1D, Dense, Dropout, Flatten, MaxPooling1D, concatenate, Reshape\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "lstm_output_size=70\n",
    "Xshape = Input(shape=(41, 1))\n",
    "Delta1shape = Input(shape=(41, 1))\n",
    "\n",
    "x1 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Xshape)\n",
    "x1 = MaxPooling1D(pool_length=(2))(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "   \n",
    "x2 = Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\")(Delta1shape)\n",
    "x2 = MaxPooling1D(pool_length=(2))(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "\n",
    "output = concatenate([x1, x2])\n",
    "\n",
    "x3 = Bidirectional(LSTM(lstm_output_size))(output)\n",
    "x3 = Dropout(0.1)(x3)\n",
    "x3 = Dense(10, activation=\"softmax\")(x3)\n",
    "\n",
    "model = Model([Xshape, Delta1shape],x3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit([X,Delta1], Y, epochs=100, validation_data=([x,delta1], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict([x,delta1])\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pred = np.zeros((82332,1), dtype=int)\n",
    "for i in range(0, predictions.shape[0]):\n",
    "    pred[i] = np.where(predictions[i] == np.amax(predictions[i]))\n",
    "pred = to_categorical(pred)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6210222027887091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika/.virtualenvs/project/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       677\n",
      "           1       1.00      0.00      0.00       583\n",
      "           2       0.35      0.01      0.01      4089\n",
      "           3       0.27      0.78      0.40     11132\n",
      "           4       0.23      0.15      0.18      6062\n",
      "           5       1.00      0.96      0.98     18871\n",
      "           6       0.85      0.60      0.70     37000\n",
      "           7       0.74      0.37      0.49      3496\n",
      "           8       0.00      0.00      0.00       378\n",
      "           9       0.00      0.00      0.00        44\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     82332\n",
      "   macro avg       0.44      0.29      0.28     82332\n",
      "weighted avg       0.72      0.62      0.63     82332\n",
      " samples avg       0.62      0.62      0.62     82332\n",
      "\n",
      "[[    0     0     3   630     1     0    10    33     0     0]\n",
      " [    0     1     6   528     2     0    13    33     0     0]\n",
      " [    0     0    23  3478   134    14   310   130     0     0]\n",
      " [    0     0    16  8655   168     1  2155   137     0     0]\n",
      " [    0     0     5  4134   918     0   944    61     0     0]\n",
      " [    0     0     2   427   105 18143   189     5     0     0]\n",
      " [    0     0    10 12186  2652     4 22108    40     0     0]\n",
      " [    0     0     1  1838    15     8   352  1282     0     0]\n",
      " [    0     0     0   220    79    10    54    15     0     0]\n",
      " [    0     0     0    22     4     0    18     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros((82332,2), dtype=int)\n",
    "pred = np.append(pred, z, axis=1)\n",
    "\n",
    "pred.shape\n",
    "\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y,pred))\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix,classification_report,confusion_matrix\n",
    "print(\"Classification Report: \\n\",classification_report(y,pred))\n",
    "conmat = np.array(confusion_matrix(y.argmax(axis=1), pred.argmax(axis=1)))\n",
    "confusion = pd.DataFrame(conmat, index=['0','1','2','3','4','5','6','7','8','9'],\n",
    "                        columns=[['0','1','2','3','4','5','6','7','8','9']])\n",
    "print (conmat)\n",
    "conmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/200\n",
      "175341/175341 [==============================] - 181s 1ms/step - loss: 1.3443 - accuracy: 0.5405 - val_loss: 1.2772 - val_accuracy: 0.5997\n",
      "Epoch 2/200\n",
      "175341/175341 [==============================] - 168s 959us/step - loss: 1.3282 - accuracy: 0.5460 - val_loss: 1.2803 - val_accuracy: 0.5933\n",
      "Epoch 3/200\n",
      "175341/175341 [==============================] - 169s 963us/step - loss: 1.3220 - accuracy: 0.5477 - val_loss: 1.2852 - val_accuracy: 0.5870\n",
      "Epoch 4/200\n",
      "175341/175341 [==============================] - 191s 1ms/step - loss: 1.3181 - accuracy: 0.5491 - val_loss: 1.2878 - val_accuracy: 0.5891\n",
      "Epoch 5/200\n",
      "175341/175341 [==============================] - 185s 1ms/step - loss: 1.3152 - accuracy: 0.5501 - val_loss: 1.2773 - val_accuracy: 0.5873\n",
      "Epoch 6/200\n",
      "175341/175341 [==============================] - 196s 1ms/step - loss: 1.2621 - accuracy: 0.5568 - val_loss: 1.1190 - val_accuracy: 0.6173\n",
      "Epoch 7/200\n",
      "175341/175341 [==============================] - 173s 989us/step - loss: 1.0816 - accuracy: 0.6028 - val_loss: 1.0374 - val_accuracy: 0.6040\n",
      "Epoch 8/200\n",
      "175341/175341 [==============================] - 173s 988us/step - loss: 1.1019 - accuracy: 0.5968 - val_loss: 1.0276 - val_accuracy: 0.6231\n",
      "Epoch 9/200\n",
      "175341/175341 [==============================] - 173s 986us/step - loss: 1.1057 - accuracy: 0.5927 - val_loss: 1.0352 - val_accuracy: 0.6272\n",
      "Epoch 10/200\n",
      "175341/175341 [==============================] - 188s 1ms/step - loss: 1.0799 - accuracy: 0.6027 - val_loss: 1.0439 - val_accuracy: 0.6250\n",
      "Epoch 11/200\n",
      "175341/175341 [==============================] - 195s 1ms/step - loss: 1.0775 - accuracy: 0.6030 - val_loss: 1.0642 - val_accuracy: 0.6199\n",
      "Epoch 12/200\n",
      "175341/175341 [==============================] - 225s 1ms/step - loss: 1.0805 - accuracy: 0.5992 - val_loss: 1.0573 - val_accuracy: 0.6154\n",
      "Epoch 13/200\n",
      "175341/175341 [==============================] - 205s 1ms/step - loss: 1.0844 - accuracy: 0.5993 - val_loss: 1.0388 - val_accuracy: 0.6237\n",
      "Epoch 14/200\n",
      "175341/175341 [==============================] - 201s 1ms/step - loss: 1.0859 - accuracy: 0.5973 - val_loss: 1.7069 - val_accuracy: 0.3995\n",
      "Epoch 15/200\n",
      "175341/175341 [==============================] - 207s 1ms/step - loss: 1.0418 - accuracy: 0.6136 - val_loss: 2.1069 - val_accuracy: 0.3976\n",
      "Epoch 16/200\n",
      "175341/175341 [==============================] - 179s 1ms/step - loss: 1.0323 - accuracy: 0.6159 - val_loss: 2.2005 - val_accuracy: 0.3741\n",
      "Epoch 17/200\n",
      "175341/175341 [==============================] - 179s 1ms/step - loss: 1.0220 - accuracy: 0.6178 - val_loss: 2.1490 - val_accuracy: 0.4046\n",
      "Epoch 18/200\n",
      "175341/175341 [==============================] - 175s 995us/step - loss: 1.0065 - accuracy: 0.6226 - val_loss: 1.9528 - val_accuracy: 0.3825\n",
      "Epoch 19/200\n",
      "175341/175341 [==============================] - 186s 1ms/step - loss: 1.0018 - accuracy: 0.6248 - val_loss: 2.0567 - val_accuracy: 0.3828\n",
      "Epoch 20/200\n",
      "175341/175341 [==============================] - 183s 1ms/step - loss: 0.9962 - accuracy: 0.6269 - val_loss: 2.0444 - val_accuracy: 0.3982\n",
      "Epoch 21/200\n",
      "175341/175341 [==============================] - 182s 1ms/step - loss: 0.9909 - accuracy: 0.6280 - val_loss: 1.9730 - val_accuracy: 0.3848\n",
      "Epoch 22/200\n",
      "175341/175341 [==============================] - 204s 1ms/step - loss: 0.9899 - accuracy: 0.6278 - val_loss: 2.1509 - val_accuracy: 0.3875\n",
      "Epoch 23/200\n",
      "175341/175341 [==============================] - 194s 1ms/step - loss: 0.9886 - accuracy: 0.6279 - val_loss: 2.0840 - val_accuracy: 0.3759\n",
      "Epoch 24/200\n",
      "175341/175341 [==============================] - 168s 956us/step - loss: 0.9873 - accuracy: 0.6281 - val_loss: 2.0855 - val_accuracy: 0.3855\n",
      "Epoch 25/200\n",
      "175341/175341 [==============================] - 201s 1ms/step - loss: 0.9847 - accuracy: 0.6284 - val_loss: 2.0739 - val_accuracy: 0.3861\n",
      "Epoch 26/200\n",
      "175341/175341 [==============================] - 183s 1ms/step - loss: 0.9847 - accuracy: 0.6293 - val_loss: 2.1001 - val_accuracy: 0.3847\n",
      "Epoch 27/200\n",
      "175341/175341 [==============================] - 169s 966us/step - loss: 0.9863 - accuracy: 0.6281 - val_loss: 2.1487 - val_accuracy: 0.3820\n",
      "Epoch 28/200\n",
      "175341/175341 [==============================] - 184s 1ms/step - loss: 0.9803 - accuracy: 0.6295 - val_loss: 2.1533 - val_accuracy: 0.3598\n",
      "Epoch 29/200\n",
      "175341/175341 [==============================] - 225s 1ms/step - loss: 0.9810 - accuracy: 0.6295 - val_loss: 2.1214 - val_accuracy: 0.3823\n",
      "Epoch 30/200\n",
      "175341/175341 [==============================] - 176s 1ms/step - loss: 0.9775 - accuracy: 0.6306 - val_loss: 2.2582 - val_accuracy: 0.3815\n",
      "Epoch 31/200\n",
      "175341/175341 [==============================] - 176s 1ms/step - loss: 1.1420 - accuracy: 0.5910 - val_loss: 1.5939 - val_accuracy: 0.3535\n",
      "Epoch 32/200\n",
      "175341/175341 [==============================] - 191s 1ms/step - loss: 1.0797 - accuracy: 0.5961 - val_loss: 2.3482 - val_accuracy: 0.3618\n",
      "Epoch 33/200\n",
      "175341/175341 [==============================] - 191s 1ms/step - loss: 1.0333 - accuracy: 0.6113 - val_loss: 2.3573 - val_accuracy: 0.3782\n",
      "Epoch 34/200\n",
      "175341/175341 [==============================] - 168s 958us/step - loss: 0.9973 - accuracy: 0.6236 - val_loss: 2.1306 - val_accuracy: 0.3289\n",
      "Epoch 35/200\n",
      "175341/175341 [==============================] - 169s 964us/step - loss: 0.9836 - accuracy: 0.6275 - val_loss: 2.2465 - val_accuracy: 0.3746\n",
      "Epoch 36/200\n",
      "175341/175341 [==============================] - 172s 983us/step - loss: 0.9888 - accuracy: 0.6274 - val_loss: 1.7361 - val_accuracy: 0.3955\n",
      "Epoch 37/200\n",
      "175341/175341 [==============================] - 170s 969us/step - loss: 1.1037 - accuracy: 0.5971 - val_loss: 2.2167 - val_accuracy: 0.3769\n",
      "Epoch 38/200\n",
      "175341/175341 [==============================] - 182s 1ms/step - loss: 0.9944 - accuracy: 0.6263 - val_loss: 2.2510 - val_accuracy: 0.3836\n",
      "Epoch 39/200\n",
      "175341/175341 [==============================] - 209s 1ms/step - loss: 0.9959 - accuracy: 0.6274 - val_loss: 2.1704 - val_accuracy: 0.3721\n",
      "Epoch 40/200\n",
      "175341/175341 [==============================] - 173s 984us/step - loss: 0.9914 - accuracy: 0.6291 - val_loss: 2.2598 - val_accuracy: 0.3591\n",
      "Epoch 41/200\n",
      "175341/175341 [==============================] - 185s 1ms/step - loss: 0.9835 - accuracy: 0.6296 - val_loss: 2.1984 - val_accuracy: 0.3499\n",
      "Epoch 42/200\n",
      "175341/175341 [==============================] - 178s 1ms/step - loss: 0.9820 - accuracy: 0.6306 - val_loss: 2.0768 - val_accuracy: 0.3593\n",
      "Epoch 43/200\n",
      "175341/175341 [==============================] - ETA: 0s - loss: 0.9809 - accuracy: 0.63 - 194s 1ms/step - loss: 0.9809 - accuracy: 0.6313 - val_loss: 2.1272 - val_accuracy: 0.3754\n",
      "Epoch 44/200\n",
      "175341/175341 [==============================] - 185s 1ms/step - loss: 0.9779 - accuracy: 0.6311 - val_loss: 2.0760 - val_accuracy: 0.3766\n",
      "Epoch 45/200\n",
      " 74176/175341 [===========>..................] - ETA: 1:33 - loss: 0.9771 - accuracy: 0.6307"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-b3afaf624b5d>\", line 1, in <module>\n",
      "    history = model.fit([X,Delta1], Y, epochs=200, validation_data=([x,delta1], y))\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/engine/training.py\", line 1239, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/keras/engine/training_arrays.py\", line 196, in fit_loop\n",
      "    outs = fit_function(ins_batch)\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\", line 3251, in __call__\n",
      "    inputs = nest.flatten(inputs)\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/util/nest.py\", line 241, in flatten\n",
      "    return _pywrap_tensorflow.Flatten(structure, expand_composites)\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 2562, in Flatten\n",
      "    return _pywrap_tensorflow_internal.Flatten(nested, expand_composites)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ritika/.virtualenvs/pythree/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "history = model.fit([X,Delta1], Y, epochs=200, validation_data=([x,delta1], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
